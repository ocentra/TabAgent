{"version":3,"file":"background.js","mappings":";;;;;;;;;;;;;;;;AAAqE;AACpB;AACjD;AACA,MAAM,wEAAwB;AAC9B;AACA;AACA;AACA,cAAc,8DAAc;AAC5B;;;;;;;;;;;;;;;;;ACR+C;AAC/C;AACA,kBAAkB,cAAc;AAChC;AACA,wHAAwH,6DAAa;AACrI;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;;;;;;;;;;;;;;;;ACXA;AACA;AACA;AACA,GAAG;AACH;;;;;;;;;;;;;;;;;ACJiD;AACjD;AACA,yEAAyE,8DAAc;AACvF;;;;;;;;;;;;;;;;ACHA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;;;;;;;;;;;;;;;;ACNA;AACA;AACA,yFAAyF;AACzF,IAAI;AACJ;AACA;AACA,GAAG;AACH;;;;;;;;;;;;;;;;ACPA;AACA;AACA;;;;;;;;;;;;;;;;ACFA;AACA;AACA;AACA,GAAG;AACH;;;;;;;;;;;;;;;;;ACJkC;AAClC;AACA,kBAAkB,sDAAO;AACzB;AACA;AACA;AACA,oBAAoB,sDAAO;AAC3B;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;ACVkC;AACS;AAC3C;AACA,UAAU,2DAAW;AACrB,qBAAqB,sDAAO;AAC5B;;;;;;;;;;;;;;;;ACLA;AACA;;AAEA;AACA;AACA,IAAI;AACJ;AACA,GAAG;AACH;;;;;;;;;;;;;;;;;;;;ACRiD;AACA;AACI;AACd;AACvC;AACA;AACA;AACA,uBAAuB,gEAAgB;AACvC;AACA;AACA;AACA;AACA;AACA;AACA,aAAa,yDAAS,eAAe,8DAAc;AACnD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK,GAAG,8DAAc;AACtB,GAAG;AACH;;;;;;;;;;;;;;;;ACzBA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;AC5CiD;AACI;AAC9C;AACP;AACA;AACA;AACA;AACA;AACA,2BAA2B,6DAAmB;AAC9C,oBAAoB,2BAA2B;AAC/C;AACA;AACA,sBAAsB,kEAAe;AACrC;AACA;AACA;AACA;AACA,+BAA+B,6DAAmB;AAClD,oBAAoB,+BAA+B;AACnD;AACA;AACA;AACA;AACA,sBAAsB,kEAAe;AACrC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,kEAAe;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;ACrDoD;AAC7C;AACP;AACA;AACA;AACA;AACA,0BAA0B,gEAAsB;AAChD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;AChBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACO,6BAA6B;AAC7B;AACP;AACA;AACA;AACO;AACP;AACA;AACA;AACO;AACP;AACA;AACA;AACO,mCAAmC;AACnC;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACrDO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,YAAY;AAChC;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP,+BAA+B,OAAO;AACtC;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACO;AACP;AACA,8CAA8C,iBAAiB;AAC/D;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;AC5GqF;AAClC;AACI;;AAEvD;AACA;AACA;AACA;AACO;AACP;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB,oEAAuB;AACxC,gBAAgB,gEAAY;;AAE5B;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,YAAY;AACZ;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,YAAY,kBAAkB;AAC9B;AACO;AACP,YAAY,oEAAuB;AACnC,eAAe,gEAAY;AAC3B;AACA;AACA;AACA,KAAK;AACL,IAAI;AACJ,WAAW,4DAAsB;AACjC;AACA;;AAEA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA,KAAK;AACL;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mDAAmD,2DAAqB;AACxE;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL;AACA;AACA;AACA,KAAK;AACL,GAAG;AACH;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;;AAEA;AACA;AACA,aAAa,SAAS;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yEAAyE,2DAAqB;AAC9F;AACA;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,GAAG;AACH;AACA;AACA;AACA,MAAM,mDAAS;AACf;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA,KAAK;AACL,IAAI;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;AChQ0C;;AAE1C;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA,iBAAiB,2CAAS;AAC1B;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B;AAC5B,gDAAgD;AAChD;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;ACzCwC;AACgC;;AAExE;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA,eAAe,qDAAW;AAC1B;AACA;AACA,8BAA8B;AAC9B,sBAAsB;;AAEtB,mBAAmB;;AAEnB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA,QAAQ;AACR;AACA;AACA,KAAK;AACL,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,UAAU,kEAAQ;AAClB;AACA;AACA,SAAS,yBAAyB;AAClC,OAAO;AACP;AACA;AACA,GAAG;AACH;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,2EAAiB;AAC5B;AACA;;;;;;;;;;;;;;;;;;ACxFiH;AACzC;AACF;AACtE;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,qDAAW;;AAE1B;AACA;AACA;AACA;AACA;AACA,eAAe,2DAAqB;AACpC;AACA;;AAEA;AACA,kBAAkB;AAClB,oBAAoB;AACpB,8BAA8B;AAC9B,sBAAsB;;AAEtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa,+CAAK;AAClB;AACA;AACA,aAAa,+CAAK;AAClB;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,2DAAqB;AACpC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa,2EAAiB;AAC9B;AACA,6BAA6B,+CAAK;AAClC;AACA,SAAS;AACT,OAAO;AACP;AACA;AACA,eAAe,2EAAiB;AAChC,OAAO;AACP;AACA;AACA,6BAA6B,+CAAK;AAClC;AACA,SAAS;AACT,OAAO,yBAAyB;AAChC;AACA;AACA;AACA,iBAAiB,kEAAQ;AACzB;AACA,WAAW;AACX,UAAU;AACV;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,2EAAiB;AAC5B;AACA;;AAEA;AACA,yBAAyB;AACzB;AACA;AACA;AACA,WAAW,2DAAqB;AAChC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;;AAEL;AACA;AACA;AACA;AACA;AACA,aAAa,+CAAK;AAClB;AACA;AACA;AACA;AACA;AACA,UAAU;AACV;AACA;AACA;AACA,cAAc;AACd;AACA;AACA,WAAW;AACX;AACA,OAAO;AACP;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA,gBAAgB,4DAAkB,SAAS,+EAAqB;AAChE;AACA;AACA,GAAG;AACH;AACA;AACA;;;;;;;;;;;;;;;;;;;AC5RmD;AACO;AACK;AACR;AACvD;;AAEA;AACA,eAAe,4DAAY;AAC3B;AACA,mEAAe,EAAE,wEAAkB;AAC5B;AACP;;AAEA;;AAEA;AACA;AACA;AACA;AACA,aAAa,gEAAc;AAC3B;AACA;AACA;AACA,KAAK;AACL,4EAA4E;AAC5E;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA,KAAK;AACL,IAAI;AACJ;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC9CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEyG;AAClG,mBAAmB,kDAAK;AACc;AACW;AACxD;AACA;;AAEA;AACA;AACA;AACA;AACO;AACP;AACA;AACO;AACA;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACO;AACP;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ;AACR;AACA;AACA;AACA;AACA,GAAG;AACH;AACO;AACP;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,UAAU;AACV;AACA;AACA;AACA,QAAQ;AACR;AACA;AACA;AACA;AACA,GAAG;AACH;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL,GAAG;AACH;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,UAAU;AACV;AACA;AACA;AACA;AACA,QAAQ;AACR;AACA;AACA;AACA,GAAG;AACH;AACO;AACP;AACA;AACA;AACA,KAAK;AACL,GAAG;AACH;AACO;AACP,YAAY,oEAAuB;AACnC;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,qDAAW;AACvB;AACA;AACA;AACA,gBAAgB;AAChB;AACA,gBAAgB,uDAAY;AAC5B;AACA,yBAAyB,2DAAqB;AAC9C;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,WAAW,+CAAK;AAChB,GAAG;AACH;AACA,GAAG;AACH;AACA;AACA,gDAAgD;AAChD,+CAA+C;AAC/C,mEAAmE;AACnE;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,2BAA2B,2DAAqB;;AAEhD;AACA,sCAAsC,2DAAqB;AAC3D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,KAAK;AACL;AACA,KAAK,GAAG;AACR;AACA;AACA;AACA;AACA;AACA,KAAK;AACL,WAAW,2DAAqB;AAChC,GAAG;AACH;AACO;AACP;AACA;AACA;AACO;AACP;AACA;AACA,GAAG;AACH,QAAQ,mDAAS;AACjB;AACA;AACA;AACA,GAAG;AACH;AACA;AACO;AACP;AACA;AACA;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACxVA;AACA;AACA;AACA;AACA;AACA;AACA;;AAE6C;AACW;AACe;AAChE,mBAAmB,kDAAK;AAC/B;AACO;;AAEP;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;;AAEA;AACA;AACA;AACA;AACO;AACP;AACA,IAAI,+CAAK;AACT;AACA;AACA,eAAe,qDAAW;AAC1B;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL,GAAG;AACH;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACO;AACP,YAAY,oEAAuB;AACnC;AACA;AACA;AACA,aAAa,qDAAW;;AAExB;AACA;AACA;AACA,YAAY;AACZ;AACA,iBAAiB,uDAAY;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA,yCAAyC;AACzC,sCAAsC;AACtC,yDAAyD;AACzD,mFAAmF;;AAEnF;AACA;AACA,GAAG;AACH;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;ACrJ0E;AACnE,mBAAmB,kDAAK;AACxB;AACA;AACP;AACA,UAAU,sDAAK;AACf;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACO;AACP;AACA;AACA,WAAW,2DAAqB;AAChC,IAAI;AACJ;AACA;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;AC7DmD;AAC5C,mBAAmB,kDAAK;AACxB;AACP;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACO;AACA;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA,KAAK;AACL,GAAG;AACH;AACO;AACP;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;ACvDO;AACP;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA,2DAA2D;AAC3D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;AChCA;AACA;AACA;AACO;AACP;AACA;AACO;AACA;AACA;AACA;AACP;AACA;AACA;AACA;AACA,KAAK;AACL,GAAG;AACH;AACO;AACP;AACA;;AAEA;AACA;AACA;AACO;AACP;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP,+BAA+B;AAC/B;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACO;AACP;AACA;AACA,IAAI;AACJ;AACA;AACA;;;;;;;;;;;;;;;ACvDA;AACA;AACA;AACA,WAAW,QAAQ;AACnB;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY;AACZ;;AAEA;AACA;AACA;AACA;AACA;AACA,YAAY,cAAc;AAC1B;;AAEA;AACA;AACA;AACA,YAAY;AACZ;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY;AACZ;;AAEA;AACA,yBAAyB;AACzB;AACA;AACA;AACA;AACA,GAAG;;AAEH;AACA;AACA;AACA,cAAc,UAAU;AACxB;AACA;AACA;AACA,GAAG;AACH;AACA;;AAEA;AACA,GAAG;;AAEH;AACA;AACA,cAAc,WAAW;AACzB,cAAc;AACd;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA,MAAM;AACN;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;;AAEA;AACA,OAAO;AACP;AACA;;AAEA;AACA,OAAO;AACP;AACA,GAAG;;AAEH;AACA;AACA,cAAc,mBAAmB;AACjC,cAAc,eAAe;AAC7B;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,KAAK;;AAEL;AACA;;AAEA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;;AAEA;;AAEA;;AAEA;AACA,GAAG;;AAEH;AACA;AACA,cAAc,SAAS;AACvB,cAAc;AACd;AACA;AACA;AACA,GAAG;;AAEH;AACA;AACA;AACA,cAAc,UAAU;AACxB,cAAc,WAAW;AACzB,cAAc,QAAQ;AACtB;AACA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA,KAAK;AACL;AACA,GAAG;;AAEH;AACA;AACA;AACA,cAAc,QAAQ;AACtB,cAAc;AACd;AACA;AACA;;AAEA;AACA,GAAG;;AAEH;AACA;AACA,cAAc;AACd;AACA;AACA;;AAEA;AACA;AACA;AACA,KAAK;;AAEL;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY;AACZ;;AAEA;AACA;;AAEA;;AAEA;;AAEA,2BAA2B;;;AAG3B;AACA;AACA,GAAG;AACH;AACA;AACA;AACA,YAAY,SAAS;AACrB,YAAY;AACZ;;;AAGA;AACA,wBAAwB;;AAExB,8DAA8D;;AAE9D;AACA;;AAEA;;AAEA;AACA,IAAI;;;AAGJ;AACA;AACA;AACA;AACA;AACA,YAAY;AACZ;;;AAGA;AACA;AACA;AACA,2BAA2B;;AAE3B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AAGA;AACA;AACA;AACA;AACA;AACA,QAAQ;;;AAGR;;AAEA;AACA,KAAK;AACL,GAAG;AACH;;;;;;;;;;ACxRA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI,KAA4D;AAChE,IAAI,CACoG;AACxG,CAAC,uBAAuB;;AAExB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,gBAAgB,sCAAsC,kBAAkB;AACvF,8BAA8B;AAC9B;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB;AACxB;AACA;AACA;AACA;AACA,qDAAqD,OAAO;AAC5D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iFAAiF,OAAO;AACxF;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,gBAAgB,qBAAM;;AAEtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA,oBAAoB;AACpB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,cAAc,2EAA2E;AACzF,cAAc,6DAA6D;AAC3E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS,IAAI;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gDAAgD,OAAO;AACvD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gDAAgD,OAAO;AACvD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4DAA4D;AAC5D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wEAAwE,mDAAmD,2BAA2B,IAAI,0BAA0B,oBAAoB;AACxM,uEAAuE,oBAAoB;AAC3F;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0CAA0C,OAAO;AACjD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iDAAiD;AACjD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM,gBAAgB;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B;AAC1B,wBAAwB;;AAExB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gCAAgC;AAChC,KAAK;AACL;AACA;AACA,kCAAkC,kCAAkC;AACpE,yCAAyC,4BAA4B;AACrE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mEAAmE,uBAAuB;AAC1F;AACA;AACA;AACA;AACA,2DAA2D,2CAA2C,IAAI;AAC1G;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK,IAAI;AACT;AACA;AACA;AACA;AACA;AACA;AACA,KAAK,IAAI;AACT;AACA;AACA;AACA;AACA;AACA,mCAAmC;AACnC;AACA,mBAAmB;AACnB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK,IAAI;AACT;AACA;AACA;;AAEA;AACA,2BAA2B;AAC3B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe;AACf;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA,iBAAiB;AACjB,SAAS;AACT;AACA;AACA,4EAA4E,eAAe;AAC3F,aAAa;AACb,4EAA4E,4BAA4B;AACxG,aAAa;AACb,SAAS;AACT;AACA;AACA;AACA;AACA,0DAA0D,6CAA6C;AACvG;AACA,iBAAiB;AACjB;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iDAAiD;AACjD;AACA;AACA;AACA,iBAAiB,YAAY;AAC7B,aAAa;AACb,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,8CAA8C,2DAA2D;AACzG,aAAa;AACb,SAAS;AACT;AACA,+BAA+B,aAAa;AAC5C,oCAAoC;AACpC,SAAS;AACT,uBAAuB,mBAAmB,uBAAuB;AACjE;AACA;AACA;AACA,+BAA+B,cAAc;AAC7C,oCAAoC;AACpC,SAAS;AACT;AACA,+BAA+B,yBAAyB;AACxD,oCAAoC;AACpC,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB;AACzB,qBAAqB;AACrB;AACA,iBAAiB;AACjB,aAAa;AACb;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+DAA+D,uDAAuD,sBAAsB,sCAAsC,sBAAsB,sBAAsB,uCAAuC;AACrQ,4CAA4C,yCAAyC,IAAI;AACzF,iBAAiB;AACjB,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+DAA+D,uDAAuD,wBAAwB;AAC9I;AACA;AACA;AACA,qBAAqB,IAAI;AACzB,iBAAiB;AACjB,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gDAAgD,SAAS;AACzD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yFAAyF,mBAAmB;AAC5G;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,OAAO;AACnC;AACA;AACA;AACA;AACA,UAAU;AACV;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,iDAAiD,qCAAqC;AACtF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B,yDAAyD;AACpF;AACA;AACA;AACA;AACA;AACA;AACA,UAAU;AACV;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,UAAU;AACV;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+DAA+D,mDAAmD;AAClH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+BAA+B,wBAAwB;AACvD,wDAAwD,mDAAmD;AAC3G;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB,aAAa;AACb;AACA;AACA;AACA;AACA;AACA,2FAA2F,gBAAgB;AAC3G,aAAa;AACb;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,8BAA8B,2EAA2E;AACzG;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+BAA+B;AAC/B;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,OAAO;AAC/B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,OAAO;AAC/B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+CAA+C,oEAAoE,IAAI,+CAA+C;AACtK;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wCAAwC,8BAA8B;AACtE,2CAA2C,sCAAsC;AACjF,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wDAAwD,0CAA0C;AAClG,oCAAoC,qBAAqB;AACzD;AACA;AACA;AACA;AACA;AACA;AACA,aAAa,yBAAyB,6CAA6C;AACnF;AACA;AACA;AACA;AACA,qEAAqE,yBAAyB;AAC9F;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oFAAoF,6BAA6B;AACjH,8BAA8B,iBAAiB,iDAAiD;AAChG;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2CAA2C,YAAY;AACvD;AACA;AACA,qBAAqB;AACrB,4DAA4D;AAC5D;AACA,iBAAiB;AACjB;AACA;AACA,oDAAoD,OAAO;AAC3D,gFAAgF,sCAAsC;AACtH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2CAA2C,iFAAiF;AAC5H,aAAa,wBAAwB,iFAAiF;AACtH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+DAA+D,2BAA2B,iFAAiF,IAAI;AAC/K,uCAAuC,iFAAiF;AACxH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA,+DAA+D,2BAA2B,2CAA2C,IAAI;AACzI,uCAAuC,4EAA4E;AACnH;AACA;AACA;AACA,+DAA+D,2BAA2B,oDAAoD,IAAI;AAClJ,uCAAuC,4EAA4E;AACnH;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB,2BAA2B,mCAAmC,sCAAsC,IAAI;AACzH,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2CAA2C,uFAAuF;AAClI;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2CAA2C,uFAAuF;AAClI;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB,aAAa;AACb;AACA;AACA;AACA;AACA,6DAA6D,mBAAmB;AAChF,oEAAoE,uBAAuB;AAC3F;AACA;AACA,2CAA2C,0CAA0C;AACrF;AACA;AACA;AACA;AACA;AACA;AACA,wEAAwE,gBAAgB;AACxF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA,qEAAqE,gBAAgB;AACrF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB,iBAAiB;AACjB,aAAa;AACb;AACA;AACA;AACA;AACA;AACA,2CAA2C,0CAA0C;AACrF,aAAa;AACb;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA,KAAK;;AAEL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8CAA8C,OAAO;AACrD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA,qFAAqF,mBAAmB;AACxG;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B;AAC7B,yBAAyB;AACzB,qBAAqB;AACrB;AACA;AACA;AACA,aAAa;AACb;AACA;;AAEA;AACA,mCAAmC,sBAAsB;AACzD;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb,SAAS;AACT;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gDAAgD,qCAAqC;AACrF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2EAA2E,6BAA6B,mBAAmB,0BAA0B;AACrJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0DAA0D,mCAAmC;AAC7F;AACA;AACA;AACA;AACA,0CAA0C;AAC1C,wEAAwE,sBAAsB,mBAAmB,kBAAkB,UAAU,iBAAiB,gBAAgB,UAAU;AACxL,8EAA8E,sBAAsB;AACpG;AACA,iBAAiB;AACjB;AACA,SAAS;AACT;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2EAA2E,sCAAsC;AACjH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;;AAEL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iDAAiD,8CAA8C;AAC/F;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB,0BAA0B,oCAAoC;AACnF;AACA;AACA;AACA,mDAAmD,SAAS,eAAe;AAC3E,4CAA4C,eAAe;AAC3D;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA,uDAAuD,wBAAwB,4CAA4C,aAAa;AACxI;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB;AACzB;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA,yCAAyC;AACzC,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA,wDAAwD,cAAc;AACtE;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sDAAsD,yBAAyB;AAC/E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sDAAsD,gCAAgC;AACtF;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB,iBAAiB;AACjB;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA,qDAAqD,cAAc;AACnE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wCAAwC,aAAa;AACrD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0DAA0D,gBAAgB;AAC1E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB;AACzB;AACA;AACA;AACA;AACA,4CAA4C,WAAW;AACvD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mDAAmD,8CAA8C;AACjG;AACA;AACA;AACA;AACA;AACA,iCAAiC,sBAAsB;AACvD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC,wBAAwB,kDAAkD,IAAI,qBAAqB;AACpI;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC,wBAAwB,mDAAmD,IAAI;AAChH;AACA,6BAA6B;AAC7B,yBAAyB;AACzB;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB,iBAAiB;AACjB,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kDAAkD,uBAAuB,uCAAuC;AAChH,uDAAuD,qDAAqD;AAC5G;AACA,wDAAwD,eAAe,YAAY;AACnF;AACA,iIAAiI,uBAAuB;AACxJ;AACA,yBAAyB;AACzB,qBAAqB;AACrB,iBAAiB;AACjB;AACA;AACA;AACA;AACA,KAAK;AACL,iDAAiD;;AAEjD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qEAAqE,wBAAwB;AAC7F;AACA;AACA;AACA,2BAA2B,0BAA0B;AACrD,2BAA2B;AAC3B;AACA;AACA;AACA,2BAA2B,0BAA0B;AACrD,2BAA2B;AAC3B;AACA;AACA;AACA;AACA,wBAAwB,YAAY;AACpC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0CAA0C,+BAA+B;AACzE;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB;AACzB,aAAa;AACb;AACA,aAAa;AACb,4DAA4D,kBAAkB;AAC9E,4DAA4D,kBAAkB;AAC9E;AACA;AACA;AACA;AACA,sEAAsE,6EAA6E;AACnJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kDAAkD,gBAAgB;AAClE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0CAA0C,wDAAwD;AAClG;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+DAA+D,iEAAiE;AAChI;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2DAA2D,2BAA2B;AACtF;AACA;AACA;AACA;AACA,2DAA2D,6CAA6C;AACxG;AACA;AACA;AACA;AACA,2DAA2D,8CAA8C;AACzG;AACA;AACA;AACA;AACA,2DAA2D,oDAAoD;AAC/G;AACA;AACA;AACA;AACA,2DAA2D,uCAAuC;AAClG;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kEAAkE,+BAA+B;AACjG;AACA;AACA,kEAAkE,oBAAoB;AACtF;AACA;AACA;AACA;AACA;AACA,kEAAkE,6BAA6B;AAC/F;AACA;AACA;AACA;AACA;AACA,kEAAkE,6BAA6B,4BAA4B,IAAI;AAC/H;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4DAA4D,kDAAkD;AAC9G;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0CAA0C,0BAA0B;AACpE;AACA;AACA,aAAa;AACb;AACA;AACA;AACA,kFAAkF,4CAA4C;AAC9H;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0DAA0D;AAC1D;AACA,kCAAkC;AAClC;AACA,6CAA6C,4CAA4C;AACzF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,OAAO;AAC9B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yCAAyC;AACzC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC,+CAA+C;AAChF,iCAAiC;AACjC;AACA,iCAAiC,gDAAgD;AACjF,iCAAiC;AACjC;AACA;AACA;AACA;AACA,4DAA4D,wFAAwF;AACpJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA,0CAA0C,+BAA+B;AACzE;AACA;AACA;AACA;AACA,4DAA4D,gCAAgC;AAC5F;AACA;AACA,KAAK;;AAEL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iDAAiD;AACjD,0CAA0C;AAC1C,0CAA0C;AAC1C;AACA;AACA;AACA,SAAS;AACT;;AAEA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6EAA6E,8CAA8C;AAC3H,sEAAsE,8CAA8C;AACpH;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB;AACzB,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB,4CAA4C,yBAAyB;AACrE;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uEAAuE,iBAAiB;AACxF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA,8CAA8C,gEAAgE,mBAAmB,+DAA+D;AAChM;AACA;AACA;AACA,iBAAiB;AACjB,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oFAAoF;AACpF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;;AAEL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb,SAAS;AACT;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,iEAAiE,6BAA6B;AAC9F;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,sCAAsC;AACtC;AACA;AACA;AACA,sCAAsC;AACtC;AACA;AACA;;AAEA;AACA;AACA,iCAAiC;AACjC;AACA;AACA;AACA;AACA;AACA,oCAAoC;AACpC;AACA;AACA;AACA;AACA;AACA,oCAAoC;AACpC;AACA;AACA,oCAAoC;AACpC;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0DAA0D,kCAAkC;AAC5F;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B;AAC7B,2FAA2F,gCAAgC;AAC3H;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B;AAC7B,oEAAoE;AACpE;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sDAAsD,WAAW;AACjE;AACA;AACA;AACA;AACA,yCAAyC,4BAA4B,sCAAsC;AAC3G;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6CAA6C,kFAAkF;AAC/H;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4CAA4C,YAAY;AACxD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4CAA4C,YAAY;AACxD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yDAAyD,wDAAwD;AACjH;AACA;AACA;AACA,0FAA0F,oBAAoB;AAC9G;AACA,yBAAyB;AACzB;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sEAAsE;AACtE,mEAAmE;AACnE;AACA;AACA;AACA;AACA;AACA;AACA,4DAA4D,oDAAoD,qBAAqB,eAAe;AACpJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iEAAiE;AACjE;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6CAA6C,YAAY;AACzD;AACA;AACA;AACA;AACA,+DAA+D,iBAAiB,6BAA6B;AAC7G;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qDAAqD,kBAAkB;AACvE;AACA;AACA,qDAAqD,kBAAkB;AACvE;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wCAAwC,YAAY;AACpD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA,2DAA2D;AAC3D;AACA,qBAAqB;AACrB,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6DAA6D,mCAAmC;AAChG;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA,gEAAgE,wCAAwC;AACxG;AACA,0CAA0C,sCAAsC;AAChF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,wCAAwC;AACxC,SAAS;AACT;AACA;AACA,0CAA0C;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4DAA4D,gCAAgC;AAC5F;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+CAA+C,+BAA+B;AAC9E;AACA,kEAAkE,oEAAoE;AACtI;AACA,yBAAyB;AACzB;AACA;AACA;AACA;AACA;AACA,aAAa;AACb,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA,kDAAkD,oCAAoC;AACtF;AACA;AACA;AACA;AACA,kDAAkD,wEAAwE;AAC1H;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB;AACzB;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA,2CAA2C,gBAAgB;AAC3D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uDAAuD,sCAAsC;AAC7F;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA,4DAA4D,gCAAgC;AAC5F;AACA;AACA;AACA,yBAAyB;AACzB,gEAAgE,sCAAsC;AACtG;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA,iGAAiG,uBAAuB;AACxH;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA,iFAAiF,0BAA0B;AAC3G;AACA;AACA;AACA;AACA;AACA,aAAa;AACb,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,cAAc,wDAAwD;AACtE,cAAc,6BAA6B;AAC3C,yCAAyC,8BAA8B;AACvE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,mDAAmD,2CAA2C;AAC9F;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,6BAA6B;AACzD;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qEAAqE,2CAA2C;AAChH;AACA;AACA;AACA,wBAAwB,uBAAuB;AAC/C;AACA;AACA;AACA,4BAA4B,6BAA6B;AACzD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sDAAsD;AACtD;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;;AAEL;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B;AAC5B,0BAA0B;AAC1B;AACA;AACA,SAAS;AACT;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb,0CAA0C,iBAAiB;AAC3D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2CAA2C,mBAAmB;AAC9D,8CAA8C,6BAA6B;AAC3E,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA,0DAA0D,YAAY;AACtE;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,SAAS;AACT;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uCAAuC;AACvC;AACA;AACA,SAAS,wBAAwB,mCAAmC;AACpE;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,8CAA8C,qEAAqE,IAAI,MAAM;AAC7H;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA,aAAa;AACb;AACA;AACA,8CAA8C,mCAAmC;AACjF;AACA,aAAa;AACb;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oCAAoC,0BAA0B;AAC9D;AACA;AACA;AACA;AACA;AACA,gCAAgC,4CAA4C;AAC5E;AACA;AACA;AACA;AACA;AACA,gCAAgC,4CAA4C;AAC5E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kDAAkD;AAClD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8CAA8C;AAC9C;AACA;AACA;AACA,8CAA8C;AAC9C;AACA;AACA;AACA;AACA,yCAAyC;AACzC;AACA;AACA;AACA,0CAA0C;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB;AACzB,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uCAAuC;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;;AAEA;AACA,4EAA4E,uDAAuD;AACnI;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA,qDAAqD;AACrD;AACA;AACA,wDAAwD,gBAAgB;AACxE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qDAAqD,mBAAmB;AACxE;AACA;AACA;AACA,sEAAsE,gBAAgB;AACtF;AACA;AACA,kDAAkD,uBAAuB;AACzE;AACA;AACA,mEAAmE,yCAAyC;AAC5G;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sEAAsE,iCAAiC;AACvG;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,2DAA2D;AAC3D;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sCAAsC;AACtC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA,aAAa;AACb,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA,0DAA0D,kCAAkC;AAC5F;AACA;AACA;AACA,kEAAkE,8BAA8B;AAChG;AACA,aAAa;AACb,SAAS;AACT;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA,SAAS;AACT;;AAEA;AACA,2CAA2C,+BAA+B,+BAA+B,+BAA+B;AACxI;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mCAAmC,wBAAwB;AAC3D,4DAA4D,sEAAsE;AAClI;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA,sEAAsE;AACtE;AACA,gIAAgI;AAChI,qDAAqD,qBAAqB;AAC1E;AACA;AACA,4DAA4D,WAAW;AACvE,aAAa;AACb;AACA;AACA,aAAa;AACb,SAAS;AACT;;AAEA;AACA;AACA,wBAAwB,WAAW;AACnC;AACA;AACA;AACA;AACA,mCAAmC,WAAW;AAC9C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2DAA2D,oBAAoB;AAC/E;AACA,gOAAgO;AAChO;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qDAAqD,+BAA+B;AACpF;AACA;AACA;AACA;AACA,sDAAsD,gBAAgB;AACtE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iEAAiE,UAAU;AAC3E;AACA;AACA,2BAA2B;AAC3B;AACA,iDAAiD,YAAY,4BAA4B,aAAa,sFAAsF;AAC5L;AACA,qBAAqB;AACrB;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4CAA4C,kBAAkB;AAC9D;AACA;AACA;AACA;AACA,iCAAiC;AACjC;AACA;AACA;AACA;AACA,iCAAiC;AACjC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC;AACjC;AACA;AACA;AACA;AACA;AACA,6BAA6B;AAC7B;AACA;AACA;AACA,sDAAsD,+CAA+C;AACrG,uBAAuB;AACvB;AACA,eAAe;AACf;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,sCAAsC,4BAA4B,eAAe;AACjF;AACA;AACA,0DAA0D,gBAAgB;AAC1E;AACA;AACA;AACA;AACA;AACA;AACA,mFAAmF,6BAA6B;AAChH;AACA;AACA;AACA,mFAAmF,6BAA6B;AAChH;AACA;AACA;AACA,mFAAmF,6BAA6B;AAChH;AACA;AACA;AACA,mFAAmF,0BAA0B;AAC7G;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iGAAiG,UAAU,YAAY,eAAe;AACtI;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gDAAgD;AAChD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6CAA6C;AAC7C;AACA;AACA;AACA,iCAAiC;AACjC;AACA;AACA,oDAAoD,iBAAiB;AACrE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6CAA6C;AAC7C,iCAAiC;AACjC,sEAAsE,2CAA2C;AACjH;AACA,iCAAiC;AACjC,6BAA6B;AAC7B;AACA;AACA;AACA;AACA;AACA,qDAAqD,sCAAsC,iCAAiC,gBAAgB;AAC5I;AACA;AACA,wDAAwD,4CAA4C;AACpG;AACA;AACA;AACA,iDAAiD;AACjD;AACA;AACA,0FAA0F,YAAY,mDAAmD;AACzJ;AACA,iCAAiC;AACjC,6BAA6B;AAC7B;AACA,uBAAuB;AACvB;AACA,eAAe;AACf;AACA;AACA;AACA;AACA,8BAA8B,2DAA2D;AACzF;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mCAAmC,0CAA0C;AAC7E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+CAA+C,YAAY;AAC3D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B;AAC7B,yBAAyB;AACzB;AACA;AACA;AACA,2BAA2B;AAC3B,iBAAiB;AACjB;AACA,SAAS;AACT;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uCAAuC,WAAW;AAClD;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA,6GAA6G,sEAAsE;AACnL,yDAAyD,YAAY;AACrE;AACA;AACA,yFAAyF;AACzF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oGAAoG,YAAY;AAChH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wEAAwE,+CAA+C;AACvH;AACA;AACA;AACA;AACA;AACA;AACA,wFAAwF,2BAA2B;AACnH,gGAAgG,qCAAqC;AACrI,sFAAsF,SAAS;AAC/F;AACA;AACA;AACA,yCAAyC;AACzC;AACA;AACA,oGAAoG;AACpG;AACA,6BAA6B;AAC7B,2BAA2B;AAC3B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8CAA8C,6CAA6C;AAC3F,kDAAkD,wDAAwD;AAC1G;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4EAA4E,UAAU,eAAe;AACrG;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qDAAqD;AACrD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6DAA6D;AAC7D,yDAAyD;AACzD;AACA;AACA;AACA;AACA;AACA,6DAA6D;AAC7D,yDAAyD;AACzD;AACA;AACA;AACA;AACA,6DAA6D;AAC7D,yDAAyD;AACzD,qDAAqD;AACrD;AACA;AACA,yCAAyC;AACzC;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA,mBAAmB;AACnB,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gDAAgD;AAChD,+CAA+C,8BAA8B;AAC7E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+BAA+B;AAC/B;AACA,6DAA6D,8BAA8B;AAC3F;AACA;AACA,iEAAiE,8BAA8B;AAC/F;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mDAAmD,QAAQ;AAC3D;AACA;AACA;AACA;AACA;AACA;AACA,kDAAkD,sCAAsC;AACxF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uGAAuG,2BAA2B;AAClI;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB;AACzB;AACA,gDAAgD,2BAA2B;AAC3E;AACA;AACA;AACA;AACA;AACA,yBAAyB;AACzB;AACA;AACA;AACA,uFAAuF,2BAA2B;AAClH;AACA;AACA,sCAAsC,oEAAoE;AAC1G;AACA;AACA;AACA,4DAA4D,2BAA2B;AACvF;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA,oEAAoE,uDAAuD;AAC3H;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,6CAA6C,WAAW;AACxD;AACA;AACA;AACA;AACA,uEAAuE;AACvE;AACA;AACA;AACA,oEAAoE,sBAAsB;AAC1F;AACA;AACA;AACA;AACA,gGAAgG,+BAA+B;AAC/H;AACA,yGAAyG,gBAAgB;AACzH;AACA,uFAAuF,gBAAgB;AACvG;AACA;AACA;AACA,uGAAuG,4CAA4C;AACnJ;AACA;AACA;AACA;AACA;AACA,mHAAmH,+BAA+B;AAClJ,yGAAyG,gBAAgB;AACzH;AACA,uFAAuF,gBAAgB;AACvG;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+GAA+G,4CAA4C;AAC3J;AACA;AACA;AACA,uGAAuG,gBAAgB;AACvH;AACA;AACA;AACA;AACA;AACA;AACA,2GAA2G,4CAA4C;AACvJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mFAAmF,mBAAmB;AACtG;AACA;AACA;AACA;AACA,yBAAyB;AACzB;AACA;AACA,yBAAyB;AACzB;AACA;AACA,yBAAyB;AACzB;AACA;AACA,iBAAiB;AACjB;AACA;AACA,sDAAsD,gBAAgB;AACtE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+JAA+J,qBAAqB;AACpL;AACA,kFAAkF,UAAU;AAC5F;AACA;AACA;AACA;AACA;AACA,6DAA6D;AAC7D;AACA;AACA,yCAAyC,GAAG;AAC5C;AACA;AACA,iEAAiE,uEAAuE;AACxI,iCAAiC;AACjC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC;AACjC;AACA;AACA;AACA,iCAAiC;AACjC;AACA;AACA,yBAAyB;AACzB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2EAA2E,OAAO;AAClF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC;AACjC;AACA;AACA;AACA,iCAAiC;AACjC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yDAAyD;AACzD,yDAAyD;AACzD,6CAA6C;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B;AAC7B,2BAA2B;AAC3B;AACA,mBAAmB;AACnB;AACA,SAAS;AACT;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2FAA2F;AAC3F;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA,aAAa;AACb;AACA;AACA,sFAAsF,+BAA+B;AACrH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC;AACjC;AACA,qBAAqB;AACrB;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B,wBAAwB;AACtD,aAAa;AACb;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA,iGAAiG;AACjG;AACA;AACA;AACA,2CAA2C,mEAAmE;AAC9G,wCAAwC,wCAAwC;AAChF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sDAAsD;AACtD;AACA;AACA;AACA;AACA,qDAAqD,0BAA0B;AAC/E;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA,8CAA8C,sBAAsB;AACpE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iEAAiE,0CAA0C;AAC3G;AACA;AACA;AACA;AACA;AACA,qCAAqC;AACrC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA,6BAA6B,0BAA0B;AACvD;AACA,+BAA+B,6EAA6E;AAC5G,+CAA+C,2BAA2B;AAC1E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,0BAA0B;AACpD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA,uCAAuC,wBAAwB;AAC/D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2CAA2C,iBAAiB;AAC5D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mEAAmE,gCAAgC;AACnG,aAAa;AACb;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB;AACzB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4EAA4E,YAAY;AACxF;AACA;AACA;AACA;AACA;AACA;AACA,wDAAwD,4CAA4C;AACpG;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;;AAEL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qEAAqE,4CAA4C;AACjH;AACA;AACA;AACA;AACA;AACA,KAAK;;AAEL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB;AACpB;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA,wCAAwC;AACxC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sDAAsD,2DAA2D;AACjH,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B;AAC7B;AACA,iBAAiB;AACjB;AACA;AACA;AACA,SAAS;AACT,4CAA4C;AAC5C,4CAA4C;AAC5C;AACA;;AAEA;AACA,qCAAqC;AACrC;AACA,+CAA+C,YAAY;AAC3D;AACA,SAAS;AACT;AACA,qCAAqC,YAAY;AACjD;AACA;AACA,aAAa,6CAA6C,eAAe;AACzE,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,+BAA+B;AAC/B,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,+BAA+B,eAAe;AAC9C;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gCAAgC,qBAAqB;AACrD,yCAAyC,uCAAuC,GAAG;AACnF;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,2CAA2C;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,8DAA8D,2BAA2B;AACzF;AACA,+BAA+B,wBAAwB;AACvD;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA,mCAAmC,oCAAoC;AACvE;AACA,SAAS;AACT;;AAEA;AACA,sCAAsC,YAAY;AAClD;;AAEA;AACA,sCAAsC,eAAe;AACrD;;AAEA;AACA,sCAAsC,uBAAuB;AAC7D;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;;AAEL,sCAAsC,kBAAkB;;AAExD;;AAEA,CAAC;AACD;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AClzLA;AACA;AACA;AACqC;AACrC;AACA,oEAAoE,2CAAM;AAC1E,IAAI,kDAAa;AACjB,+EAA+E,kDAAa,EAAE,MAAM,aAAa;AACjH;AACA,QAAQ;AACR,kEAAkE;AAEA;AAClE,iEAAe,KAAK,EAAC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACb4C;AAC1D;AACA;AACP;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACO;AACP;AACA;AACA;AACO;AACP;AACA;AACA;AACO;AACP;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,oBAAoB;AACxC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA,oBAAoB,oBAAoB;AACxC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA,sCAAsC;AACtC;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI,+EAAkB;AACtB;AACO;AACP;AACA;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC9HqV;AAC/S;AACtC;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP,aAAa;AACb,eAAe;AACf,cAAc;AACd,mBAAmB;AACnB,kBAAkB;AAClB,yBAAyB;AACzB,yBAAyB;AACzB,0BAA0B;AAC1B,wBAAwB;AACxB,kBAAkB;AAClB,mBAAmB;AACnB,eAAe;AACf,wBAAwB;AACxB,yCAAyC;AACzC,qBAAqB;AACrB,iBAAiB;AACjB;AACA;;;;;;;;;;;;;;;;;;;;AC3CyF;AACxB;AAC1D,yGAAyG,QAAQ,8FAA8F,IAAI;AAC1N;AACO;AACP;AACA,oBAAoB,iFAAwB;AAC5C;AACA;AACA;AACO;AACP,WAAW,6EAAoB,iBAAiB,yEAA2B;AAC3E;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACbgD;AACwB;AAClB;AACpB;AACR;AACS;AAC5B;AACP,qBAAqB,6DAAW;AAChC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP,6BAA6B,mEAAY;AACzC,WAAW,gEAAiB;AAC5B;AACO;AACP;AACA,WAAW,8DAAe;AAC1B;AACA;AACA;AACA;AACA;AACA;AACO;AACP,eAAe,8DAAe;AAC9B;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC7CmS;AAC/P;AACpC;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP,YAAY;AACZ,YAAY;AACZ,YAAY;AACZ,YAAY;AACZ,aAAa;AACb,WAAW;AACX,mBAAmB;AACnB,mBAAmB;AACnB,YAAY;AACZ,WAAW;AACX,qBAAqB;AACrB,eAAe;AACf,wBAAwB;AACxB,sBAAsB;AACtB,uBAAuB;AACvB,qBAAqB;AACrB,eAAe;AACf,gBAAgB;AAChB;AACO;AACP,OAAO,wDAAQ;AACf,OAAO,wDAAQ;AACf,OAAO,wDAAQ;AACf,OAAO,wDAAQ;AACf,OAAO,yDAAS;AAChB,OAAO,uDAAO;AACd,OAAO,+DAAe;AACtB,OAAO,+DAAe;AACtB,OAAO,wDAAQ;AACf,OAAO,uDAAO;AACd,QAAQ,iEAAiB;AACzB,QAAQ,2DAAW;AACnB,QAAQ,oEAAoB;AAC5B,QAAQ,kEAAkB;AAC1B,QAAQ,mEAAmB;AAC3B,QAAQ,iEAAiB;AACzB,QAAQ,2DAAW;AACnB,QAAQ,4DAAY;AACpB;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA,oBAAoB,6BAA6B;AACjD;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA,KAAK;AACL;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACzFsD;AAC/C;AACP;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,uBAAuB;AAC3C;AACA,2BAA2B,qDAAW;AACtC,0BAA0B,qDAAW;AACrC;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,oBAAoB;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP,iBAAiB,qDAAW;AAC5B;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA,iBAAiB,qDAAW;AAC5B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA,iBAAiB,qDAAW;AAC5B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACvKO;AACP;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACA;AACA,KAAK;AACL;AACA;AACO;AACP;AACA;AACA;AACA,KAAK;AACL;AACA;AACO;AACP;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP,2BAA2B;AAC3B;AACO;AACP;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,0BAA0B;AAClD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC,UAAU;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;ACrIgB;AACc;AACsB;AACpD;AACA;AACA;AACA;AACA;AACA,oBAAoB,kDAAW;AAC/B;AACA;AACA,iBAAiB,gBAAgB;AACjC;AACA;AACA,eAAe,UAAU;AACzB;AACA;AACA,eAAe,2CAAI;AACnB;AACA;AACA,eAAe,iDAAc,uBAAuB,4CAAS;AAC7D;AACA,SAAS,8CAAO;AAChB;AACA;AACA;AACA,qBAAqB,kDAAW;AAChC,QAAQ,6CAAM;AACd;AACA,uCAAuC,OAAO;AAC9C;AACA;AACA;AACA;AACA;AACA,eAAe,iDAAc,wBAAwB,4CAAS;AAC9D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGE;;;;;;;;;;;;;;;;;;;;;;;;;AC3Cc;AAChB;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,sBAAsB;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe;AACf;AACA;AACA;AACA;AACA;AACA;AACA,UAAU;AACV;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ;AACR;AACA;AACA;AACA;AACA,sBAAsB;AACtB,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,oBAAoB;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,4CAAK;AACb;AACA;AACA;AACA;AACA,gEAAgE;AAChE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI,6CAAM;AACV,MAAM,iDAAU,QAAQ,iDAAU;AAClC,UAAU,KAAK;AACf;AACA;AACA,IAAI,6CAAM;AACV;AACA,SAAS,MAAM,sBAAsB,KAAK;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,UAAU,2CAA2C;AACrD;AACA;AACA;AACA;AACA;AACA,uBAAuB,iDAAU;AACjC;AACA;AACA;AACA,MAAM,+CAAQ;AACd;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA,UAAU;AACV;AACA;AACA;AACA,UAAU,WAAW;AACrB;AACA;AACA;AACA;AACA,MAAM,6CAAM,CAAC,0CAAG,2CAA2C,KAAK;AAChE;AACA,MAAM;AACN;AACA;AACA,+BAA+B,8CAAO;AACtC;AACA,MAAM,8CAAO;AACb;AACA;AACA,MAAM,+CAAQ;AACd;AACA;AACA;AACA,UAAU,iDAAU;AACpB,QAAQ,6CAAM;AACd;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,EAAE,6CAAM,oCAAoC,SAAS;AACrD,OAAO,8CAAO;AACd;AACA;AACA;AACA,EAAE,6CAAM,CAAC,8CAAO,8CAA8C,SAAS;AACvE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,0CAAG;AACd;AACA;AACA,YAAY,8CAAO;AACnB;AACA;AACA,gBAAgB,+CAAQ;AACxB;AACA;AACA,iBAAiB,4CAAK;AACtB;AACA;AACA,UAAU,SAAS,+CAAQ;AAC3B;AACA;AACA;AACA;AACA;AACA,eAAe,4CAAK;AACpB,UAAU;AACV;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAWE;;;;;;;;;;;;;;;;;;;;;;;ACnVc;AACsB;AACc;AACI;AACN;AACA;AACV;AACxC,oBAAoB,KAAK,oEAAO,qEAAQ;AACxC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,2CAAI;AACvB;AACA,eAAe,iDAAc,+BAA+B,4CAAS;AACrE;AACA,UAAU,0CAAG;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB,qEAAQ;AAC7B;AACA,eAAe,iDAAc,gCAAgC,4CAAS;AACtE;AACA;AACA;AACA;AACA,qBAAqB,2CAAI;AACzB;AACA,WAAW,6CAAM;AACjB;AACA;AACA;AACA,eAAe;AACf;AACA;AACA;AACA;AACA;AACA;AACA,eAAe;AACf;AACA;AACA;AACA;AACA;AACA;AACA,aAAa,QAAQ;AACrB,cAAc,QAAQ;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa,QAAQ;AACrB,cAAc,QAAQ;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa,WAAW;AACxB,cAAc,QAAQ;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa,GAAG;AAChB;AACA;AACA,sBAAsB;AACtB;AACA;AACA;AACA;AACA,eAAe;AACf;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe;AACf;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe;AACf;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGE;;;;;;;;;;;;;;;;;;;AChJ2C;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,cAAc;AACf;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,UAAU;AACV,mBAAmB;AACnB;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA,aAAa,GAAG;AAChB;AACA,eAAe,eAAe;AAC9B;AACA,aAAa,UAAU;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM,SAAS,8CAAO;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN,gBAAgB,6CAAU;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,qBAAqB;AAClD,MAAM;AACN,6BAA6B,sBAAsB;AACnD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa,UAAU;AACvB;AACA;AACA;AACA;AACA;AACA;AACA,aAAa,UAAU;AACvB;AACA;AACA;AACA;AACA;AACA;AACA,aAAa,QAAQ;AACrB;AACA;AACA;AACA;AACA;AACA;AACA,aAAa,QAAQ;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa,yBAAyB;AACtC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa,UAAU;AACvB,eAAe,SAAS;AACxB;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa,GAAG;AAChB,aAAa,GAAG;AAChB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAKE;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACjPe;AACgB;AAqBhB;AACjB;AACA;AACA,mBAAmB;AACnB;AACA;AACA,kBAAkB,8CAAO;AACzB,qCAAqC,mBAAmB;AACxD;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB,mDAAY;AAC7B;AACA;AACA;AACA;AACA,MAAM,8CAAO;AACb,MAAM,4CAAK,OAAO,4CAAK;AACvB,MAAM,8CAAO;AACb,yBAAyB,8CAAO,WAAW,8CAAO,gCAAgC,8CAAO;AACzF;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM,4CAAK;AACX,SAAS,mDAAY,EAAE,kDAAW;AAClC;AACA;AACA;AACA;AACA;AACA,iCAAiC,8CAAQ;AACzC;AACA;AACA,iCAAiC,8CAAQ;AACzC;AACA;AACA,iCAAiC,8CAAQ;AACzC;AACA;AACA,iCAAiC,8CAAQ;AACzC;AACA;AACA,SAAS,kDAAW;AACpB;AACA;AACA;AACA;AACA,cAAc,kDAAW;AACzB,uBAAuB,+CAAQ,OAAO,6CAAM;AAC5C,4BAA4B,8CAAO;AACnC;AACA;AACA,OAAO,8CAAO,aAAa,8CAAO;AAClC;AACA;AACA;AACA;AACA;AACA,QAAQ,+CAAQ;AAChB;AACA,MAAM,SAAS,+CAAQ;AACvB;AACA,MAAM;AACN,mCAAmC,8CAAO;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS,iDAAU;AACnB;AACA;AACA,MAAM,8CAAO,QAAQ,8CAAO;AAC5B;AACA;AACA;AACA,mBAAmB;AACnB,yBAAyB,SAAS;AAClC;AACA,sBAAsB,yCAAK;AAC3B,oCAAoC,SAAS;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS,0CAAO;AAChB,WAAW,4CAAS;AACpB,QAAQ,4CAAS;AACjB,QAAQ,yCAAM;AACd,UAAU,2CAAQ;AAClB,OAAO,2CAAQ;AACf,QAAQ,2CAAQ;AAChB,UAAU,2CAAQ;AAClB,WAAW,2CAAQ;AACnB;AACA,UAAU,2CAAQ;AAClB,UAAU,2CAAQ;AAClB,SAAS,2CAAQ;AACjB,UAAU,2CAAQ;AAClB;AACA,aAAa,wCAAK;AAClB;AACA;AACA,cAAc,6CAAU;AACxB,GAAG;AACH;AACA,KAAK,2CAAQ;AACb;AACA,KAAK,2CAAQ;AACb,KAAK,2CAAQ;AACb,KAAK,0CAAO;AACZ,KAAK,wCAAK;AACV;AACA,KAAK,4CAAS;AACd,KAAK,yCAAM;AACX;AACA,MAAM,2CAAQ;AACd,MAAM,2CAAQ;AACd;AACA,MAAM,2CAAQ;AACd;AACA,MAAM,2CAAQ;AACd;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS,8CAAO;AAChB;AACA;AACA,SAAS,kDAAW,gBAAgB,6CAAM,QAAQ,6CAAM;AACxD;AAkBE;;;;;;;;;;;;;;;;;AC9LF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAIE;;;;;;;;;;;;;;;;;;ACzBkB;AACgB;AACpC;AACA,EAAE,6CAAM;AACR;AACA;AACA;AACA;AACA,gBAAgB,iDAAc;AAC9B,mBAAmB,mDAAY;AAC/B,MAAM;AACN;AACA;AACA,4CAA4C;AAC5C;AACA;AACA;AACA,iBAAiB,mDAAY;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGE;;;;;;;;;;;;;;;;;;AChCkC;AACL;AAC/B;AACA,SAAS,6CAAM;AACf,IAAI,4CAAK;AACT;AACA;AACA;AAGE;;;;;;;;;;;;;;;;;;ACVoC;AACP;AAC/B;AACA,eAAe,4CAAK,mCAAmC,2CAAQ;AAC/D;AACA;AACA;AAGE;;;;;;;;;;;;;;;;;ACTmC;AACrC,+CAA+C,kDAAQ,eAAe,eAAe;AAGnF;;;;;;;;;;;;;;;;;;;;ACDkB;AACc;AACO;AACV;AAC/B;AACA,gBAAgB,iDAAc;AAC9B,UAAU,YAAY,EAAE,mDAAY;AACpC;AACA;AACA;AACA;AACA;AACA,iBAAiB,qDAAK,CAAC,2CAAI;AAC3B;AACA;AACA,SAAS,4CAAK;AACd;AAGE;;;;;;;;;;;;;;;;ACtBF;AAGE;;;;;;;;;;;;;;;;;;ACHuC;AACV;AAC/B,sDAAsD,qDAAU,CAAC,4CAAK;AAGpE;;;;;;;;;;;;;;;;;;ACLuC;AACV;AAC/B,uDAAuD,qDAAU,CAAC,4CAAK;AAGrE;;;;;;;;;;;;;;;;;ACFkB;AACpB;AACA;AACA,gBAAgB,iDAAc;AAC9B,SAAS,mDAAY;AACrB;AAGE;;;;;;;;;;;;;;;;;;ACRkB;AACW;AAC/B;AACA,gBAAgB,iDAAc;AAC9B;AACA,YAAY,mDAAY;AACxB,SAAS,4CAAK;AACd;AACA;AACA;AACA;AACA;AAGE;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACjB4B;AACH;AACL;AACG;AACC;AACF;AACQ;AACC;AACT;AACC;AACF;AACC;AACF;AACC;AACE;AACM;AACT;AACC;AACM;AACN;AACK;AACC;AACP;AACA;AACC;;;;;;;;;;;;;;;;;ACrBH;AACpB;AACA;AACA;AACA,gBAAgB,iDAAc;AAC9B,SAAS,mDAAY;AACrB;AAGE;;;;;;;;;;;;;;;;;;ACTkB;AACW;AAC/B;AACA,gBAAgB,iDAAc;AAC9B;AACA,YAAY,mDAAY;AACxB,SAAS,4CAAK;AACd;AACA;AACA;AACA;AACA;AAGE;;;;;;;;;;;;;;;;;;ACjBoE;AACvC;AAC/B;AACA,gBAAgB,4CAAK;AACrB,MAAM,8CAAO;AACb,EAAE,6CAAM,CAAC,8CAAO;AAChB;AACA;AACA,QAAQ,4CAAK;AACb,QAAQ,8CAAO;AACf;AACA;AACA;AAGE;;;;;;;;;;;;;;;;;;;ACZkB;AACwB;AACb;AAC/B;AACA,gBAAgB,iDAAc;AAC9B;AACA,YAAY,mDAAY;AACxB,cAAc,4CAAK,iDAAiD,4CAAK;AACzE,0BAA0B,8CAAO;AACjC;AACA;AAGE;;;;;;;;;;;;;;;;;AChByC;AAC3C,+CAA+C,wDAAW,eAAe,mBAAmB;AAG1F;;;;;;;;;;;;;;;;;;ACJwC;AAC0C;AACpF;AACA,cAAc,mDAAY;AAC1B,SAAS,8EAAc;AACvB;AAGE;;;;;;;;;;;;;;;;;;ACRoE;AACvC;AAC/B;AACA,gBAAgB,4CAAK;AACrB,MAAM,8CAAO;AACb,EAAE,6CAAM,CAAC,8CAAO;AAChB;AACA;AACA,QAAQ,4CAAK;AACb,QAAQ,8CAAO;AACf;AACA;AACA;AAGE;;;;;;;;;;;;;;;;;;;ACZkB;AACwB;AACb;AAC/B;AACA,gBAAgB,iDAAc;AAC9B;AACA,YAAY,mDAAY;AACxB,cAAc,4CAAK,iDAAiD,4CAAK;AACzE,WAAW,0CAAO;AAClB;AACA;AAGE;;;;;;;;;;;;;;;;;;AChB6D;AAChC;AAC/B;AACA,YAAY,4CAAK,yCAAyC,2CAAQ;AAClE,mBAAmB,4CAAK,sCAAsC,2CAAQ;AACtE;AACA;AACA,IAAI,6CAAM;AACV;AACA,oFAAoF,EAAE;AACtF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kBAAkB,sDAAe;AACjC;AACA;AACA;AACA,GAAG;AACH;AAGE;;;;;;;;;;;;;;;;;;ACvBkB;AACe;AACnC;AACA,MAAM,4CAAK;AACX,gBAAgB,iDAAc;AAC9B;AACA,aAAa,mDAAY;AACzB;AACA;AAGE;;;;;;;;;;;;;;;;;;;ACdoC;AACD;AACN;AAC/B,kDAAkD,iDAAM,CAAC,4CAAK,mCAAmC,2CAAQ;AAGvG;;;;;;;;;;;;;;;;;;;ACNoC;AACD;AACN;AAC/B,mDAAmD,iDAAM,CAAC,4CAAK,mCAAmC,2CAAQ;AAGxG;;;;;;;;;;;;;;;;;;ACN6C;AAChB;AAC/B;AACA,OAAO,8CAAO;AACd,MAAM,+CAAQ;AACd,eAAe,4CAAK,mCAAmC,2CAAQ;AAC/D;AACA;AAGE;;;;;;;;;;;;;;;;;ACV6B;AAC/B,4CAA4C,4CAAK,eAAe,eAAe;AAG7E;;;;;;;;;;;;;;;;;;;;ACDkB;AACc;AACO;AACV;AAC/B;AACA,gBAAgB,iDAAc;AAC9B,UAAU,YAAY,EAAE,mDAAY;AACpC;AACA;AACA;AACA;AACA;AACA,iBAAiB,qDAAK,CAAC,2CAAI;AAC3B,SAAS,4CAAK;AACd;AAGE;;;;;;;;;;;;;;;;ACpBF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGE;;;;;;;;;;;;;;;;;;ACnC2C;AACP;AACtC;AACA,YAAY,mDAAY;AACxB,SAAS,4CAAK;AACd;AAGE;;;;;;;;;;;;;;;;;;ACR2C;AACE;AAC/C;AACA,eAAe,mDAAY;AAC3B;AACA;AACA;AACA,QAAQ,6CAAM;AACd,MAAM,6CAAM;AACZ;AACA;AACA;AACA;AACA;AACA;AAGE;;;;;;;;;;;;;;;;;;ACjB2C;AACW;AACxD;AACA,YAAY,mDAAY;AACxB,MAAM,4CAAK;AACX,EAAE,6CAAM,CAAC,+CAAQ;AACjB;AACA;AAGE;;;;;;;;;;;;;;;;;ACV2C;AAC7C;AACA,eAAe,mDAAY;AAC3B;AACA;AAGE;;;;;;;;;;;;;;;;;;ACP2C;AACW;AACxD;AACA,YAAY,mDAAY;AACxB,MAAM,4CAAK;AACX,EAAE,6CAAM,CAAC,+CAAQ;AACjB;AACA;AAGE;;;;;;;;;;;;;;;;;;ACV2C;AACW;AACxD;AACA,YAAY,mDAAY;AACxB,MAAM,4CAAK;AACX,EAAE,6CAAM;AACR,IAAI,+CAAQ;AACZ;AACA;AACA;AACA;AAGE;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACboB;AACA;AACC;AACE;AACH;AACE;AACH;AACC;AACE;AACF;AACK;AACL;AACE;AACD;AACI;AACH;;;;;;;;;;;;;;;;;;ACfqB;AACW;AACxD;AACA,YAAY,mDAAY;AACxB,MAAM,4CAAK;AACX,EAAE,6CAAM,CAAC,+CAAQ;AACjB;AACA;AAGE;;;;;;;;;;;;;;;;;;ACV2C;AACoB;AACjE;AACA,eAAe,mDAAY;AAC3B;AACA,EAAE,6CAAM,CAAC,8CAAO;AAChB,gBAAgB,wCAAK;AACrB,EAAE,6CAAM,gCAAgC,2CAAQ;AAChD;AACA;AAGE;;;;;;;;;;;;;;;;;;ACZ2C;AACW;AACxD;AACA,YAAY,mDAAY;AACxB,MAAM,4CAAK;AACX,EAAE,6CAAM;AACR,IAAI,+CAAQ;AACZ;AACA;AACA;AACA;AAGE;;;;;;;;;;;;;;;;;ACb2C;AAC7C;AACA,eAAe,mDAAY;AAC3B;AACA;AAGE;;;;;;;;;;;;;;;;;ACP2C;AAC7C;AACA,eAAe,mDAAY;AAC3B;AACA;AAGE;;;;;;;;;;;;;;;;;;ACP2C;AACa;AAC1D;AACA,eAAe,mDAAY;AAC3B,EAAE,6CAAM;AACR,IAAI,8CAAO,0CAA0C,2CAAQ;AAC7D;AACA;AACA,EAAE,6CAAM;AACR;AACA;AACA;AACA;AACA;AAGE;;;;;;;;;;;;;;;;;;;AChB2C;AACW;AACjB;AACvC;AACA,eAAe,mDAAY;AAC3B;AACA;AACA,MAAM,4CAAK;AACX,EAAE,6CAAM,CAAC,+CAAQ;AACjB,SAAS,mDAAQ;AACjB;AAGE;;;;;;;;;;;;;;;;;;ACb2C;AACW;AACxD;AACA,YAAY,mDAAY;AACxB,MAAM,4CAAK;AACX,EAAE,6CAAM;AACR,IAAI,+CAAQ;AACZ;AACA;AACA;AACA;AAGE;;;;;;;;;;;;;;;;;;ACb2C;AACY;AACzD;AACA,iBAAiB,mDAAY;AAC7B,MAAM,+CAAQ,OAAO,+CAAQ,OAAO,6CAAM,OAAO,6CAAM;AACvD,MAAM,6CAAM,OAAO,+CAAQ;AAC3B,EAAE,6CAAM;AACR;AAGE;;;;;;;;;;;;;;;;;;;ACV2C;AACW;AACjB;AACvC;AACA,cAAc,mDAAY;AAC1B;AACA;AACA,MAAM,4CAAK;AACX,EAAE,6CAAM,CAAC,+CAAQ;AACjB,EAAE,6CAAM;AACR,IAAI,4CAAK,YAAY,+CAAQ;AAC7B;AACA;AACA,SAAS,mDAAQ;AACjB;AAGE;;;;;;;;;;;;;;;;;;ACjB2C;AACU;AACvD;AACA,eAAe,mDAAY;AAC3B,EAAE,6CAAM;AACR,IAAI,8CAAO;AACX;AACA;AACA,gBAAgB,wCAAK;AACrB;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AAGE;;;;;;;;;;;;;;;;;;ACpB2C;AACkB;AAC/D;AACA,cAAc,mDAAY;AAC1B,EAAE,6CAAM,CAAC,8CAAO;AAChB;AACA,WAAW,8CAAO;AAClB,QAAQ,8CAAO;AACf;AACA,MAAM;AACN;AACA,MAAM,6CAAM;AACZ,QAAQ,+CAAQ,YAAY,0CAAG,iBAAiB,0CAAG;AACnD;AACA;AACA;AACA;AACA;AACA,GAAG,IAAI;AACP;AAGE;;;;;;;;;;;;;;;;;;ACtB2C;AACU;AACvD;AACA,iBAAiB,mDAAY;AAC7B,EAAE,6CAAM,CAAC,8CAAO;AAChB;AACA;AACA,QAAQ,4CAAK;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AAGE;;;;;;;;;;;;;;;;;;ACdqB;AACwC;AAC/D;AACA,gBAAgB,mDAAY;AAC5B,MAAM,4CAAK;AACX,EAAE,6CAAM,CAAC,8CAAO;AAChB,gBAAgB,iDAAc;AAC9B;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA,cAAc,mDAAY;AAC1B;AACA;AACA;AACA;AACA;AACA,WAAW,6CAAM;AACjB,GAAG;AACH;AAGE;;;;;;;;;;;;;;;;;;;AC3B2C;AACmB;AACJ;AAC5D;AACA,MAAM,8CAAO,cAAc,0DAAO;AAClC,cAAc,mDAAY;AAC1B,MAAM,4CAAK;AACX,EAAE,6CAAM;AACR,IAAI,8CAAO;AACX;AACA;AACA,SAAS,8CAAO;AAChB;AAGE;;;;;;;;;;;;;;;;;;;ACf2C;AACU;AACQ;AAC/D;AACA,MAAM,8CAAO,cAAc,4DAAQ;AACnC,UAAU,WAAW,EAAE,mDAAY;AACnC,MAAM,4CAAK;AACX,EAAE,6CAAM,CAAC,8CAAO;AAChB,SAAS,4DAAQ,UAAU,oBAAoB;AAC/C;AAGE;;;;;;;;;;;;;;;;;;ACZ2C;AACY;AACzD;AACA,sBAAsB,mDAAY;AAClC,EAAE,6CAAM,CAAC,8CAAO;AAChB,yBAAyB,8CAAO;AAChC;AAGE;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACT4B;AACE;AACD;AACN;AACD;AACC;AACJ;AACU;AACL;AACH;AACC;AACF;AACC;AACA;AACD;AACE;AACC;AACM;AACR;AACC;AACI;AACN;;;;;;;;;;;;;;;;;;ACrBuB;AACmB;AAChE;AACA,eAAe,mDAAY;AAC3B,MAAM,4CAAK;AACX;AACA;AACA,MAAM,4CAAK;AACX,EAAE,6CAAM,CAAC,8CAAO;AAChB;AACA;AACA,MAAM,4CAAK;AACX;AACA,EAAE,6CAAM;AACR;AACA;AACA;AACA;AACA;AACA,cAAc,8CAAO;AACrB;AACA;AACA,GAAG;AACH;AACA;AAGE;;;;;;;;;;;;;;;;;;AC3B2C;AACL;AACxC,yCAAyC,8CAAO,CAAC,mDAAY;AAG3D;;;;;;;;;;;;;;;;;;;ACL2C;AACmB;AACP;AACzD;AACA,MAAM,8CAAO,cAAc,wDAAM;AACjC,cAAc,mDAAY;AAC1B,MAAM,4CAAK;AACX,EAAE,6CAAM;AACR,IAAI,8CAAO;AACX;AACA;AACA,SAAS,8CAAO;AAChB;AAGE;;;;;;;;;;;;;;;;;;;ACf2C;AACU;AACK;AAC5D;AACA,MAAM,8CAAO,cAAc,0DAAO;AAClC,UAAU,WAAW,EAAE,mDAAY;AACnC,MAAM,4CAAK;AACX,EAAE,6CAAM,CAAC,8CAAO;AAChB,SAAS,0DAAO,UAAU,oBAAoB;AAC9C;AAGE;;;;;;;;;;;;;;;;;;ACTqB;AACgC;AACvD;AACA,gBAAgB,mDAAY;AAC5B,MAAM,4CAAK;AACX,EAAE,6CAAM,CAAC,8CAAO;AAChB,gBAAgB,iDAAc;AAC9B;AACA;AACA,WAAW,mDAAY;AACvB;AACA;AACA;AACA;AACA,qBAAqB;AACrB,OAAO;AACP;AACA,GAAG;AACH;AAGE;;;;;;;;;;;;;;;;;;;ACxB2C;AACU;AACE;AACzD;AACA,MAAM,8CAAO,cAAc,wDAAM;AACjC,UAAU,WAAW,EAAE,mDAAY;AACnC,MAAM,4CAAK;AACX,EAAE,6CAAM,CAAC,8CAAO;AAChB,SAAS,wDAAM,UAAU,oBAAoB;AAC7C;AAGE;;;;;;;;;;;;;;;;;;;ACZ2C;AACU;AACE;AACzD;AACA,MAAM,8CAAO,cAAc,wDAAM;AACjC,UAAU,WAAW,EAAE,mDAAY;AACnC,MAAM,4CAAK;AACX,EAAE,6CAAM,CAAC,8CAAO;AAChB,SAAS,wDAAM,UAAU,oBAAoB;AAC7C;AAGE;;;;;;;;;;;;;;;;;ACZ0E;AAC5E,aAAa,qEAAwB,CAAC,6CAAK;AAGzC;;;;;;;;;;;;;;;;;ACJ2C;AAC7C;AACA,cAAc,mDAAY;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGE;;;;;;;;;;;;;;;;;;ACbqB;AACgC;AACvD;AACA,gBAAgB,iDAAc;AAC9B,gBAAgB,mDAAY;AAC5B,uBAAuB,mDAAY;AACnC;AACA,MAAM,4CAAK;AACX,EAAE,6CAAM,CAAC,8CAAO;AAChB;AACA,WAAW,mDAAY;AACvB;AACA;AACA;AACA;AACA,qBAAqB;AACrB,OAAO;AACP;AACA,GAAG;AACH;AAGE;;;;;;;;;;;;;;;;;;ACzB2C;AACU;AACvD;AACA,cAAc,mDAAY;AAC1B,MAAM,4CAAK;AACX,EAAE,6CAAM,CAAC,8CAAO;AAChB;AACA;AACA;AACA;AAGE;;;;;;;;;;;;;;;;;;ACZ2C;AACL;AACxC;AACA,gBAAgB,mDAAY;AAC5B,SAAS,8CAAO;AAChB;AAGE;;;;;;;;;;;;;;;;;;ACR2C;AACC;AAC9C;AACA,eAAe,mDAAY;AAC3B;AACA;AACA;AACA,MAAM,4CAAK;AACX;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA,IAAI,6CAAM;AACV;AACA;AACA;AACA;AACA;AACA;AACA;AAGE;;;;;;;;;;;;;;;;;;;;AC5B2C;AACR;AACqC;AAC9B;AAC5C;AACA,UAAU,gBAAgB,EAAE,mDAAY;AACxC,MAAM,4CAAK;AACX,EAAE,6CAAM,CAAC,8CAAO;AAChB,MAAM,+CAAQ;AACd,WAAW,qDAAK,CAAC,2CAAI;AACrB;AACA;AACA,cAAc,0CAAO;AACrB;AACA;AACA;AAGE;;;;;;;;;;;;;;;;;;AClB2C;AACqB;AAClE;AACA,iBAAiB,mDAAY;AAC7B;AACA,MAAM,4CAAK;AACX,EAAE,6CAAM,CAAC,8CAAO;AAChB,EAAE,6CAAM,CAAC,gDAAS;AAClB,MAAM,8CAAO;AACb,IAAI,6CAAM;AACV;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,4CAAK;AACb,IAAI,6CAAM;AACV,MAAM,8CAAO;AACb;AACA;AACA;AACA;AACA;AACA;AACA,kBAAkB,cAAc;AAChC;AACA,aAAa,4CAAK;AAClB,KAAK;AACL;AACA;AACA;AACA;AAGE;;;;;;;;;;;;;;;;;;ACnC2C;AACoB;AACjE;AACA,EAAE,6CAAM,CAAC,8CAAO,WAAW,GAAG;AAC9B,eAAe,mDAAY;AAC3B,gBAAgB,wCAAK;AACrB,EAAE,6CAAM;AACR,eAAe,2CAAQ;AACvB,OAAO,GAAG;AACV;AACA;AACA;AAGE;;;;;;;;;;;;;;;;;ACdoC;AACtC,gBAAgB,kDAAO;AACvB;AACA;AACA;AAGE;;;;;;;;;;;;;;;;;;ACP2C;AACe;AAC5D;AACA,YAAY,mDAAY;AACxB,MAAM,4CAAK;AACX,MAAM,+CAAQ;AACd,YAAY,6CAAU;AACtB;AAGE;;;;;;;;;;;;;;;;;ACVoC;AACtC,eAAe,kDAAO;AACtB;AACA;AACA;AAGE;;;;;;;;;;;;;;;;;ACPoC;AACtC,gBAAgB,kDAAO;AACvB;AACA;AACA;AAGE;;;;;;;;;;;;;;;;;;;;;;;ACPuB;AACA;AACD;AACC;;;;;;;;;;;;;;;;;;ACHoB;AACN;AACvC;AACA,gBAAgB,mDAAY;AAC5B,SAAS,6CAAM,qDAAqD,6CAAM;AAC1E;AAGE;;;;;;;;;;;;;;;;;;;;;ACRoB;AACA;AACD;;;;;;;;;;;;;;;;;;ACFwB;AACO;AACpD;AACA,sBAAsB,kDAAW;AACjC;AACA,EAAE,6CAAM;AACR,UAAU,mDAAY;AACtB;AAGE;;;;;;;;;;;;;;;;;;ACV2C;AACN;AACvC;AACA,gBAAgB,mDAAY;AAC5B;AACA,SAAS,6CAAM,qCAAqC,6CAAM;AAC1D;AAGE;;;;;;;;;;;;;;;;;;ACT2C;AACY;AACzD;AACA,eAAe,mDAAY;AAC3B,EAAE,6CAAM;AACR,IAAI,8CAAO;AACX;AACA;AACA,SAAS,8CAAO;AAChB;AAGE;;;;;;;;;;;;;;;;;ACZwE;AAC1E,YAAY,qEAAwB,CAAC,4CAAI;AAGvC;;;;;;;;;;;;;;;;;ACJwE;AAC1E,YAAY,qEAAwB,CAAC,4CAAI;AAGvC;;;;;;;;;;;;;;;;;ACJ0E;AAC5E,aAAa,qEAAwB,CAAC,6CAAK;AAGzC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACJoB;AACD;AACA;AACC;AACD;AACC;AACD;;;;;;;;;;;;;;;;;ACNqD;AAC1E,YAAY,qEAAwB,CAAC,4CAAI;AAGvC;;;;;;;;;;;;;;;;;ACJ0E;AAC5E,aAAa,qEAAwB,CAAC,6CAAK;AAGzC;;;;;;;;;;;;;;;;;ACJwE;AAC1E,YAAY,qEAAwB,CAAC,4CAAI;AAGvC;;;;;;;;;;;;;;;;;;ACJ2C;AACqB;AAClE;AACA;AACA;AACA;AACA;AACA,MAAM,8CAAO;AACb,IAAI,6CAAM;AACV;AACA;AACA;AACA,IAAI;AACJ,IAAI,6CAAM,CAAC,+CAAQ;AACnB;AACA;AACA;AACA;AACA,oBAAoB,6CAAM;AAC1B,IAAI,mDAAY;AAChB;AACA;AACA,SAAS,mDAAY;AACrB;AAGE;;;;;;;;;;;;;;;;;;AC1B2C;AACP;AACtC;AACA,eAAe,mDAAY;AAC3B,6BAA6B,4CAAK;AAClC;AAGE;;;;;;;;;;;;;;;;;;;;;ACRqB;AACE;AACA;;;;;;;;;;;;;;;;;;ACFoB;AACN;AACvC;AACA;AACA;AACA,sBAAsB,6CAAM;AAC5B,MAAM,mDAAY;AAClB;AACA;AACA;AACA;AACA,GAAG;AACH,SAAS,mDAAY;AACrB;AACA;AACA;AACA;AACA;AACA;AAGE;;;;;;;;;;;;;;;;;;ACrB2C;AACN;AACvC;AACA,EAAE,6CAAM;AACR;AACA;AACA;AACA,aAAa,mDAAY;AACzB;AACA;AAGE;;;;;;;;;;;;;;;;;ACZyB;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACAkB;AACuB;AACpE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,UAAU,sCAAsC,EAAE,IAAI;AACtD,UAAU,sCAAsC,EAAE,IAAI;AACtD,UAAU,kDAAkD;AAC5D,UAAU,yDAAyD;AACnE,UAAU,oDAAoD;AAC9D,UAAU,gDAAgD;AAC1D,UAAU,mDAAmD;AAC7D,UAAU,6CAA6C,EAAE,IAAI;AAC7D,UAAU,4CAA4C;AACtD,UAAU,uDAAuD;AACjE,UAAU,0DAA0D;AACpE;AACA;AACA;AACA;AACA,GAAG;AACH,UAAU,kDAAkD,EAAE;AAC9D;AACA,CAAC;AACD;AACA;AACA,MAAM,4CAAK;AACX;AACA;AACA,4DAA4D,iBAAiB;AAC7E,2DAA2D,iBAAiB;AAC5E;AACA;AACA;AACA;AACA,cAAc,6CAAU,cAAc,MAAM;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM,6CAAM;AACZ,YAAY,mDAAY;AACxB,MAAM,6CAAM;AACZ,MAAM,+CAAQ;AACd;AACA,iBAAiB,6CAAM;AACvB;AACA;AACA;AACA;AACA;AACA,gCAAgC,sBAAsB;AACtD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAgCE;;;;;;;;;;;;;;;;;;ACjO2C;AACP;AACtC;AACA,eAAe,mDAAY;AAC3B,SAAS,kDAAO;AAChB;AAGE;;;;;;;;;;;;;;;;;;ACR2C;AAWxB;AACrB;AACA,UAAU,kDAAkD,EAAE,mDAAY;AAC1E;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,wDAAa;AACpC,EAAE,qDAAU;AACZ,EAAE,qDAAU;AACZ;AACA;AACA,aAAa,uDAAY;AACzB;AACA,aAAa,0DAAe;AAC5B;AACA,aAAa,wDAAa;AAC1B;AACA,aAAa,uDAAY;AACzB;AACA,aAAa,sDAAW;AACxB;AACA,aAAa,uDAAY;AACzB;AACA;AACA;AACA;AACA;AACA;AACA,wCAAwC,yDAAkB;AAC1D;AACA;AACA;AACA,wCAAwC,yDAAkB;AAC1D;AACA;AACA;AAGE;;;;;;;;;;;;;;;;;;ACrD2C;AAMxB;AACrB;AACA;AACA,4BAA4B,qDAAU;AACtC;AACA;AACA,eAAe,mDAAY;AAC3B,uBAAuB,wDAAa;AACpC,eAAe,yDAAkB,4BAA4B,QAAQ;AACrE,6BAA6B,yDAAkB;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA,uDAAuD,uDAAgB;AACvE,8CAA8C,uDAAgB;AAC9D;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGE;;;;;;;;;;;;;;;;;;;AClD2C;AACW;AAOnC;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,EAAE;AAC5B,GAAG;AACH;AACA;AACA;AACA,eAAe,mDAAY;AAC3B,+BAA+B,kDAAW;AAC1C;AACA;AACA,MAAM,4CAAK;AACX;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wCAAwC,SAAS;AACjD;AACA,kBAAkB,qDAAc;AAChC,QAAQ,+CAAQ;AAChB;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ;AACR;AACA;AACA;AACA;AACA,MAAM,4CAAK,oBAAoB,4CAAK,qBAAqB,4CAAK;AAC9D;AACA;AACA;AACA,EAAE,6CAAM;AACR;AACA;AACA,2FAA2F,UAAU;AACrG;AACA,qDAAqD,uDAAgB,GAAG,wDAAa;AACrF;AACA;AACA;AACA,OAAO,4CAAK;AACZ,OAAO,4CAAK;AACZ,OAAO,4CAAK;AACZ,OAAO,4CAAK;AACZ;AACA,EAAE,qDAAU;AACZ;AACA;AAGE;;;;;;;;;;;;;;;;;;AC9E2C;AACR;AACrC;AACA,iBAAiB,mDAAY;AAC7B,SAAS,kDAAQ,QAAQ,8BAA8B;AACvD;AAGE;;;;;;;;;;;;;;;;;;ACR2C;AACiC;AAC9E;AACA,eAAe,mDAAY;AAC3B;AACA,aAAa,wDAAa;AAC1B,EAAE,qDAAU;AACZ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,sDAAW;AAC9B,eAAe,kDAAO;AACtB;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AAGE;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC5B2C;AACW;AASnC;AACsB;AACZ;AACgB;AACV;AACQ;AACV;AACF;AACE;AACJ;AACA;AAC/B;AACA,QAAQ,yCAAK;AACb,QAAQ,yCAAK;AACb,QAAQ,0CAAM;AACd,QAAQ,oDAAW;AACnB,QAAQ,wCAAK;AACb,QAAQ,4CAAO;AACf,QAAQ,6CAAO;AACf,QAAQ,sDAAY;AACpB,QAAQ,wDAAa;AACrB,QAAQ,yCAAK;AACb,QAAQ,8CAAQ;AAChB;AACA;AACA,eAAe,mDAAY;AAC3B,MAAM,4CAAK;AACX,MAAM,4CAAK;AACX,eAAe,sDAAW;AAC1B,8BAA8B,kDAAW;AACzC,uBAAuB,wDAAa;AACpC;AACA,EAAE,qDAAU;AACZ,wCAAwC,SAAS;AACjD;AACA,kBAAkB,qDAAc;AAChC;AACA;AACA,QAAQ,+CAAQ;AAChB;AACA,gBAAgB,yDAAc;AAC9B,QAAQ;AACR;AACA,QAAQ;AACR,QAAQ,6CAAM;AACd;AACA,gDAAgD,gBAAgB;AAChE;AACA,gBAAgB,oDAAS;AACzB;AACA;AACA;AACA;AACA;AACA;AAGE;;;;;;;;;;;;;;;;;;;;ACnE2C;AACD;AACU;AAcjC;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO,kDAAW;AAClB,SAAS,oDAAa;AACtB,WAAW,sDAAe;AAC1B,QAAQ,mDAAY;AACpB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI,EAAE,mDAAY;AAClB,MAAM,4CAAK,UAAU,4CAAK;AAC1B;AACA,EAAE,6CAAM;AACR,IAAI,6CAAM;AACV;AACA;AACA,EAAE,6CAAM,CAAC,8CAAU;AACnB,EAAE,6CAAM;AACR,sBAAsB,uDAAgB;AACtC,gCAAgC,YAAY;AAC5C;AACA,EAAE,6CAAM;AACR,IAAI,4CAAK;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sCAAsC,yDAAkB;AACxD;AACA;AACA;AACA;AACA;AACA;AACA,MAAM,6CAAM;AACZ;AACA;AACA;AACA;AACA,kCAAkC,qDAAU;AAC5C,gCAAgC,oDAAa,wBAAwB,oDAAa;AAClF;AACA,oDAAoD,yDAAkB;AACtE;AACA,+BAA+B,uDAAY;AAC3C,QAAQ;AACR;AACA;AACA;AACA,sBAAsB,kDAAO;AAC7B;AACA;AACA;AACA;AACA;AACA,2BAA2B,wDAAa;AACxC,MAAM,qDAAU;AAChB;AACA;AACA;AACA;AAGE;;;;;;;;;;;;;;;;;AChGwC;AAC1C;AACA,SAAS,sDAAW;AACpB;AAGE;;;;;;;;;;;;;;;;;ACNwC;AAC1C;AACA,SAAS,sDAAW;AACpB;AAGE;;;;;;;;;;;;;;;;;ACNmD;AACrD;AACA,SAAS,oDAAS,CAAC,sDAAW;AAC9B;AAGE;;;;;;;;;;;;;;;;;ACNwC;AAC1C;AACA,SAAS,sDAAW;AACpB;AAGE;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACNwB;AACC;AACK;AACC;AACF;AACD;AACC;AACH;AACC;AACD;AACA;AACL;AACQ;AACL;AACI;AACA;AACL;AACD;AACC;AACF;AACA;;;;;;;;;;;;;;;;;ACpBmB;AAC1C;AACA,SAAS,sDAAW;AACpB;AAGE;;;;;;;;;;;;;;;;;ACNiD;AACnD;AACA,SAAS,kDAAO,CAAC,sDAAW;AAC5B;AAGE;;;;;;;;;;;;;;;;;ACNqD;AACvD,6CAA6C,sDAAW,CAAC,sDAAW;AAGlE;;;;;;;;;;;;;;;;;ACJwC;AAC1C;AACA,SAAS,sDAAW;AACpB;AAGE;;;;;;;;;;;;;;;;;ACNwC;AAC1C;AACA,SAAS,sDAAW;AACpB;AAGE;;;;;;;;;;;;;;;;;ACNwC;AAC1C;AACA,SAAS,sDAAW;AACpB;AAGE;;;;;;;;;;;;;;;;;ACNwC;AAC1C;AACA,SAAS,sDAAW;AACpB;AAGE;;;;;;;;;;;;;;;;;ACNiD;AACnD;AACA,YAAY,sDAAW;AACvB,iBAAiB,kDAAO;AACxB;AACA;AACA;AACA;AACA;AAGE;;;;;;;;;;;;;;;;;ACXwC;AAC1C;AACA,SAAS,sDAAW;AACpB;AAGE;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACN2B;AACL;AACE;AACA;AACG;AACC;AACL;AACF;AACG;AACD;AACF;AACE;AACI;AACP;AACG;AACK;AACP;AACI;;;;;;;;;;;;;;;;ACjB3B;AAGE;;;;;;;;;;;;;;;;;;ACHwC;AACkB;AAC5D;AACA,gBAAgB,mDAAY;AAC5B,SAAS,4DAAQ,UAAU,oBAAoB;AAC/C;AAGE;;;;;;;;;;;;;;;;;;ACR2C;AACqB;AAClE;AACA,eAAe,mDAAY;AAC3B,yBAAyB,+CAAQ;AACjC,MAAM,4CAAK;AACX,EAAE,6CAAM;AACR,IAAI,+CAAQ;AACZ;AACA;AACA,EAAE,6CAAM;AACR,IAAI,+CAAQ;AACZ;AACA;AACA;AACA;AAGE;;;;;;;;;;;;;;;;;;;;;AClByB;AACJ;AACM;;;;;;;;;;;;;;;;ACF7B;AAGE;;;;;;;;;;;;;;;;;ACH2C;AAC7C,6DAA6D,mDAAY;AAGvE;;;;;;;;;;;;;;;;;;;;;;;ACJ6B;AACC;AACL;AACE;;;;;;;;;;;;;;;;;;ACHgB;AACP;AACtC;AACA,eAAe,mDAAY;AAC3B;AACA;AACA,QAAQ,4CAAK;AACb;AACA;AACA;AACA;AACA;AACA;AAGE;;;;;;;;;;;;;;;;;;ACf2C;AACmB;AAChE;AACA,cAAc,mDAAY;AAC1B,MAAM,4CAAK;AACX,EAAE,6CAAM;AACR,IAAI,+CAAQ;AACZ,wDAAwD,6CAAM,MAAM;AACpE;AACA;AACA;AACA;AACA;AACA,oBAAoB;AACpB;AACA;AACA;AAGE;;;;;;;;;;;;;;;;;;ACnB2C;AACqB;AAClE;AACA,UAAU,sBAAsB,EAAE,mDAAY;AAC9C;AACA;AACA;AACA;AACA;AACA,MAAM,4CAAK;AACX,EAAE,6CAAM;AACR,IAAI,+CAAQ;AACZ;AACA;AACA,EAAE,6CAAM;AACR,IAAI,+CAAQ;AACZ;AACA;AACA,mBAAmB;AACnB;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AAGE;;;;;;;;;;;;;;;;;AC5BqC;AACvC;AACA,SAAS,oDAAS;AAClB;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AAGE;;;;;;;;;;;;;;;;;;ACbwC;AAC8B;AACxE;AACA,gBAAgB,mDAAY;AAC5B,SAAS,oEAAY,UAAU,6BAA6B;AAC5D;AAGE;;;;;;;;;;;;;;;;;;ACR2C;AACN;AACvC;AACA,eAAe,mDAAY;AAC3B,2BAA2B,6CAAM;AACjC;AAGE;;;;;;;;;;;;;;;;;;ACR2C;AACN;AACvC;AACA,eAAe,mDAAY;AAC3B,0BAA0B,6CAAM;AAChC;AAGE;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACRgC;AACD;AACD;AACJ;AACM;AACJ;AACH;;;;;;;;;;;;;;;;;;ACNkB;AACoB;AACjE;AACA,eAAe,mDAAY;AAC3B,MAAM,4CAAK;AACX,EAAE,6CAAM,CAAC,8CAAO;AAChB,gBAAgB,wCAAK;AACrB,EAAE,6CAAM;AACR,EAAE,6CAAM,YAAY,0CAAO;AAC3B,YAAY,2CAAQ;AACpB;AACA;AACA;AACA;AAGE;;;;;;;;;;;;;;;;;;AChB2C;AACa;AAC1D;AACA,eAAe,mDAAY;AAC3B,EAAE,6CAAM;AACR,IAAI,8CAAO,qBAAqB,0CAAO;AACvC;AACA;AACA,cAAc,2CAAQ;AACtB;AACA,kBAAkB,iBAAiB;AACnC;AACA;AACA,oBAAoB,gBAAgB;AACpC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGE;;;;;;;;;;;;;;;;;;ACxB2C;AACwB;AACrE;AACA,eAAe,mDAAY;AAC3B,MAAM,4CAAK;AACX,EAAE,6CAAM;AACR,IAAI,8CAAO,qBAAqB,0CAAO;AACvC;AACA;AACA,SAAS,mDAAY;AACrB;AAGE;;;;;;;;;;;;;;;;;;ACb2C;AACa;AAC1D;AACA,eAAe,mDAAY;AAC3B,EAAE,6CAAM;AACR,IAAI,8CAAO,qBAAqB,0CAAO;AACvC;AACA;AACA;AACA;AACA,cAAc,2CAAQ;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGE;;;;;;;;;;;;;;;;;;ACtB2C;AAC2B;AACxE;AACA,eAAe,mDAAY;AAC3B,MAAM,4CAAK;AACX,EAAE,6CAAM,CAAC,8CAAO;AAChB,gBAAgB,wCAAK;AACrB,SAAS,6CAAM,CAAC,8CAAO;AACvB;AAGE;;;;;;;;;;;;;;;;;;;ACX2C;AACW;AACxD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,cAAc,mDAAY;AAC1B;AACA,MAAM,4CAAK;AACX,qBAAqB,4CAAK;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,cAAc,mDAAY;AAC1B,OAAO,+CAAQ;AACf;AACA;AACA,IAAI,6CAAM;AACV;AACA;AACA;AACA,IAAI,6CAAM;AACV;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,cAAc;AAClC;AACA;AACA;AACA;AACA;AACA;AACA;AAIE;;;;;;;;;;;;;;;;;;AC1F2C;AACW;AACxD;AACA,eAAe,mDAAY;AAC3B,EAAE,6CAAM;AACR,sBAAsB,+CAAQ,OAAO,4CAAK;AAC1C;AACA;AACA,gBAAgB,wCAAK;AACrB;AACA;AAGE;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACbuB;AACM;AACP;AACI;AACG;AACF;AACA;AACA;AACL;AACA;AACK;AACC;AACH;AACF;AACK;AACH;AACD;AACA;AACH;;;;;;;;;;;;;;;;;;AClBsB;AACqB;AAClE;AACA,cAAc,mDAAY;AAC1B;AACA,MAAM,4CAAK;AACX,EAAE,6CAAM,CAAC,+CAAQ,YAAY,+CAAQ;AACrC;AACA;AACA;AACA;AACA,cAAc,4CAAK,WAAW,+CAAQ;AACtC,oBAAoB,4CAAK,SAAS,+CAAQ;AAC1C,EAAE,6CAAM;AACR;AACA;AACA;AACA;AACA;AACA;AAGE;;;;;;;;;;;;;;;;;ACtBuC;AACzC;AACA,SAAS,qDAAU,uBAAuB,0BAA0B;AACpE;AAGE;;;;;;;;;;;;;;;;;ACNwC;AAC1C;AACA,iBAAiB,sDAAW,uBAAuB,eAAe;AAClE;AACA;AAGE;;;;;;;;;;;;;;;;;ACPwC;AAC1C;AACA,SAAS,sDAAW,uBAAuB,cAAc;AACzD;AAGE;;;;;;;;;;;;;;;;;ACNwC;AAC1C;AACA,SAAS,sDAAW,uBAAuB,eAAe;AAC1D;AAGE;;;;;;;;;;;;;;;;;;ACN2C;AACW;AACxD;AACA,eAAe,mDAAY;AAC3B;AACA,eAAe,wCAAK;AACpB,EAAE,6CAAM;AACR,cAAc,2CAAQ;AACtB;AACA;AACA;AACA;AAGE;;;;;;;;;;;;;;;;;;ACd2C;AACW;AACxD;AACA,eAAe,mDAAY;AAC3B;AACA,eAAe,wCAAK;AACpB,EAAE,6CAAM;AACR,cAAc,2CAAQ;AACtB;AACA;AACA;AACA;AAGE;;;;;;;;;;;;;;;;;ACduC;AACzC;AACA,SAAS,qDAAU,uBAAuB,0BAA0B;AACpE;AAGE;;;;;;;;;;;;;;;;;;ACN2C;AACW;AACxD;AACA,eAAe,mDAAY;AAC3B,MAAM,4CAAK;AACX,EAAE,6CAAM;AACR,eAAe,2CAAQ;AACvB;AACA;AACA;AACA;AAGE;;;;;;;;;;;;;;;;;ACb2C;AAC7C;AACA,qBAAqB,mDAAY;AACjC;AACA;AACA;AAGE;;;;;;;;;;;;;;;;;ACR2C;AAC7C;AACA,SAAS,mDAAY;AACrB;AAGE;;;;;;;;;;;;;;;;;;ACN2C;AACoB;AACjE;AACA,eAAe,mDAAY;AAC3B;AACA;AACA,MAAM,8CAAO,qBAAqB,wCAAK;AACvC,EAAE,6CAAM;AACR,eAAe,2CAAQ;AACvB;AACA;AACA;AACA;AACA;AACA;AAGE;;;;;;;;;;;;;;;;;;ACjB2C;AACJ;AACzC;AACA,4BAA4B,mDAAY;AACxC,oBAAoB,+CAAQ;AAC5B;AACA;AACA;AAGE;;;;;;;;;;;;;;;;;;ACV2C;AACc;AAC3D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kCAAkC,SAAS;AAC3C;AACA;AACA;AACA;AACA;AACA,eAAe,mDAAY;AAC3B;AACA;AACA;AACA,EAAE,6CAAM;AACR,IAAI,+CAAQ,OAAO,+CAAQ,yBAAyB,+CAAQ;AAC5D;AACA;AACA;AACA;AACA;AACA,kBAAkB,gBAAgB;AAClC;AACA;AACA;AACA;AACA;AACA,EAAE,6CAAM;AACR;AACA;AACA;AACA;AACA;AAGE;;;;;;;;;;;;;;;;;AC5CiC;AACnC;AACA,SAAS,gDAAO;AAChB;AAGE;;;;;;;;;;;;;;;;;;ACN2C;AACL;AACxC;AACA,gBAAgB,mDAAY;AAC5B,SAAS,8CAAO;AAChB;AAGE;;;;;;;;;;;;;;;;;;ACR2C;AACL;AACxC;AACA,gBAAgB,mDAAY;AAC5B,SAAS,8CAAO;AAChB;AAGE;;;;;;;;;;;;;;;;;ACRuC;AACzC;AACA,SAAS,qDAAU,uBAAuB,yBAAyB;AACnE;AAGE;;;;;;;;;;;;;;;;;;ACN2C;AACF;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B;AAC7B;AACA;AACA,cAAc,mDAAY;AAC1B,sBAAsB,EAAE;AACxB,wBAAwB,EAAE;AAC1B;AACA,kBAAkB,6CAAU;AAC5B,2BAA2B,QAAQ;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AAGE;;;;;;;;;;;;;;;;;AC5BsD;AACxD,cAAc,oEAAyB;AACvC;AACA;AACA,CAAC;AAGC;;;;;;;;;;;;;;;;;ACPsD;AACxD,eAAe,oEAAyB;AACxC;AACA;AACA,CAAC;AAGC;;;;;;;;;;;;;;;;;ACPsD;AACxD,cAAc,oEAAyB;AAGrC;;;;;;;;;;;;;;;;;ACJsD;AACxD,eAAe,oEAAyB;AACxC;AACA;AACA,CAAC;AAGC;;;;;;;;;;;;;;;;;ACPsD;AACxD,cAAc,oEAAyB;AAGrC;;;;;;;;;;;;;;;;;;ACJ2C;AACP;AACtC;AACA,iBAAiB,mDAAY;AAC7B,kBAAkB,4CAAK;AACvB,kBAAkB,4CAAK;AACvB;AACA;AAGE;;;;;;;;;;;;;;;;;ACVsD;AACxD,eAAe,oEAAyB;AACxC;AACA;AACA,CAAC;AAGC;;;;;;;;;;;;;;;;;ACPsD;AACxD,aAAa,oEAAyB;AAGpC;;;;;;;;;;;;;;;;;ACJsD;AACxD,cAAc,oEAAyB;AACvC;AACA;AACA,CAAC;AAGC;;;;;;;;;;;;;;;;;ACPsD;AACxD;AACA,0BAA0B,oEAAyB;AACnD;AACA;AACA;AACA;AACA;AACA;AAGE;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACXqB;AACC;AACD;AACC;AACD;AACC;AACA;AACF;AACC;AACY;AACA;AACb;AACC;AACD;;;;;;;;;;;;;;;;;ACbkC;AACxD;AACA,0BAA0B,oEAAyB;AACnD;AACA;AACA;AACA;AACA;AACA;AAGE;;;;;;;;;;;;;;;;;ACXsD;AACxD,aAAa,oEAAyB;AAGpC;;;;;;;;;;;;;;;;;ACJsD;AACxD,cAAc,oEAAyB;AACvC;AACA;AACA,CAAC;AAGC;;;;;;;;;;;;;;;;;ACPsD;AACxD,aAAa,oEAAyB;AAGpC;;;;;;;;;;;;;;;;;;;;;;;ACJ2C;AACqB;AAClE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,cAAc,mDAAY;AAC1B;AACA;AACA,MAAM,4CAAK;AACX,MAAM,6CAAM;AACZ;AACA,MAAM,+CAAQ;AACd,SAAS,+CAAQ;AACjB;AACA;AACA;AACA;AACA,uBAAuB,IAAI,OAAO,gCAAgC;AAClE;AACA;AAQE;;;;;;;;;;;;;;;;;;;;;;;;;AClC2C;AACP;AACS;AACZ;AACA;AACI;AACN;AACE;AACI;AACvC;AACA,eAAe,mDAAY;AAC3B;AACA,MAAM,4CAAK;AACX;AACA;AACA;AACA;AACA,eAAe,oDAAS;AACxB;AACA;AACA;AACA,eAAe,gDAAO;AACtB;AACA;AACA,eAAe,gDAAO;AACtB;AACA;AACA;AACA;AACA;AACA,eAAe,oDAAS;AACxB;AACA;AACA,eAAe,8CAAM;AACrB;AACA;AACA,eAAe,gDAAO;AACtB;AACA,IAAI;AACJ;AACA;AACA,YAAY,uDAAgB,8BAA8B,QAAQ;AAClE;AAGE;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC7CwB;AACC;AACF;AACA;AACG;AACD;AACH;AACC;AACE;AACJ;;;;;;;;;;;;;;;;;;ACTsB;AACJ;AACzC;AACA,YAAY,mDAAY;AACxB,SAAS,+CAAQ;AACjB;AAGE;;;;;;;;;;;;;;;;;;ACR2C;AACG;AAChD;AACA,cAAc,mDAAY;AAC1B,MAAM,4CAAK;AACX,MAAM,+CAAQ;AACd;AACA;AAGE;;;;;;;;;;;;;;;;;;;ACV2C;AACC;AACC;AAC/C;AACA,cAAc,mDAAY;AAC1B,MAAM,6CAAM;AACZ,MAAM,4CAAK;AACX;AACA;AACA;AACA,YAAY,uDAAgB,oBAAoB,IAAI;AACpD;AAGE;;;;;;;;;;;;;;;;;ACdqC;AACvC,mBAAmB,gDAAS;AAG1B;;;;;;;;;;;;;;;;;;;ACJ2C;AACW;AACT;AAC/C;AACA,cAAc,mDAAY;AAC1B,MAAM,4CAAK;AACX,MAAM,6CAAM;AACZ;AACA;AACA;AACA,MAAM,+CAAQ;AACd,YAAY,uDAAgB,oBAAoB,IAAI;AACpD;AAGE;;;;;;;;;;;;;;;;;ACfwD;AAC1D,uCAAuC,oDAAS,qBAAqB,8CAAO,EAAE,8CAAO;AAGnF;;;;;;;;;;;;;;;;;ACJ0D;AAC5D,wCAAwC,oDAAS,qBAAqB,+CAAQ,EAAE,+CAAQ;AAGtF;;;;;;;;;;;;;;;;;;;ACJ2C;AACC;AACO;AACrD;AACA,cAAc,mDAAY;AAC1B,MAAM,4CAAK;AACX,MAAM,6CAAM;AACZ,WAAW,iEAAa;AACxB;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AAGE;;;;;;;;;;;;;;;;;;;ACpB2C;AACc;AACZ;AAC/C;AACA,YAAY,mDAAY;AACxB;AACA;AACA;AACA,QAAQ,+CAAQ;AAChB;AACA,kBAAkB,8CAAO,SAAS,8CAAO;AACzC;AACA,QAAQ,+CAAQ;AAChB;AACA,SAAS,6CAAM;AACf;AAGE;;;;;;;;;;;;;;;;;AClBoB;;;;;;;;;;;;;;;;;ACGC;AACvB;AACA;AACA;AACA,qBAAqB,mDAAY;AACjC;AACA,SAAS,mDAAY;AACrB;AACA;AACA;AACA,IAAI,iDAAc,sBAAsB,WAAW;AACnD;AACA;AAGE;;;;;;;;;;;;;;;;AClBF;AACA;AACA;AACA;AAGE;;;;;;;;;;;;;;;;;;ACNwC;AACS;AACnD;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA,uBAAuB,mDAAY;AACnC;AACA,QAAQ,+CAAQ;AAChB,QAAQ;AACR,QAAQ,kDAAW;AACnB;AACA;AACA;AACA,GAAG;AACH;AAGE;;;;;;;;;;;;;;;;;;;ACpBwC;AACR;AAC2C;AAC7E;AACA;AACA;AACA;AACA;AACA,sCAAsC,SAAS;AAC/C,EAAE,6CAAM;AACR;AACA,yBAAyB,6CAAM,QAAQ,6CAAM,mBAAmB,8CAAO;AACvE;AACA,EAAE,6CAAM;AACR;AACA;AACA;AACA,OAAO,4CAAK,gBAAgB,6CAAM,iBAAiB,6CAAM;AACzD,IAAI,6CAAM;AACV,MAAM,8CAAO,4BAA4B,8CAAO;AAChD;AACA;AACA;AACA;AACA;AACA,oBAAoB,uBAAuB;AAC3C;AACA;AACA,SAAS,4CAAK;AACd;AACA,kBAAkB,mDAAY;AAC9B,UAAU,4CAAK,SAAS,8CAAO,oBAAoB,8CAAO;AAC1D,QAAQ,6CAAM;AACd,WAAW,4CAAK;AAChB;AACA;AACA;AACA,QAAQ;AACR,QAAQ,6CAAM;AACd,UAAU,8CAAO,qBAAqB,8CAAO;AAC7C;AACA;AACA,sBAAsB,sDAAe;AACrC;AACA;AACA;AACA,KAAK;AACL;AACA,SAAS,4CAAK;AACd,IAAI,6CAAM;AACV;AACA;AACA;AACA,WAAW,2CAAI;AACf;AACA,WAAW,mDAAY;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,SAAS,2CAAI;AACb;AACA;AACA,GAAG;AACH;AAGE;;;;;;;;;;;;;;;;;;;ACzEwC;AACR;AASd;AACpB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ,wCAAwC,SAAS;AACjD,EAAE,6CAAM;AACR;AACA,uEAAuE,YAAY;AACnF;AACA;AACA,IAAI,6CAAM;AACV;AACA;AACA;AACA,2CAA2C,YAAY;AACvD;AACA;AACA;AACA;AACA;AACA;AACA,cAAc,mDAAY;AAC1B,IAAI,6CAAM;AACV,sBAAsB,+CAAQ;AAC9B;AACA;AACA;AACA;AACA,GAAG;AACH;AACA,QAAQ,4CAAK;AACb,QAAQ,4CAAK;AACb,WAAW,8CAAO;AAClB,GAAG;AACH;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS,2CAAI;AACb,4BAA4B;AAC5B,YAAY,yBAAyB;AACrC;AACA,sBAAsB,mDAAY;AAClC;AACA;AACA;AACA;AACA;AACA;AACA,UAAU,8CAAO;AACjB;AACA;AACA;AACA;AACA;AACA,eAAe;AACf;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6FAA6F,8CAAO;AACpG;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,IAAI,6CAAM;AACV,MAAM,4CAAK,SAAS,4CAAK;AACzB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,EAAE,6CAAM;AACR;AACA;AACA;AACA,YAAY,sDAAe;AAC3B;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI,6CAAM,4BAA4B,KAAK,IAAI,IAAI;AACnD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGE;;;;;;;;;;;;;;;;;;ACnrBgC;AACqB;AACvD;AACA,EAAE,6CAAM;AACR,IAAI,+CAAQ,WAAW,8CAAO;AAC9B;AACA;AACA,SAAS,2CAAI;AACb;AACA;AACA;AACA;AACA;AAGE;;;;;;;;;;;;;;;;;;;;;;ACf0C;AACF;AACD;AAWrB;AACkC;AACvB;AAC/B,qCAAqC;AACrC;AACA,UAAU,qBAAqB;AAC/B;AACA,IAAI,6CAAM,CAAC,8CAAU;AACrB,IAAI,6CAAM;AACV;AACA;AACA;AACA,IAAI;AACJ,IAAI,6CAAM;AACV,MAAM,+CAAQ;AACd;AACA;AACA;AACA,MAAM,8CAAO;AACb,IAAI,6CAAM;AACV;AACA;AACA;AACA,IAAI,6CAAM;AACV,oBAAoB,2CAAQ,kBAAkB,yCAAM;AACpD;AACA;AACA,IAAI,6CAAM;AACV,2BAA2B,2CAAQ;AACnC;AACA;AACA;AACA;AACA,IAAI,6CAAM;AACV,MAAM,8CAAO;AACb;AACA;AACA;AACA,eAAe,4CAAK,eAAe,iBAAiB;AACpD,qBAAqB,iDAAc;AACnC;AACA,WAAW,+CAAQ,yBAAyB,kEAAQ;AACpD;AACA,QAAQ,sCAAsC;AAC9C;AACA;AACA;AACA,gCAAgC,8CAAU;AAC1C;AACA,cAAc,8CAAO;AACrB,QAAQ,4CAAK;AACb,QAAQ,+CAAQ;AAChB,MAAM,6CAAM;AACZ;AACA;AACA;AACA,MAAM,SAAS,6CAAM;AACrB,MAAM,6CAAM;AACZ;AACA;AACA;AACA,MAAM;AACN,MAAM,6CAAM;AACZ;AACA;AACA;AACA;AACA,4BAA4B,2CAAI;AAChC;AACA;AACA,QAAQ,4CAAK;AACb;AACA,aAAa;AACb,GAAG;AACH,8BAA8B,2CAAQ;AACtC;AACA;AACA,yBAAyB,8CAAO;AAChC;AACA;AACA;AACA;AACA;AACA,0BAA0B,2CAAI;AAC9B;AACA;AACA;AACA,QAAQ,8CAAO;AACf;AACA,eAAe,8CAAO;AACtB;AACA,MAAM,6CAAM;AACZ,2BAA2B,2CAAQ;AACnC;AACA;AACA;AACA,IAAI,6CAAM,CAAC,+CAAQ;AACnB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ;AACR;AACA,QAAQ;AACR;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB;AACvB;AACA;AACA;AACA,OAAO;AACP;AACA;AACA,aAAa;AACb,GAAG;AACH,+BAA+B,6CAAM;AACrC;AACA;AACA,6BAA6B,2CAAI;AACjC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B;AAC3B;AACA;AACA,SAAS;AACT,iBAAiB;AACjB;AACA;AACA,MAAM;AACN,aAAa;AACb,GAAG;AACH,SAAS,6CAAM;AACf;AAGE;;;;;;;;;;;;;;;;;;ACtL4C;AACF;AAC5C;AACA;AACA;AACA;AACA,iBAAiB,mDAAU;AAC3B;AACA,wBAAwB,iDAAc;AACtC,OAAO;AACP;AACA;AACA,GAAG;AACH;AAGE;;;;;;;;;;;;;;;;;;;;;;;AChBuC;AACU;AACQ;AACR;AACZ;AACE;AACY;AACrD;AACA;AACA;AACA;AACA;AACA,EAAE,6CAAM,iBAAiB,+CAAQ;AACjC,EAAE,6CAAM;AACR,6DAA6D,0CAAG;AAChE;AACA;AACA,EAAE,6CAAM;AACR;AACA;AACA;AACA,EAAE,6CAAM;AACR;AACA;AACA;AACA,YAAY,kDAAW;AACvB,qCAAqC,OAAO,uEAAE;AAC9C,iCAAiC,KAAK,8DAAa,+DAAE;AACrD;AACA;AACA;AACA;AACA,QAAQ,0CAAG;AACX,uBAAuB,uBAAuB,EAAE;AAChD,MAAM;AACN;AACA,MAAM,6CAAM,mCAAmC,YAAY;AAC3D,wBAAwB;AACxB;AACA;AACA;AACA,iBAAiB,kEAAgB;AACjC;AACA;AACA,iCAAiC;AACjC;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,iBAAiB,sDAAU;AAC3B;AACA;AACA;AAGE;;;;;;;;;;;;;;;;;;;;AC1DwC;AACR;AACwC;AACvC;AACnC;AACA,mBAAmB,+CAAQ;AAC3B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ,qCAAqC,aAAa,mBAAmB,IAAI;AACzE;AACA;AACA,IAAI,+CAAQ;AACZ;AACA;AACA,MAAM,mDAAY;AAClB;AACA;AACA;AACA,gBAAgB,2CAAQ;AACxB;AACA;AACA,gBAAgB,8CAAO;AACvB,QAAQ,gDAAO;AACf,UAAU,2CAAI;AACd;AACA;AACA;AACA;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA;AACA;AACA;AACA,MAAM,OAAO,4CAAK;AAClB;AACA;AACA;AACA,iDAAiD,kBAAkB,IAAI;AACvE,KAAK;AACL,aAAa;AACb,GAAG;AACH;AAGE;;;;;;;;;;;;;;;;;;ACnDkB;AAC8B;AAClD;AACA;AACA,EAAE,6CAAM,CAAC,0CAAG;AACZ;AACA,gBAAgB,iDAAc;AAC9B;AACA;AACA,uBAAuB,8CAAO;AAC9B;AACA,eAAe,mDAAY;AAC3B;AACA;AACA;AACA;AACA;AACA,4CAA4C;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,mDAAY;AAC/B;AACA;AACA;AACA,+BAA+B,SAAS;AACxC;AACA;AACA,eAAe;AACf;AACA,GAAG;AACH;AAGE;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACxC0B;AACH;AACI;AACL;AACE;AACF;AACD;AACO;AACN;AACA;AACC;AACD;AACA;AACF;AACI;AACD;AACK;AACA;AACL;AACH;AACY;AACX;AACA;AACO;AACF;AACJ;AACC;;;;;;;;;;;;;;;;AC1BzB;AAGE;;;;;;;;;;;;;;;;;;;ACH4C;AACJ;AAQtB;AACpB;AACA,mBAAmB,+CAAQ;AAC3B,UAAU,mDAAmD;AAC7D;AACA;AACA;AACA,gBAAgB,2CAAQ;AACxB;AACA,MAAM,kDAAW,CAAC,8CAAO;AACzB;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA,oBAAoB,8CAAO;AAC3B,UAAU,8CAAO;AACjB;AACA;AACA;AACA;AACA,kBAAkB,8CAAO;AACzB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA,kBAAkB,mDAAU;AAC5B,iBAAiB;AACjB;AACA,iBAAiB,mDAAY;AAC7B,uBAAuB;AACvB;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AAGE;;;;;;;;;;;;;;;;;AC9DkC;AACpC;AACA,gBAAgB,yCAAK;AACrB;AACA;AAGE;;;;;;;;;;;;;;;;;;;;ACP4C;AAI1B;AASA;AAC0B;AAC9C;AACA,iBAAiB,+CAAQ;AACzB,EAAE,6CAAM,CAAC,8CAAO;AAChB;AACA,kBAAkB,+CAAQ,mBAAmB,+CAAQ,CAAC,8CAAO,6CAA6C,+CAAQ,oBAAoB,8CAAO;AAC7I,cAAc,2CAAQ;AACtB,kBAAkB,mBAAmB;AACrC;AACA;AACA,IAAI,6CAAM;AACV;AACA;AACA;AACA;AACA;AACA,gBAAgB,iDAAc;AAC9B;AACA;AACA;AACA;AACA,wBAAwB,mDAAY;AACpC;AACA,sBAAsB,eAAe;AACrC;AACA;AACA;AACA;AACA,UAAU,8CAAO;AACjB,+BAA+B,mDAAU;AACzC;AACA;AACA,SAAS;AACT;AACA,QAAQ;AACR;AACA;AACA;AACA;AACA;AACA,sBAAsB,6CAAU;AAChC;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,0DAAa;AACrC;AACA;AACA;AACA,gCAAgC,WAAW;AAC3C;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,oBAAoB,6CAAU;AAC9B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AAGE;;;;;;;;;;;;;;;;;ACzFgE;AAClE;AACA,qBAAqB,+CAAQ;AAC7B,EAAE,6CAAM,CAAC,8CAAO;AAChB;AACA,oBAAoB,gDAAS;AAC7B;AACA,GAAG;AACH;AAGE;;;;;;;;;;;;;;;;;;ACPkB;AAkBA;AACpB;AACA,MAAM,8CAAO;AACb;AACA,4CAA4C,iDAAc;AAC1D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,+CAAQ,aAAa,gDAAS;AACtC;AACA;AACA,QAAQ;AACR;AACA;AACA,MAAM,SAAS,8CAAO;AACtB,gDAAgD,mDAAY;AAC5D,MAAM,SAAS,+CAAQ;AACvB;AACA;AACA,wBAAwB,kDAAW;AACnC;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B,kDAAW,0BAA0B,2CAAQ;AACxE,iCAAiC,mDAAY;AAC7C,UAAU;AACV;AACA;AACA,QAAQ,SAAS,iDAAU;AAC3B,+BAA+B,mDAAY;AAC3C,QAAQ;AACR;AACA;AACA,eAAe,0CAAG,iBAAiB,mDAAY;AAC/C;AACA,yBAAyB,8CAAO;AAChC;AACA,cAAc,8CAAO;AACrB,cAAc,+CAAQ;AACtB;AACA;AACA;AACA,MAAM;AACN,sBAAsB,+CAAQ,yCAAyC,mDAAY;AACnF;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM,4CAAK;AACX;AACA,QAAQ,kDAAW,cAAc,oBAAoB;AACrD;AACA;AACA;AACA,sBAAsB,mDAAY;AAClC,MAAM,4CAAK;AACX;AACA,6BAA6B,oDAAa;AAC1C;AACA;AACA;AACA,QAAQ,kDAAW,cAAc,oBAAoB;AACrD,QAAQ;AACR,QAAQ,+CAAQ;AAChB;AACA;AACA,yBAAyB,0CAAG;AAC5B,sBAAsB,8CAAO;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI,6CAAM;AACV,IAAI,6CAAM;AACV;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,IAAI,6CAAM;AACV;AACA;AACA;AACA;AACA;AAGE;;;;;;;;;;;;;;;;;AC7IkD;AACpD;AACA,gBAAgB,iDAAc;AAC9B;AACA,aAAa,6CAAM;AACnB;AACA;AAGE;;;;;;;;;;;;;;;;;;ACTwC;AACI;AAC9C;AACA;AACA,UAAU,mDAAY;AACtB,IAAI,6CAAM,CAAC,+CAAQ;AACnB;AACA,GAAG;AACH;AAGE;;;;;;;;;;;;;;;;;;ACXwC;AACI;AAC9C;AACA;AACA,UAAU,mDAAY;AACtB,IAAI,6CAAM,CAAC,+CAAQ;AACnB;AACA,GAAG;AACH;AAGE;;;;;;;;;;;;;;;;ACXF;AACA;AACA;AACA;AACA;AACA,sCAAsC;AACtC;AACA,eAAe;AACf;AACA,GAAG;AACH;AAGE;;;;;;;;;;;;;;;;;ACbuC;AACzC,aAAa,kDAAU;AAGrB;;;;;;;;;;;;;;;;;;;;;;;;;ACDkB;AACsB;AAC0B;AACV;AACJ;AACZ;AACD;AACR;AACF;AAC/B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,kDAAW;AACvB,qCAAqC,SAAS,sEAAE;AAChD;AACA;AACA,yBAAyB,6CAAU;AACnC,IAAI,6CAAM;AACV,QAAQ,kDAAW,6BAA6B,kDAAW;AAC3D,UAAU,GAAG;AACb;AACA,IAAI,6CAAM;AACV;AACA;AACA;AACA;AACA,cAAc,mBAAmB;AACjC,MAAM,6CAAM;AACZ;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB,4CAAK;AACtB;AACA,eAAe,8CAAM;AACrB;AACA;AACA;AACA,eAAe;AACf,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA,8CAA8C,6CAAU;AACxD;AACA;AACA;AACA,gBAAgB,kDAAW;AAC3B,iBAAiB,kDAAW;AAC5B,SAAS;AACT;AACA;AACA;AACA;AACA,MAAM,6CAAM;AACZ;AACA,WAAW,gCAAgC,GAAG,iCAAiC;AAC/E;AACA,MAAM,6CAAM;AACZ;AACA,WAAW,IAAI;AACf;AACA;AACA;AACA;AACA;AACA,qBAAqB,2CAAI;AACzB;AACA;AACA,gBAAgB,4BAA4B;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA,cAAc;AACd;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kBAAkB,yBAAyB;AAC3C;AACA,eAAe,sDAAW;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gDAAgD,2CAAQ;AACxD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB,kEAAQ;AACjC;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA,wBAAwB,+CAAQ;AAChC,wBAAwB,+CAAQ;AAChC,gBAAgB;AAChB;AACA,wBAAwB,+CAAQ;AAChC,wBAAwB,+CAAQ;AAChC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe;AACf;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,sDAAU;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA;AACA,KAAK;AACL,WAAW,6CAAM;AACjB,GAAG;AACH;AAGE;;;;;;;;;;;;;;;;AC9LF;AACA;AACA;AAGE;;;;;;;;;;;;;;;;;ACGkB;AACpB;AACA,MAAM,8CAAO,eAAe,+CAAQ;AACpC,YAAY,0CAAO;AACnB;AACA,MAAM,+CAAQ,mBAAmB,+CAAQ;AACzC;AACA;AACA;AACA;AACA;AACA,qBAAqB,8CAAO;AAC5B;AACA,iBAAiB,8CAAO;AACxB;AACA;AACA;AACA;AACA;AACA;AACA,MAAM,6CAAM;AACZ;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS,+CAAQ,QAAQ,+CAAQ,YAAY,8CAAO;AACpD;AACA;AACA;AACA;AACA;AACA;AAGE;;;;;;;;;;;;;;;;;;AClE+B;AACF;AAC/B;AACA,SAAS,4CAAK;AACd,IAAI,8CAAM,eAAe,oBAAoB,WAAW;AACxD,MAAM,WAAW;AACjB;AACA;AACA;AAGE;;;;;;;;;;;;;;;;;;;ACX4C;AACJ;AACJ;AACtC;AACA,gBAAgB,+CAAQ;AACxB;AACA;AACA,wBAAwB,mDAAU,yCAAyC,2CAAI;AAC/E;AACA,SAAS,6CAAM;AACf;AAGE;;;;;;;;;;;;;;;;;;ACbuC;AACJ;AACrC;AACA,SAAS,kDAAW;AACpB;AACA;AACA,SAAS,kDAAQ;AACjB;AAGE;;;;;;;;;;;;;;;;;;ACV0C;AASxB;AACpB;AACA,MAAM,+CAAQ,iBAAiB;AAC/B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS,2CAAI;AACb,aAAa;AACb,2BAA2B,2CAAQ;AACnC;AACA;AACA;AACA;AACA;AACA;AACA,cAAc,8CAAO;AACrB,UAAU,8CAAO;AACjB;AACA;AACA,UAAU,kDAAW;AACrB,mBAAmB;AACnB,UAAU;AACV,kBAAkB,2CAAI;AACtB,2BAA2B,mDAAY;AACvC;AACA,aAAa;AACb,YAAY,+CAAQ;AACpB;AACA,WAAW;AACX;AACA,QAAQ,UAAU,8CAAO;AACzB,iBAAiB;AACjB;AACA;AACA,GAAG;AACH;AAGE;;;;;;;;;;;;;;;;;ACrDqE;AACvE,aAAa,gEAAmB,CAAC,6CAAK;AAGpC;;;;;;;;;;;;;;;;;ACDyB;AAC3B,mBAAmB,gEAAmB,CAAC,mDAAW;AAGhD;;;;;;;;;;;;;;;;;;;;;ACPoB;AACM;AACL;;;;;;;;;;;;;;;;;ACFkD;AACzE,cAAc,gEAAmB,CAAC,8CAAM;AAGtC;;;;;;;;;;;;;;;;;;ACJsC;AACgB;AACxD;AACA,SAAS,gEAAmB;AAC5B;AACA;AACA,UAAU,8CAAO;AACjB;AACA,QAAQ;AACR;AACA;AACA;AACA;AACA;AACA;AAGE;;;;;;;;;;;;;;;;;ACjBkD;AACpD,sBAAsB,gEAAqB;AAGzC;;;;;;;;;;;;;;;;;ACJkD;AACpD,oBAAoB,gEAAqB;AACzC;AACA;AAGE;;;;;;;;;;;;;;;;;ACNkD;AACpD,sBAAsB,gEAAqB;AAC3C;AACA;AAGE;;;;;;;;;;;;;;;;;ACNkD;AACpD,oBAAoB,gEAAqB;AAGvC;;;;;;;;;;;;;;;;;;;;;;;ACJ6C;AACJ;AACI;AACJ;AAMzC;;;;;;;;;;;;;;;;;ACTmE;AACrE,YAAY,gEAAmB,CAAC,4CAAI;AAGlC;;;;;;;;;;;;;;;;;ACJmE;AACrE,YAAY,gEAAmB,CAAC,4CAAI;AAGlC;;;;;;;;;;;;;;;;;ACJqE;AACvE,aAAa,gEAAmB,CAAC,6CAAK;AAGpC;;;;;;;;;;;;;;;;;ACJmE;AACrE,YAAY,gEAAmB,CAAC,4CAAI;AAGlC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACJyB;AACA;AACE;AACF;AACA;AACE;AACF;AACE;AAU3B;;;;;;;;;;;;;;;;;ACjBmE;AACrE,YAAY,gEAAmB,CAAC,4CAAI;AAGlC;;;;;;;;;;;;;;;;;ACJqE;AACvE,aAAa,gEAAmB,CAAC,6CAAK;AAGpC;;;;;;;;;;;;;;;;;ACJmE;AACrE,YAAY,gEAAmB,CAAC,4CAAI;AAGlC;;;;;;;;;;;;;;;;;ACJqE;AACvE,aAAa,gEAAmB,CAAC,6CAAK;AAGpC;;;;;;;;;;;;;;;;;ACJ6D;AAC/D;AACA;AACA;AACA;AACA,kBAAkB,8CAAO;AACzB;AACA;AACA,iBAAiB,mDAAY,gBAAgB,qBAAqB;AAClE,gBAAgB,8CAAO;AACvB,WAAW,8CAAO;AAClB;AACA;AAGE;;;;;;;;;;;;;;;;;;;ACfuB;AACF;;;;;;;;;;;;;;;;;ACDkD;AACzE,cAAc,gEAAmB,CAAC,8CAAM;AAGtC;;;;;;;;;;;;;;;;;ACJ2C;AAC7C;AACA,kBAAkB,mDAAY;AAC9B;AAGE;;;;;;;;;;;;;;;;;;;;;;;;;ACNqB;AACM;AACP;AACE;AACA;;;;;;;;;;;;;;;;;ACJmB;AAC3C;AACA;AACA,cAAc,6CAAU;AACxB;AACA;AACA;AACA;AACA;AACA;AAGE;;;;;;;;;;;;;;;;;ACZqE;AACvE,aAAa,gEAAmB,CAAC,6CAAK;AAGpC;;;;;;;;;;;;;;;;;ACJyE;AAC3E,eAAe,gEAAmB,CAAC,+CAAO;AAGxC;;;;;;;;;;;;;;;;;ACJyD;AAC3D;AACA,EAAE,6CAAM;AACR;AACA;AACA;AACA;AACA,EAAE,6CAAM,CAAC,iDAAU;AACnB,kBAAkB,6CAAM;AACxB;AAGE;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACZsB;AACE;AACG;AACH;AACG;AACH;;;;;;;;;;;;;;;;;;ACLa;AACS;AAChD;AACA,EAAE,6CAAM;AACR,IAAI,8CAAO;AACX;AACA;AACA,wCAAwC,yCAAK;AAC7C;AACA;AAGE;;;;;;;;;;;;;;;;;;;;;;;ACZoB;AACA;AACA;AACD;;;;;;;;;;;;;;;;;;ACH2B;AACrB;AAC3B;AACA,EAAE,6CAAM;AACR,IAAI,8CAAO;AACX;AACA;AACA,YAAY,wCAAG;AACf;AACA;AAGE;;;;;;;;;;;;;;;;;;ACZqC;AACG;AAC1C;AACA;AACA,uBAAuB,gDAAS;AAChC,oBAAoB,yCAAK;AACzB;AACA;AAGE;;;;;;;;;;;;;;;;;;ACVqC;AACS;AAChD;AACA,EAAE,6CAAM,CAAC,8CAAO;AAChB,wCAAwC,yCAAK;AAC7C;AACA;AAGE;;;;;;;;;;;;;;;;;;;;;;;;;;ACTgD;AACqB;AACM;AACrB;AACpB;AAUhB;AACpB;AACA;AACA,gBAAgB,kDAAW;AAC3B,aAAa,0CAAO,oBAAoB,6CAAc,mBAAmB,0DAAgB,mBAAmB,6DAAmB;AAC/H,GAAG;AACH;AACA;AACA;AACA;AACA,aAAa,gDAAS;AACtB;AACA,UAAU,6CAAM;AAChB,UAAU,8CAAO;AACjB,UAAU,+CAAQ,gBAAgB;AAClC,UAAU,+CAAQ;AAClB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,cAAc,4BAA4B;AAC1C;AACA;AACA;AACA;AACA;AACA,EAAE,6CAAM;AACR;AACA;AACA;AACA;AACA;AACA;AACA,MAAM,6CAA6C;AACnD;AACA;AACA;AACA;AACA,UAAU,yBAAyB;AACnC;AACA;AACA;AACA,IAAI,2CAAI;AACR;AACA;AACA,YAAY,8CAAO;AACnB,OAAO,8CAAO;AACd;AACA,6BAA6B,QAAQ;AACrC;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA,gCAAgC;AAChC,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA,6CAA6C,WAAW;AACxD;AACA,WAAW;AACX,SAAS;AACT,OAAO;AACP;AACA;AACA,yBAAyB,yCAAK;AAC9B;AACA;AACA;AACA;AACA;AACA;AAOE;;;;;;;;;;;;;;;;;;ACxG+D;AAM5C;AACrB,2DAA2D,qDAAc;AACzE,SAAS,yDAAc;AACvB,mBAAmB;AACnB,QAAQ,+CAAQ,SAAS,0CAAG;AAC5B;AACA;AACA,WAAW,sDAAW;AACtB;AACA;AACA;AACA;AACA;AACA,uBAAuB,mDAAY;AACnC;AACA,eAAe,gDAAK,oBAAoB,6CAAM;AAC9C;AACA,OAAO;AACP,QAAQ;AACR;AACA,GAAG;AACH;AAGE;;;;;;;;;;;;;;;;;;AC9B4C;AAKzB;AACrB;AACA,sDAAsD,qDAAc;AACpE,SAAS,yDAAc;AACvB;AACA,IAAI,6CAAM;AACV;AACA,+BAA+B,MAAM;AACrC;AACA,WAAW,sDAAW;AACtB;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B,+CAAQ,OAAO,+CAAQ;AACrD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP,QAAQ;AACR;AACA,GAAG;AACH;AAGE;;;;;;;;;;;;;;;;;ACtCmB;AACrB,8DAA8D,qDAAc;AAC5E;AACA,SAAS,yDAAc;AACvB,WAAW,sDAAW;AACtB;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP,QAAQ;AACR;AACA,GAAG;AACH;AAGE;;;;;;;;;;;;;;;;;;ACtBqD;AACmB;AAC1E,sDAAsD,qDAAc;AACpE,SAAS,yDAAc;AACvB;AACA,gBAAgB,8CAAO;AACvB,MAAM,6CAAM;AACZ,wBAAwB,+CAAQ;AAChC;AACA;AACA;AACA,WAAW,sDAAW;AACtB;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP,QAAQ;AACR;AACA,GAAG;AACH;AAGE;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACzByB;AACL;AACQ;AACR;AACA;AACA;AACA;AACA;AACC;AACG;AACH;AACE;AACH;AACE;;;;;;;;;;;;;;;;;;ACba;AAKhB;AACrB,sDAAsD,qDAAc;AACpE,SAAS,yDAAc;AACvB,WAAW,sDAAW;AACtB;AACA;AACA;AACA;AACA,+BAA+B,8CAAO;AACtC;AACA;AACA,OAAO;AACP,QAAQ;AACR;AACA,GAAG;AACH;AAGE;;;;;;;;;;;;;;;;;;ACvBmC;AAKhB;AACrB,sDAAsD,qDAAc;AACpE,SAAS,yDAAc;AACvB,WAAW,sDAAW;AACtB;AACA;AACA;AACA;AACA,+BAA+B,8CAAO;AACtC;AACA;AACA,OAAO;AACP,QAAQ;AACR;AACA,GAAG;AACH;AAGE;;;;;;;;;;;;;;;;;ACnBmB;AACrB,sDAAsD,qDAAc;AACpE,SAAS,yDAAc;AACvB,WAAW,sDAAW;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP,QAAQ;AACR;AACA,GAAG;AACH;AAGE;;;;;;;;;;;;;;;;;;ACtB2C;AAKxB;AACrB,sDAAsD,qDAAc;AACpE,SAAS,yDAAc;AACvB,WAAW,sDAAW;AACtB;AACA,MAAM,6CAAM;AACZ,QAAQ,8CAAO;AACf,iBAAiB,cAAc;AAC/B;AACA;AACA;AACA;AACA,QAAQ;AACR;AACA;AACA;AACA,KAAK;AACL,GAAG;AACH;AAGE;;;;;;;;;;;;;;;;;;;AC1BkC;AACc;AAK7B;AACrB,uDAAuD,qDAAc;AACrE,SAAS,yDAAc;AACvB,kBAAkB,+CAAQ,+BAA+B,6CAAU;AACnE,sBAAsB,yCAAK;AAC3B,eAAe,SAAS;AACxB;AACA;AACA,4CAA4C,MAAM;AAClD,WAAW,sDAAW;AACtB;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA,KAAK;AACL,GAAG;AACH;AAGE;;;;;;;;;;;;;;;;;;AC/B2C;AACd;AAC/B,0DAA0D,qDAAc;AACxE;AACA;AACA,oBAAoB;AACpB,GAAG;AACH,SAAS,4CAAK;AACd;AAGE;;;;;;;;;;;;;;;;;;ACX8E;AAM3D;AACrB;AACA;AACA;AACA;AACA;AACA;AACA,uDAAuD,qDAAc;AACrE,SAAS,yDAAc;AACvB;AACA;AACA;AACA,QAAQ,+CAAQ,wCAAwC,0CAAG;AAC3D;AACA;AACA,WAAW,sDAAW;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,+CAAQ;AAC5B,8BAA8B,gDAAK;AACnC;AACA,0BAA0B,+CAAQ,2CAA2C;AAC7E;AACA,iDAAiD,8CAAO;AACxD,qCAAqC,8CAAO;AAC5C;AACA,YAAY,+CAAQ;AACpB;AACA;AACA;AACA,yCAAyC,8CAAO;AAChD,OAAO;AACP,QAAQ;AACR;AACA,GAAG;AACH;AAGE;;;;;;;;;;;;;;;;;;;ACjD+B;AAKZ;AACQ;AAC7B,yDAAyD,qDAAc;AACvE;AACA,kBAAkB,yDAAc;AAChC,WAAW,sDAAW;AACtB,WAAW,0CAAG;AACd,kBAAkB,0CAAI,QAAQ,aAAa;AAC3C;AACA;AACA,KAAK;AACL,GAAG;AACH;AACA;AAGE;;;;;;;;;;;;;;;;;;ACrBmC;AAMhB;AACrB,sDAAsD,qDAAc;AACpE,SAAS,yDAAc;AACvB,WAAW,sDAAW;AACtB;AACA;AACA;AACA;AACA,YAAY,8CAAO;AACnB,eAAe,gDAAK;AACpB;AACA,OAAO;AACP,QAAQ;AACR;AACA,GAAG;AACH;AAGE;;;;;;;;;;;;;;;;;;ACxBwC;AACgC;AAC1E,wDAAwD,qDAAc;AACtE,SAAS,yDAAc;AACvB,WAAW,sDAAW;AACtB,WAAW,0CAAG;AACd,UAAU,8CAAO;AACjB;AACA,QAAQ;AACR;AACA;AACA;AACA,KAAK;AACL,GAAG;AACH;AAGE;;;;;;;;;;;;;;;;;;;;;;ACjBwD;AACnB;AACuB;AACV;AACpD;AACA,QAAQ,qEAAc;AACtB,OAAO,qEAAc;AACrB,QAAQ,qEAAc;AACtB;AACA;AACA;AACA;AACA;AACA;AACA,OAAO,+DAAW;AAClB;AACA;AACA;AACA,2BAA2B,yBAAyB;AACpD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB,mDAAK;AAC1B,qBAAqB,8CAAO;AAC5B;AACA;AACA;AACA;AACA,eAAe;AACf,KAAK;AACL;AACA,cAAc,6BAA6B;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,8CAAO;AACnB;AACA;AACA;AACA;AACA;AACA,gBAAgB,6CAAU;AAC1B;AACA;AACA;AACA;AACA;AAKE;;;;;;;;;;;;;;;;;;;AC3EoC;AACC;AACA;AACvC;AACA;AACA,SAAS,mDAAQ;AACjB;AACA;AACA;AACA;AACA,qBAAqB,mDAAK;AAC1B;AACA;AACA;AACA,4BAA4B,+CAAQ;AACpC;AACA;AACA;AACA;AACA,6CAA6C,+CAAQ;AACrD;AACA;AACA;AACA,8CAA8C,+CAAQ;AACtD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AAGE;;;;;;;;;;;;;;;;;;;AC/CiC;AACS;AACL;AACvC;AACA,SAAS,mDAAQ;AACjB;AACA;AACA;AACA,qBAAqB,wDAAK;AAC1B,sBAAsB,mBAAmB;AACzC,YAAY,4CAAK;AACjB;AACA;AACA,KAAK;AACL;AACA;AACA;AAGE;;;;;;;;;;;;;;;;;;;ACnBgD;AAChB;AAC0C;AAC5E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sBAAsB,gDAAS;AAC/B,oBAAoB,kDAAW;AAC/B;AACA;AACA;AACA;AACA,IAAI,6CAAM;AACV,MAAM,+CAAQ;AACd,2CAA2C,gCAAgC;AAC3E;AACA;AACA;AACA;AACA,QAAQ,6CAAM;AACd;AACA;AACA;AACA,uCAAuC,aAAa;AACpD,QAAQ;AACR;AACA,QAAQ;AACR,QAAQ,6CAAM,EAAE,iDAAU,wCAAwC,MAAM;AACxE;AACA,UAAU,gDAAS;AACnB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB,kDAAW;AAC5B,IAAI,6CAAM,mCAAmC,SAAS;AACtD;AACA;AACA;AACA;AACA;AACA;AACA,eAAe;AACf;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,QAAQ;AACvB;AACA;AACA,eAAe,2CAAM;AACrB;AACA;AACA,sBAAsB;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,OAAO;AACtB;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AAGE;;;;;;;;;;;;;;;;AC5FF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGE;;;;;;;;;;;;;;;;;;;;;;ACbqD;AACO;AAC9B;AACK;AACrC;AACA,qCAAqC,sEAAc;AACnD,sDAAsD;AACtD;AACA,IAAI,6CAAM;AACV;AACA;AACA;AACA;AACA,IAAI,6CAAM;AACV,MAAM,0CAAG,CAAC,8CAAgB;AAC1B,0BAA0B,GAAG;AAC7B;AACA,mBAAmB,8CAAgB;AACnC;AACA,oBAAoB,yCAAK;AACzB;AACA;AACA;AACA;AACA;AACA;AACA;AAKE;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC/BF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,gBAAgB;AACpC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sBAAsB,cAAc;AACpC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC,QAAQ;AACzC;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qCAAqC,SAAS;AAC9C;AACA;AACA,QAAQ;AACR;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kCAAkC,kBAAkB;AACpD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,uBAAuB,EAAE,GAAG,sBAAsB,cAAc;AAC/E;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kBAAkB,uBAAuB;AACzC;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ;AACR;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,UAAU;AACV;AACA;AACA,QAAQ;AACR;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,iBAAiB;AACrC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,QAAQ;AACR;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ;AACR;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,UAAU;AACV;AACA;AACA;AACA;AACA;AACA;AACA,wCAAwC,SAAS;AACjD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC,QAAQ;AACzC;AACA;AACA,QAAQ;AACR;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,UAAU;AACV;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ;AACR;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B,eAAe,IAAI;AACjD;AACA;AACA,sDAAsD;AACtD;AACA,wBAAwB;AACxB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AA0CE;;;;;;;;;;;;;;;;;;AC5jBF;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB;AACpB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;;;;;;;;;;;;;;;;;;;ACrEA;AACA;AACA;;AAEwC;AAC4C;;AAEpF;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oDAAoD,sDAAM;AAC1D;AACA;AACA,QAAQ,kFAAyB;AACjC;AACA,SAAS;AACT;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN,MAAM,sEAAa;AACnB;AACA;AACA;AACA;AACA,wBAAwB,uBAAuB;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8CAA8C;;AAE9C;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ;AACR;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACM;AACP;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;AC5I8D;AAC0E;AACvF;;AAEjD;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,uBAAuB;AACnD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA,QAAQ,kFAAyB;AACjC;AACA,SAAS;AACT;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,0EAAiB;AACrC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS,8EAAY;AACrB;AACA;AACA;AACA,aAAa,kFAAyB;AACtC;AACA,GAAG;AACH;AACA;AACA;AACA,aAAa,kFAAyB;AACtC;AACA,GAAG;AACH,CAAC;;AAED;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B,0DAAY;AAC1C;AACA;AACA;AACA;AACA,wBAAwB,yBAAyB;AACjD;AACA;AACA,2BAA2B,4EAAmB;AAC9C;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ;AACR;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,+BAA+B;AAC5D;AACA;AACA;AACA,4BAA4B,4EAAmB;AAC/C,WAAW;AACX;AACA,OAAO;AACP;AACA,QAAQ,kFAAyB;AACjC;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;AC3NiE;AACY;AACQ;AACU;AACxF;AACP;AACA;AACA,IAAI;AACJ;AACA;AACA;AACO;AACA;AACP,SAAS,2EAAkB;AAC3B;AACA,+BAA+B,wEAAmB,oCAAoC,8DAAK;AAC3F;;AAEA;AACA;AACA;AACA;AACA;AACA,yBAAyB,sEAAiB;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,uBAAuB,oEAAe;AACtC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,uEAAc;AACtC,2BAA2B,uEAAc;AACzC;AACA;AACA,sBAAsB,+BAA+B;AACrD;AACA,2BAA2B,0FAAqC;AAChE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB,oEAAmB;AACxC;AACA;AACA,MAAM;AACN;AACA,MAAM,0DAAS;AACf;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;ACvGA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;;AAEA;AACA;AACA;AACO;AACP;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;ACzHuF;AACiE;AACtE;AAClF;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa,2EAAkB;AAC/B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM,uEAAc;AACpB;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,UAAU,8DAAK;AACf,UAAU;AACV;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ;AACR;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL;AACA;AACA;;AAEA;AACA,sBAAsB,+FAAwC;AAC9D;AACA;AACA,kBAAkB,0EAAiB;AACnC;AACA,KAAK;;AAEL;AACA;AACA;AACA,kBAAkB,0EAAiB;AACnC,uBAAuB,sEAAwB;AAC/C;AACA;AACA,iBAAiB,2EAAkB;AACnC;AACA;AACA;AACA;AACA;AACA,wCAAwC,uEAAc;AACtD,UAAU,uEAAc;AACxB,SAAS;AACT,QAAQ;AACR;AACA,sBAAsB,0EAA4B;AAClD;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACM;AACP;AACA,sBAAsB,kFAAyB;AAC/C;AACA;AACA,yCAAyC;AACzC;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA,6BAA6B,4EAAmB;AAChD;AACA,iBAAiB,4EAAmB;AACpC;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;;;;;;;;;;;;;;;AChKA;AACA;AACA;AACA;AACA;AACA;;AAEO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;AChCA;AACA;AACA;AACA;AACA;AAC0C;AAC8B;AAC5B;AACU;AACJ;AACD;AACE;AACQ;;AAE3D;AACA;AACA;AACA;AACA,YAAY,mDAAQ;AACpB,cAAc,0DAAmB;AACjC,WAAW,qDAAW;AACtB,gBAAgB,+DAAgB;AAChC,cAAc,2DAAc;AAC5B;AACA;AACA;;AAEA;AACA;AACA;AACA;AACO;AACP,EAAE,yDAAc;AAChB;AACA;AACA,GAAG;;AAEH;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA,YAAY,wDAAU;AACtB;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,UAAU,4DAAc;AACxB;AACA,KAAK;AACL;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,kBAAkB,0DAAY;AAC9B;AACA;AACA;AACA;AACA;AACA,QAAQ,4CAAK;AACb;AACA;AACA,QAAQ,4CAAK;AACb;AACA,KAAK;AACL;AACA;AACA;;;;;;;;;;;;;;;;;;;ACvF+C;AACI;AAC5C;AACP;AACA;AACA,UAAU,wDAAU;AACpB;AACA,KAAK;AACL;AACA;AACO;AACP;AACA;AACA;AACA,KAAK;AACL,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA,iEAAiE,+DAAc;AAC/E;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACtCqF;AAC8C;AACvF;AACP;AACE;AAChC;AACP;AACA;AACA;AACA;AACA,0BAA0B,4DAAW;AACrC,0BAA0B,4DAAW;AACrC,uBAAuB,yDAAQ;AAC/B,wBAAwB,0DAAS;AACjC,KAAK;AACL;AACA,0BAA0B,4DAAW;AACrC,0BAA0B,4DAAW;AACrC,uBAAuB,yDAAQ;AAC/B,wBAAwB,0DAAS;AACjC;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,UAAU,uFAA2B;AACrC;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,UAAU,uFAA2B;AACrC;AACA;AACA,KAAK;AACL;AACA;AACA,eAAe,8EAAkB;AACjC;AACA,KAAK;AACL;AACA,2BAA2B,8EAAkB;AAC7C,KAAK;AACL;AACA;AACA,eAAe,+FAAmC;AAClD;AACA,KAAK;AACL;AACA;AACA,eAAe,+FAAmC;AAClD;AACA;AACA,GAAG;AACH;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACpEmC;AACgB;AACgB;AACpB;AACqB;AACG;AACZ;AACI;AACV;AAC9C;AACA;AACA;AACP;AACA;AACA;AACA;AACA,sBAAsB,gFAAyB;AAC/C,uBAAuB,wDAAa,iCAAiC,4CAAM;AAC3E;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,KAAK,GAAG,yCAAG,6BAA6B,4EAAqB;AAC7D,oCAAoC,wEAAqB,gCAAgC,UAAU;;AAEnG;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,0BAA0B;AACpD;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,0DAAY;AACpC,gCAAgC,0DAAY;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACO;AACP;AACA;AACA;AACA;AACA,UAAU,wDAAU;AACpB;AACA;AACA,KAAK;AACL;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa,0DAAY;AACzB,GAAG;AACH;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACO;AACP,8BAA8B,oEAAW;AACzC,iIAAiI;AACjI;AACA;AACO;AACP;AACA;AACO,+BAA+B,6EAAuB;AAC7D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,GAAG;AACH;AACA,CAAC;AACD;;;;;;;;;;;;;;;;;;;;;;;;;ACxI4F;AACpC;AACe;AACK;;AAE5E;AACA;AACA;AACA;AACO;AACP,oBAAoB,oFAAwB;;AAE5C;AACA;AACA;AACA;AACA;AACA,WAAW,iFAAwB;AACnC,UAAU,2EAAkB;AAC5B;AACA;AACA,SAAS,kEAAW;AACpB;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,OAAO;AACP;AACA,GAAG;AACH;AACO;AACP,oBAAoB,oFAAwB;AAC5C;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA,SAAS,wEAAiB;AAC1B;AACA;AACA;AACA;AACA,GAAG;AACH;AACO;AACP,qBAAqB,+CAAS,QAAQ,8CAAQ;AAC9C;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,GAAG,GAAG,8CAAQ;AACd;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ;AACR;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,GAAG,GAAG,4CAAM,sCAAsC,yCAAG;AACrD;AACA,GAAG;AACH;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AClGkE;AACe;AAC5B;AACqB;AACQ;AACnB;AACoC;AACkC;AAC1B;AACvD;AACpD,uBAAuB,4EAA2B;AAClD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,EAAE,gFAAc;AAChB;AACA,CAAC;AACD;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA,UAAU,wDAAU;AACpB;AACA,KAAK;AACL,GAAG;AACH;AACA;AACA,GAAG;AACH;AACA;AACA,GAAG;AACH;AACA;AACA,gBAAgB,0EAAiB,CAAC,0FAAkC;AACpE;AACA,yCAAyC,4CAAM,0BAA0B,yCAAG,wDAAwD,4CAAM,oBAAoB,yCAAG,gBAAgB,mFAA8B,CAAC,uEAAc,iBAAiB,+CAAS,sDAAsD,2DAAoB,2CAA2C,yCAAG,0DAA0D,kDAAW,CAAC,+EAA0B;AAChd;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA,gBAAgB,0EAAiB,CAAC,0FAAkC;AACpE;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,4DAAc;AAC1B;AACA,OAAO;AACP;AACA,mBAAmB,qEAAW;AAC9B,eAAe,2DAAY;AAC3B;AACA,GAAG;AACH;AACA;AACA,QAAQ,2DAAY;AACpB;AACA,cAAc,wDAAU;AACxB;AACA,SAAS;AACT;AACA;AACA,cAAc,wDAAU;AACxB;AACA;AACA,uBAAuB,yCAAG,wCAAwC,yCAAG,SAAS,qEAAW,kBAAkB,2DAAoB;AAC/H,GAAG;AACH;AACA;AACA;AACA;AACA,GAAG;AACH;AACA,sBAAsB,oFAAwB;AAC9C;AACA;AACA;AACA,KAAK;AACL,GAAG;AACH;AACA;AACA;AACA;AACA,OAAO;AACP;AACA,KAAK;AACL,GAAG;AACH;AACA,sBAAsB,oFAAwB;AAC9C;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,oBAAoB,gGAAwC;AAC5D,gBAAgB,mEAAS;AACzB;AACA,KAAK;AACL,GAAG;AACH;AACA,sBAAsB,oFAAwB;AAC9C,oBAAoB,mEAAS;AAC7B;AACA,WAAW,mEAAW;AACtB;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,wBAAwB;;AAExB;AACA,qBAAqB,0DAAa;AAClC;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;;AAEH;AACA;AACA;AACA;AACA;AACA,UAAU,wDAAU;AACpB;AACA,KAAK;AACL;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA,MAAM,8DAAY;AAClB;AACA,IAAI;AACJ;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACpLmC;AACkF;AAC1D;AACwC;AACrD;AACyB;AAChE;AACA;AACP;AACA;AACA;AACA,IAAI,uDAAW,CAAC,+EAAwB;AACxC,GAAG;AACH;AACA;AACA,aAAa,kEAAe;AAC5B;AACA,GAAG;AACH;AACA;AACA;AACA,eAAe,kFAA2B,YAAY,iDAAW,CAAC,+EAA0B;AAC5F;AACA,KAAK;AACL;AACA;AACA,eAAe,2EAAkB,8CAA8C,oEAAgB;AAC/F;AACA;AACA;AACA,iBAAiB,0EAAqB;AACtC;AACA,eAAe,kEAAW;AAC1B;AACA;AACA;AACA;AACO;AACiC;AACD;AACF;AACrC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACzCuC;AAC4E;AAC1D;AACwE;AAC1H;AACP,0BAA0B,kEAAmB;AAC7C,yGAAyG,+FAA+B,MAAM,uFAA2B;AACzK;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA,0BAA0B,0DAAS;AACnC,0BAA0B,sDAAK;AAC/B;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa,iEAAoB;AACjC;AACA;AACA;AACA,GAAG;AACH;AACO;AACP;AACA,WAAW,iEAAoB;AAC/B,IAAI;AACJ;AACA,qBAAqB,0DAAS;AAC9B;AACA;AACA;;AAEA;AACA;AACA;AACO;AACP;AACA,WAAW,kEAAqB;AAChC;AACA;AACA;AACA;AACO;AACA;AACA;AACP;AACA;AACA;AACA;AACA;AACO;AACP,SAAS,mEAAkB,+DAA+D,iDAAe;AACzG;;AAEA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC5FyE;AACA;AACkF;AAC4B;AAC7E;AAC/B;AACwO;AAC9P;AACqG;AAC7E;AACtE;AACP;AACA;AACA;AACA,6BAA6B,iEAAoB;AACjD;AACA;AACA;AACA;AACA,6BAA6B,2EAAoB;AACjD,uBAAuB,kEAAW;AAClC,uBAAuB,+FAA+B,oBAAoB,6FAAiC;AAC3G,IAAI,kFAA2B;AAC/B,aAAa,oEAAa,qDAAqD,4CAAM,YAAY,yCAAG,MAAM,+DAAc,WAAW,iDAAW,CAAC,uEAA0B;AACzK;AACA;AACA;AACA,WAAW,oDAAc;AACzB;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oEAAoE,+EAA4B;AAChG;AACA;AACA;AACA;AACA;AACA,YAAY,wDAAU;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,gEAAgB;AAC7C,0BAA0B,wEAAoB;AAC9C;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA,eAAe,2DAAY;AAC3B,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA,cAAc,+FAA+B;AAC7C;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,kBAAkB,kEAAgB;AAClC;AACA,OAAO;AACP;AACA;;AAEA;AACA,UAAU,kEAAW;AACrB;AACA,gCAAgC;AAChC;AACA,OAAO;AACP,KAAK;AACL;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,wEAAiB;AAC9C,qBAAqB,uDAAK;AAC1B;AACA;AACA;AACA;AACA,qBAAqB,6FAAiC;AACtD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA,mBAAmB,0EAAwB;AAC3C,kBAAkB,oEAAkB;AACpC;AACA;AACA;AACA,qBAAqB,+DAAc;AACnC;AACA;AACA;AACA;AACA,kCAAkC,2DAAS;AAC3C;AACA;AACA;AACA,gBAAgB,kEAAW;AAC3B;AACA,sBAAsB,+DAAc;AACpC,WAAW,EAAE,6FAAiC;;AAE9C;AACA;AACA,UAAU;AACV;AACA,eAAe,sEAAwB;AACvC;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB,cAAc,mGAAkC,oBAAoB,oEAAa;AACjF;AACA,eAAe,2DAAY;AAC3B,KAAK;AACL,iCAAiC,sGAAqC;AACtE;AACA;AACA;AACA;AACA,IAAI,mFAAsB;AAC1B,2BAA2B,2FAA0B;AACrD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW;AACX,SAAS;AACT;AACA;AACA;AACA,4CAA4C,uFAA0B;AACtE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wCAAwC,0EAAmB;AAC3D;AACA;AACA;AACA,4DAA4D,uFAA0B,mBAAmB;AACzG;AACA,eAAe;AACf;AACA;AACA,WAAW;;AAEX;AACA;AACA;AACA;AACA,SAAS;AACT,iCAAiC,0CAAO;AACxC,OAAO;AACP;AACA;AACA;AACA;AACA,uBAAuB,mFAAsB;AAC7C;AACA,KAAK;AACL;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL,UAAU,qGAAoC;AAC9C,UAAU,gGAA+B;AACzC,UAAU,2FAA0B;AACpC;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,kEAAY,kBAAkB,yEAAmB;AAC3E;AACA,OAAO;AACP;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4CAA4C,uFAA0B;AACtE;AACA;AACA,sBAAsB,mGAAkC,CAAC,uDAAK,qCAAqC,oEAAa;AAChH;AACA;AACA;AACA;AACA,iBAAiB,2DAAY;AAC7B;AACA,mBAAmB;AACnB;AACA;AACA;AACA,OAAO;AACP;AACA;AACA,iBAAiB,2DAAY;AAC7B;AACA,mBAAmB;AACnB;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qCAAqC,oDAAc,aAAa,4CAAM,8BAA8B,oDAAc,aAAa,4CAAM;AACrI;AACA,YAAY,wDAAU;AACtB;AACA;AACA,OAAO;AACP,MAAM;AACN;AACA;AACA;AACA;AACA,CAAC;AACD;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC1VoH;AAClE;AACG;AACA;AACN;;AAE/C;AACA;AACO;AACP,qBAAqB,kFAAkB,CAAC,8DAAK;AAC7C,qCAAqC;;AAErC;AACA,SAAS,2DAAa;AACtB;AACA;AACA,GAAG;AACH;AACO;AACP;AACA,QAAQ,0DAAY;AACpB,YAAY,wDAAU;AACtB;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACgD;AACzC;AACP;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP,MAAM,kFAAsB;AAC5B;AACA,OAAO;AACP,MAAM,iFAAqB;AAC3B;AACA,OAAO;AACP;AACA;AACA;AACA;;;;;;;;;;;;;;;;AC/CA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN,yDAAyD;AACzD;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACO;AACP;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;AChCkE;AAClE;AACA;AACA;AACA;AAC8D;AACI;AAC3D;AACP;AACA;AACA;AACA;AACA,kCAAkC,gBAAgB;AAClD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,UAAU,4DAAc;AACxB;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,qBAAqB,cAAc,IAAI,qBAAqB;AAC5D;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,sBAAsB,gBAAgB,IAAI,cAAc;AACxD;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,sBAAsB,gBAAgB,IAAI,cAAc;AACxD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,sEAAsE;AACtE;AACA;AACA;;AAEA;AACA;AACA;AACA,cAAc,QAAQ;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,QAAQ;AACR;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,sEAAsE;AACtE;AACA;AACA;;AAEA;AACA;AACA;AACA,sCAAsC,2BAA2B,SAAS;AAC1E,4CAA4C,2BAA2B,SAAS;AAChF;AACA;AACA;AACA,UAAU;AACV;AACA,wBAAwB,mBAAmB;AAC3C;AACA,UAAU;AACV;AACA;AACA,qCAAqC,4DAAc;AACnD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM,SAAS,0DAAQ;AACvB;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,MAAM,yBAAyB,0DAAQ;AACvC;AACA;AACA,MAAM,WAAW,4DAAc;AAC/B;AACA;AACA;AACA;AACA;AACA,sEAAsE;AACtE;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,sBAAsB,wBAAwB;AAC9C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sBAAsB,gBAAgB;AACtC;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,uBAAuB,UAAU;AACjC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,eAAe,oBAAoB;AACnC,QAAQ,0DAAQ;AAChB;AACA;AACA;AACA;AACA,UAAU,4DAAc;AACxB;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,4DAAc;AAC1B;AACA,OAAO;AACP;AACA;AACA;;AAEA,8BAA8B,uDAAM;AACpC;AACA;AACA,QAAQ,uDAAM;AACd;AACA;AACA;AACA,QAAQ,uDAAM;AACd;AACA;AACA;AACA;;AAEA;AACA,IAAI,uDAAM;AACV;AACA;;AAEA;AACA;AACA;AACA;AACA,sBAAsB,wBAAwB;AAC9C;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,aAAa,QAAQ;AACrB;AACA;AACA;AACA,YAAY,wDAAU;AACtB;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACM;AACP;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA,CAAC;;AAED;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA,cAAc,wDAAU;AACxB;AACA;AACA,SAAS;AACT;AACA;AACA;AACA,QAAQ;AACR;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA,UAAU,4DAAc;AACxB;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,2CAA2C;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,UAAU,4DAAc;AACxB;AACA;AACA,KAAK;AACL;AACA;AACA,sCAAsC;AACtC;AACA;AACA;AACA;AACA;AACA;AACA,UAAU,4DAAc;AACxB;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA,uCAAuC;AACvC;AACA;;AAEA;AACA;AACA;AACO;AACP,oDAAoD,0DAAQ;AAC5D;AACO;AACP;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC7d8B;AACoF;AACnB;AACxF;AACA;AACA;AACA;AACP;AACA;AACO;AACP;AACA,cAAc,mEAAkB;AAChC;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,0DAAS;AACjC;AACA,wBAAwB,wCAAK;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,GAAG;AACH;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACO;AACA;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA,UAAU,0DAAS;AACnB;AACA;AACA,cAAc,4DAAW;AACzB;AACA;AACA,IAAI,4DAAW;AACf,GAAG;AACH;AACA;AACO;AACP;AACA;AACA;AACA,MAAM,0DAAS;AACf;AACA;AACA,cAAc,4DAAW;AACzB;AACA,IAAI,4DAAW;AACf,GAAG;AACH;AACA;;AAEA;AACA;AACA;AACO;AACP;AACA;AACA,IAAI;AACJ;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACO;AACP;AACA;AACA,IAAI;AACJ;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;AACA;AACA;AACA;AACO;AACP;;AAEA;AACA;AACA;AACA;AACA,mBAAmB,iFAA2B;AAC9C;AACA;;AAEA;AACA;AACA;AACA,oBAAoB,wDAAO;AAC3B;AACA,KAAK;AACL;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,GAAG;AACH,2FAA2F;;AAE3F;AACA;AACA;;AAEA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB,wDAAO;AACxB;AACA;AACA;AACA;AACA;AACA,sBAAsB,2EAAqB;AAC3C;AACA;AACA;AACA,KAAK;AACL,GAAG;AACH;AACA,SAAS,4DAAW;AACpB;AACA;;;;;;;;;;;;;;;;;;;;;AChP8D;AACgB;AAC8B;AACrG;AACP,YAAY,wDAAS;AACrB;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;AACA,6BAA6B,wDAAS;AACtC;AACA,IAAI;AACJ;AACA;AACA;AACO;AACP;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;;AAEA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,oEAAe;AAClC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA,+BAA+B,mEAAqB;AACpD;AACA;AACA,mDAAmD,8EAA4B;AAC/E;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,oEAAkB;AAC1C;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY;AACZ;AACA;AACA,UAAU;AACV;AACA;AACA;AACA;AACA,KAAK;AACL,GAAG;AACH;AACA,yBAAyB,sEAAiB;AAC1C;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+BAA+B,mEAAqB;AACpD;AACA;AACA,mDAAmD,8EAA4B;AAC/E;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL,GAAG;AACH;AACA;AACA;;;;;;;;;;;;;;;;;;;;;ACtJ0D;AACkB;AACS;AACvB;AACf;AACxC;AACP;AACA,gBAAgB,mEAAqB;AACrC,uBAAuB,sEAAY;AACnC;AACA;AACA;AACA;AACA,IAAI,8FAAuC;;AAE3C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,wDAAU;AAC1B;AACA;AACA,WAAW;AACX;AACA,OAAO;AACP;AACA,WAAW,yFAA0B;AACrC;AACA;AACA,CAAC;AACM,wCAAwC;AAC/C;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;ACtC+B;AACyC;AAC2E;AACzF;AACc;AACmB;AACN;AACtC;AAC/C,iBAAiB,oDAAG;AACpB;AACO;AACP;AACA,wBAAwB,yCAAO;AAC/B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,iFAA2B;AAClD;AACA;AACA;AACA;AACA,uCAAuC,+DAAc;AACrD;AACA;AACA,MAAM;AACN;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,cAAc,wDAAU;AACxB;AACA;AACA;AACA,SAAS;AACT;AACA,KAAK;AACL;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kBAAkB,2EAAoB;AACtC;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA,wCAAwC,6DAAW;AACnD;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP,oBAAoB,8EAAuB;AAC3C;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA,OAAO;AACP,yCAAyC,oEAAkB;AAC3D;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,cAAc,oEAAkB;AAChC;AACA,SAAS;AACT,OAAO;AACP;AACA;AACA,cAAc,oEAAkB;AAChC;AACA,SAAS;AACT,OAAO;AACP;AACA,mGAAmG,oEAAkB;AACrH,KAAK;AACL,kBAAkB,+DAAc;AAChC;AACA,sBAAsB,+DAAc;AACpC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B,6DAAW;AACtC;AACA;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL;AACA;AACA;AACA;AACA,WAAW,2DAAU;AACrB;AACA;AACA;AACA,yBAAyB,2DAAU;AACnC;AACA;AACA;AACA;AACA,MAAM;AACN,0BAA0B,2DAAU;AACpC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,oDAAG;AAC/B;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,aAAa,oEAAkB;AAC/B;AACA;AACA;AACA;AACA,QAAQ;AACR;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,8DAAY;AACxB,KAAK;AACL;AACA;AACA;AACA,CAAC;AACM;AACP,kBAAkB,sEAAoB;AACtC;AACA,QAAQ,8FAAgC,CAAC,mEAAqB;AAC9D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;AC9NA;AACA;AACA;AACA;AACA;AACkE;AAChB;AAC3C;AACP;AACA,qBAAqB,+DAAY;AACjC;AACA,GAAG;AACH;AACO;AACP;AACA,mBAAmB,+DAAY;AAC/B;AACA;AACO;AACP,SAAS,2EAAsB;AAC/B;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;AClCA;AACA;AACA;;AAE8C;AACJ;AAC1C;AACO;AACP;AACA,uBAAuB,4DAAa;AACpC;AACA,KAAK;AACL;AACA,mBAAmB,sDAAK;AACxB;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACpBO;AACP;AACA;;AAEA;AACA;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACA;AACO;AACP;AACA;;AAEA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP,kBAAkB,gBAAgB;AAClC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;;AAEA;AACA;AACA;AACO;AACP;AACA,6BAA6B,IAAI;AACjC;AACA;AACA;AACA;AACO;AACP;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kBAAkB,aAAa;AAC/B;AACA;AACA;;AAEA;AACA;AACA;AACO;AACP;AACA;AACA,GAAG;AACH;AACO;AACP;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;AC7J8C;AAC9C;AACA;AACA;AACA;AACA;AACO;AACA;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP,yBAAyB;AACzB;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA,QAAQ;AACR;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACO;AACP;AACA;AACO;AACP,YAAY,2DAAS;AACrB;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;;;;;;;;;;;;;;;;;ACtF4C;;AAE5C;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA,kBAAkB,yDAAO;AACzB,GAAG;AACH;AACA,+LAA+L,qBAAqB,sCAAsC,8CAA8C;AACxS;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;ACnCA;AACA;AACA;AACA;AACO;AACP;;;;;;;;;;;;;;;;;ACLO;AACP;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACA;AACP;AACA;AACA,kBAAkB,SAAS;AAC3B;AACA,aAAa;AACb;AACA;AACA;AACA;;;;;;;;;;;;;;;;ACxBO;AACP;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;ACjBA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,UAAU;AACjC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB,UAAU;AAC/B,qBAAqB,UAAU;AAC/B;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;ACnCA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACO;AACP;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sBAAsB,0BAA0B;AAChD;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B,UAAU;AACrC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sBAAsB,0BAA0B;AAChD;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA,sBAAsB,0BAA0B;AAChD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;ACvSO;AACP;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEO;AACP;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,iBAAiB;AACrC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACO;AACP,yBAAyB;AACzB;;AAEA;AACA;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACA;;AAEA;AACA;AACA;AACA;AACO;AACP,wBAAwB;;AAExB;AACA;AACA;AACA;AACA,0CAA0C;AAC1C,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;;AAEP;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;AC/NO;AACP;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACO;AACP,wCAAwC;AACxC;AACA;AACA;AACA;AACA,+BAA+B;AAC/B;;AAEA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;ACzDsD;AACF;AACO;AACpD;AACA;AACP,wBAAwB,oEAAqB;AAC7C;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA,QAAQ,+DAAiB,mBAAmB,+DAAiB,gCAAgC,iEAAiB,CAAC,+DAAiB;AAChI;AACA,MAAM;AACN;AACA;AACA,GAAG;AACH;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;AC7BA;AACA;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;;AAEA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACO;AACA;AACA;AACA;AACA;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP,KAAK;AACL,IAAI;AACJ;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA,GAAG;AACH;AACA;;AAEA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;;AAEA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;;;;;;;;;;;;;;;;ACvGO;AACA;AACP;;;;;;;;;;;;;;;;;ACFA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA,sBAAsB,yBAAyB;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;;;;;;;;;;;;;;;ACzCA;AACA;AACA;AACO;AACP;;;;;;;;;;;;;;;;;;;;;;;ACJA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA,kBAAkB,YAAY;AAC9B;AACA;AACA;AACA;;AAEA;AACA;AACA;AACO;;AAEP;AACA;AACA;AACO;AACP;AACA;AACA;AACA;;AAEA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACO;AACP;AACA;;AAEA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;;AAEA;AACA;AACA;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACA;;;;;;;;;;;;;;;AClFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;AClCA;AACA;AACA;AACA;;AAEiG;AAC1F;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,cAAc,2EAAkB;AAChC;AACA;AACA;AACA,CAAC;AACM;AACP;AACA;AACO;AACP;AACA;AACA;AACA;AACO;AACP;AACA;AACO;AACA;;AAEP;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA,8BAA8B,4DAAG;AACjC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACA;;AAEP;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,EAAE,iEAAQ;AACV,cAAc,2EAAkB;AAChC;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;AClGiE;AACtB;AACmB;AACvD;;AAEP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;;AAEP;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB,2EAAqB;AAC1C;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ;AACR;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;;AAEH;AACA;AACA;AACA;AACA,UAAU,wDAAU;AACpB;AACA,KAAK;AACL;AACA;AACA;AACO;AACA;AACA;AACA;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ;AACR;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ;AACR;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,8EAAqB;AAC5C;AACA,uBAAuB,8EAAqB;AAC5C;AACA,sBAAsB,8EAAqB;AAC3C;AACA;AACA,MAAM;AACN;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;ACvS6E;AACwB;AACyB;AACvH;AACP,wBAAwB,yFAAmC;AAC3D;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;;AAEA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB;AACxB;AACA,eAAe,iFAAwB;AACvC,cAAc,2EAAkB;AAChC;AACA,kBAAkB,yFAAmC;AACrD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kCAAkC,uEAAgB;AAClD;AACA,2BAA2B,4DAAG;AAC9B,sBAAsB,uEAAc;AACpC;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,yBAAyB,+FAAwC;AACjE;AACA;AACA;AACA,UAAU;AACV;AACA;AACA;AACA,YAAY;AACZ,oCAAoC,uEAAc;AAClD,0BAA0B,uEAAc;AACxC;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACO;AACP;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;AC9F+F;;AAE/F;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;AACA,sCAAsC;AACtC;AACA;AACA;AACA;AACA,aAAa,kEAAS;AACtB,YAAY,2EAAkB;AAC9B,oBAAoB,kEAAS;AAC7B,KAAK;AACL,4BAA4B,4DAAG;AAC/B,uBAAuB,uEAAc;AACrC;AACA;AACA;AACA;;;;;;;;;;;;;;;;;ACvCsD;AACqB;AACpE;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,kEAAS,CAAC,uFAAgC,KAAK,uFAAgC;AAC1F,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACrBwD;AACZ;AACyD;AACoE;AACnG;AACkB;AACZ;;AAE5E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA,8BAA8B,oEAAoB;AAClD;AACA,YAAY,6DAAa;AACzB;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gCAAgC,uEAAc;;AAE9C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY;AACZ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ;AACR;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,0DAA0D,8CAAQ;AAClE;AACA;AACA;AACA;AACA,YAAY,oDAAc,6BAA6B,4CAAM;AAC7D;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA,IAAI,oDAAc,4BAA4B,4CAAM;AACpD;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6DAA6D,oEAAoB;AACjF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,uEAAgB;AACvC;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM,sEAAa;AACnB,uBAAuB,uEAAgB;AACvC,KAAK;AACL,6CAA6C,uEAAc;AAC3D;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB,yEAAoB;AAC7C;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,yEAAoB;AACnC;AACA;AACA;AACA;AACA;AACA,oFAAoF,wEAAqB;AACzG;AACA;AACA;AACA;AACA,oDAAoD,8DAAkB;AACtE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uKAAuK,6EAAmB;AAC1L;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,yEAAoB;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0CAA0C,kEAAe;AACzD;AACA,mBAAmB,yEAAoB;AACvC;;AAEA;AACA;AACA;AACA;AACA,6CAA6C;AAC7C,mBAAmB,mEAAS;AAC5B,0GAA0G;AAC1G,kBAAkB,4EAAkB;AACpC,YAAY;AACZ;AACA,mBAAmB,6DAAG;AACtB,aAAa;AACb,kBAAkB,4EAAkB;AACpC;AACA,WAAW;AACX;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6DAA6D,6EAAmB;AAChF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iGAAiG,wEAAc;AAC/G;AACA;AACA,yCAAyC,kEAAe;AACxD,SAAS;AACT,OAAO;AACP;AACA;AACA,0BAA0B,+FAAwC;AAClE;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,yDAAU;AACtC;AACA,eAAe;AACf;AACA;AACA,aAAa;AACb;AACA;AACA;AACA,WAAW;AACX;AACA,OAAO;AACP;AACA,oDAAoD,iFAAqC;AACzF;AACA,sCAAsC,yDAAU;AAChD;AACA;AACA,eAAe;AACf,aAAa;AACb,WAAW;AACX;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA,QAAQ,6DAAa;AACrB,OAAO;AACP,KAAK;AACL;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;ACtUsG;AAC3B;AACpE;AACP,gCAAgC;AAChC,sFAAsF;AACtF,uDAAuD,gCAAgC;AACvF,WAAW,4DAAG;AACd,KAAK;AACL,qCAAqC,2EAAkB;AACvD,GAAG;AACH;AACA,mBAAmB,uEAAc;AACjC;AACA;AACA;AACO;AACP,YAAY,kEAAS;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA,mBAAmB,8DAAK;AACxB,uBAAuB,uFAAgC;AACvD;AACA;AACA;AACA;AACA,GAAG;AACH;AACO;AACP;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AChDA;AACA;AACA;AACA;AACA;;AAEiG;AAC5B;AAC8B;AAChD;AACU;AACwC;AAC5C;AAC2B;AACjB;AACvB;AACZ;AACA;AACF;AACK;AACJ;AACH;AACkB;AACvC;AACP,UAAU,kEAAS;AACnB,uBAAuB,0EAA8B;AACrD,uBAAuB,0EAA8B;AACrD,6BAA6B,gEAAgB;AAC7C;AACA,iBAAiB,iFAA2B;AAC5C;AACA;AACA;AACA;AACA;AACA,oBAAoB,iDAAe;AACnC,kBAAkB,iDAAe;AACjC;AACA,kBAAkB,iDAAe;AACjC,gBAAgB,iDAAe;AAC/B,OAAO;AACP;AACA,kBAAkB,0CAAO;AACzB,gBAAgB,0CAAO;AACvB,OAAO;AACP,6BAA6B,0CAAO;AACpC,iBAAiB,0CAAO;AACxB,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,gBAAgB,iDAAe;AAC/B,cAAc,iDAAe;AAC7B,KAAK;AACL;AACA,YAAY,0EAAoB;AAChC,UAAU,0EAAoB;AAC9B,KAAK;AACL,qBAAqB,0EAAoB;AACzC;AACA;AACA,EAAE,0EAA0B;AAC5B,EAAE,sEAAwB;AAC1B;AACA;AACO;AACP,SAAS,qDAAc,CAAC,oDAAa,gCAAgC,6CAAM,yCAAyC,6CAAM,4BAA4B;AACtJ;AACO;AACP;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA,aAAa,0EAA8B;AAC3C;AACA,oBAAoB,iFAA2B;AAC/C;AACA,sDAAsD,+CAAQ;AAC9D;AACA;AACA;AACA,wBAAwB,8DAAkB;AAC1C;AACA,4BAA4B,iGAAiC,wBAAwB,8DAAK;AAC1F;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,KAAK;AACL;AACA,aAAa,gFAAwB;AACrC;AACA;AACA;AACA,0BAA0B,8DAAkB;AAC5C;AACA,8BAA8B,iGAAiC,wBAAwB,8DAAK;AAC5F;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW;AACX;AACA,OAAO;AACP,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sBAAsB,8DAAkB;AACxC,WAAW;AACX,UAAU;AACV,yBAAyB,8DAAkB;AAC3C,UAAU,iCAAiC,8DAAkB,yCAAyC,wEAAc;AACpH;AACA;AACA,sBAAsB,8DAAkB;AACxC,WAAW;AACX,UAAU;AACV,yBAAyB,8DAAkB;AAC3C;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,kBAAkB,yDAAU;AAC5B;AACA;AACA,aAAa;AACb,YAAY;AACZ,2BAA2B,8DAAkB,CAAC,wEAAc;AAC5D;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;ACnN6H;AAC9D;AACqB;AAC7E;AACA;AACP,+BAA+B,2EAAqB;AACpD;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B,6EAAuB;AAClD;AACA;;AAEA;AACA;AACA;AACA;AACO;AACP;AACA,gBAAgB,yFAAmC;AACnD;AACA;AACA,KAAK;AACL;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,GAAG;AACH;AACO;AACP;AACA,2BAA2B,2EAAoB;AAC/C;AACA;AACA;AACA;AACA,oBAAoB;AACpB;AACA,UAAU,2EAAkB;AAC5B;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sBAAsB,4DAAG;AACzB,eAAe,yFAAmC;AAClD,iBAAiB,uEAAc;AAC/B;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AClH8C;AACiF;AACU;AACnE;AAChB;AACkC;AACZ;AACQ;AACxC;;AAE5C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA,8BAA8B,oEAAoB;AAClD;AACA,YAAY,6DAAa;AACzB;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL,GAAG;;AAEH;AACA;AACA;AACA;AACA,yBAAyB,0EAAqB;AAC9C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,GAAG;AACH,8DAA8D,4CAAM;AACpE;AACA;AACA;AACA,KAAK;AACL;AACA,GAAG;;AAEH;AACA,EAAE,oDAAc,4BAA4B,4CAAM;AAClD;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA,6DAA6D,oEAAoB;AACjF;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B,+EAAwB;AACnD;AACA,kBAAkB;AAClB;AACA,uBAAuB,uEAAgB;AACvC,wDAAwD,uEAAc;AACtE;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B,uEAAc;AACzC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,UAAU,sEAAa;AACvB;AACA,WAAW;AACX;AACA,qBAAqB,uEAAgB;AACrC;AACA;;AAEA;AACA;AACA;AACA,QAAQ;AACR;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,6DAAa;AAC5B;AACA;AACA;AACA;AACA;AACA;AACA,qCAAqC,wEAAqB;AAC1D;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sBAAsB,8DAAkB;AACxC;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,6DAA6D,4EAAmB;AAChF;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uCAAuC,kEAAe;AACtD,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB,mEAAU;AACnC;AACA;AACA;AACA;AACA,yCAAyC,iGAAiC,8CAA8C,+DAAK;AAC7H,WAAW;AACX;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,iDAAiD,iFAAqC;AACtF;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB,oEAAoB;AACrC;AACA;AACA;AACA;AACA,eAAe;AACf;AACA;AACA;AACA,eAAe;AACf;AACA,+CAA+C,kEAAe,QAAQ,uEAAc;AACpF;AACA,WAAW;AACX,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,yDAAU;AACpC;AACA,aAAa;AACb;AACA;AACA,WAAW;AACX;AACA;AACA;AACA;AACA,wBAAwB,+FAAwC;AAChE;AACA;AACA;AACA,WAAW;AACX;AACA,qDAAqD,iFAAqC;AAC1F;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;AC1XA;AACA;AACA;AACA;;AAEiD;AAC4B;AACtE;AACP;AACA;AACA,IAAI;AACJ;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa,0DAAY;AACzB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA,MAAM,sEAAa;AACnB,KAAK;AACL,IAAI;AACJ;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACO;AACP,SAAS,2EAAkB;AAC3B;AACA;AACA;AACA;AACA,gCAAgC,0DAAY;AAC5C,wBAAwB,0BAA0B;AAClD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACtGwH;AACzC;AAC9B;AAC2B;AACd;AACb;AACN;;AAE3C;AACA;AACA;AACA;AACO;AACP,SAAS,kEAAS;AAClB,SAAS,4EAAsB;AAC/B;AACA,WAAW,oEAAc;AACzB;AACA,eAAe,iFAAwB;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,2EAAkB;AAClC;AACA;AACA;;AAEA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA,oCAAoC,yFAAyB;AAC7D;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,KAAK;AACL,GAAG;;AAEH;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,GAAG;;AAEH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA,eAAe,0DAAY;AAC3B,KAAK;AACL;AACA;AACA,YAAY,8DAAmB;AAC/B;AACA;AACA;AACA,OAAO;AACP;AACA,GAAG;;AAEH;AACA;AACA;AACA,qBAAqB,2EAAoB;AACzC;AACA,2BAA2B,4DAAG;AAC9B,sBAAsB,uEAAc;AACpC;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACO;AACP;AACA,UAAU,wDAAU;AACpB;AACA;AACA,KAAK;AACL;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AClI8D;AACjB;AAC6K;AACvD;AACnG;AACL;AACiB;AACO;AAChB;AACF;AACgC;AACwC;AAC1E;AACF;AACZ;AAC2C;AACnB;AACzE;AACA;AACA;AACO;AACA;AACP;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA,yGAAyG,0BAA0B,cAAc,kBAAkB,cAAc,2BAA2B,0EAA6B,cAAc,oBAAoB,qGAAsB;AACjS;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,iEAAgB;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mDAAmD,4CAAM;AACzD,MAAM;;AAEN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,uEAAc;AAC9B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mDAAmD,iFAA4B;AAC/E;AACA;AACA;AACA,kCAAkC,iFAA4B;AAC9D,cAAc,wDAAU;AACxB;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA,SAAS;AACT;AACA;AACA,2BAA2B,gFAAyB;AACpD,qCAAqC,wEAAqB,sEAAsE,0EAAyB;AACzJ,mCAAmC,8CAAQ,oBAAoB,uFAAiC;AAChG,6CAA6C,0CAAG;AAChD,8BAA8B,iFAAuB;AACrD;AACA,yBAAyB,yDAAa,gDAAgD,4CAAM,yBAAyB,0CAAG;AACxH;AACA,8BAA8B,0FAAwB;AACtD;AACA,aAAa,qFAAmB;AAChC,KAAK;AACL,4EAA4E,4CAAM;AAClF;AACA;AACA;AACA,OAAO;AACP;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,WAAW,0EAAoB;AAC/B;;AAEA;AACA;AACA;AACA;AACA;AACA,IAAI,wFAA6B;AACjC,UAAU,uEAAa;AACvB;;AAEA;AACA;AACA;AACA,UAAU,uEAAa;AACvB;AACA;AACA,UAAU,uEAAa;AACvB;AACA;AACA,IAAI,wFAA6B;AACjC;AACA;AACA;AACA;AACA;AACA;AACA,IAAI,wFAA6B;AACjC;AACA;AACA,IAAI,iFAA0B;AAC9B,uBAAuB,wEAAc;AACrC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,2EAA2B;AAC1C,QAAQ;AACR;AACA;AACA;AACA;AACA;AACA;AACA,IAAI,wFAA6B;AACjC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB,qFAA0B;AACnD;AACA;AACA;AACA;AACA;AACA,SAAS;AACT,OAAO;AACP,MAAM;AACN;AACA;AACA,0BAA0B,yBAAyB;AACnD;AACA,yBAAyB,qFAA0B;AACnD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,wDAAU;AACtB;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,+FAAwC;AAChE,wBAAwB,2EAA2B;AACnD;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI,wFAA6B;AACjC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,KAAK;AACL;AACA,qBAAqB,mEAAS;AAC9B;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,kBAAkB,+FAAwC;AAC1D;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;;AAEL;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,IAAI,wFAA6B;AACjC;AACA;AACA;AACA,oBAAoB,qFAA0B;AAC9C;AACA;AACA,cAAc,wDAAU;AACxB;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,QAAQ;AACR;AACA,wBAAwB,2EAAiB;AACzC,0BAA0B,wEAAc;AACxC;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,IAAI,wFAA6B;AACjC;AACA,IAAI,iFAA0B;AAC9B;AACA;;AAEA;AACA;AACA;AACA;AACA,IAAI,wFAA6B;AACjC,kBAAkB,qFAA0B;AAC5C;AACA;AACA,YAAY,wDAAU;AACtB;AACA,OAAO;AACP;;AAEA;AACA;AACA;AACA,cAAc,0EAAoB;AAClC;AACA;AACA;AACA;AACA,QAAQ;AACR;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,IAAI,wFAA6B;AACjC,IAAI,0DAAc;AAClB;AACA;AACA;AACA,KAAK;AACL;AACA,iBAAiB,+DAAgB;AACjC;AACA,gBAAgB,4DAAa;AAC7B;AACA;AACA;AACA,IAAI,wFAA6B;AACjC,IAAI,0DAAc;AAClB;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,cAAc,4DAAa;AAC3B;AACA;AACA,SAAS;AACT;AACA,OAAO;AACP,MAAM;AACN;AACA,mBAAmB,+DAAgB;AACnC;;AAEA;AACA;AACA,cAAc,wDAAU;AACxB;AACA,iBAAiB,mEAAS;AAC1B;AACA,cAAc,4DAAa;AAC3B;AACA;AACA;AACA;AACA,IAAI,wFAA6B;AACjC;AACA,iBAAiB,+DAAgB;AACjC;AACA,gBAAgB,4DAAa;AAC7B;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,IAAI,wFAA6B;AACjC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,4DAAa;AAC7B;AACA;;AAEA;AACA;AACA;AACA;AACA,UAAU,uEAAa;AACvB;;AAEA;AACA;AACA;AACA;AACA;AACA,UAAU,uEAAa;AACvB;AACA;AACA,UAAU,uEAAa;AACvB;AACA;AACA,UAAU,uEAAa;AACvB;;AAEA;AACA;AACA;AACA;AACA;AACA,YAAY,4DAAc;AAC1B;AACA;AACA,OAAO;AACP;AACA;AACA,YAAY,4DAAc;AAC1B;AACA;AACA,OAAO;AACP;AACA;AACA,YAAY,wDAAU;AACtB;AACA,OAAO;AACP;AACA;AACA,YAAY,wDAAU;AACtB;AACA;AACA;AACA,OAAO;AACP;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa,0EAAoB;AACjC;;AAEA;AACA;AACA,WAAW,uEAAa;AACxB;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,aAAa,2EAAqB;AAClC;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa,+DAAmB;AAChC,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,UAAU,mFAAwB;AAClC;AACA,SAAS,8EAAY;AACrB;AACA;AACA,yBAAyB,4CAAM;AAC/B;AACA,GAAG;AACH;AACA;AACA,yBAAyB,4CAAM;AAC/B;AACA,GAAG;AACH;AACA;AACA,yBAAyB,4CAAM;AAC/B;;AAEA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,GAAG;AACH,CAAC;;AAED;AACA;AACA;AACA;AACA;AACA,4BAA4B;AAC5B;AACA;AACA;AACA;AACA,0BAA0B,iEAAO;AACjC;AACA;AACA;AACA,KAAK;AACL,GAAG;AACH;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACO;AACP;AACA;AACA;AACA,8BAA8B;AAC9B,0BAA0B;AAC1B;AACA,cAAc;AACd,cAAc;AACd,kBAAkB;AAClB,cAAc;AACd;AACA,2BAA2B,0EAA6B;AACxD,oBAAoB,qGAAsB;AAC1C,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa,2DAAY;AACzB;AACA,EAAE,0DAAc;AAChB,SAAS,4FAAiC;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT,OAAO;AACP,gBAAgB,0EAAoB;AACpC;AACA;AACA;AACA;AACA,KAAK;AACL,MAAM,0DAAc;AACpB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL,GAAG;AACH;AACO;AACP;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC3zBqE;AACgC;AACa;AACU;AACxE;AAC7C;AACA;AACA;AACA;;AAEP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACA,4BAA4B,6EAAuB;AAC1D;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACM;AACP,SAAS,yFAAmC;AAC5C;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACO;AACP,4BAA4B,iEAAY;AACxC;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA,GAAG;AACH;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACO;AACA;AACA;AACP;AACA;AACA;AACA;AACA;AACA,qBAAqB,oEAAW;AAChC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,WAAW,iFAAwB;AACnC,UAAU,2EAAkB;AAC5B;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA,WAAW,+FAAwC;AACnD;;AAEA;AACA;AACA;AACA;AACA;AACA,cAAc,uEAAc;AAC5B,uBAAuB,sEAAwB;AAC/C;AACA;AACA,YAAY,wDAAU;AACtB;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA,YAAY,wDAAU;AACtB;AACA;AACA,OAAO;AACP;AACA;AACA,WAAW,uEAAc;AACzB;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA,UAAU,wDAAU;AACpB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,8BAA8B,wEAAiB;AAC/C,mBAAmB,8DAAK,CAAC,uEAAc;;AAEvC;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,YAAY,kEAAW;AACvB,kBAAkB,uEAAc;AAChC;AACA,OAAO;AACP,MAAM;AACN,WAAW,sEAAwB;AACnC;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA,UAAU,wDAAU;AACpB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,8BAA8B,wEAAiB;AAC/C,mBAAmB,8DAAK,CAAC,uEAAc;;AAEvC;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,YAAY,kEAAW;AACvB,kBAAkB,uEAAc;AAChC;AACA,OAAO;AACP,MAAM;AACN,WAAW,sEAAwB;AACnC;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC7Q8D;AAChB;AACD;AAC0J;AAC5J;AACK;AACiB;AAClC;AACW;AACc;AAC2E;AACwF;AACtJ;AACpB;AACwB;;AAEzE;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,qGAAqG;AACrG;AACA;AACA;AACA;AACA,yBAAyB,wDAAS;AAClC,uBAAuB,iEAAY;AACnC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B,yCAAO;AAClC;AACA,6CAA6C,wDAAQ,oBAAoB,sFAAiC;AAC1G,wBAAwB,0EAAqB;AAC7C,gCAAgC,0EAAqB;AACrD,mCAAmC,uDAAY;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B,gFAAyB,mCAAmC,iFAAqB;;AAE5G;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kCAAkC,gGAAgC;AAClE;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,yDAAU;AACtB;AACA,OAAO;AACP;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,oBAAoB,wEAAiB,qBAAqB,+FAA+B,CAAC,sFAAsB,gBAAgB,uFAA2B;AAC3J;AACA,YAAY,yDAAU;AACtB;AACA;AACA,OAAO;AACP;AACA,mBAAmB,2EAAoB;AACvC;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,8DAAc;AACjC;;AAEA;AACA;AACA,cAAc,yDAAU;AACxB;AACA,SAAS;AACT;AACA,sCAAsC,sFAAsB;AAC5D;AACA,YAAY,+FAA+B,4BAA4B,uFAA2B;AAClG;AACA,iBAAiB,uFAA2B;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,eAAe,kFAAwB;AACvC,cAAc,4EAAkB;AAChC;AACA;AACA;AACA;AACA,OAAO;AACP,oCAAoC;AACpC;AACA;AACA;AACA,OAAO;;AAEP;AACA,qBAAqB,mEAAS;AAC9B;AACA;AACA,MAAM,0DAAc;AACpB;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,cAAc,yDAAU;AACxB;AACA;AACA,SAAS;AACT;AACA,oBAAoB,wEAAc;AAClC;AACA;AACA;AACA;AACA,cAAc,yDAAU;AACxB;AACA;AACA;AACA;AACA;AACA,kBAAkB,wEAAc;AAChC,SAAS;AACT;AACA,KAAK;AACL;AACA;AACA;AACA,6BAA6B,sEAAkB;AAC/C;;AAEA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,KAAK;AACL;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,UAAU,uEAAa;AACvB;AACA;AACA,UAAU,uEAAa;AACvB;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,UAAU,uEAAa;AACvB;AACA;AACA,UAAU,uEAAa;AACvB;AACA;AACA,UAAU,uEAAa;AACvB;AACA;AACA,UAAU,uEAAa;AACvB;AACA;AACA;AACA;AACA;AACA,UAAU,uEAAa;AACvB;AACA;AACA,UAAU,uEAAa;AACvB;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,+DAAmB;AAC/B;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS,8EAAY;AACrB;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,GAAG;AACH,CAAC;;AAED;AACA;AACA,YAAY,SAAS;AACrB;AACA;AACA;AACA,UAAU,yDAAU;AACpB;AACA;AACA;AACA,KAAK;AACL;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA,oBAAoB,wEAAqB;AACzC,YAAY,iFAAqB;AACjC;AACA;AACA;AACA,aAAa,2DAAY;AACzB,GAAG;AACH;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,cAAc;AACd;AACA;AACA;AACA;AACA,iBAAiB,uEAAiB;AAClC;AACA,CAAC;AACD,EAAE,0DAAc;AAChB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,2DAAY;AACvB,cAAc,yDAAU;AACxB;AACA,SAAS;AACT;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,gCAAgC,qEAAW;AAC3C;AACA;AACA,UAAU,+DAAmB;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,GAAG;AACH;AACA,GAAG;AACH;AACA;AACA,GAAG;AACH;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACO;AACP,8BAA8B,qEAAW;AACzC,yHAAyH;AACzH,6BAA6B,yFAAyB;AACtD;AACA;AACA;AACA,iEAAiE,mFAAwB;AACzF,QAAQ,+DAAmB;AAC3B;AACA;AACA,GAAG;AACH;AACA;AACA;AACO;AACP;AACA;AACO;AACP;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;AC/kBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEwI;AAC5F;AACK;AACa;AAC9D;AACO;AACP;AACA;AACA,kBAAkB,0DAAa;AAC/B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW;AACX;AACA;AACA,SAAS;AACT,QAAQ;AACR;AACA;AACA;AACA;AACA;AACA,KAAK;AACL,GAAG;AACH;AACA;AACO;AACP,SAAS,2EAAkB,+CAA+C,4EAA2B;AACrG;;AAEA;AACA;AACA;AACA;AACA;AACA;AACO;AACP,YAAY,sEAA+B,oCAAoC,0DAAY;AAC3F;AACA,EAAE,yDAAc;AAChB;AACA;;AAEA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC7E2F;AAC6F;AAC7I;AACC;AAC0B;AACrB;AACa;AACgD;AACxC;AAC/D;AACP;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA,wBAAwB,mDAAG;AAC3B,GAAG;AACH;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA,6CAA6C,sDAAM,yBAAyB,mDAAG,wDAAwD,sDAAM,oBAAoB,mDAAG,gBAAgB,mFAA8B,CAAC,uEAAc,iBAAiB,yDAAS,wDAAwD,oEAAoB,2CAA2C,mDAAG,qEAAqE,2DAAW,CAAC,+EAA0B;AAChe,GAAG;AACH;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,QAAQ,0DAAY;AACpB;AACA,cAAc,wDAAU;AACxB;AACA,SAAS;AACT;AACA;AACA,cAAc,wDAAU;AACxB;;AAEA;AACA;AACA,cAAc,wDAAU;AACxB;AACA,SAAS;AACT;AACA,sBAAsB,2EAAqB;AAC3C;AACA,cAAc,wDAAU;AACxB;AACA,SAAS;AACT;AACA;AACA,uBAAuB,mDAAG,SAAS,qEAAW,eAAe,oEAAoB;AACjF,GAAG;AACH;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,oBAAoB,2EAAqB;AACzC;AACA;AACA,aAAa,0EAAoB;AACjC;AACA;AACA,YAAY,wDAAU;AACtB;AACA,OAAO;AACP;AACA;AACA,YAAY,wDAAU;AACtB;AACA;AACA,OAAO;AACP;AACA;AACA;AACA,YAAY,wDAAU;AACtB;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA,OAAO;AACP,MAAM;AACN;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA,iBAAiB,mEAAS;AAC1B;AACA;AACA;AACA;AACA,aAAa,0DAAY;AACzB,MAAM;AACN,aAAa,0DAAY;AACzB;AACA,GAAG;AACH;AACA,WAAW,+DAAK;AAChB,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA,UAAU,uEAAa;AACvB,GAAG;AACH;AACA,UAAU,uEAAa;AACvB,GAAG;AACH;AACA,UAAU,uEAAa;AACvB,GAAG;AACH;AACA,UAAU,uEAAa;AACvB,GAAG;AACH;AACA,UAAU,uEAAa;AACvB,GAAG;AACH;AACA,UAAU,uEAAa;AACvB,GAAG;AACH;AACA,UAAU,uEAAa;AACvB,GAAG;AACH;AACA;AACA;AACA;AACA,wBAAwB,oFAA4B;AACpD;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sEAAsE,oFAA4B;AAClG,GAAG;AACH;AACA;AACA,kBAAkB,+DAAK;AACvB;AACA;AACA,KAAK;AACL;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA,KAAK;AACL,GAAG;AACH;AACA;AACA;AACA;AACA;AACA,cAAc,mEAAS;;AAEvB;AACA;AACA,YAAY,wDAAU;AACtB;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,IAAI,kFAA0B;AAC9B;AACA,yDAAyD,gGAAwC;AACjG,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,wDAAU;AACtC;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,MAAM,kFAA0B;AAChC;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL,GAAG;AACH;AACA,UAAU,wDAAU;AACpB;AACA;AACO;AACP;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA,EAAE,0DAAc;AAChB;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA,kCAAkC;;AAElC;AACA,MAAM,0DAAY;AAClB;AACA;AACA;AACA;AACA;AACA,SAAS,4EAAkB;AAC3B,mBAAmB,qEAAW;;AAE9B;AACA;AACA,aAAa,0DAAY;AACzB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI,mEAAS;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,kEAAQ;AACrC,YAAY;AACZ;AACA,4BAA4B,kEAAQ;AACpC;AACA,UAAU;AACV;AACA,8BAA8B,kEAAQ;AACtC,UAAU;AACV;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0CAA0C,kEAAQ;AAClD;AACA;AACA,KAAK;AACL;AACA,GAAG;AACH;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;ACvX8D;AACI;AACI;AACtE;AACA;AACA;;AAEiD;AACjD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ;AACR;AACA;AACA,SAAS;AACT;AACA,MAAM;AACN;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACO;AACP;;AAEA,iDAAiD;AACjD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB;AACvB;AACA;AACA,EAAE,gFAAc;AAChB;AACA;AACA;AACA;AACA,SAAS,8EAAY;AACrB;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,GAAG;AACH,CAAC,cAAc,kFAAgB;AACxB;AACP;;AAEA,qDAAqD;AACrD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB;AACxB;AACA;AACA,EAAE,gFAAc;AAChB;AACA;AACA;AACA;AACA,SAAS,8EAAY;AACrB;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,GAAG;AACH,CAAC,cAAc,kFAAgB;AACxB;AACP;AACA;AACO;AACP;AACA;AACO;AACP,2BAA2B,0DAAY;AACvC;AACO;AACP,+BAA+B,0DAAY;AAC3C;;AAEA;AACA;AACA;AACA;AACO;AACP;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;ACrIqE;AACD;AACmE;AAC3E;AACjB;AACS;;AAEpD;AACA;AACA;AACA;AACO;AACP,mBAAmB,iFAA2B;AAC9C,eAAe,kEAAS;AACxB,6BAA6B,8DAAK;AAClC;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA,kBAAkB,gEAAO;AACzB;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iEAAiE,gEAAiB;AAClF,YAAY;AACZ;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA,yBAAyB,6EAAoB;AAC7C;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA,WAAW;AACX;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB,6EAAoB;AAC7C;AACA;AACA,WAAW;AACX,UAAU;AACV;AACA;AACA,WAAW;AACX;AACA;AACA;AACA,IAAI;AACJ,8DAA8D,kFAAyB;AACvF;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACO;AACP;AACA,UAAU,wDAAU;AACpB;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kBAAkB,wEAAe;AACjC,KAAK;AACL,GAAG;AACH;AACA,oBAAoB,sBAAsB;AAC1C;AACA;AACA;AACA;AACA,iDAAiD,mDAAmB,mBAAmB,mDAAmB;AAC1G;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACO;AACP;AACA,UAAU,wDAAU;AACpB;AACA,KAAK;AACL;AACA,mBAAmB,iEAAa;AAChC;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACO;AACP;AACA,UAAU,wDAAU;AACpB;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA,kBAAkB,+DAAY;AAC9B;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;AC/OwD;AACpB;AACuB;AACW;AACuB;AAC7B;AACA;AACD;AAC/D;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA,IAAI,wDAAY,CAAC,oDAAY;AAC7B,WAAW;AACX,cAAc;AACd,KAAK;AACL,IAAI,wDAAY,CAAC,oDAAY;AAC7B,UAAU;AACV,SAAS;AACT,gBAAgB;AAChB,aAAa;AACb,SAAS;AACT,UAAU;AACV,SAAS;AACT,SAAS;AACT,UAAU;AACV,SAAS;AACT,UAAU;AACV,UAAU;AACV,UAAU;AACV,UAAU;AACV,SAAS;AACT,YAAY;AACZ,WAAW;AACX,WAAW;AACX,KAAK;AACL;AACA;AACA,aAAa,8CAAK;AAClB;AACA;;;;;;;;;;;;;;;;;;;;AC/C8D;AACD;AACa;AAC/B;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,gBAAgB,4DAAG;AACnB;AACA;AACA,qBAAqB,0EAA2B;AAChD;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,cAAc,wDAAU;AACxB;AACA;AACA;AACA,SAAS;AACT,QAAQ;AACR;AACA;AACA,MAAM;AACN;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA,SAAS,8EAAY;AACrB;AACA;AACA,aAAa,kFAAyB;AACtC;;AAEA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA,OAAO;AACP,aAAa,kFAAyB;AACtC;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,sBAAsB,sBAAsB;AAC5C;AACA;AACA;AACA,aAAa,kFAAyB;AACtC;AACA,GAAG;AACH,CAAC;AACD;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACzF8D;AAChB;AACuD;AAC4G;AACxI;AAC7B;AACY;AACG;AACuD;AAChD;AAClE;AACA;AACA;AACA;AACO;AACP;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA,YAAY;AACZ;AACA;AACA,yBAAyB,4DAAG;AAC5B;AACA;AACA,yBAAyB,iDAAe;AACxC;AACA;AACA,6BAA6B,0EAAqB;AAClD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,wDAAU;AACtB;AACA;AACA,OAAO;AACP;AACA;AACA,yBAAyB,2EAAmB;AAC5C;AACA,MAAM;AACN;AACA;AACA,6BAA6B,2EAAmB;AAChD;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,cAAc,wDAAU;AACxB;AACA;AACA,SAAS;AACT,QAAQ;AACR;AACA;AACA;AACA;AACA,gBAAgB,uEAAc;AAC9B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,UAAU;AACV;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,wDAAU;AACtB;AACA;AACA;AACA,OAAO;AACP;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,uEAAc;AAClC;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,mEAAU;AAC9B;AACA,aAAa,wEAAmB;AAChC;AACA,KAAK;AACL;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kBAAkB,wEAAmB;AACrC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI,yDAAc;AAClB,gBAAgB,iEAAY;AAC5B;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,cAAc,0EAA4B;AAC1C,QAAQ;AACR;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,WAAW,2EAAsB;AACjC;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,UAAU,uEAAa;AACvB;AACA;AACA,WAAW,2EAAsB;AACjC;AACA;AACA,WAAW,2EAAsB;AACjC;AACA;AACA,WAAW,2EAAsB;AACjC;AACA;AACA,WAAW,2EAAsB;AACjC;;AAEA;AACA;AACA;AACA;AACA,UAAU,uEAAa;AACvB;AACA;AACA,UAAU,uEAAa;AACvB;AACA;AACA,UAAU,uEAAa;AACvB;AACA;AACA,UAAU,uEAAa;AACvB;AACA,SAAS,8EAAY;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,uDAAM;AACd;AACA;AACA;AACA;AACA,QAAQ,0DAAS;AACjB;AACA,QAAQ,yDAAQ;AAChB;AACA,QAAQ,oDAAG;AACX;AACA,QAAQ,4DAAW,CAAC,+EAA0B;AAC9C;AACA,QAAQ,qEAAoB;AAC5B,oCAAoC,uEAAc;AAClD;AACA,YAAY;AACZ;AACA;AACA,SAAS,GAAG,uDAAM;AAClB;AACA;AACA;AACA;AACA,QAAQ,oDAAG;AACX,iBAAiB,uEAAc;AAC/B,SAAS;AACT,kBAAkB,4CAAK;AACvB;AACA;AACA;AACA;AACA,4BAA4B,uDAAM;AAClC;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA,4BAA4B,wEAAmB;AAC/C,aAAa,kFAAyB,uBAAuB,oEAAe;AAC5E;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,GAAG;AACH,CAAC;AACM;AACP;AACA;AACA;AACA;;AAEA;AACA;AACA;AACO;AACP;AACA;AACO;AACP,EAAE,yDAAc;AAChB;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA,EAAE,yEAAuB;AACzB;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,6BAA6B,4DAAG;;AAEhC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,0EAAqB;AAChC;AACA;AACA,0BAA0B;AAC1B;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA,4BAA4B,uEAAc;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,sBAAsB;AACtB;AACA;AACA,QAAQ;AACR;AACA,gCAAgC,sEAAmB;AACnD;AACA;AACA;AACA,UAAU;AACV;AACA,sBAAsB;AACtB;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+BAA+B,kFAAwB;AACvD,oBAAoB;AACpB;AACA;AACA;AACA,KAAK;AACL;AACA,+BAA+B;AAC/B;;AAEA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,UAAU;AACV;AACA;AACA,OAAO;AACP;AACA;AACA;AACA,QAAQ,uEAAa;AACrB;AACA,MAAM;AACN;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACtkB2C;AACuI;AAClL;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,GAAG;AACH;AACA;;AAEA;AACA;AACA;AACO;AACP;AACA,4BAA4B,mEAAc;AAC1C;AACA,YAAY,iEAAQ;AACpB,YAAY,oEAAW;AACvB;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA,UAAU,wDAAU;AACpB;AACA;AACA;AACA;AACA,OAAO;AACP;AACA,KAAK;AACL;AACA;AACA;AACA;AACO;AACP;AACA;AACA,IAAI;AACJ;AACA;AACA;AACO;AACP;AACA;AACA,SAAS,uEAAc;AACvB;;AAEA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA,gBAAgB,oEAAW;AAC3B;AACA,YAAY,wDAAU;AACtB;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP,yBAAyB,mEAAU;AACnC;AACA;;AAEA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;;AAEA;AACA;AACA;AACA;AACO;AACP,cAAc,kEAAS;AACvB;AACA,yBAAyB,kEAAS;;AAElC;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,EAAE,sEAAa;AACf,uIAAuI;;AAEvI;AACA;AACA;AACA,kBAAkB,6EAAoB;AACtC;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,wEAAmB;AAClC;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACO;AACP;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACO;AACP;AACA,kBAAkB,wBAAwB;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACtS8D;AACwC;AAC3D;AACC;AACoJ;AAC/I;AAC1C;AACP;AACA;AACA;AACA;;AAEA;AACA,uBAAuB,iFAA2B;;AAElD;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,wDAAU;AACtB;AACA,OAAO;AACP;AACA,uBAAuB,oEAAc;AACrC;AACA;AACA;AACA;AACA;AACA;AACA,cAAc,OAAO;AACrB;AACA;AACA;AACA,WAAW,kEAAS;AACpB,cAAc,wDAAU;AACxB;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,yBAAyB,2EAAqB;AAC9C;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,OAAO;AACP,KAAK;AACL,IAAI,kFAAyB;AAC7B;AACA;AACA;AACA,WAAW,yFAAmC;AAC9C;AACA,SAAS,8EAAY;AACrB;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA;AACA;AACA,aAAa,kFAAyB;AACtC;;AAEA;AACA;AACA;AACA,GAAG;AACH;AACA;AACA,aAAa,kFAAyB;AACtC;AACA,GAAG;AACH,CAAC;AACM;AACP,iDAAiD,6EAAoB;AACrE;;AAEA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACO;AACP;AACA,IAAI,yDAAc;AAClB;AACA,sBAAsB,6EAAuB;AAC7C,kBAAkB,2EAAqB;AACvC,EAAE,0DAAY;AACd;AACA,EAAE,yDAAc;AAChB;AACA;AACO;AACP;AACA;;AAEA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACpKA;AACA;AACA;;AAEiD;AACN;AACyB;AACyJ;AACpK;AACgB;AAC7B;AACrC;AACA;AACA;AACP;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;;AAEA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA,IAAI;AACJ,sBAAsB,iFAA2B;AACjD;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACO;AACP;AACA,gDAAgD,yCAAG,oEAAoE,4CAAM,cAAc,yCAAG,uBAAuB,uEAAc,qBAAqB,+CAAS,oBAAoB,+CAAS,UAAU,4CAAM;AAC9P;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACO;AACP,yBAAyB;AACzB;AACO;AACP;AACA;AACA,YAAY,wDAAU;AACtB;AACA;AACA;AACA;AACA,OAAO;AACP,MAAM;AACN,YAAY,wDAAU;AACtB;AACA;AACA;AACA;AACA,OAAO;AACP,MAAM;AACN;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oBAAoB,oEAAW;AAC/B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY;AACZ;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA,UAAU;AACV;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kBAAkB;AAClB;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,uEAAc;AACtC,eAAe;AACf,aAAa;AACb;AACA,UAAU;AACV;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB,gBAAgB;AAChB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB;AACnB;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA,QAAQ;AACR;AACA;AACA;AACA;AACA;AACA,UAAU;AACV;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ;AACR;AACA;AACA;AACA,QAAQ;AACR;AACA,4BAA4B,uEAAc;AAC1C;AACA,QAAQ;AACR,cAAc,wDAAU;AACxB;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sBAAsB,mBAAmB;AACzC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACO;AACP;AACA;;AAEA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA,eAAe,kEAAS;AACxB;AACA;AACA;AACA,GAAG;AACH;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACO;AACP,yBAAyB;AACzB,WAAW,kEAAS;AACpB,GAAG;AACH;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA,EAAE,0DAAY;AACd,oBAAoB,iFAA2B;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB,6DAAG;AACpB,0BAA0B,qBAAqB;AAC/C;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,wEAAc;AACtC;AACA;AACA;AACA;AACA;AACA,MAAM,0DAAc;AACpB;AACA;AACA,OAAO;AACP;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qGAAqG,uEAAc;AACnH;AACA;;AAEA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA,sCAAsC;AACtC,oBAAoB,wEAAc;AAClC,aAAa;AACb;AACA,SAAS;AACT;AACA,QAAQ,uEAAa;AACrB;AACA;AACA,QAAQ,uEAAa;AACrB;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA,+EAA+E,uEAAc;AAC7F,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACO;AACP;AACA,UAAU,wDAAU;AACpB;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,UAAU,wDAAU;AACpB;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,UAAU,wDAAU;AACpB;AACA;AACA;AACA,KAAK;AACL;AACA;AACO;AACP;AACA;AACA,IAAI;AACJ;AACA;AACA;AACO;AACP,oBAAoB,iFAA2B;AAC/C,+CAA+C,yEAAmB;AAClE;AACA,SAAS,yEAAmB;AAC5B;AACA;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA,SAAS;AACT;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACO;AACP;AACA;AACA;AACA,oBAAoB,iFAA2B;AAC/C,cAAc,kEAAY;AAC1B;AACA;AACA,gBAAgB,qEAAW;AAC3B;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACO;AACP,SAAS,4EAAkB;AAC3B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,+BAA+B;AACzD;AACA;AACA;AACA,2BAA2B,+BAA+B;AAC1D;AACA;AACA;AACA;AACA;AACA,MAAM;AACN;AACA;AACA,4BAA4B,gCAAgC;AAC5D;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;;AAEA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA,qCAAqC,0EAAoB;AACzD;AACA;AACA,iBAAiB,kEAAY;AAC7B;AACA,YAAY,qEAAW;AACvB;AACA,YAAY,qEAAW;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kBAAkB,qEAAW;AAC7B;AACA,kBAAkB,qEAAW;AAC7B;AACA,WAAW;AACX;AACA;AACA,SAAS;AACT;AACA,gBAAgB,qEAAW;AAC3B;AACA,gBAAgB,qEAAW;AAC3B;AACA,SAAS;AACT;AACA,gBAAgB,qEAAW;AAC3B;AACA;AACA,SAAS;AACT;AACA,gBAAgB,qEAAW;AAC3B;AACA,gBAAgB,qEAAW;AAC3B;AACA,SAAS;AACT;AACA,gBAAgB,qEAAW;AAC3B;AACA,gBAAgB,qEAAW;AAC3B;AACA,SAAS;AACT;AACA,gBAAgB,qEAAW;AAC3B,0BAA0B,uEAAc;AACxC,gBAAgB,qEAAW;AAC3B;AACA,SAAS;AACT;AACA;AACA,SAAS;AACT;AACA,gBAAgB,qEAAW;AAC3B;AACA,gBAAgB,qEAAW;AAC3B;AACA,SAAS;AACT;AACA,gBAAgB,qEAAW;AAC3B;AACA,gBAAgB,qEAAW;AAC3B;AACA,SAAS;AACT;AACA,gBAAgB,qEAAW;AAC3B;AACA,gBAAgB,qEAAW;AAC3B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;AC7tBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAE+B;AACY;AACU;;AAErD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACA;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,cAAc,+DAAgB;AAC9B;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uCAAuC,yCAAO;AAC9C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL,GAAG;AACH;AACA,0DAA0D,yDAAS;AACnE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;AChHkC;AACE;AACpC;AACA,IAAI,gDAAS;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,CAAC,6CAAO;AACkB;AAC3B;;;;;;;;;;;;;;;;;;ACnCO,2CAA2C,uDAAuD;AAClG;AACP;AACA;AACO;AACP;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;ACd0D;AACV;AACsB;AAC1B;AACV;AACa;AACI;AACnD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6EAA6E,uDAAc;AAC3F,QAAQ,gEAAY;AACpB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC,uDAAc;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA,aAAa;AACb;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA,yBAAyB,0DAAiB;AAC1C;AACA;AACA;AACA;AACA,yBAAyB,uBAAuB;AAChD;AACA;AACA,eAAe,yDAAa;AAC5B;AACA;AACA;AACA;AACA;AACA;AACA,2CAA2C,qBAAqB,mBAAmB,qBAAqB,gBAAgB,wBAAwB;AAChJ,SAAS;AACT;AACA;AACA;AACA;AACA;AACA,CAAC;AACqB;AACtB;AACA;AACA,gFAAgF,2CAAM;AACtF;AACA;AACA,oBAAoB,4DAAU,gBAAgB,4DAAU,iBAAiB,4DAAU;AACnF;AACA;AACA,sCAAsC,mDAAU,2BAA2B,6DAAc;AACzF;AACA;;;;;;;;;;;;;;;;;;ACrGkC;AACE;AACsC;AAC1E;AACA,IAAI,gDAAS;AACb;AACA,sCAAsC;AACtC,sCAAsC;AACtC,6CAA6C,qBAAqB,mFAAqB;AACvF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,uCAAuC;AAC/D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,yCAAyC;AACrE;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,CAAC,6CAAO;AACgB;AACzB;;;;;;;;;;;;;;;;;;;;;;ACzD4C;AACF;AACwB;AACO;AAC5B;AACM;AACnD;AACA,IAAI,gDAAS;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sBAAsB,kFAAuB;AAC7C;AACA;AACA;AACA;AACA,QAAQ,gEAAY;AACpB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,kCAAkC,+CAAQ,0CAA0C,UAAU;AAC9F;AACA;AACA;AACA;AACA,gCAAgC,QAAQ;AACxC;AACA;AACA;AACA;AACA,8BAA8B;AAC9B;AACA;AACA,SAAS;AACT;AACA;AACA;AACA,QAAQ,gEAAY;AACpB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA,QAAQ,gEAAY;AACpB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,6DAAkB;AACrC;AACA;AACA;AACA,mBAAmB,uDAAY;AAC/B;AACA,YAAY,0DAAS;AACrB,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6BAA6B,mDAAU;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,CAAC,mDAAU;AACO;AACnB;AACA,IAAI,gDAAS;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wIAAwI,6DAAkB;AAC1J;AACA;AACA,CAAC;AAC2B;AAC5B;;;;;;;;;;;;;;;;;;;;;;;;;;ACjKkC;AACa;AACe;AAC5B;AACiC;AAChC;AACkE;AACvC;AACX;AACnD;AACA,IAAI,gDAAS;AACb;AACA;AACA;AACA;AACA;AACA,gBAAgB,6DAAc;AAC9B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sCAAsC,wEAAgB;AACtD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sCAAsC,yEAAiB;AACvD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sCAAsC,yEAAqB;AAC3D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,CAAC,uDAAY;AACQ;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA,IAAI,gDAAS;AACb;AACA;AACA;AACA,YAAY,4DAAU;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yBAAyB,2CAAM;AAC/B;AACA,sDAAsD;AACtD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACyB;AAC1B;AACA,QAAQ,2CAAM;AACd,QAAQ,gEAAY;AACpB;AACA;AACA,QAAQ,gFAAoB;AAC5B;AACA;AACA;AACA;AACA;AACA;AACA,gCAAgC,2CAAM;AACtC,6BAA6B,uEAAe,0BAA0B,yDAAyD;AAC/H;AACO;AACP;AACA,UAAU,4CAAI;AACd;AACA,cAAc,4CAAI;AAClB;AACA;;;;;;;;;;;;;;;;;;;;;ACvLwD;AACT;AACkB;AACpB;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gDAAgD,+CAAQ,oDAAoD,sBAAsB;AAClI;AACA;AACA;AACA;AACA,oCAAoC,QAAQ;AAC5C;AACA;AACA;AACA;AACA,kCAAkC;AAClC;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,4DAAU;AAC1B;AACA;AACA;AACA;AACA,0CAA0C,0EAAmB;AAC7D;AACA;AACA;AACA;AACA;AACA;AACA,6CAA6C,+CAAQ,uDAAuD,uBAAuB;AACnI;AACA;AACA;AACA;AACA;AACA;AACA,+CAA+C,0EAAmB;AAClE,yCAAyC,oDAAa,CAAC,oDAAa,KAAK,6CAAM,WAAW,6CAAM;AAChG;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gCAAgC,QAAQ;AACxC;AACA;AACA;AACA;AACA,8BAA8B;AAC9B;AACA;AACA;AACA,0BAA0B,0EAAmB;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY,0DAAS;AACrB;AACA;AACA;AACA;AACA,uBAAuB,0DAAS;AAChC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA,CAAC;AACuB;AACjB;AACA;AACP;AACA,uCAAuC,4DAAU,kBAAkB,4DAAU,eAAe,4DAAU;AACtG;AACA;AACA,QAAQ,4DAAU;AAClB;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;AC9IO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;ACP+C;AACD;AACvC;AACP;AACA;AACA,6BAA6B,uDAAc;AAC3C;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA,+BAA+B,wDAAU;AACzC;AACA,aAAa;AACb,SAAS;AACT;AACA,KAAK;AACL;AACA;;;;;;;;;;;;;;;;;;;;;;;;;ACvB2C;AACyB;AACtC;AACc;AACgB;AACG;AACX;AACuB;AACjB;AACnD;AACP;AACA,qBAAqB,uBAAuB;AAC5C;AACA;AACA,oBAAoB,wDAAY;AAChC,yBAAyB,6DAAiB;AAC1C,aAAa,gFAAoB;AACjC;AACA,eAAe,2CAAI;AACnB;AACA,qBAAqB,mDAAU;AAC/B;AACA,gCAAgC,OAAO,gEAAY;AACnD;AACA,YAAY,oDAAQ;AACpB,wCAAwC,wEAAgB;AACxD;AACO;AACP,qCAAqC,iBAAiB,oDAAQ;AAC9D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC,2CAAI;AACrC;AACA,qCAAqC,uFAAwB;AAC7D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA,qBAAqB;AACrB,iBAAiB;AACjB;AACA,4BAA4B,YAAY;AACxC;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,QAAQ,sEAAe;AACvB;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;ACrEmD;AACP;AACd;AACvB;AACP;AACA,qBAAqB,uBAAuB;AAC5C;AACA;AACA,WAAW,+DAAS,GAAG,2CAAI,OAAO,wDAAY;AAC9C;AACA;;;;;;;;;;;;;;;;;ACV2C;AACpC,gBAAgB,mDAAU,yBAAyB,+BAA+B;AAClF;AACP;AACA;AACA;AACA,eAAe,mDAAU,yBAAyB,wCAAwC,+BAA+B,IAAI;AAC7H;AACA;;;;;;;;;;;;;;;;;ACRmD;AACX;AACjC;AACP,uBAAuB,+DAAS,qBAAqB,qDAAS;AAC9D;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACLwE;AACtB;AACJ;AACH;AACuB;AACR;AACwB;AAClC;AACwD;AACxD;AACoB;AACG;AAChE;AACP,yBAAyB,mDAAU;AACnC;AACA;AACA;AACA,YAAY,8EAAmB;AAC/B;AACA;AACA,YAAY,8DAAW;AACvB;AACA;AACA,YAAY,0DAAS;AACrB;AACA;AACA,YAAY,sEAAe;AAC3B;AACA;AACA,YAAY,4DAAU;AACtB;AACA;AACA,YAAY,gFAAoB;AAChC;AACA;AACA;AACA,UAAU,8FAAgC;AAC1C;AACO;AACP,eAAe,mDAAU;AACzB,sBAAsB,0DAAiB;AACvC,YAAY,4DAAU;AACtB;AACA;AACA;AACA,KAAK;AACL;AACO;AACP,eAAe,mDAAU;AACzB,wBAAwB,wCAAwC;AAChE;AACA;AACA;AACA,KAAK;AACL;AACO;AACP,eAAe,mDAAU;AACzB;AACA;AACA;AACA;AACA;AACA;AACA,SAAS,mBAAmB,+BAA+B;AAC3D,wBAAwB,6EAAoB;AAC5C,KAAK;AACL;AACO;AACP,eAAe,mDAAU;AACzB;AACA;AACA,kCAAkC,gDAAQ,8CAA8C,oBAAoB;AAC5G;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,QAAQ;AAChC;AACA;AACA;AACA;AACA,sBAAsB;AACtB;AACA;AACA,KAAK;AACL;AACO;AACP,eAAe,mDAAU;AACzB,kEAAkE,+BAA+B;AACjG,KAAK;AACL;AACO;AACP,6BAA6B,8FAAkC;AAC/D;AACA;AACA;AACA;AACA,WAAW,iDAAS;AACpB;AACA,eAAe,mDAAW;AAC1B;AACA;AACA;AACA,sCAAsC,qDAAa;AACnD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B;AAC5B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT,KAAK;AACL;AACA;;;;;;;;;;;;;;;;;;;;AC9IiD;AACT;AACR;AACuB;AACzB;AACvB;AACP;AACA,qBAAqB,uBAAuB;AAC5C;AACA;AACA,oBAAoB,wDAAY;AAChC,qBAAqB,qDAAS;AAC9B;AACA;AACA;AACA,YAAY,yCAAK;AACjB;AACA;AACA,gBAAgB,qDAAS;AACzB;AACA,gBAAgB,6DAAQ,aAAa,2CAAI;AACzC;AACA;;;;;;;;;;;;;;;;;;ACtBkC;AACS;AACpC;AACP;AACA;AACA;AACA,IAAI,gDAAS;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,CAAC,mDAAU;AACkB;AAC9B;;;;;;;;;;;;;;;;AC5DsC;AAC/B;AACP,WAAW,mDAAQ;AACnB;AACA;;;;;;;;;;;;;;;;;;ACJ4C;AACL;AACyB;AACzD;AACP,kCAAkC,cAAc,oDAAQ;AACxD;AACA,WAAW,mDAAO;AAClB;AACA;AACA,yBAAyB,6EAAwB;AACjD;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT,KAAK;AACL;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;ACtBuC;AACyB;AACzD;AACP,WAAW,mDAAO;AAClB;AACA,yBAAyB,6EAAwB,gCAAgC,2EAA2E;AAC5J,KAAK;AACL;AACA;;;;;;;;;;;;;;;;;ACRuC;AACyB;AACzD;AACP,WAAW,mDAAO;AAClB;AACA,yBAAyB,6EAAwB;AACjD;AACA,SAAS;AACT,KAAK;AACL;AACA;;;;;;;;;;;;;;;;;;;;ACV8C;AACP;AACD;AACiB;AACb;AACnC;AACP;AACA,qBAAqB,uBAAuB;AAC5C;AACA;AACA,oBAAoB,wDAAY;AAChC,qBAAqB,qDAAS;AAC9B,WAAW,mDAAO;AAClB,QAAQ,mDAAQ,aAAa,sDAAI,CAAC,oDAAa,WAAW,6CAAM;AAChE,KAAK;AACL;AACA;;;;;;;;;;;;;;;;;AChBsC;AACM;AACrC;AACP,iCAAiC;AACjC,WAAW,mDAAQ,CAAC,oDAAQ;AAC5B;AACA;;;;;;;;;;;;;;;;;;ACNoD;AACM;AACM;AACzD;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uCAAuC;AACvC;AACA;AACA;AACA;AACA,QAAQ,gEAAS,oCAAoC,6EAAwB;AAC7E;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B,sEAAe,8CAA8C,mCAAmC;AAC5H;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,qBAAqB,6EAAwB;AAC7C;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;AC5D4B;AACwB;AACb;AACW;AACF;AACzC;AACP,iCAAiC;AACjC,QAAQ,4DAAU;AAClB,0CAA0C,OAAO,yCAAG,oBAAoB,qCAAqC,EAAE,gEAAS,mBAAmB;AAC3I;AACA;AACA;AACA;AACA,WAAW,mDAAO,iCAAiC,OAAO,+DAAc,4CAA4C;AACpH;AACA;;;;;;;;;;;;;;;;;ACf8C;AACd;AACzB;AACP;AACA,qBAAqB,uBAAuB;AAC5C;AACA;AACA,WAAW,yCAAK,eAAe,oDAAa,KAAK,6CAAM;AACvD;AACA;;;;;;;;;;;;;;;;;;ACT0D;AACnB;AACyB;AACzD;AACP,4BAA4B;AAC5B,WAAW,mDAAO;AAClB,yBAAyB,6EAAwB,gCAAgC,OAAO,sEAAe,sCAAsC,gCAAgC,WAAW,gBAAgB,OAAO,sEAAe,sCAAsC,+BAA+B,WAAW,mBAAmB,OAAO,sEAAe,sCAAsC,+BAA+B,WAAW;AACva,KAAK;AACL;AACA;;;;;;;;;;;;;;;;;;;;ACT8C;AACM;AACf;AACU;AACR;AAChC;AACP,8BAA8B;AAC9B,0EAA0E,WAAW,6CAAO,MAAM;AAClG;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,mDAAO;AACtB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA,iCAAiC,uDAAc;AAC/C,6CAA6C,0BAA0B;AACvE;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB,iBAAiB;AACjB,gBAAgB,gEAAS;AACzB;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,qBAAqB,uBAAuB;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B,uDAAc;AACzC;AACA;AACA;AACA,SAAS;AACT,KAAK;AACL,WAAW,gEAAS,kBAAkB,oDAAa,KAAK,6CAAM;AAC9D;AACA;;;;;;;;;;;;;;;;;ACpFiD;AACjB;AACzB;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW,6CAAK;AAChB,iCAAiC,WAAW,yDAAa,sCAAsC;AAC/F;AACA;AACA;AACA,KAAK;AACL;AACA;;;;;;;;;;;;;;;;;;ACnB8C;AACF;AACL;AAChC;AACP;AACA,qBAAqB,uBAAuB;AAC5C;AACA;AACA,oBAAoB,wDAAY;AAChC,WAAW,mDAAO;AAClB,qBAAqB,0DAAM,8BAA8B,0DAAM;AAC/D,KAAK;AACL;AACA;;;;;;;;;;;;;;;;ACbuC;AAChC;AACP,4BAA4B;AAC5B,WAAW,mDAAO;AAClB,wDAAwD,sCAAsC;AAC9F,KAAK;AACL;AACA;;;;;;;;;;;;;;;;;;ACPoD;AACb;AACyB;AACzD;AACP,WAAW,mDAAO;AAClB;AACA;AACA;AACA,0CAA0C;AAC1C,yBAAyB,6EAAwB;AACjD;AACA;AACA;AACA,YAAY,gEAAS,0DAA0D,6EAAwB,qCAAqC,oHAAoH;AAChQ;AACA;AACA,aAAa;AACb,SAAS;AACT;AACA;AACA,SAAS;AACT,KAAK;AACL;AACA;;;;;;;;;;;;;;;;ACvB2C;AACpC;AACP,eAAe,mDAAU;AACzB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT,KAAK;AACL;AACA;;;;;;;;;;;;;;;;;ACjB2C;AACe;AACnD;AACP;AACA;AACA;AACA,eAAe,mDAAU;AACzB,QAAQ,sEAAe;AACvB;AACA,YAAY,sEAAe;AAC3B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB,aAAa;AACb,SAAS;AACT,KAAK;AACL;AACA;;;;;;;;;;;;;;;;;;;ACtB2C;AACsB;AACjB;AACU;AACnD;AACP,eAAe,mDAAU;AACzB;AACA,QAAQ,sEAAe;AACvB,6BAA6B,sDAAe;AAC5C,YAAY,sEAAe;AAC3B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb,SAAS;AACT,6BAA6B,OAAO,4DAAU;AAC9C,KAAK;AACL;AACA;;;;;;;;;;;;;;;;;;AC/BoD;AACD;AACI;AAChD;AACP,WAAW,gEAAS,aAAa,mEAAW,aAAa,+DAAS;AAClE;AACA;;;;;;;;;;;;;;;;;;ACNoD;AACD;AACI;AAChD;AACP,WAAW,gEAAS,aAAa,mEAAW,aAAa,+DAAS;AAClE;AACA;;;;;;;;;;;;;;;;;ACNgE;AACkB;AAC3E;AACP,WAAW,6EAAqB,CAAC,8FAAkC;AACnE;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACL0D;AACN;AACJ;AACM;AACU;AACE;AACpB;AACI;AACF;AACU;AACwB;AACd;AACM;AACnE;AACP;AACA,YAAY,8EAAmB;AAC/B,mBAAmB,uEAAkB;AACrC;AACA,YAAY,8DAAW;AACvB,mBAAmB,6DAAa;AAChC;AACA,YAAY,0DAAS;AACrB,mBAAmB,iEAAe;AAClC;AACA,YAAY,sEAAe;AAC3B,mBAAmB,6EAAqB;AACxC;AACA,YAAY,4DAAU;AACtB,mBAAmB,mEAAgB;AACnC;AACA,YAAY,iFAAoB;AAChC,mBAAmB,wFAA0B;AAC7C;AACA;AACA,UAAU,+FAAgC;AAC1C;AACA;;;;;;;;;;;;;;;ACpCO;AACP;AACA;AACA,KAAK;AACL;AACA;AACA;;;;;;;;;;;;;;;;ACN8C;AACvC;AACP;AACA;AACA,yBAAyB,uBAAuB;AAChD;AACA;AACA;AACA;AACA,uDAAuD,oDAAa,qBAAqB,6CAAM;AAC/F;AACA,wCAAwC,oDAAa,qBAAqB,6CAAM;AAChF,KAAK;AACL;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;;;;;;;;;;;;;;;;ACnBO;AACP;AACA;AACA;AACA;AACA;AACO;AACP;;;;;;;;;;;;;;;ACPO,gCAAgC,+EAA+E;AACtH;;;;;;;;;;;;;;;;ACDsD;AAC/C,iBAAiB,mEAAgB;AACxC;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;;;;;;;;;;;;;;;;ACRsD;AAC/C,8BAA8B,mEAAgB;AACrD;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;;;;;;;;;;;;;;;;ACRsD;AAC/C,0BAA0B,mEAAgB;AACjD;AACA;AACA;AACA,2GAA2G,uCAAuC;AAClJ;AACA;AACA;AACA;AACA,CAAC;AACD;;;;;;;;;;;;;;;;;;;ACX0C;AACE;AAC5C;AACA;AACA;AACO;AACP,WAAW,uDAAU;AACrB;AACO;AACP,WAAW,yDAAW;AACtB;AACO;AACP;AACA;AACA;;;;;;;;;;;;;;;ACdA;AACA;AACO;AACP;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA,gDAAgD,sBAAsB;AACtE;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;ACrBO;AACP;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;ACNO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;ACVO;AACP,mDAAmD,6CAA6C,IAAI;AACpG;AACA;;;;;;;;;;;;;;;;;ACHmC;AACnC;AACO;AACP,QAAQ,2CAAM;AACd;AACA;AACA,wBAAwB;AACxB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP,QAAQ,2CAAM;AACd;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;AC3BO;AACP,4BAA4B;AAC5B,6BAA6B;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;ACjBO;AACP;AACA;AACA;;;;;;;;;;;;;;;ACHO,kCAAkC,sEAAsE;AAC/G;;;;;;;;;;;;;;;;ACD0C;AACnC;AACP,mCAAmC,uDAAU;AAC7C;AACA;;;;;;;;;;;;;;;ACJO;AACP;AACA;AACA;;;;;;;;;;;;;;;;;ACHuE;AAC7B;AACnC;AACP,WAAW,uDAAU,OAAO,0DAAiB;AAC7C;AACA;;;;;;;;;;;;;;;;;ACLiE;AACvB;AACnC;AACP,WAAW,uDAAU,qDAAqD,sDAAe;AACzF;AACA;;;;;;;;;;;;;;;;ACL0C;AACnC;AACP,WAAW,uDAAU;AACrB;AACA;;;;;;;;;;;;;;;;;;ACJ+D;AACrB;AACnC;AACP,WAAW,uDAAgB;AAC3B;AACA,eAAe,kDAAW;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB,KAAK,EAAE,EAAc;AAC7C,+BAA+B,8CAAO;AACtC;AACA;AACA;AACA,+BAA+B,8CAAO;AACtC;AACA,mCAAmC,8CAAO;AAC1C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT,KAAK;AACL;AACO;AACP,WAAW,uDAAU;AACrB;AACA;;;;;;;;;;;;;;;;ACtC0C;AACnC;AACP,oBAAoB,uDAAU;AAC9B;AACA;;;;;;;;;;;;;;;;;ACJ0C;AACnC;AACP,WAAW,uDAAU;AACrB;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;ACnB8C;AACP;AACvC;AACA;AACA,4CAA4C,oDAAa,KAAK,6CAAM;AACpE;AACO;AACP,WAAW,mDAAG,mBAAmB,+BAA+B;AAChE;AACA;;;;;;;;;;;;;;;ACTO;AACP;;;;;;;;;;;;;;;;;ACDsC;AAC/B;AACP;AACA,qBAAqB,uBAAuB;AAC5C;AACA;AACA;AACA;AACO;AACP;AACA,eAAe,+CAAQ;AACvB;AACA;AACA;AACA;AACA;AACA,gDAAgD,kBAAkB;AAClE;AACA;AACA;;;;;;;;;;;;;;;;;ACnBmC;AAC4B;AACxD;AACP,IAAI,uEAAe;AACnB,+BAA+B,2CAAM;AACrC;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;;;;;;;;;;;;;;;ACbO;AACP;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACHA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,SAAS,gBAAgB,sCAAsC,kBAAkB;AACjF,wBAAwB;AACxB;AACA;;AAEO;AACP;AACA;AACA;AACA,kBAAkB;AAClB;AACA;;AAEO;AACP;AACA,+CAA+C,OAAO;AACtD;AACA;AACA;AACA;AACA;AACA;AACA;;AAEO;AACP;AACA;AACA;AACA;AACA,2DAA2D,cAAc;AACzE;AACA;AACA;AACA;AACA;;AAEO;AACP;AACA;AACA,2CAA2C,QAAQ;AACnD;AACA;;AAEO;AACP,kCAAkC;AAClC;;AAEO;AACP,uBAAuB,uFAAuF;AAC9G;AACA;AACA,yGAAyG;AACzG;AACA,sCAAsC,QAAQ;AAC9C;AACA,gEAAgE;AAChE;AACA,8CAA8C,yFAAyF;AACvI,8DAA8D,2CAA2C;AACzG;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEO;AACP;AACA,kBAAkB,yBAAyB;AAC3C;AACA;AACA;AACA;;AAEO;AACP;AACA;;AAEO;AACP;AACA,4CAA4C,yEAAyE;AACrH;;AAEO;AACP;AACA;;AAEO;AACP,0BAA0B,+DAA+D,iBAAiB;AAC1G;AACA,kCAAkC,MAAM,+BAA+B,YAAY;AACnF,iCAAiC,MAAM,mCAAmC,YAAY;AACtF,8BAA8B;AAC9B;AACA,GAAG;AACH;;AAEO;AACP,YAAY,6BAA6B,0BAA0B,cAAc,qBAAqB;AACtG,2IAA2I,cAAc;AACzJ,qBAAqB,sBAAsB;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA,sCAAsC;AACtC,iCAAiC,SAAS;AAC1C,iCAAiC,WAAW,UAAU;AACtD,wCAAwC,cAAc;AACtD;AACA,4GAA4G,OAAO;AACnH,+EAA+E,iBAAiB;AAChG,uDAAuD,gBAAgB,QAAQ;AAC/E,6CAA6C,gBAAgB,gBAAgB;AAC7E;AACA,gCAAgC;AAChC;AACA;AACA,QAAQ,YAAY,aAAa,SAAS,UAAU;AACpD,kCAAkC,SAAS;AAC3C;AACA;;AAEO;AACP;AACA;AACA;AACA,eAAe,oCAAoC;AACnD;AACA;AACA,CAAC;AACD;AACA;AACA,CAAC;;AAEM;AACP;AACA;;AAEO;AACP;AACA;AACA;AACA;AACA;AACA,mBAAmB;AACnB;AACA;AACA;AACA;;AAEO;AACP;AACA;AACA;AACA;AACA;AACA;AACA,kBAAkB,MAAM;AACxB;AACA;AACA;AACA;AACA,gBAAgB;AAChB;AACA;AACA;;AAEA;AACO;AACP,2BAA2B,sBAAsB;AACjD;AACA;AACA;;AAEA;AACO;AACP,gDAAgD,QAAQ;AACxD,uCAAuC,QAAQ;AAC/C,uDAAuD,QAAQ;AAC/D;AACA;AACA;;AAEO;AACP,2EAA2E,OAAO;AAClF;AACA;AACA;AACA;AACA;AACA;AACA;;AAEO;AACP;AACA;;AAEO;AACP;AACA;AACA,wMAAwM,cAAc;AACtN,4BAA4B,sBAAsB;AAClD,wBAAwB,YAAY,sBAAsB,qCAAqC,2CAA2C,MAAM;AAChJ,0BAA0B,MAAM,iBAAiB,YAAY;AAC7D,qBAAqB;AACrB,4BAA4B;AAC5B,2BAA2B;AAC3B,0BAA0B;AAC1B;;AAEO;AACP;AACA,eAAe,6CAA6C,UAAU,sDAAsD,cAAc;AAC1I,wBAAwB,6BAA6B,oBAAoB,uCAAuC,kBAAkB;AAClI;;AAEO;AACP;AACA;AACA,yGAAyG,uFAAuF,cAAc;AAC9M,qBAAqB,8BAA8B,gDAAgD,wDAAwD;AAC3J,2CAA2C,sCAAsC,UAAU,mBAAmB,IAAI;AAClH;;AAEO;AACP,+BAA+B,uCAAuC,YAAY,KAAK,OAAO;AAC9F;AACA;;AAEA;AACA,wCAAwC,4BAA4B;AACpE,CAAC;AACD;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEO;AACP;AACA;AACA,qDAAqD,cAAc;AACnE;AACA;AACA;;AAEO;AACP,2CAA2C;AAC3C;;AAEO;AACP;AACA;AACA;AACA;;AAEO;AACP;AACA;AACA;AACA;AACA;;AAEO;AACP;AACA;AACA;;AAEO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sCAAsC,MAAM,oBAAoB,YAAY;AAC5E,qBAAqB,8CAA8C;AACnE;AACA;AACA,qBAAqB,aAAa;AAClC;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uFAAuF,SAAS,gBAAgB;AAChH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEO;AACP;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;;AAEA,iEAAe;AACf;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC,EAAC;;;;;;;;;;;;;;;;AChZF;;AAEO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,KAAK;;AAEL;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;;AAEA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;AC5C0C;AACN;;AAEpC;AACA;AACA;AACA;AACA;AACA;AACA,0BAA0B,6CAAO,GAAG,mDAAU;AAC9C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA;AACA;AACO;AACP;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;AACO;AACP;AACA;AACO;AACP;AACA;;;;;;;;;;;;;;;ACjDO;AACP;AACA;AACA,GAAG;;AAEH;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL,GAAG;AACH;AACA;AACA;AACA;AACA,KAAK;AACL,GAAG;AACH;AACA;AACA;AACA;AACA;AACA,KAAK;AACL,GAAG;AACH;;;;;;;;;;AC7BA;AACA,MAAM,IAA0C;AAChD,IAAI,iCAAgC,CAAC,MAAQ,CAAC,oCAAE,OAAO;AAAA;AAAA;AAAA,kGAAC;AACxD,IAAI,KAAK,YAQN;AACH,CAAC;AACD;AACA,sCAAsC;AACtC;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,iBAAiB,UAAU;AAC3B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,iBAAiB,GAAG;AACpB,mBAAmB,SAAS;AAC5B;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB,QAAQ;AACzB;AACA;AACA,iBAAiB,UAAU;AAC3B;AACA,iBAAiB,UAAU;AAC3B;AACA,iBAAiB,QAAQ;AACzB;AACA,iBAAiB,SAAS;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB;AACnB;AACA;AACA;AACA;AACA;AACA;AACA,YAAY;AACZ;AACA,YAAY;AACZ;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,iBAAiB,QAAQ;AACzB;AACA,iBAAiB,QAAQ;AACzB;AACA,iBAAiB,SAAS;AAC1B;AACA;AACA;AACA,iBAAiB,SAAS;AAC1B;AACA;AACA;AACA,iBAAiB,SAAS;AAC1B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB;AACnB;AACA;AACA;AACA;AACA;AACA,iDAAiD,kBAAkB,EAAE,sCAAsC,MAAM,KAAK,UAAU,YAAY;AAC5I;AACA;AACA,gDAAgD,kBAAkB,EAAE,sCAAsC,MAAM,KAAK,UAAU,YAAY;AAC3I;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB,gBAAgB;AAChB,gCAAgC,MAAM;AACtC;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,cAAc;AACd;AACA;AACA,cAAc;AACd;AACA;AACA;AACA,eAAe;AACf;AACA,WAAW;AACX;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB,QAAQ;AACzB;AACA,iBAAiB,UAAU;AAC3B;AACA;AACA,iBAAiB,UAAU;AAC3B;AACA;AACA;AACA,mBAAmB;AACnB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;;AAEA;AACA;AACA;AACA;AACA,iBAAiB,QAAQ;AACzB;AACA;AACA,iBAAiB,QAAQ,cAAc;AACvC;AACA;AACA;AACA,6DAA6D,gBAAgB;AAC7E;AACA,iBAAiB,QAAQ,cAAc;AACvC;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA,mBAAmB;AACnB;AACA,+CAA+C,eAAe;AAC9D;AACA;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,gBAAgB;AAChB;AACA;AACA;AACA;AACA,gBAAgB;AAChB;AACA;AACA;AACA;AACA,cAAc;AACd;AACA;AACA;AACA;AACA,cAAc;AACd;AACA;AACA,cAAc;AACd;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA,eAAe;AACf;AACA;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA,cAAc;AACd;AACA;AACA;AACA,WAAW;AACX;AACA;AACA,WAAW;AACX;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB,oCAAoC;AACrD;AACA;AACA;AACA;AACA,mBAAmB;AACnB;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,SAAS;AACT;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,mBAAmB,QAAQ;AAC3B;AACA;AACA;AACA,gDAAgD;AAChD;AACA;AACA;AACA;AACA,WAAW;AACX;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,GAAG;AACtB;AACA,mBAAmB,QAAQ;AAC3B;AACA,mBAAmB,aAAa;AAChC;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA,YAAY;AACZ;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA,gBAAgB;AAChB;AACA;AACA;AACA;AACA;AACA,eAAe;AACf,aAAa;AACb;AACA;AACA,aAAa;AACb;;AAEA;AACA;AACA;AACA;AACA;AACA,YAAY;AACZ;AACA;;AAEA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA,OAAO;AACP;AACA;AACA;AACA;AACA;AACA;AACA,YAAY;AACZ;AACA;AACA,UAAU;AACV;AACA;AACA;AACA,UAAU;AACV;AACA;AACA;AACA;AACA;AACA,+CAA+C,kBAAkB,EAAE,sCAAsC,MAAM,KAAK,UAAU,YAAY;AAC1I;AACA;AACA,8CAA8C,kBAAkB,EAAE,sCAAsC,MAAM,KAAK,UAAU,YAAY;AACzI;AACA;AACA;AACA;AACA;AACA,WAAW;AACX;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA,WAAW;AACX,SAAS;AACT;AACA;AACA;AACA;AACA,WAAW;AACX;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,IAAI;AACJ;AACA;AACA,CAAC;AACD;;;;;;;;;;;;;;;;;;;;;ACxsC4C;AACkD;AACX;;AAE5E;AACP;AACA;;AAEA;AACA,oCAAoC,2DAAQ;AAC5C;AACA,SAAS,2DAAQ,UAAU;AAC3B;;AAEA;;AAEA;AACA,EAAE,+DAAY;AACd,EAAE,+DAAY;AACd,EAAE,+DAAY;AACd,EAAE,+DAAY;AACd;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;;;AAIA,8BAA8B,iBAAiB,uDAAuD,UAAU;AAChH;AACA;AACA;AACA;AACA;AACA,kCAAkC,iBAAiB,wCAAwC,uBAAuB,gBAAgB,UAAU;AAC5I;AACA;AACA;AACA;AACA;AACA;AACA,YAAY;AACZ,wCAAwC,iBAAiB,gCAAgC,UAAU;AACnG;AACA;AACA,SAAS;AACT,QAAQ;AACR,oCAAoC,iBAAiB,yDAAyD,UAAU;AACxH;AACA;AACA,MAAM;AACN,gCAAgC,iBAAiB,yDAAyD,UAAU;AACpH;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC,QAAQ;AACzC;AACA;AACA,gDAAgD,uEAAsB,WAAW,uEAAsB;AACvG;AACA,uCAAuC,QAAQ;AAC/C;AACA;AACA,6BAA6B,oEAAmB,WAAW,oEAAmB;AAC9E,0BAA0B,OAAO;AACjC,+CAA+C,uEAAsB,WAAW,uEAAsB;AACtG;AACA,yCAAyC,QAAQ,uDAAuD,KAAK;AAC7G;AACA;AACA;AACA;AACA,sCAAsC,QAAQ;AAC9C;AACA,UAAU;AACV,sCAAsC,QAAQ;AAC9C;AACA,UAAU;AACV;AACA;AACA,OAAO;AACP;AACA;AACA;;AAEA;AACA;AACA,8BAA8B,QAAQ,wBAAwB,UAAU;AACxE;;AAEA,kCAAkC;AAClC;AACA;AACA,wBAAwB,+EAA4B;AACpD;AACA;AACA;AACA;AACA,wBAAwB,+DAAY;AACpC,kCAAkC,QAAQ,iDAAiD,UAAU;AACrG,mCAAmC,oEAAe,eAAe,+EAA+E;AAChJ,kCAAkC,QAAQ,uDAAuD,UAAU;AAC3G;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;AACA,kCAAkC,QAAQ,iDAAiD,UAAU;AACrG,mCAAmC,oEAAe,eAAe,8EAA8E;AAC/I,kCAAkC,QAAQ,uDAAuD,UAAU;AAC3G;AACA;;;;AAIA,MAAM,OAAO;AACb;AACA,kCAAkC,QAAQ,wBAAwB,WAAW;AAC7E;AACA,gBAAgB,+EAA4B;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA;AACA,QAAQ,oEAAe;AACvB;AACA;AACA;AACA;AACA,yCAAyC,QAAQ,iCAAiC,WAAW;AAC7F,cAAc;AACd,0CAA0C,QAAQ,uCAAuC,UAAU;AACnG;AACA,WAAW;AACX,kCAAkC,QAAQ,iDAAiD,WAAW;AACtG;AACA,QAAQ;AACR,kCAAkC,QAAQ,yBAAyB,WAAW;AAC9E;AACA;AACA;AACA;AACA;;AAEO;;AAEP,oEAAe;AACf;AACA;AACA;AACA;;AAEA,uBAAuB,+EAA4B;AACnD,8BAA8B,QAAQ,wEAAwE,2BAA2B;AACzI;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA,MAAM,oEAAe;AACrB;AACA;AACA;AACA;AACA,OAAO;AACP;AACA;AACA,sBAAsB,+DAAY;AAClC,gCAAgC,QAAQ,sDAAsD,aAAa;AAC3G;AACA;AACA;AACA,0CAA0C,QAAQ,2BAA2B,cAAc;AAC3F;AACA,cAAc;AACd,4CAA4C,QAAQ,oDAAoD,aAAa;AACrH,8BAA8B,gEAAgE;AAC9F;AACA,SAAS;AACT;AACA,wCAAwC,QAAQ,yCAAyC,aAAa;AACtG,2BAA2B,sCAAsC;AACjE,SAAS;AACT;AACA;AACA;;AAEA,4BAA4B,QAAQ,gCAAgC,cAAc;AAClF;AACA,CAAC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AChP8C;;AAE/C;AACA;AACA;AACA;AACA,GAAG;AACH;;;AAGO;AACP;AACA;AACA;AACA;AACA;;AAEO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;;;AAIO;AACP,gBAAgB,wDAAY;AAC5B;AACA;AACA;AACA;AACA;;AAEO;AACP,gBAAgB,wDAAY;AAC5B;AACA,wCAAwC,cAAc;AACtD;AACA;AACA;;AAEO;AACP,kBAAkB,wDAAY;AAC9B;AACA;AACA;AACA;AACA;;AAEO;AACP,gBAAgB,wDAAY;AAC5B;AACA;AACA;AACA;AACA;;AAEO;AACP,kBAAkB,wDAAY;AAC9B;AACA;AACA;AACA;AACA;;AAEO;AACP,kBAAkB,wDAAY;AAC9B;AACA;AACA;AACA;AACA;;AAEO;AACP,kBAAkB,wDAAY;AAC9B;AACA,4CAA4C,cAAc;AAC1D;AACA,mFAAmF,UAAU;AAC7F;;AAEA;AACA;AACA;AACA;;AAEO;AACP,kBAAkB,wDAAY;AAC9B;AACA;AACA;AACA;AACA;;AAEO;AACP,kBAAkB,wDAAY;AAC9B;AACA;AACA;AACA;AACA;;AAEO;AACP,kBAAkB,wDAAY;AAC9B;AACA;AACA;AACA,yBAAyB;AACzB;AACA;;AAEO;AACP,kBAAkB,wDAAY;AAC9B;AACA;AACA;AACA;AACA;;AAEO;AACP,kBAAkB,wDAAY;AAC9B;AACA,4CAA4C,OAAO;AACnD;AACA,yBAAyB;AACzB;AACA;;AAEA;;AAEO;AACP,gBAAgB,wDAAY;AAC5B,6BAA6B,wDAAY;AACzC;AACA;AACA;AACA,qBAAqB;AACrB;AACA;;AAEO;AACP,gBAAgB,wDAAY;AAC5B,6BAA6B,wDAAY;AACzC;AACA;AACA;AACA,qBAAqB;AACrB;AACA;;AAEO;AACP,kBAAkB,wDAAY;AAC9B,+BAA+B,wDAAY;AAC3C;AACA;AACA;AACA,yBAAyB;AACzB;AACA;;AAEO;AACP,gBAAgB,wDAAY;AAC5B,6BAA6B,wDAAY;AACzC;AACA;AACA;AACA,qBAAqB;AACrB;AACA;;AAEO;AACP,kBAAkB,wDAAY;AAC9B,+BAA+B,wDAAY;AAC3C;AACA;AACA;AACA,yBAAyB;AACzB;AACA;;AAEO;AACP,kBAAkB,wDAAY;AAC9B,+BAA+B,wDAAY;AAC3C;AACA;AACA;AACA,yBAAyB;AACzB;AACA;;AAEO;AACP,kBAAkB,wDAAY;AAC9B,+BAA+B,wDAAY;AAC3C;AACA;AACA;AACA,yBAAyB;AACzB,kFAAkF,UAAU;AAC5F;AACA;;AAEO;AACP,kBAAkB,wDAAY;AAC9B;AACA;AACA;AACA;AACA;AACA;;AAEO;AACP,kBAAkB,wDAAY;AAC9B,+BAA+B,wDAAY;AAC3C;AACA;AACA;AACA,yBAAyB;AACzB;AACA;;AAEO;AACP,kBAAkB,wDAAY;AAC9B,+BAA+B,wDAAY;AAC3C;AACA;AACA;AACA,yBAAyB;AACzB;AACA;;AAEO;AACP,kBAAkB,wDAAY;AAC9B,+BAA+B,wDAAY;AAC3C;AACA;AACA;AACA;AACA;AACA;;AAEO;AACP,kBAAkB,wDAAY;AAC9B,+BAA+B,wDAAY;AAC3C;AACA;AACA;AACA;AACA;;AAEO;AACP,kBAAkB,wDAAY;AAC9B,+BAA+B,wDAAY;AAC3C;AACA;AACA;AACA;AACA;;AAEA;;AAEO;AACP,kBAAkB,wDAAY;AAC9B;AACA;AACA;AACA,yBAAyB;AACzB;AACA;;AAEO;AACP,kBAAkB,wDAAY;AAC9B;AACA;AACA;AACA,yBAAyB;AACzB;AACA;;AAEO;AACP,kBAAkB,wDAAY;AAC9B;AACA;AACA;AACA,yBAAyB;AACzB;AACA;;AAEO;AACP,kBAAkB,wDAAY;AAC9B,kBAAkB,uBAAuB;AACzC;AACA;AACA,yBAAyB;AACzB;AACA;;AAEA;;AAEO;AACP,gBAAgB,wDAAY;AAC5B;AACA,oDAAoD;AACpD;AACA;AACA;;AAEO;AACP,gBAAgB,wDAAY;AAC5B;AACA,sDAAsD;AACtD;AACA;AACA;;AAEO;AACP,gBAAgB,wDAAY;AAC5B;AACA;AACA;AACA;AACA;;AAEO;AACP,kBAAkB,wDAAY;AAC9B;AACA,kBAAkB;AAClB;AACA;AACA;AACA;;AAEO;AACP,gBAAgB,wDAAY;AAC5B;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA;;AAEO;AACP,gBAAgB,wDAAY;AAC5B,6BAA6B,wDAAY;AACzC;AACA,mBAAmB;AACnB;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA;;AAEO;AACP,gBAAgB,wDAAY;AAC5B,6BAA6B,wDAAY;AACzC;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA;;AAEO;AACP,kBAAkB,wDAAY;AAC9B,+BAA+B,wDAAY;AAC3C,kCAAkC;AAClC;AACA;AACA,yBAAyB;AACzB;AACA;;AAEO;AACP,kBAAkB,wDAAY;AAC9B,+BAA+B,wDAAY;AAC3C;AACA;AACA;AACA;AACA;;AAEO;AACP,gBAAgB,wDAAY;AAC5B;AACA;AACA;AACA;AACA;;AAEO;AACP,gBAAgB,wDAAY;AAC5B;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;ACxZO;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;;AAEM;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;;AAEM;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;;AAEM;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;;AAEM;AACP;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;;AAEM;AACP;AACA;AACA,CAAC;;AAEM;AACP;AACA;AACA;AACA;AACA,CAAC;;AAEM;AACP;AACA,CAAC;;AAEM;AACP;AACA;AACA;AACA;AACA;AACA,CAAC;;AAEM;AACP;AACA;AACA;AACA;AACA;AACA,CAAC;;;;;;;;;;;;;;;;;;;;;;AChIwC;AACoD;;;AAG7F;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,SAAS,kDAAQ;AACjB;AACA;AACA;AACA;AACA,sBAAsB,kDAAQ;AAC9B,cAAc;AACd,4CAA4C,cAAc,2CAA2C,MAAM;AAC3G;AACA;AACA;AACA;;AAEA,oCAAoC;AACpC;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,QAAQ,kDAAQ;AAChB,QAAQ,kDAAQ,WAAW,qFAAoC;AAC/D;AACA,2CAA2C,cAAc;AACzD;AACA;AACA,cAAc;AACd,6CAA6C,cAAc;AAC3D;AACA,SAAS;AACT,MAAM;AACN,oCAAoC,cAAc;AAClD;AACA;;AAEA;AACA,eAAe,kDAAQ;AACvB;AACA,MAAM;AACN;AACA,oCAAoC,cAAc;AAClD;;AAEA,uEAAuE,cAAc,KAAK,QAAQ,oBAAoB,uBAAuB,cAAc,gBAAgB;AAC3K,oDAAoD,yFAAyF;AAC7I;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA,+BAA+B,kDAAQ;AACvC,mCAAmC,cAAc;AACjD;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA,kDAAkD,cAAc;AAChE;AACA;AACA,yDAAyD;AACzD,2EAA2E;AAC3E,6EAA6E;AAC7E,mFAAmF;AACnF;AACA;;AAEA;;AAEA;AACA;AACA;AACA,iCAAiC,YAAY,EAAE,kCAAkC;AACjF;AACA;AACA;AACA;AACA;AACA,UAAU;AACV,+CAA+C,UAAU;AACzD;AACA,KAAK;;AAEL;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,oBAAoB,sBAAsB;AAC1C;AACA;AACA,cAAc;AACd,2CAA2C,cAAc;AACzD;AACA;AACA,UAAU;AACV,wCAAwC,cAAc;AACtD;AACA;AACA,MAAM;AACN;AACA;;AAEA,yBAAyB,gEAAe;;AAExC;AACA;AACA,kBAAkB,kDAAQ;AAC1B,UAAU;AACV,wCAAwC,cAAc,kDAAkD,MAAM;AAC9G;AACA,MAAM;AACN;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;AClKA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACoD;AACpD,KAAK,iEAAmB;AACxB;AACA;AACA;AACA,2CAA2C;AAC3C;AACA;AACA;AACA;AACA;;AAEA,oFAAoF,GAAG;AACvF;AACA;AACA;;;AAGqD;AACU;AACK;AACM;AACnB;AACX;AACH;AAmBX;AAOA;;;;AAI9B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gDAAgD,2BAA2B;AAC3E;AACA;AACA;;;;AAIA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,cAAc,gCAAgC;AAC9C,iBAAiB,gBAAgB;AACjC,qBAAqB,gBAAgB;AACrC,iBAAiB,gCAAgC;AACjD;AACA;AACA;AACA;AACA;AACA,iCAAiC,gCAAgC;AACjE,8BAA8B,gBAAgB;AAC9C,4BAA4B,gBAAgB;AAC5C,iCAAiC,gBAAgB;AACjD,iCAAiC;AACjC,iBAAiB;AACjB;AACA;AACA,SAAS;AACT,qBAAqB,iCAAiC;AACtD,kBAAkB;AAClB,KAAK;AACL;AACA;AACA;;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA,KAAK;AACL;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA,KAAK;AACL;AACA;AACA;AACA;AACA;AACA,GAAG;AACH;AACA;;AAEA,kDAAQ,WAAW,oEAAmB;AACtC,kDAAQ,WAAW,uEAAsB;AACzC,kDAAQ,WAAW,uEAAsB;AACzC,kDAAQ,WAAW,oEAAmB;AACtC,kDAAQ,WAAW,oEAAmB;AACtC,kDAAQ,WAAW,uEAAsB;AACzC,kDAAQ,WAAW,uEAAsB;AACzC,kDAAQ,WAAW,sEAAqB;AACxC,kDAAQ,WAAW,oEAAmB;AACtC,kDAAQ,WAAW,wEAAuB;AAC1C,kDAAQ,WAAW,4EAA2B;AAC9C,kDAAQ,WAAW,uEAAsB;AACzC,kDAAQ,WAAW,uEAAsB;AACzC,kDAAQ,WAAW,gEAAe;AAClC,kDAAQ,WAAW,iEAAgB;AACnC,kDAAQ,WAAW,4EAA2B;AAC9C,kDAAQ,WAAW,mEAAkB;AACrC,kDAAQ,WAAW,wFAAuC;AAC1D,kDAAQ,WAAW,uEAAsB;AACzC;AACA;AACA;AACA,aAAa,uBAAuB;AACpC;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wFAAwF,mBAAmB;AAC3G;AACA;AACA;AACA,UAAU;AACV;AACA,iFAAiF,mBAAmB;AACpG;AACA;AACA;AACA,UAAU;AACV,8EAA8E,KAAK;AACnF;AACA;AACA;AACA,uEAAuE,KAAK,gBAAgB,mBAAmB;AAC/G;AACA;AACA;AACA;AACA;AACA,kEAAkE,KAAK,0BAA0B,UAAU;AAC3G,2EAA2E,KAAK,0BAA0B,UAAU;AACpH;AACA;AACA;;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AAGA;;AAEA,gCAAgC,6EAAiB;AACjD;AACA;AACA;AACA,cAAc;AACd;AACA;AACA,UAAU,YAAY,6EAA6E,mBAAmB;AACtH;;AAEA,gCAAgC,6EAAiB;AACjD;AACA;AACA;AACA,eAAe;AACf;AACA;AACA,UAAU,YAAY,mFAAmF,mBAAmB;;AAE5H;AACA,MAAM;AACN;AACA,0DAA0D,OAAO;AACjE,0EAA0E,sBAAsB;AAChG;AACA;;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;;AAEL;AACA;AACA;AACA,oBAAoB,oEAAe;AACnC;AACA;AACA,wDAAwD,0EAA0E;AAClI;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA,MAAM;AACN,gFAAgF,qBAAqB;AACrG;AACA;AACA;AACA;AACA,iBAAiB;AACjB;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB;AACnB;;AAEA;AACA;AACA;AACA,QAAQ,iDAAW,CAAC,8EAAsB;AAC1C,QAAQ,iDAAW,CAAC,oFAAyB;AAC7C,QAAQ,iDAAW,CAAC,iEAAgB;AACpC;AACA;;AAEA;AACA;AACA,mCAAmC,sDAAgB;AACnD;AACA,yBAAyB,6EAAiB;AAC1C,aAAa;AACb,8EAA8E,eAAe;;AAE7F;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA,cAAc;AACd;AACA;AACA;AACA,UAAU;AACV;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,kDAAkD,sDAAgB;AAClE;AACA,6BAA6B,6EAAiB;AAC9C,iBAAiB;AACjB,iFAAiF,0BAA0B;AAC3G,cAAc;AACd;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA,UAAU;AACV;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA,mEAAmE,0EAA0E;AAC7I;AACA;AACA;;AAEA;AACA;AACA,kBAAkB;AAClB;AACA;AACA,6EAA6E,uBAAuB;AACpG;AACA;AACA;AACA,8DAA8D,iCAAiC;AAC/F;AACA,gEAAgE,yBAAyB;AACzF;AACA;AACA,gCAAgC,eAAe;AAC/C;AACA,sBAAsB;AACtB;AACA;AACA;AACA,cAAc;AACd;AACA;AACA;AACA,SAAS;;AAET;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB,MAAM;AACN;AACA;AACA;AACA;;AAEA,6HAA6H,sBAAsB;AACnJ,sDAAsD,iCAAiC;AACvF;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,cAAc,OAAO,OAAO,WAAW,GAAG,2CAA2C;AACrF;;AAEA;AACA;AACA;AACA;;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,cAAc;AACd,gCAAgC;AAChC,cAAc;AACd,2EAA2E,uBAAuB;AAClG;AACA;AACA;AACA;AACA;AACA;AACA;AACA,UAAU;AACV;AACA;AACA;AACA;AACA,kBAAkB,6EAA4B;AAC9C,uBAAuB;AACvB;AACA;AACA,cAAc,kDAAQ;AACtB,oEAAoE,uBAAuB;AAC3F,MAAM;AACN,iFAAiF,uBAAuB;AACxG;AACA;;;AAGA;AACA;;AAEA;AACA;AACA;AACA;AACA,UAAU;AACV;AACA;AACA;AACA,iCAAiC,8EAA6B;AAC9D;AACA,cAAc,kDAAQ;AACtB,qEAAqE,wCAAwC;AAC7G,MAAM;AACN,kFAAkF,WAAW;AAC7F;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,UAAU;AACV;AACA;AACA;AACA,iCAAiC,4EAA2B;AAC5D;AACA,cAAc,kDAAQ;AACtB,mEAAmE,mBAAmB;AACtF,MAAM;AACN,gFAAgF,WAAW;AAC3F;AACA;;AAEA;AACA,oDAAoD,gBAAgB;AACpE;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gDAAgD,WAAW;AAC3D;AACA;AACA;AACA;AACA,iBAAiB;AACjB,MAAM;AACN,8DAA8D,OAAO;AACrE,iBAAiB;AACjB;AACA;;AAEA;AACA,0CAA0C,WAAW;AACrD;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA,oDAAoD,WAAW;AAC/D,qBAAqB,kCAAkC,WAAW;AAClE;AACA,gDAAgD,WAAW;AAC3D,iBAAiB;AACjB,MAAM;AACN,sDAAsD,kBAAkB;AACxE,iBAAiB;AACjB;AACA;;AAEA;AACA,yCAAyC,QAAQ;AACjD;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA,qBAAqB,uCAAuC,QAAQ;AACpE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uCAAuC,6CAA6C;AACpF;AACA;AACA,4CAA4C,yCAAyC;AACrF;AACA;AACA,iBAAiB,uBAAuB;AACxC,MAAM;AACN,sDAAsD,eAAe;AACrE,iBAAiB;AACjB;AACA;;AAEA;AACA,2CAA2C,mBAAmB;AAC9D;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA,qBAAqB,uCAAuC,QAAQ;AACpE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA,qBAAqB,kCAAkC,WAAW,oBAAoB,OAAO;AAC7F;AACA,8CAA8C,mBAAmB;AACjE;AACA;AACA,iBAAiB;AACjB,MAAM;AACN,yDAAyD,0BAA0B;AACnF,iBAAiB;AACjB;AACA;;AAEA;AACA,2CAA2C,sBAAsB;AACjE;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA,qBAAqB,kCAAkC,WAAW;AAClE;AACA;AACA;AACA;AACA,oDAAoD,sBAAsB;AAC1E,qBAAqB,kCAAkC,WAAW,uBAAuB,UAAU;AACnG;AACA;AACA,0CAA0C,2BAA2B;AACrE;AACA;AACA,8CAA8C,sBAAsB;AACpE;AACA;AACA,iBAAiB,uBAAuB;AACxC,MAAM;AACN,yDAAyD,6BAA6B;AACtF,iBAAiB;AACjB;AACA;;AAEA;AACA,0CAA0C,sBAAsB;AAChE;AACA;AACA;AACA,qBAAqB,wDAAwD,UAAU;AACvF;AACA;AACA;AACA;AACA,qBAAqB,kCAAkC,WAAW;AAClE;AACA;AACA,uCAAuC,mBAAmB;AAC1D;AACA;AACA,6CAA6C,sBAAsB;AACnE;AACA;AACA,iBAAiB;AACjB,MAAM;AACN,wDAAwD,6BAA6B;AACrF,iBAAiB;AACjB;AACA;;AAEA;AACA,kDAAkD,QAAQ;AAC1D;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA,qBAAqB,+BAA+B,QAAQ;AAC5D;AACA;AACA;AACA,wCAAwC,kCAAkC;AAC1E;AACA;AACA,qDAAqD,0CAA0C;AAC/F;AACA,iBAAiB;AACjB,MAAM;AACN,gEAAgE,eAAe;AAC/E,iBAAiB;AACjB;AACA;;AAEA;AACA,gDAAgD,QAAQ;AACxD;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA,iDAAiD,QAAQ;AACzD,qBAAqB,+BAA+B,QAAQ;AAC5D;AACA;AACA,2CAA2C,QAAQ;AACnD;AACA,iBAAiB;AACjB,MAAM;AACN,8DAA8D,eAAe;AAC7E,iBAAiB;AACjB;AACA;;AAEA;AACA,gDAAgD,kBAAkB;AAClE;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA,qBAAqB,+BAA+B,QAAQ;AAC5D;AACA;AACA,wCAAwC,gCAAgC;AACxE;AACA;AACA,2CAA2C,kBAAkB;AAC7D;AACA,iBAAiB;AACjB,MAAM;AACN,8DAA8D,yBAAyB;AACvF,iBAAiB;AACjB;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,qCAAqC,mBAAmB;AACxD;AACA;AACA;AACA,iDAAiD,6BAA6B;AAC9E,iBAAiB;AACjB,MAAM;AACN,2DAA2D,OAAO;AAClE,iBAAiB;AACjB;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,8BAA8B,YAAY,mBAAmB,SAAS,mBAAmB;AACzF;AACA;AACA,yDAAyD,wBAAwB;AACjF,iBAAiB;AACjB,MAAM;AACN,+DAA+D,OAAO;AACtE,iBAAiB;AACjB;AACA;;AAEA;AACA;AACA,oDAAoD,WAAW;AAC/D;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,8FAA8F,sDAAsD;AACpJ;AACA;;AAEA,uBAAuB,wEAAuB;AAC9C,0BAA0B,kDAAQ;AAClC,2DAA2D,wCAAwC;AACnG,MAAM;AACN,mHAAmH,sBAAsB;AACzI,uBAAuB,wEAAuB;AAC9C;AACA,+BAA+B,kDAAQ;AACvC,UAAU;AACV,mFAAmF,yBAAyB;AAC5G;AACA,wDAAwD,4BAA4B;AACpF;AACA;AACA;;AAEA;AACA;AACA,+CAA+C,WAAW;AAC1D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,qEAAoB;AAC3C,0BAA0B,kDAAQ;AAClC,gDAAgD,+CAA+C;AAC/F,MAAM;AACN,gHAAgH,sBAAsB;AACtI,uBAAuB,qEAAoB;AAC3C,0BAA0B,kDAAQ;AAClC,mDAAmD,4BAA4B;AAC/E;AACA;AACA;;AAEA;AACA;AACA,+CAA+C,WAAW;AAC1D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+FAA+F,QAAQ;AACvG;AACA;AACA;AACA;AACA,uFAAuF;AACvF,2FAA2F,mDAAmD;AAC9I;AACA,uBAAuB,qEAAoB;AAC3C,0BAA0B,kDAAQ;AAClC,4CAA4C,wEAAwE;AACpH,MAAM;AACN,gHAAgH,sBAAsB;AACtI,uBAAuB,qEAAoB;AAC3C,0BAA0B,kDAAQ;AAClC,mDAAmD,4BAA4B;AAC/E;AACA;AACA;;AAEA;AACA;AACA,kDAAkD,WAAW;AAC7D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8FAA8F,mDAAmD;AACjJ;AACA,uBAAuB,wEAAuB;AAC9C,0BAA0B,kDAAQ;AAClC,8CAA8C,mFAAmF;AACjI,MAAM;AACN,mHAAmH,sBAAsB;AACzI,uBAAuB,wEAAuB;AAC9C,0BAA0B,kDAAQ;AAClC,sDAAsD,4BAA4B;AAClF;AACA;AACA;;AAEA;AACA;AACA,kDAAkD,WAAW;AAC7D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB,sBAAsB;AACtC;AACA;AACA,kGAAkG,mDAAmD;AACrJ;AACA;AACA,uBAAuB,wEAAuB;AAC9C,0BAA0B,kDAAQ;AAClC,8CAA8C,mFAAmF;AACjI,MAAM;AACN,mHAAmH,sBAAsB;AACzI,uBAAuB,wEAAuB;AAC9C,0BAA0B,kDAAQ;AAClC,sDAAsD,4BAA4B;AAClF;AACA;AACA;;AAEA;AACA;AACA,iDAAiD,WAAW;AAC5D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,uEAAsB;AAC7C,0BAA0B,kDAAQ;AAClC,6CAA6C,6EAA6E;AAC1H,MAAM;AACN,kHAAkH,sBAAsB;AACxI,uBAAuB,uEAAsB;AAC7C,0BAA0B,kDAAQ;AAClC,qDAAqD,4BAA4B;AACjF;AACA;AACA,UAAU;AACV,2EAA2E,qCAAqC;AAChH;AACA;AACA;AACA;;AAEA;AACA;AACA,+CAA+C,WAAW;AAC1D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,qEAAoB;AAC3C,0BAA0B,kDAAQ;AAClC,2CAA2C,+CAA+C;AAC1F,MAAM;AACN,gHAAgH,sBAAsB;AACtI,uBAAuB,qEAAoB;AAC3C,0BAA0B,kDAAQ;AAClC,mDAAmD,4BAA4B;AAC/E;AACA;AACA;;AAEA;AACA;AACA,oDAAoD,WAAW;AAC/D;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uDAAuD,8BAA8B;AACrF,uBAAuB,yEAAwB;AAC/C,0BAA0B,kDAAQ;AAClC,iDAAiD,yCAAyC;AAC1F,MAAM;AACN,qHAAqH,sBAAsB;AAC3I,uBAAuB,yEAAwB;AAC/C,0BAA0B,kDAAQ;AAClC,wDAAwD,4BAA4B;AACpF;AACA;AACA;;AAEA;AACA;AACA,wDAAwD,WAAW;AACnE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT,oDAAoD,+BAA+B;AACnF,uBAAuB,6EAA4B;AACnD,0BAA0B,kDAAQ;AAClC,yDAAyD,0CAA0C;AACnG,MAAM;AACN,yHAAyH,sBAAsB;AAC/I,uBAAuB,6EAA4B;AACnD,0BAA0B,kDAAQ;AAClC,4DAA4D,4BAA4B;AACxF;AACA;AACA;;AAEA;AACA;AACA,kDAAkD,WAAW;AAC7D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sBAAsB,6EAA4B;AAClD;AACA,+BAA+B,6BAA6B;AAC5D;AACA;AACA;AACA,0CAA0C;AAC1C,kBAAkB,kDAAQ;AAC1B,UAAU;AACV;AACA;AACA,uBAAuB,wEAAuB;AAC9C,0BAA0B,kDAAQ;AAClC,8CAA8C,+CAA+C;AAC7F,MAAM;AACN,mHAAmH,sBAAsB;AACzI,uBAAuB,wEAAuB;AAC9C,0BAA0B,kDAAQ;AAClC,sDAAsD,4BAA4B;AAClF;AACA;AACA;;AAEA;AACA;AACA,kDAAkD,WAAW;AAC7D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,wEAAuB;AAC9C,0BAA0B,kDAAQ;AAClC,8CAA8C,+CAA+C;AAC7F,MAAM;AACN,mHAAmH,sBAAsB;AACzI,uBAAuB,wEAAuB;AAC9C,0BAA0B,kDAAQ;AAClC,sDAAsD,4BAA4B;AAClF;AACA;AACA;;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sDAAsD,sCAAsC;AAC5F,qBAAqB;AACrB,MAAM;AACN,qBAAqB;AACrB,4DAA4D,kBAAkB;AAC9E;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,kEAAiB;AACxC;AACA;AACA,kBAAkB,kDAAQ;AAC1B,UAAU;AACV;AACA;AACA,kDAAkD,+BAA+B;AACjF,MAAM;AACN,6GAA6G,sBAAsB;AACnI,uBAAuB,kEAAiB;AACxC;AACA;AACA,kBAAkB,kDAAQ,mCAAmC;AAC7D,UAAU;AACV;AACA;AACA,2CAA2C,4BAA4B;AACvE;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,6EAA4B;AACnD;AACA;AACA,kBAAkB,kDAAQ;AAC1B,UAAU;AACV;AACA;AACA,2DAA2D,iEAAiE;AAC5H,MAAM;AACN,0HAA0H,sBAAsB;AAChJ,uBAAuB,6EAA4B;AACnD;AACA;AACA,kBAAkB,kDAAQ,mCAAmC;AAC7D,UAAU;AACV;AACA;AACA,wDAAwD,4BAA4B;AACpF;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,oBAAoB,eAAe;AACnC;AACA,UAAU;AACV;AACA;AACA;AACA,uBAAuB,oEAAmB;AAC1C;AACA;AACA,kBAAkB,kDAAQ;AAC1B,UAAU;AACV;AACA;AACA;AACA,MAAM;AACN,+GAA+G,sBAAsB;AACrI,uBAAuB,oEAAmB;AAC1C;AACA;AACA,kBAAkB,kDAAQ,mCAAmC;AAC7D,UAAU;AACV;AACA;AACA,6CAA6C,4BAA4B;AACzE;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,yFAAwC;AAC/D;AACA;AACA,kBAAkB,kDAAQ;AAC1B,UAAU;AACV;AACA;AACA,sEAAsE,WAAW;AACjF,MAAM;AACN,iGAAiG,sBAAsB;AACvH,uBAAuB,yFAAwC;AAC/D;AACA;AACA,kBAAkB,kDAAQ;AAC1B,UAAU;AACV;AACA;AACA,mEAAmE,4BAA4B;AAC/F;AACA;AACA;;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uDAAuD,uBAAuB;AAC9E,iBAAiB;AACjB,MAAM;AACN,sFAAsF,OAAO;AAC7F,iBAAiB;AACjB;AACA;;;AAGA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,KAAK;;AAEL;AACA;AACA;AACA;;AAEA,aAAa,uBAAuB;AACpC;;;;;;;;;;;;;UCr0CA;UACA;;UAEA;UACA;UACA;UACA;UACA;UACA;UACA;UACA;UACA;UACA;UACA;UACA;UACA;;UAEA;UACA;;UAEA;UACA;UACA;;;;;WCtBA;WACA;WACA;WACA;WACA;WACA,iCAAiC,WAAW;WAC5C;WACA;;;;;WCPA;WACA;WACA;WACA;WACA,yCAAyC,wCAAwC;WACjF;WACA;WACA;;;;;WCPA;WACA;WACA;WACA;WACA,GAAG;WACH;WACA;WACA,CAAC;;;;;WCPD;;;;;WCAA;WACA;WACA;WACA,uDAAuD,iBAAiB;WACxE;WACA,gDAAgD,aAAa;WAC7D;;;;;;;;;;;;;;;;;;ACN4C;AACpB,CAAC;AACzB;;AAE6C;AACJ;AACqF;;AAE9H,gDAAc;;;AAGd;AACA;;AAEA;AACA;;AAEA,uBAAuB,oEAAiB;AACxC;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;;AAEA;;;AAGA;AACA;AACA,UAAU,+EAA+E,QAAQ,oEAAe;AAChH;AACA;AACA;AACA;AACA,QAAQ,mDAAiB;AACzB,QAAQ,mDAAiB;AACzB;AACA;AACA;AACA;AACA,IAAI,mDAAiB;AACrB,UAAU,oEAAe,aAAa,0CAA0C;AAChF;AACA,IAAI,mDAAiB;AACrB,UAAU,oEAAe,aAAa,2CAA2C;AACjF,IAAI,mDAAiB;AACrB;;AAEA;AACA;AACA,sBAAsB,oEAAe;AACrC,mCAAmC,oEAAe;AAClD;AACA;AACA,KAAK;AACL;AACA;;AAEA;AACA;AACA,QAAQ,mDAAiB;AACzB;AACA;AACA,IAAI,mDAAiB;AACrB,UAAU,sEAAiB;AAC3B;AACA,kBAAkB,wEAAiB;AACnC;AACA,KAAK;AACL,IAAI,mDAAiB;AACrB;;AAEA;AACA;AACA,iCAAiC,oEAAiB;AAClD,YAAY,mDAAiB,sFAAsF,cAAc;AACjI;AACA;AACA,MAAM;AACN,QAAQ,oDAAkB,+DAA+D,aAAa;AACtG;AACA;AACA,YAAY,oDAAkB,kEAAkE,aAAa;AAC7G,UAAU;AACV,YAAY,oDAAkB,kEAAkE,aAAa;AAC7G,+BAA+B,oEAAiB;AAChD,+EAA+E,aAAa;AAC5F;AACA;;AAEA,IAAI,oDAAkB,sCAAsC,cAAc;AAC1E;AACA,+BAA+B,oEAAe;AAC9C;AACA,2BAA2B,oEAAe;AAC1C,SAAS;AACT;AACA,YAAY,oEAAe;AAC3B,YAAY,oDAAkB,8BAA8B,cAAc;AAC1E,qBAAqB;AACrB,UAAU;AACV,YAAY,oDAAkB,yEAAyE,cAAc;AACrH;AACA;AACA,MAAM;AACN,QAAQ,oDAAkB,4CAA4C,cAAc;AACpF,2BAA2B,oEAAiB;AAC5C;AACA,+FAA+F,cAAc;AAC7G;AACA,UAAU,4DAA4D,oEAAiB,uCAAuC,oEAAiB;AAC/I,iFAAiF,cAAc;AAC/F;AACA;AACA,6EAA6E,cAAc;AAC3F;AACA;;AAEA;AACA,IAAI,oDAAkB,+CAA+C,iBAAiB;AACtF,6BAA6B,oEAAiB,uCAAuC,oEAAiB;AACtG,iCAAiC,oEAAiB;AAClD;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,IAAI,oDAAkB;AACtB,uBAAuB,oEAAiB;AACxC;AACA;AACA;;AAEA;AACA,YAAY,oDAAkB;AAC9B,+BAA+B,oEAAiB;AAChD;AACA;AACA,SAAS;AACT,KAAK;;AAEL;AACA;AACA,iCAAiC,oEAAiB;AAClD,YAAY,oDAAkB,yCAAyC,kBAAkB;AACzF;AACA,+BAA+B,oEAAiB;AAChD;AACA;AACA,KAAK;;AAEL;AACA;;AAEA;AACA,IAAI,mDAAiB,2BAA2B,QAAQ,mBAAmB,iBAAiB;AAC5F;AACA;AACA,QAAQ,oDAAkB,0CAA0C,iBAAiB;AACrF,MAAM;AACN,QAAQ,oDAAkB;AAC1B,qEAAqE,YAAY;AACjF;;AAEA,6BAA6B,oEAAiB,6CAA6C,oEAAiB,8BAA8B,oEAAiB;AAC3J,+CAA+C,QAAQ,sBAAsB,iBAAiB;AAC9F,QAAQ,oDAAkB;AAC1B;AACA;;AAEA;AACA;AACA;;AAEA,6BAA6B,oEAAiB;AAC9C,QAAQ,mDAAiB,uCAAuC,QAAQ;AACxE;AACA;AACA,6BAA6B,oEAAiB;AAC9C,QAAQ,mDAAiB,4CAA4C,QAAQ;AAC7E;AACA;AACA,6BAA6B,oEAAiB;AAC9C,QAAQ,oDAAkB;AAC1B,8FAA8F,iBAAiB;AAC/G;;AAEA,IAAI,mDAAiB,oDAAoD,QAAQ;AACjF,uBAAuB,oEAAiB;AACxC;AACA;AACA;AACA;;AAEA,QAAQ,oDAAkB,iDAAiD,QAAQ;AACnF,qCAAqC,yBAAyB,oBAAoB;AAClF;AACA,gBAAgB,oDAAkB,sCAAsC,QAAQ;AAChF,mCAAmC,oEAAiB;AACpD;AACA;AACA,aAAa;AACb,KAAK;;AAEL;AACA;AACA,iCAAiC,oEAAiB;AAClD,YAAY,oDAAkB,aAAa,iBAAiB,wBAAwB,SAAS;AAC7F,qEAAqE,SAAS;AAC9E,+BAA+B,oEAAiB;AAChD;AACA;AACA,KAAK;;AAEL;AACA;;AAEA;AACA;AACA,+BAA+B,kFAA6B;AAC5D;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sBAAsB,gDAAgD;AACtE,sBAAsB,gDAAgD;AACtE,sBAAsB,wDAAwD;AAC9E,sBAAsB;AACtB;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;AACA,cAAc,kFAA6B;AAC3C;AACA;AACA,SAAS;AACT,QAAQ,mDAAiB;AACzB,MAAM;AACN,QAAQ,oDAAkB;AAC1B;AACA;AACA;;AAEA;AACA;AACA,QAAQ,sEAAe;AACvB,+BAA+B,oEAAe;AAC9C;AACA,2BAA2B,oEAAe;AAC1C,SAAS;AACT;AACA;AACA;AACA;;AAEA;AACA;AACA,QAAQ,mDAAiB,sCAAsC,MAAM;AACrE;AACA;AACA;AACA,IAAI,mDAAiB,4DAA4D,SAAS;AAC1F,UAAU,sEAAiB;AAC3B;AACA;AACA;AACA,KAAK;AACL,IAAI,mDAAiB,uCAAuC,MAAM;AAClE,IAAI,mDAAiB,8DAA8D,SAAS;AAC5F;;AAEA;;;AAGA;AACA,IAAI,mDAAiB,mEAAmE,IAAI;AAC5F;AACA;;AAEA;AACA;AACA;AACA,YAAY,mDAAiB,gDAAgD,SAAS;AACtF;AACA,gBAAgB,iEAAY,gCAAgC,mDAAiB,iDAAiD,UAAU,IAAI,YAAY;AACxJ;AACA;AACA;AACA;;AAEA;AACA,8BAA8B,iEAAY,UAAU,yBAAyB;AAC7E;AACA;AACA;AACA;AACA;AACA,YAAY,mDAAiB,+CAA+C,UAAU;;AAEtF;AACA;AACA;AACA;AACA;AACA,wBAAwB,mDAAiB,kCAAkC,WAAW;AACtF;AACA,wBAAwB,iEAAY;AACpC;AACA;AACA;AACA,gBAAgB,iEAAY;AAC5B;AACA,oBAAoB,iEAAY;AAChC,qDAAqD,6BAA6B,kCAAkC,UAAU;AAC9H,iBAAiB;AACjB,aAAa;;AAEb;AACA,YAAY,mDAAiB,sFAAsF,UAAU;;AAE7H;AACA,kBAAkB,sEAAiB;AACnC,0BAA0B,kBAAkB;AAC5C;AACA,aAAa;AACb,YAAY,mDAAiB,qFAAqF,UAAU;;AAE5H;AACA,YAAY,mDAAiB,qGAAqG,UAAU;AAC5I,2CAA2C,sEAAiB;AAC5D,0BAA0B,kBAAkB;AAC5C,8BAA8B;AAC9B;AACA;AACA;AACA,0BAA0B;AAC1B;AACA,qCAAqC,0CAA0C,WAAW,UAAU,QAAQ;AAC5G;AACA,sBAAsB;AACtB;AACA,iCAAiC;AACjC;AACA;AACA,aAAa;;AAEb,YAAY,mDAAiB;;AAE7B;AACA;AACA;AACA;;AAEA;;AAEA;AACA,kGAAkG,mBAAmB;AACrH;AACA;AACA;AACA;AACA,gBAAgB,mDAAiB;AACjC;AACA,cAAc;AACd;AACA;;AAEA,UAAU;AACV,iEAAiE,cAAc;AAC/E,UAAU;AACV,6BAA6B;AAC7B,gBAAgB,iEAAY,gCAAgC,mDAAiB,iDAAiD,WAAW,kBAAkB,YAAY;AACvK;AACA;AACA,KAAK;AACL;;;AAGA;AACA,IAAI,mDAAiB,wCAAwC,IAAI,YAAY,OAAO,eAAe,UAAU;AAC7G;AACA,QAAQ,mDAAiB,yDAAyD,kBAAkB,YAAY,OAAO,aAAa,oBAAoB;AACxJ,QAAQ,oEAAe;AACvB;AACA;AACA,SAAS,aAAa,mDAAiB,mDAAmD,kBAAkB;AAC5G;;;AAGA;AACA;AACA;AACA,YAAY,mDAAiB,wEAAwE,IAAI;AACzG;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,UAAU;AACV,YAAY,mDAAiB,qEAAqE,IAAI,IAAI,oBAAoB;AAC9H,8BAA8B,4HAA4H;AAC1J;AACA;;;AAGA,MAAM;AACN,QAAQ,mDAAiB,oDAAoD,IAAI;AACjF;AACA;;AAEA;AACA;AACA;AACA,QAAQ,qEAAgB,gBAAgB,mBAAmB;AAC3D,gBAAgB,sEAAe;AAC/B,iCAAiC,sEAAe;AAChD,cAAc;AACd;AACA;AACA,SAAS;AACT,KAAK;AACL;;AAEA;AACA;AACA,sBAAsB,SAAS;AAC/B;AACA;AACA,6DAA6D;AAC7D;AACA;AACA;AACA;AACA,KAAK,EAAE;AACP,IAAI,mDAAiB,gDAAgD,SAAS,KAAK,IAAI;AACvF;AACA;AACA,uCAAuC,MAAM;AAC7C;AACA;AACA,KAAK;AACL;AACA;AACA,QAAQ,oDAAkB,oDAAoD,SAAS;AACvF;AACA,+CAA+C,SAAS;AACxD;AACA,2CAA2C,iBAAiB,WAAW,SAAS,KAAK,iCAAiC;AACtH;AACA;AACA,IAAI,mDAAiB,sDAAsD,SAAS,WAAW,yBAAyB;AACxH;AACA;;;;AAIA;AACA,IAAI,mDAAiB,wCAAwC,cAAc;AAC3E;AACA;AACA,QAAQ,mDAAiB,6CAA6C,SAAS,iBAAiB,MAAM;AACtG;AACA,kBAAkB,oEAAe;AACjC,YAAY,oEAAe;AAC3B,UAAU;AACV,YAAY,mDAAiB,uCAAuC,QAAQ;AAC5E;AACA;AACA;AACA;AACA;AACA;;AAEA,uBAAuB,iEAAY,SAAS,oBAAoB;AAChE;AACA;AACA;AACA,kBAAkB,iEAAY;AAC9B,UAAU;AACV;AACA,gBAAgB,mDAAiB,oCAAoC,OAAO;AAC5E;AACA;AACA;AACA;;AAEA,oEAAe;AACf,IAAI,mDAAiB;AACrB;AACA,UAAU,kDAAQ;AAClB,IAAI,sEAAiB;AACrB,4BAA4B,8BAA8B;AAC1D,0BAA0B,oDAAkB;AAC5C,IAAI,mDAAiB;AACrB,IAAI,oEAAe;AACnB;AACA;AACA,YAAY,oEAAe;AAC3B,gBAAgB,mDAAiB;AACjC,aAAa;AACb,gBAAgB,oDAAkB;AAClC,aAAa;AACb;AACA,KAAK;AACL,SAAS,oDAAkB;AAC3B,KAAK;AACL;AACA,QAAQ,oDAAkB;AAC1B,KAAK;AACL,CAAC;;AAED,oEAAe;AACf,IAAI,mDAAiB;AACrB;AACA,UAAU,kDAAQ;AAClB,6BAA6B,oEAAiB;AAC9C;AACA,YAAY,oDAAkB;AAC9B,SAAS;AACT;AACA,CAAC;;AAED,mEAAc;AACd;AACA,QAAQ,oDAAkB;AAC1B;AACA;AACA;AACA,IAAI,mDAAiB,2BAA2B,MAAM;AACtD;AACA;AACA,QAAQ,mDAAiB,UAAU,iBAAiB,iBAAiB,MAAM;AAC3E;AACA,kBAAkB,oEAAe;AACjC,YAAY,mDAAiB,wBAAwB,iBAAiB;AACtE,UAAU;AACV,YAAY,mDAAiB,0BAA0B,iBAAiB;AACxE;AACA,gBAAgB,mDAAiB,4CAA4C,OAAO;AACpF;AACA;AACA;AACA,0BAA0B,oEAAe,+BAA+B,MAAM;AAC9E,0BAA0B,sEAAiB,cAAc,6BAA6B;AACtF,kBAAkB;AAClB,oBAAoB,oDAAkB;AACtC;AACA;AACA;AACA,MAAM;AACN,QAAQ,mDAAiB,4BAA4B,MAAM;AAC3D;AACA,CAAC;;AAED,oEAAe;AACf,IAAI,mDAAiB,oBAAoB,SAAS;AAClD;AACA;AACA,QAAQ,mDAAiB,iBAAiB,UAAU,UAAU,OAAO;AACrE;AACA;AACA;AACA,kBAAkB,oEAAe,+BAA+B,MAAM;AACtE,YAAY,mDAAiB,gDAAgD,MAAM;AACnF,kBAAkB,sEAAiB,cAAc,6BAA6B;AAC9E,YAAY,mDAAiB,kCAAkC,OAAO;AACtE,UAAU;AACV,YAAY,oDAAkB,gEAAgE,OAAO;AACrG;AACA,MAAM;AACN,QAAQ,mDAAiB,WAAW,UAAU;AAC9C;AACA,CAAC;;AAED;AACA,oEAAe;AACf;AACA,YAAY,gBAAgB;AAC5B;;AAEA,IAAI,mDAAiB,2BAA2B,KAAK,6BAA6B,cAAc;;AAEhG,sBAAsB,mEAAgB;AACtC,QAAQ,mDAAiB,kCAAkC,KAAK;AAChE;AACA;AACA,iBAAiB,mEAAgB;AACjC,gBAAgB,mDAAiB;AACjC,mCAAmC,oEAAiB;AACpD;AACA;AACA;AACA;AACA,oCAAoC;AACpC;AACA,iBAAiB,mEAAgB;AACjC,gBAAgB,mDAAiB;AACjC,mCAAmC,oEAAiB;AACpD;AACA;AACA;AACA;AACA,oCAAoC;AACpC;AACA;AACA;AACA;AACA;AACA,iBAAiB,mEAAgB;AACjC;AACA;AACA;AACA,wBAAwB,mDAAiB;AACzC;AACA;AACA,kBAAkB;AAClB,oBAAoB,mDAAiB;AACrC;AACA;AACA,yCAAyC,oEAAiB;AAC1D,oBAAoB,mDAAiB,6DAA6D,iBAAiB;AACnH,uCAAuC,oEAAiB;AACxD;AACA,gBAAgB,oEAAe,eAAe,MAAM,+DAAY,qDAAqD;AACrH;AACA,wBAAwB,mDAAiB;AACzC;AACA,iBAAiB;AACjB;AACA,iBAAiB,mEAAgB;AACjC,gBAAgB,mDAAiB,oCAAoC,gBAAgB;AACrF,yEAAyE,oEAAiB;AAC1F,+EAA+E,oEAAiB;AAChG;AACA,iBAAiB,mEAAgB;AACjC,yCAAyC,oEAAiB;AAC1D,oBAAoB,mDAAiB,gEAAgE,iBAAiB;AACtH;AACA,mCAAmC,oEAAiB;AACpD;AACA,iBAAiB,mEAAgB;AACjC,gBAAgB,mDAAiB;AACjC,mCAAmC,oEAAiB;AACpD;AACA,iBAAiB,mEAAgB;AACjC,gBAAgB,oDAAkB;AAClC,mCAAmC,oEAAiB;AACpD;AACA,iBAAiB,mEAAgB;AACjC,gBAAgB,mDAAiB;AACjC,mCAAmC,oEAAiB;AACpD;AACA,iBAAiB,mEAAgB;AACjC,gBAAgB,oDAAkB;AAClC;AACA,mCAAmC,oEAAiB;AACpD,sCAAsC,oEAAiB;AACvD;AACA;AACA,kBAAkB,2BAA2B,oEAAiB;AAC9D;AACA;AACA;AACA,oCAAoC;AACpC;AACA;AACA;AACA;AACA,YAAY,mDAAiB;AAC7B,YAAY,iEAAY,SAAS;AACjC;AACA;AACA,wBAAwB,iEAAY,uBAAuB,MAAM,+DAAY,yDAAyD;AACtI;AACA;AACA,qCAAqC,mDAAiB,+CAA+C,OAAO;AAC5G;AACA,6BAA6B;AAC7B;AACA,iBAAiB;AACjB,aAAa;AACb,gBAAgB,oDAAkB;AAClC,aAAa;AACb;AACA;AACA;AACA;AACA;;AAEA,iBAAiB,sEAAmB;AACpC,QAAQ,mDAAiB;AACzB;AACA,QAAQ,mDAAiB,oDAAoD,QAAQ;AACrF;AACA,YAAY,oDAAkB;AAC9B,2BAA2B,4DAA4D;AACvF;AACA;;AAEA;AACA;AACA;AACA,gBAAgB,mDAAiB,cAAc,QAAQ;AACvD,+BAA+B,2EAA2E,QAAQ,IAAI;AACtH,aAAa;AACb;AACA,gBAAgB,oDAAkB,cAAc,QAAQ;AACxD,+BAA+B,sCAAsC;AACrE,aAAa;AACb;AACA;;AAEA,iBAAiB,sEAAmB;AACpC;AACA,gBAAgB,uCAAuC;AACvD;;AAEA,iCAAiC,oEAAiB;AAClD,YAAY,oDAAkB,6CAA6C,iBAAiB;AAC5F,2BAA2B,kDAAkD,iBAAiB,gCAAgC;AAC9H;AACA;;AAEA,QAAQ,mDAAiB,8CAA8C,cAAc;AACrF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,YAAY,mDAAiB,8BAA8B,cAAc;AACzE,2BAA2B,kEAAkE;AAC7F,SAAS;AACT;AACA,YAAY,oDAAkB,yCAAyC,cAAc;AACrF,qCAAqC,oEAAiB,gCAAgC,oEAAiB;AACvG,2BAA2B,sCAAsC;AACjE,SAAS;;AAET;AACA;;AAEA,iBAAiB,sEAAmB;AACpC,QAAQ,mDAAiB;AACzB;AACA,qDAAqD,mBAAmB;AACxE,uCAAuC,eAAe;AACtD,yCAAyC,oCAAoC;AAC7E;AACA;AACA;;AAEA,iBAAiB,sEAAmB;AACpC,QAAQ,mDAAiB;AACzB;AACA,qDAAqD,eAAe;AACpE,uCAAuC,eAAe;AACtD,yCAAyC,oCAAoC;AAC7E;AACA;AACA;;AAEA,iBAAiB,sEAAmB;AACpC,QAAQ,mDAAiB,2DAA2D,iBAAiB;AACrG,uBAAuB,wCAAwC;AAC/D;AACA;;AAEA,iBAAiB,sEAAmB;AACpC,QAAQ,mDAAiB,oDAAoD,aAAa;AAC1F;AACA;AACA;AACA,gBAAgB,mDAAiB,kBAAkB,aAAa;AAChE,+BAA+B,6DAA6D,aAAa,IAAI;AAC7G,aAAa;AACb;AACA,gBAAgB,oDAAkB,kBAAkB,aAAa;AACjE,+BAA+B,sCAAsC;AACrE,aAAa;AACb;AACA;;AAEA,iBAAiB,sEAAmB;AACpC;AACA,QAAQ,mDAAiB,4CAA4C,iBAAiB;AACtF;AACA;AACA;AACA;AACA;AACA,gBAAgB,mDAAiB,yBAAyB,oBAAoB;AAC9E;AACA;AACA;AACA;AACA,iBAAiB;AACjB,cAAc;AACd,gBAAgB,oDAAkB;AAClC;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA,SAAS;AACT;AACA;;AAEA,iBAAiB,sEAAmB;AACpC;AACA;AACA;AACA,wBAAwB,wBAAwB,QAAQ,oEAAe;AACvE,+BAA+B,yCAAyC;AACxE,cAAc;AACd,gBAAgB,oDAAkB;AAClC,+BAA+B,oCAAoC;AACnE;AACA,SAAS;AACT;AACA;;AAEA,iBAAiB,sEAAmB;AACpC;AACA;AACA;AACA;AACA,+BAA+B,8CAA8C;AAC7E;AACA;AACA;AACA,oCAAoC,UAAU;AAC9C,qCAAqC,oEAAe;AACpD,+BAA+B,2CAA2C;AAC1E,cAAc;AACd,gBAAgB,oDAAkB,mCAAmC,UAAU;AAC/E,+BAA+B,oCAAoC;AACnE;AACA,SAAS;AACT;AACA;;AAEA,iBAAiB,sEAAmB;AACpC;AACA;AACA;AACA,SAAS;AACT,2BAA2B,sCAAsC;AACjE,SAAS;AACT;AACA;;AAEA,iBAAiB,sEAAmB;AACpC;AACA;AACA;AACA,wBAAwB,kBAAkB,eAAe,YAAY,QAAQ,oEAAe,4BAA4B,eAAe;AACvI,+BAA+B,6BAA6B;AAC5D,cAAc;AACd,+BAA+B,sCAAsC;AACrE;AACA,SAAS;AACT;AACA;;AAEA,iBAAiB,sEAAmB;AACpC,uBAAuB,oBAAoB;AAC3C;AACA;;AAEA,sBAAsB,+DAAY;AAClC;AACA;AACA;;AAEA,IAAI,mDAAiB,4BAA4B,KAAK;AACtD;AACA,CAAC;;AAED,mDAAiB,qD","sources":["webpack://tabagent/./node_modules/@babel/runtime/helpers/esm/construct.js","webpack://tabagent/./node_modules/@babel/runtime/helpers/esm/createClass.js","webpack://tabagent/./node_modules/@babel/runtime/helpers/esm/getPrototypeOf.js","webpack://tabagent/./node_modules/@babel/runtime/helpers/esm/inheritsLoose.js","webpack://tabagent/./node_modules/@babel/runtime/helpers/esm/isNativeFunction.js","webpack://tabagent/./node_modules/@babel/runtime/helpers/esm/isNativeReflectConstruct.js","webpack://tabagent/./node_modules/@babel/runtime/helpers/esm/readOnlyError.js","webpack://tabagent/./node_modules/@babel/runtime/helpers/esm/setPrototypeOf.js","webpack://tabagent/./node_modules/@babel/runtime/helpers/esm/toPrimitive.js","webpack://tabagent/./node_modules/@babel/runtime/helpers/esm/toPropertyKey.js","webpack://tabagent/./node_modules/@babel/runtime/helpers/esm/typeof.js","webpack://tabagent/./node_modules/@babel/runtime/helpers/esm/wrapNativeSuper.js","webpack://tabagent/./node_modules/array-push-at-sort-position/dist/esm/index.js","webpack://tabagent/./node_modules/binary-decision-diagram/dist/esm/src/minimal-string/minimal-string-to-simple-bdd.js","webpack://tabagent/./node_modules/binary-decision-diagram/dist/esm/src/minimal-string/resolve-with-simple-bdd.js","webpack://tabagent/./node_modules/binary-decision-diagram/dist/esm/src/minimal-string/string-format.js","webpack://tabagent/./node_modules/binary-decision-diagram/dist/esm/src/util.js","webpack://tabagent/./node_modules/broadcast-channel/dist/esbrowser/broadcast-channel.js","webpack://tabagent/./node_modules/broadcast-channel/dist/esbrowser/leader-election-util.js","webpack://tabagent/./node_modules/broadcast-channel/dist/esbrowser/leader-election-web-lock.js","webpack://tabagent/./node_modules/broadcast-channel/dist/esbrowser/leader-election.js","webpack://tabagent/./node_modules/broadcast-channel/dist/esbrowser/method-chooser.js","webpack://tabagent/./node_modules/broadcast-channel/dist/esbrowser/methods/indexed-db.js","webpack://tabagent/./node_modules/broadcast-channel/dist/esbrowser/methods/localstorage.js","webpack://tabagent/./node_modules/broadcast-channel/dist/esbrowser/methods/native.js","webpack://tabagent/./node_modules/broadcast-channel/dist/esbrowser/methods/simulate.js","webpack://tabagent/./node_modules/broadcast-channel/dist/esbrowser/options.js","webpack://tabagent/./node_modules/broadcast-channel/dist/esbrowser/util.js","webpack://tabagent/./node_modules/custom-idle-queue/dist/es/index.js","webpack://tabagent/./node_modules/dexie/dist/dexie.js","webpack://tabagent/./node_modules/dexie/import-wrapper.mjs","webpack://tabagent/./node_modules/event-reduce-js/dist/esm/src/actions/action-functions.js","webpack://tabagent/./node_modules/event-reduce-js/dist/esm/src/actions/index.js","webpack://tabagent/./node_modules/event-reduce-js/dist/esm/src/bdd/bdd.generated.js","webpack://tabagent/./node_modules/event-reduce-js/dist/esm/src/index.js","webpack://tabagent/./node_modules/event-reduce-js/dist/esm/src/states/index.js","webpack://tabagent/./node_modules/event-reduce-js/dist/esm/src/states/state-resolver.js","webpack://tabagent/./node_modules/event-reduce-js/dist/esm/src/util.js","webpack://tabagent/./node_modules/mingo/dist/esm/aggregator.js","webpack://tabagent/./node_modules/mingo/dist/esm/core.js","webpack://tabagent/./node_modules/mingo/dist/esm/cursor.js","webpack://tabagent/./node_modules/mingo/dist/esm/lazy.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/_predicates.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/accumulator/_internal.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/accumulator/accumulator.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/accumulator/addToSet.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/accumulator/avg.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/accumulator/bottom.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/accumulator/bottomN.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/accumulator/count.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/accumulator/covariancePop.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/accumulator/covarianceSamp.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/accumulator/first.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/accumulator/firstN.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/accumulator/index.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/accumulator/last.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/accumulator/lastN.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/accumulator/max.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/accumulator/maxN.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/accumulator/median.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/accumulator/mergeObjects.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/accumulator/min.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/accumulator/minN.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/accumulator/percentile.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/accumulator/push.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/accumulator/stdDevPop.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/accumulator/stdDevSamp.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/accumulator/sum.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/accumulator/top.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/accumulator/topN.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/arithmetic/_internal.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/arithmetic/abs.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/arithmetic/add.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/arithmetic/ceil.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/arithmetic/divide.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/arithmetic/exp.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/arithmetic/floor.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/arithmetic/index.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/arithmetic/ln.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/arithmetic/log.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/arithmetic/log10.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/arithmetic/mod.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/arithmetic/multiply.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/arithmetic/pow.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/arithmetic/round.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/arithmetic/sqrt.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/arithmetic/subtract.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/arithmetic/trunc.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/array/arrayElemAt.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/array/arrayToObject.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/array/concatArrays.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/array/filter.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/array/first.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/array/firstN.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/array/in.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/array/index.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/array/indexOfArray.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/array/isArray.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/array/last.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/array/lastN.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/array/map.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/array/maxN.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/array/minN.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/array/nin.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/array/range.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/array/reduce.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/array/reverseArray.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/array/size.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/array/slice.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/array/sortArray.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/array/zip.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/bitwise/_internal.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/bitwise/bitAnd.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/bitwise/bitNot.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/bitwise/bitOr.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/bitwise/bitXor.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/bitwise/index.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/boolean/and.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/boolean/index.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/boolean/not.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/boolean/or.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/comparison/cmp.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/comparison/eq.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/comparison/gt.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/comparison/gte.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/comparison/index.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/comparison/lt.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/comparison/lte.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/comparison/ne.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/conditional/cond.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/conditional/ifNull.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/conditional/index.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/conditional/switch.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/custom/function.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/custom/index.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/date/_internal.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/date/dateAdd.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/date/dateDiff.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/date/dateFromParts.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/date/dateFromString.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/date/dateSubtract.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/date/dateToParts.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/date/dateToString.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/date/dateTrunc.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/date/dayOfMonth.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/date/dayOfWeek.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/date/dayOfYear.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/date/hour.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/date/index.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/date/isoDayOfWeek.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/date/isoWeek.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/date/isoWeekYear.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/date/millisecond.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/date/minute.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/date/month.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/date/second.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/date/week.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/date/year.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/index.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/literal.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/median.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/misc/getField.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/misc/index.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/misc/rand.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/misc/sampleRate.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/object/index.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/object/mergeObjects.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/object/objectToArray.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/object/setField.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/object/unsetField.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/percentile.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/set/allElementsTrue.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/set/anyElementTrue.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/set/index.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/set/setDifference.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/set/setEquals.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/set/setIntersection.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/set/setIsSubset.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/set/setUnion.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/string/_internal.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/string/concat.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/string/index.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/string/indexOfBytes.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/string/ltrim.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/string/regexFind.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/string/regexFindAll.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/string/regexMatch.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/string/replaceAll.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/string/replaceOne.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/string/rtrim.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/string/split.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/string/strLenBytes.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/string/strLenCP.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/string/strcasecmp.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/string/substr.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/string/substrBytes.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/string/substrCP.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/string/toLower.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/string/toUpper.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/string/trim.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/trignometry/_internal.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/trignometry/acos.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/trignometry/acosh.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/trignometry/asin.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/trignometry/asinh.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/trignometry/atan.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/trignometry/atan2.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/trignometry/atanh.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/trignometry/cos.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/trignometry/cosh.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/trignometry/degreesToRadians.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/trignometry/index.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/trignometry/radiansToDegrees.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/trignometry/sin.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/trignometry/sinh.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/trignometry/tan.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/type/_internal.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/type/convert.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/type/index.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/type/isNumber.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/type/toBool.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/type/toDate.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/type/toDecimal.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/type/toDouble.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/type/toInt.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/type/toLong.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/type/toString.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/type/type.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/variable/index.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/expression/variable/let.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/pipeline/_internal.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/pipeline/addFields.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/pipeline/bucket.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/pipeline/bucketAuto.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/pipeline/count.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/pipeline/densify.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/pipeline/facet.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/pipeline/fill.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/pipeline/graphLookup.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/pipeline/group.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/pipeline/index.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/pipeline/limit.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/pipeline/lookup.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/pipeline/match.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/pipeline/merge.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/pipeline/out.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/pipeline/project.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/pipeline/redact.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/pipeline/replaceRoot.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/pipeline/replaceWith.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/pipeline/sample.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/pipeline/set.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/pipeline/setWindowFields.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/pipeline/skip.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/pipeline/sort.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/pipeline/sortByCount.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/pipeline/unionWith.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/pipeline/unset.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/pipeline/unwind.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/query/array/all.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/query/array/elemMatch.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/query/array/index.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/query/array/size.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/query/bitwise/_internal.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/query/bitwise/bitsAllClear.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/query/bitwise/bitsAllSet.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/query/bitwise/bitsAnyClear.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/query/bitwise/bitsAnySet.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/query/bitwise/index.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/query/comparison/eq.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/query/comparison/gt.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/query/comparison/gte.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/query/comparison/in.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/query/comparison/index.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/query/comparison/lt.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/query/comparison/lte.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/query/comparison/ne.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/query/comparison/nin.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/query/element/exists.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/query/element/index.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/query/element/type.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/query/evaluation/expr.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/query/evaluation/index.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/query/evaluation/jsonSchema.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/query/evaluation/mod.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/query/evaluation/regex.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/query/evaluation/where.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/query/index.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/query/logical/and.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/query/logical/index.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/query/logical/nor.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/query/logical/not.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/query/logical/or.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/update/_internal.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/update/addToSet.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/update/bit.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/update/currentDate.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/update/inc.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/update/index.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/update/max.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/update/min.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/update/mul.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/update/pop.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/update/pull.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/update/pullAll.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/update/push.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/update/rename.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/update/set.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/update/unset.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/window/_internal.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/window/linearFill.js","webpack://tabagent/./node_modules/mingo/dist/esm/operators/window/locf.js","webpack://tabagent/./node_modules/mingo/dist/esm/query.js","webpack://tabagent/./node_modules/mingo/dist/esm/types.js","webpack://tabagent/./node_modules/mingo/dist/esm/updater.js","webpack://tabagent/./node_modules/mingo/dist/esm/util.js","webpack://tabagent/./node_modules/oblivious-set/dist/esm/src/index.js","webpack://tabagent/./node_modules/rxdb/dist/esm/change-event-buffer.js","webpack://tabagent/./node_modules/rxdb/dist/esm/doc-cache.js","webpack://tabagent/./node_modules/rxdb/dist/esm/event-reduce.js","webpack://tabagent/./node_modules/rxdb/dist/esm/hooks.js","webpack://tabagent/./node_modules/rxdb/dist/esm/incremental-write.js","webpack://tabagent/./node_modules/rxdb/dist/esm/overwritable.js","webpack://tabagent/./node_modules/rxdb/dist/esm/plugin.js","webpack://tabagent/./node_modules/rxdb/dist/esm/plugins/attachments/attachments-utils.js","webpack://tabagent/./node_modules/rxdb/dist/esm/plugins/local-documents/index.js","webpack://tabagent/./node_modules/rxdb/dist/esm/plugins/local-documents/local-documents-helper.js","webpack://tabagent/./node_modules/rxdb/dist/esm/plugins/local-documents/local-documents.js","webpack://tabagent/./node_modules/rxdb/dist/esm/plugins/local-documents/rx-local-document.js","webpack://tabagent/./node_modules/rxdb/dist/esm/plugins/migration-schema/index.js","webpack://tabagent/./node_modules/rxdb/dist/esm/plugins/migration-schema/migration-helpers.js","webpack://tabagent/./node_modules/rxdb/dist/esm/plugins/migration-schema/rx-migration-state.js","webpack://tabagent/./node_modules/rxdb/dist/esm/plugins/query-builder/index.js","webpack://tabagent/./node_modules/rxdb/dist/esm/plugins/query-builder/mquery/mquery-utils.js","webpack://tabagent/./node_modules/rxdb/dist/esm/plugins/query-builder/mquery/nosql-query-builder.js","webpack://tabagent/./node_modules/rxdb/dist/esm/plugins/storage-dexie/dexie-helper.js","webpack://tabagent/./node_modules/rxdb/dist/esm/plugins/storage-dexie/dexie-query.js","webpack://tabagent/./node_modules/rxdb/dist/esm/plugins/storage-dexie/rx-storage-dexie.js","webpack://tabagent/./node_modules/rxdb/dist/esm/plugins/storage-dexie/rx-storage-instance-dexie.js","webpack://tabagent/./node_modules/rxdb/dist/esm/plugins/update/index.js","webpack://tabagent/./node_modules/rxdb/dist/esm/plugins/update/mingo-updater.js","webpack://tabagent/./node_modules/rxdb/dist/esm/plugins/utils/utils-array.js","webpack://tabagent/./node_modules/rxdb/dist/esm/plugins/utils/utils-document.js","webpack://tabagent/./node_modules/rxdb/dist/esm/plugins/utils/utils-error.js","webpack://tabagent/./node_modules/rxdb/dist/esm/plugins/utils/utils-global.js","webpack://tabagent/./node_modules/rxdb/dist/esm/plugins/utils/utils-hash.js","webpack://tabagent/./node_modules/rxdb/dist/esm/plugins/utils/utils-map.js","webpack://tabagent/./node_modules/rxdb/dist/esm/plugins/utils/utils-object-deep-equal.js","webpack://tabagent/./node_modules/rxdb/dist/esm/plugins/utils/utils-object-dot-prop.js","webpack://tabagent/./node_modules/rxdb/dist/esm/plugins/utils/utils-object.js","webpack://tabagent/./node_modules/rxdb/dist/esm/plugins/utils/utils-other.js","webpack://tabagent/./node_modules/rxdb/dist/esm/plugins/utils/utils-premium.js","webpack://tabagent/./node_modules/rxdb/dist/esm/plugins/utils/utils-promise.js","webpack://tabagent/./node_modules/rxdb/dist/esm/plugins/utils/utils-regex.js","webpack://tabagent/./node_modules/rxdb/dist/esm/plugins/utils/utils-revision.js","webpack://tabagent/./node_modules/rxdb/dist/esm/plugins/utils/utils-rxdb-version.js","webpack://tabagent/./node_modules/rxdb/dist/esm/plugins/utils/utils-string.js","webpack://tabagent/./node_modules/rxdb/dist/esm/plugins/utils/utils-time.js","webpack://tabagent/./node_modules/rxdb/dist/esm/query-cache.js","webpack://tabagent/./node_modules/rxdb/dist/esm/query-planner.js","webpack://tabagent/./node_modules/rxdb/dist/esm/replication-protocol/checkpoint.js","webpack://tabagent/./node_modules/rxdb/dist/esm/replication-protocol/conflicts.js","webpack://tabagent/./node_modules/rxdb/dist/esm/replication-protocol/default-conflict-handler.js","webpack://tabagent/./node_modules/rxdb/dist/esm/replication-protocol/downstream.js","webpack://tabagent/./node_modules/rxdb/dist/esm/replication-protocol/helper.js","webpack://tabagent/./node_modules/rxdb/dist/esm/replication-protocol/index.js","webpack://tabagent/./node_modules/rxdb/dist/esm/replication-protocol/meta-instance.js","webpack://tabagent/./node_modules/rxdb/dist/esm/replication-protocol/upstream.js","webpack://tabagent/./node_modules/rxdb/dist/esm/rx-change-event.js","webpack://tabagent/./node_modules/rxdb/dist/esm/rx-collection-helper.js","webpack://tabagent/./node_modules/rxdb/dist/esm/rx-collection.js","webpack://tabagent/./node_modules/rxdb/dist/esm/rx-database-internal-store.js","webpack://tabagent/./node_modules/rxdb/dist/esm/rx-database.js","webpack://tabagent/./node_modules/rxdb/dist/esm/rx-document-prototype-merge.js","webpack://tabagent/./node_modules/rxdb/dist/esm/rx-document.js","webpack://tabagent/./node_modules/rxdb/dist/esm/rx-error.js","webpack://tabagent/./node_modules/rxdb/dist/esm/rx-query-helper.js","webpack://tabagent/./node_modules/rxdb/dist/esm/rx-query-mingo.js","webpack://tabagent/./node_modules/rxdb/dist/esm/rx-query-single-result.js","webpack://tabagent/./node_modules/rxdb/dist/esm/rx-query.js","webpack://tabagent/./node_modules/rxdb/dist/esm/rx-schema-helper.js","webpack://tabagent/./node_modules/rxdb/dist/esm/rx-schema.js","webpack://tabagent/./node_modules/rxdb/dist/esm/rx-storage-helper.js","webpack://tabagent/./node_modules/rxdb/dist/esm/rx-storage-multiinstance.js","webpack://tabagent/./node_modules/rxjs/dist/esm5/internal/BehaviorSubject.js","webpack://tabagent/./node_modules/rxjs/dist/esm5/internal/NotificationFactories.js","webpack://tabagent/./node_modules/rxjs/dist/esm5/internal/Observable.js","webpack://tabagent/./node_modules/rxjs/dist/esm5/internal/ReplaySubject.js","webpack://tabagent/./node_modules/rxjs/dist/esm5/internal/Subject.js","webpack://tabagent/./node_modules/rxjs/dist/esm5/internal/Subscriber.js","webpack://tabagent/./node_modules/rxjs/dist/esm5/internal/Subscription.js","webpack://tabagent/./node_modules/rxjs/dist/esm5/internal/config.js","webpack://tabagent/./node_modules/rxjs/dist/esm5/internal/firstValueFrom.js","webpack://tabagent/./node_modules/rxjs/dist/esm5/internal/observable/combineLatest.js","webpack://tabagent/./node_modules/rxjs/dist/esm5/internal/observable/concat.js","webpack://tabagent/./node_modules/rxjs/dist/esm5/internal/observable/empty.js","webpack://tabagent/./node_modules/rxjs/dist/esm5/internal/observable/from.js","webpack://tabagent/./node_modules/rxjs/dist/esm5/internal/observable/innerFrom.js","webpack://tabagent/./node_modules/rxjs/dist/esm5/internal/observable/merge.js","webpack://tabagent/./node_modules/rxjs/dist/esm5/internal/operators/OperatorSubscriber.js","webpack://tabagent/./node_modules/rxjs/dist/esm5/internal/operators/concatAll.js","webpack://tabagent/./node_modules/rxjs/dist/esm5/internal/operators/distinctUntilChanged.js","webpack://tabagent/./node_modules/rxjs/dist/esm5/internal/operators/filter.js","webpack://tabagent/./node_modules/rxjs/dist/esm5/internal/operators/map.js","webpack://tabagent/./node_modules/rxjs/dist/esm5/internal/operators/merge.js","webpack://tabagent/./node_modules/rxjs/dist/esm5/internal/operators/mergeAll.js","webpack://tabagent/./node_modules/rxjs/dist/esm5/internal/operators/mergeInternals.js","webpack://tabagent/./node_modules/rxjs/dist/esm5/internal/operators/mergeMap.js","webpack://tabagent/./node_modules/rxjs/dist/esm5/internal/operators/mergeWith.js","webpack://tabagent/./node_modules/rxjs/dist/esm5/internal/operators/observeOn.js","webpack://tabagent/./node_modules/rxjs/dist/esm5/internal/operators/share.js","webpack://tabagent/./node_modules/rxjs/dist/esm5/internal/operators/shareReplay.js","webpack://tabagent/./node_modules/rxjs/dist/esm5/internal/operators/startWith.js","webpack://tabagent/./node_modules/rxjs/dist/esm5/internal/operators/subscribeOn.js","webpack://tabagent/./node_modules/rxjs/dist/esm5/internal/operators/switchMap.js","webpack://tabagent/./node_modules/rxjs/dist/esm5/internal/scheduled/scheduleArray.js","webpack://tabagent/./node_modules/rxjs/dist/esm5/internal/scheduled/scheduleAsyncIterable.js","webpack://tabagent/./node_modules/rxjs/dist/esm5/internal/scheduled/scheduleIterable.js","webpack://tabagent/./node_modules/rxjs/dist/esm5/internal/scheduled/scheduleObservable.js","webpack://tabagent/./node_modules/rxjs/dist/esm5/internal/scheduled/schedulePromise.js","webpack://tabagent/./node_modules/rxjs/dist/esm5/internal/scheduled/scheduleReadableStreamLike.js","webpack://tabagent/./node_modules/rxjs/dist/esm5/internal/scheduled/scheduled.js","webpack://tabagent/./node_modules/rxjs/dist/esm5/internal/scheduler/dateTimestampProvider.js","webpack://tabagent/./node_modules/rxjs/dist/esm5/internal/scheduler/timeoutProvider.js","webpack://tabagent/./node_modules/rxjs/dist/esm5/internal/symbol/iterator.js","webpack://tabagent/./node_modules/rxjs/dist/esm5/internal/symbol/observable.js","webpack://tabagent/./node_modules/rxjs/dist/esm5/internal/util/EmptyError.js","webpack://tabagent/./node_modules/rxjs/dist/esm5/internal/util/ObjectUnsubscribedError.js","webpack://tabagent/./node_modules/rxjs/dist/esm5/internal/util/UnsubscriptionError.js","webpack://tabagent/./node_modules/rxjs/dist/esm5/internal/util/args.js","webpack://tabagent/./node_modules/rxjs/dist/esm5/internal/util/argsArgArrayOrObject.js","webpack://tabagent/./node_modules/rxjs/dist/esm5/internal/util/arrRemove.js","webpack://tabagent/./node_modules/rxjs/dist/esm5/internal/util/createErrorClass.js","webpack://tabagent/./node_modules/rxjs/dist/esm5/internal/util/createObject.js","webpack://tabagent/./node_modules/rxjs/dist/esm5/internal/util/errorContext.js","webpack://tabagent/./node_modules/rxjs/dist/esm5/internal/util/executeSchedule.js","webpack://tabagent/./node_modules/rxjs/dist/esm5/internal/util/identity.js","webpack://tabagent/./node_modules/rxjs/dist/esm5/internal/util/isArrayLike.js","webpack://tabagent/./node_modules/rxjs/dist/esm5/internal/util/isAsyncIterable.js","webpack://tabagent/./node_modules/rxjs/dist/esm5/internal/util/isFunction.js","webpack://tabagent/./node_modules/rxjs/dist/esm5/internal/util/isInteropObservable.js","webpack://tabagent/./node_modules/rxjs/dist/esm5/internal/util/isIterable.js","webpack://tabagent/./node_modules/rxjs/dist/esm5/internal/util/isPromise.js","webpack://tabagent/./node_modules/rxjs/dist/esm5/internal/util/isReadableStreamLike.js","webpack://tabagent/./node_modules/rxjs/dist/esm5/internal/util/isScheduler.js","webpack://tabagent/./node_modules/rxjs/dist/esm5/internal/util/lift.js","webpack://tabagent/./node_modules/rxjs/dist/esm5/internal/util/mapOneOrManyArgs.js","webpack://tabagent/./node_modules/rxjs/dist/esm5/internal/util/noop.js","webpack://tabagent/./node_modules/rxjs/dist/esm5/internal/util/pipe.js","webpack://tabagent/./node_modules/rxjs/dist/esm5/internal/util/reportUnhandledError.js","webpack://tabagent/./node_modules/rxjs/dist/esm5/internal/util/throwUnobservableError.js","webpack://tabagent/./node_modules/tslib/tslib.es6.mjs","webpack://tabagent/./node_modules/unload/dist/es/browser.js","webpack://tabagent/./node_modules/unload/dist/es/index.js","webpack://tabagent/./node_modules/unload/dist/es/node.js","webpack://tabagent/./node_modules/webextension-polyfill/dist/browser-polyfill.js","webpack://tabagent/./src/eventBus.js","webpack://tabagent/./src/events/dbEvents.js","webpack://tabagent/./src/events/eventNames.js","webpack://tabagent/./src/log-client.js","webpack://tabagent/./src/minimaldb.js","webpack://tabagent/webpack/bootstrap","webpack://tabagent/webpack/runtime/compat get default export","webpack://tabagent/webpack/runtime/define property getters","webpack://tabagent/webpack/runtime/global","webpack://tabagent/webpack/runtime/hasOwnProperty shorthand","webpack://tabagent/webpack/runtime/make namespace object","webpack://tabagent/./src/background.js"],"sourcesContent":["import isNativeReflectConstruct from \"./isNativeReflectConstruct.js\";\nimport setPrototypeOf from \"./setPrototypeOf.js\";\nfunction _construct(t, e, r) {\n  if (isNativeReflectConstruct()) return Reflect.construct.apply(null, arguments);\n  var o = [null];\n  o.push.apply(o, e);\n  var p = new (t.bind.apply(t, o))();\n  return r && setPrototypeOf(p, r.prototype), p;\n}\nexport { _construct as default };","import toPropertyKey from \"./toPropertyKey.js\";\nfunction _defineProperties(e, r) {\n  for (var t = 0; t < r.length; t++) {\n    var o = r[t];\n    o.enumerable = o.enumerable || !1, o.configurable = !0, \"value\" in o && (o.writable = !0), Object.defineProperty(e, toPropertyKey(o.key), o);\n  }\n}\nfunction _createClass(e, r, t) {\n  return r && _defineProperties(e.prototype, r), t && _defineProperties(e, t), Object.defineProperty(e, \"prototype\", {\n    writable: !1\n  }), e;\n}\nexport { _createClass as default };","function _getPrototypeOf(t) {\n  return _getPrototypeOf = Object.setPrototypeOf ? Object.getPrototypeOf.bind() : function (t) {\n    return t.__proto__ || Object.getPrototypeOf(t);\n  }, _getPrototypeOf(t);\n}\nexport { _getPrototypeOf as default };","import setPrototypeOf from \"./setPrototypeOf.js\";\nfunction _inheritsLoose(t, o) {\n  t.prototype = Object.create(o.prototype), t.prototype.constructor = t, setPrototypeOf(t, o);\n}\nexport { _inheritsLoose as default };","function _isNativeFunction(t) {\n  try {\n    return -1 !== Function.toString.call(t).indexOf(\"[native code]\");\n  } catch (n) {\n    return \"function\" == typeof t;\n  }\n}\nexport { _isNativeFunction as default };","function _isNativeReflectConstruct() {\n  try {\n    var t = !Boolean.prototype.valueOf.call(Reflect.construct(Boolean, [], function () {}));\n  } catch (t) {}\n  return (_isNativeReflectConstruct = function _isNativeReflectConstruct() {\n    return !!t;\n  })();\n}\nexport { _isNativeReflectConstruct as default };","function _readOnlyError(r) {\n  throw new TypeError('\"' + r + '\" is read-only');\n}\nexport { _readOnlyError as default };","function _setPrototypeOf(t, e) {\n  return _setPrototypeOf = Object.setPrototypeOf ? Object.setPrototypeOf.bind() : function (t, e) {\n    return t.__proto__ = e, t;\n  }, _setPrototypeOf(t, e);\n}\nexport { _setPrototypeOf as default };","import _typeof from \"./typeof.js\";\nfunction toPrimitive(t, r) {\n  if (\"object\" != _typeof(t) || !t) return t;\n  var e = t[Symbol.toPrimitive];\n  if (void 0 !== e) {\n    var i = e.call(t, r || \"default\");\n    if (\"object\" != _typeof(i)) return i;\n    throw new TypeError(\"@@toPrimitive must return a primitive value.\");\n  }\n  return (\"string\" === r ? String : Number)(t);\n}\nexport { toPrimitive as default };","import _typeof from \"./typeof.js\";\nimport toPrimitive from \"./toPrimitive.js\";\nfunction toPropertyKey(t) {\n  var i = toPrimitive(t, \"string\");\n  return \"symbol\" == _typeof(i) ? i : i + \"\";\n}\nexport { toPropertyKey as default };","function _typeof(o) {\n  \"@babel/helpers - typeof\";\n\n  return _typeof = \"function\" == typeof Symbol && \"symbol\" == typeof Symbol.iterator ? function (o) {\n    return typeof o;\n  } : function (o) {\n    return o && \"function\" == typeof Symbol && o.constructor === Symbol && o !== Symbol.prototype ? \"symbol\" : typeof o;\n  }, _typeof(o);\n}\nexport { _typeof as default };","import getPrototypeOf from \"./getPrototypeOf.js\";\nimport setPrototypeOf from \"./setPrototypeOf.js\";\nimport isNativeFunction from \"./isNativeFunction.js\";\nimport construct from \"./construct.js\";\nfunction _wrapNativeSuper(t) {\n  var r = \"function\" == typeof Map ? new Map() : void 0;\n  return _wrapNativeSuper = function _wrapNativeSuper(t) {\n    if (null === t || !isNativeFunction(t)) return t;\n    if (\"function\" != typeof t) throw new TypeError(\"Super expression must either be null or a function\");\n    if (void 0 !== r) {\n      if (r.has(t)) return r.get(t);\n      r.set(t, Wrapper);\n    }\n    function Wrapper() {\n      return construct(t, arguments, getPrototypeOf(this).constructor);\n    }\n    return Wrapper.prototype = Object.create(t.prototype, {\n      constructor: {\n        value: Wrapper,\n        enumerable: !1,\n        writable: !0,\n        configurable: !0\n      }\n    }), setPrototypeOf(Wrapper, t);\n  }, _wrapNativeSuper(t);\n}\nexport { _wrapNativeSuper as default };","/**\n * copied and adapted from npm 'binary-search-insert'\n * @link https://www.npmjs.com/package/binary-search-insert\n */\nexport function pushAtSortPosition(array, item, compareFunction, low) {\n  var length = array.length;\n  var high = length - 1;\n  var mid = 0;\n\n  /**\n   * Optimization shortcut.\n   */\n  if (length === 0) {\n    array.push(item);\n    return 0;\n  }\n\n  /**\n   * So we do not have to get the ret[mid] doc again\n   * at the last we store it here.\n   */\n  var lastMidDoc;\n  while (low <= high) {\n    // https://github.com/darkskyapp/binary-search\n    // http://googleresearch.blogspot.com/2006/06/extra-extra-read-all-about-it-nearly.html\n    mid = low + (high - low >> 1);\n    lastMidDoc = array[mid];\n    if (compareFunction(lastMidDoc, item) <= 0.0) {\n      // searching too low\n      low = mid + 1;\n    } else {\n      // searching too high\n      high = mid - 1;\n    }\n  }\n  if (compareFunction(lastMidDoc, item) <= 0.0) {\n    mid++;\n  }\n\n  /**\n   * Insert at correct position\n   */\n  array.splice(mid, 0, item);\n  return mid;\n}","import { splitStringToChunks } from '../util.js';\nimport { getNumberOfChar } from './string-format.js';\nexport function minimalStringToSimpleBdd(str) {\n    const nodesById = new Map();\n    // parse leaf nodes\n    const leafNodeAmount = parseInt(str.charAt(0) + str.charAt(1), 10);\n    const lastLeafNodeChar = (2 + leafNodeAmount * 2);\n    const leafNodeChars = str.substring(2, lastLeafNodeChar);\n    const leafNodeChunks = splitStringToChunks(leafNodeChars, 2);\n    for (let i = 0; i < leafNodeChunks.length; i++) {\n        const chunk = leafNodeChunks[i];\n        const id = chunk.charAt(0);\n        const value = getNumberOfChar(chunk.charAt(1));\n        nodesById.set(id, value);\n    }\n    // parse internal nodes\n    const internalNodeChars = str.substring(lastLeafNodeChar, str.length - 3);\n    const internalNodeChunks = splitStringToChunks(internalNodeChars, 4);\n    for (let i = 0; i < internalNodeChunks.length; i++) {\n        const chunk = internalNodeChunks[i];\n        const id = chunk.charAt(0);\n        const idOf0Branch = chunk.charAt(1);\n        const idOf1Branch = chunk.charAt(2);\n        const level = getNumberOfChar(chunk.charAt(3));\n        if (!nodesById.has(idOf0Branch)) {\n            throw new Error('missing node with id ' + idOf0Branch);\n        }\n        if (!nodesById.has(idOf1Branch)) {\n            throw new Error('missing node with id ' + idOf1Branch);\n        }\n        const node0 = nodesById.get(idOf0Branch);\n        const node1 = nodesById.get(idOf1Branch);\n        const node = {\n            l: level, // level is first for prettier json output\n            0: node0,\n            1: node1\n        };\n        nodesById.set(id, node);\n    }\n    // parse root node\n    const last3 = str.slice(-3);\n    const idOf0 = last3.charAt(0);\n    const idOf1 = last3.charAt(1);\n    const levelOfRoot = getNumberOfChar(last3.charAt(2));\n    const nodeOf0 = nodesById.get(idOf0);\n    const nodeOf1 = nodesById.get(idOf1);\n    const rootNode = {\n        l: levelOfRoot,\n        0: nodeOf0,\n        1: nodeOf1,\n    };\n    return rootNode;\n}\n//# sourceMappingURL=minimal-string-to-simple-bdd.js.map","import { booleanToBooleanString } from '../util.js';\nexport function resolveWithSimpleBdd(simpleBdd, fns, input) {\n    let currentNode = simpleBdd;\n    let currentLevel = simpleBdd.l;\n    while (true) {\n        const booleanResult = fns[currentLevel](input);\n        const branchKey = booleanToBooleanString(booleanResult);\n        currentNode = currentNode[branchKey];\n        if (typeof currentNode === 'number' || typeof currentNode === 'string') {\n            return currentNode;\n        }\n        else {\n            currentLevel = currentNode.l;\n        }\n    }\n}\n//# sourceMappingURL=resolve-with-simple-bdd.js.map","/*\nlet t = 0;\nwhile (t < 10000) {\n    const char = String.fromCharCode(t);\n    console.log(t + ' : ' + char);\n    t++;\n}\n*/\n/*\n\nTo have a really small string representation, we have to hack some stuff\nwhich makes is complicated but effective.\n\nRules for the string:\n- The string starts with a number like '23' that defines how many leaf-nodes we have\n- leaf nodes consist of two chars like 'ab'\n    - the first char is the id\n    - the second the value is a number you can get via String.charCodeAt()\n- Internal nodes have four chars like 'abcd'\n    - the first char is the id\n    - the second char is the id of the 0-branch\n    - the third char is the id of the 1-branch\n    - the last char is the id of the boolean-function (= level)\n- The last 3 chars of the string is the root node like 'abc'\n    - it looks like the internal-node but without the id (first char)\n\n*/\n// we use this because 39 is the quotes which causes problems\nexport const CHAR_CODE_OFFSET = 40; // String.fromCharCode(33) === ')'\nexport function getCharOfLevel(level) {\n    const charCode = CHAR_CODE_OFFSET + level;\n    return String.fromCharCode(charCode);\n}\nexport function getNumberOfChar(char) {\n    const charCode = char.charCodeAt(0);\n    return charCode - CHAR_CODE_OFFSET;\n}\nexport function getCharOfValue(value) {\n    const charCode = CHAR_CODE_OFFSET + value;\n    return String.fromCharCode(charCode);\n}\nexport const FIRST_CHAR_CODE_FOR_ID = 97; // String.fromCharCode(97) === 'a'\nexport function getNextCharId(lastCode) {\n    // jump these codes because they look strange\n    if (lastCode >= 128 && lastCode <= 160) {\n        lastCode = 161;\n    }\n    const char = String.fromCharCode(lastCode);\n    return {\n        char,\n        nextCode: lastCode + 1\n    };\n}\n//# sourceMappingURL=string-format.js.map","export function booleanStringToBoolean(str) {\n    if (str === '1') {\n        return true;\n    }\n    else {\n        return false;\n    }\n}\nexport function booleanToBooleanString(b) {\n    if (b) {\n        return '1';\n    }\n    else {\n        return '0';\n    }\n}\nexport function oppositeBoolean(input) {\n    if (input === '1') {\n        return '0';\n    }\n    else {\n        return '1';\n    }\n}\nexport function lastChar(str) {\n    return str.slice(-1);\n}\n/**\n * @link https://stackoverflow.com/a/1349426\n */\nfunction makeid(length = 6) {\n    let result = '';\n    const characters = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789';\n    const charactersLength = characters.length;\n    for (let i = 0; i < length; i++) {\n        result += characters.charAt(Math.floor(Math.random() * charactersLength));\n    }\n    return result;\n}\nconst nodeIdPrefix = makeid(4);\nlet lastIdGen = 0;\nexport function nextNodeId() {\n    const ret = 'node_' + nodeIdPrefix + '_' + lastIdGen;\n    lastIdGen++;\n    return ret;\n}\n/**\n * @link https://stackoverflow.com/a/16155417\n */\nexport function decimalToPaddedBinary(decimal, padding) {\n    const binary = (decimal >>> 0).toString(2);\n    const padded = binary.padStart(padding, '0');\n    return padded;\n}\nexport function oppositeBinary(i) {\n    if (i === '1') {\n        return '0';\n    }\n    else if (i === '0') {\n        return '1';\n    }\n    else {\n        throw new Error('non-binary given');\n    }\n}\nexport function binaryToDecimal(binary) {\n    return parseInt(binary, 2);\n}\nexport function minBinaryWithLength(length) {\n    return new Array(length).fill(0).map(() => '0').join('');\n}\nexport function maxBinaryWithLength(length) {\n    return new Array(length).fill(0).map(() => '1').join('');\n}\nexport function getNextStateSet(stateSet) {\n    const decimal = binaryToDecimal(stateSet);\n    const increase = decimal + 1;\n    const binary = decimalToPaddedBinary(increase, stateSet.length);\n    return binary;\n}\nexport function firstKeyOfMap(map) {\n    const iterator1 = map.keys();\n    return iterator1.next().value;\n}\n/**\n * Shuffles array in place. ES6 version\n * @link https://stackoverflow.com/a/6274381\n */\nexport function shuffleArray(a) {\n    for (let i = a.length - 1; i > 0; i--) {\n        const j = Math.floor(Math.random() * (i + 1));\n        [a[i], a[j]] = [a[j], a[i]];\n    }\n    return a;\n}\nexport function lastOfArray(ar) {\n    return ar[ar.length - 1];\n}\n/**\n * @link https://stackoverflow.com/a/6259536\n */\nexport function splitStringToChunks(str, chunkSize) {\n    const chunks = [];\n    for (let i = 0, charsLength = str.length; i < charsLength; i += chunkSize) {\n        chunks.push(str.substring(i, i + chunkSize));\n    }\n    return chunks;\n}\n//# sourceMappingURL=util.js.map","import { isPromise, PROMISE_RESOLVED_FALSE, PROMISE_RESOLVED_VOID } from './util.js';\nimport { chooseMethod } from './method-chooser.js';\nimport { fillOptionsWithDefaults } from './options.js';\n\n/**\n * Contains all open channels,\n * used in tests to ensure everything is closed.\n */\nexport var OPEN_BROADCAST_CHANNELS = new Set();\nvar lastId = 0;\nexport var BroadcastChannel = function BroadcastChannel(name, options) {\n  // identifier of the channel to debug stuff\n  this.id = lastId++;\n  OPEN_BROADCAST_CHANNELS.add(this);\n  this.name = name;\n  if (ENFORCED_OPTIONS) {\n    options = ENFORCED_OPTIONS;\n  }\n  this.options = fillOptionsWithDefaults(options);\n  this.method = chooseMethod(this.options);\n\n  // isListening\n  this._iL = false;\n\n  /**\n   * _onMessageListener\n   * setting onmessage twice,\n   * will overwrite the first listener\n   */\n  this._onML = null;\n\n  /**\n   * _addEventListeners\n   */\n  this._addEL = {\n    message: [],\n    internal: []\n  };\n\n  /**\n   * Unsent message promises\n   * where the sending is still in progress\n   * @type {Set<Promise>}\n   */\n  this._uMP = new Set();\n\n  /**\n   * _beforeClose\n   * array of promises that will be awaited\n   * before the channel is closed\n   */\n  this._befC = [];\n\n  /**\n   * _preparePromise\n   */\n  this._prepP = null;\n  _prepareChannel(this);\n};\n\n// STATICS\n\n/**\n * used to identify if someone overwrites\n * window.BroadcastChannel with this\n * See methods/native.js\n */\nBroadcastChannel._pubkey = true;\n\n/**\n * clears the tmp-folder if is node\n * @return {Promise<boolean>} true if has run, false if not node\n */\nexport function clearNodeFolder(options) {\n  options = fillOptionsWithDefaults(options);\n  var method = chooseMethod(options);\n  if (method.type === 'node') {\n    return method.clearNodeFolder().then(function () {\n      return true;\n    });\n  } else {\n    return PROMISE_RESOLVED_FALSE;\n  }\n}\n\n/**\n * if set, this method is enforced,\n * no mather what the options are\n */\nvar ENFORCED_OPTIONS;\nexport function enforceOptions(options) {\n  ENFORCED_OPTIONS = options;\n}\n\n// PROTOTYPE\nBroadcastChannel.prototype = {\n  postMessage: function postMessage(msg) {\n    if (this.closed) {\n      throw new Error('BroadcastChannel.postMessage(): ' + 'Cannot post message after channel has closed ' +\n      /**\n       * In the past when this error appeared, it was really hard to debug.\n       * So now we log the msg together with the error so it at least\n       * gives some clue about where in your application this happens.\n       */\n      JSON.stringify(msg));\n    }\n    return _post(this, 'message', msg);\n  },\n  postInternal: function postInternal(msg) {\n    return _post(this, 'internal', msg);\n  },\n  set onmessage(fn) {\n    var time = this.method.microSeconds();\n    var listenObj = {\n      time: time,\n      fn: fn\n    };\n    _removeListenerObject(this, 'message', this._onML);\n    if (fn && typeof fn === 'function') {\n      this._onML = listenObj;\n      _addListenerObject(this, 'message', listenObj);\n    } else {\n      this._onML = null;\n    }\n  },\n  addEventListener: function addEventListener(type, fn) {\n    var time = this.method.microSeconds();\n    var listenObj = {\n      time: time,\n      fn: fn\n    };\n    _addListenerObject(this, type, listenObj);\n  },\n  removeEventListener: function removeEventListener(type, fn) {\n    var obj = this._addEL[type].find(function (obj) {\n      return obj.fn === fn;\n    });\n    _removeListenerObject(this, type, obj);\n  },\n  close: function close() {\n    var _this = this;\n    if (this.closed) {\n      return;\n    }\n    OPEN_BROADCAST_CHANNELS[\"delete\"](this);\n    this.closed = true;\n    var awaitPrepare = this._prepP ? this._prepP : PROMISE_RESOLVED_VOID;\n    this._onML = null;\n    this._addEL.message = [];\n    return awaitPrepare\n    // wait until all current sending are processed\n    .then(function () {\n      return Promise.all(Array.from(_this._uMP));\n    })\n    // run before-close hooks\n    .then(function () {\n      return Promise.all(_this._befC.map(function (fn) {\n        return fn();\n      }));\n    })\n    // close the channel\n    .then(function () {\n      return _this.method.close(_this._state);\n    });\n  },\n  get type() {\n    return this.method.type;\n  },\n  get isClosed() {\n    return this.closed;\n  }\n};\n\n/**\n * Post a message over the channel\n * @returns {Promise} that resolved when the message sending is done\n */\nfunction _post(broadcastChannel, type, msg) {\n  var time = broadcastChannel.method.microSeconds();\n  var msgObj = {\n    time: time,\n    type: type,\n    data: msg\n  };\n  var awaitPrepare = broadcastChannel._prepP ? broadcastChannel._prepP : PROMISE_RESOLVED_VOID;\n  return awaitPrepare.then(function () {\n    var sendPromise = broadcastChannel.method.postMessage(broadcastChannel._state, msgObj);\n\n    // add/remove to unsent messages list\n    broadcastChannel._uMP.add(sendPromise);\n    sendPromise[\"catch\"]().then(function () {\n      return broadcastChannel._uMP[\"delete\"](sendPromise);\n    });\n    return sendPromise;\n  });\n}\nfunction _prepareChannel(channel) {\n  var maybePromise = channel.method.create(channel.name, channel.options);\n  if (isPromise(maybePromise)) {\n    channel._prepP = maybePromise;\n    maybePromise.then(function (s) {\n      // used in tests to simulate slow runtime\n      /*if (channel.options.prepareDelay) {\n           await new Promise(res => setTimeout(res, this.options.prepareDelay));\n      }*/\n      channel._state = s;\n    });\n  } else {\n    channel._state = maybePromise;\n  }\n}\nfunction _hasMessageListeners(channel) {\n  if (channel._addEL.message.length > 0) return true;\n  if (channel._addEL.internal.length > 0) return true;\n  return false;\n}\nfunction _addListenerObject(channel, type, obj) {\n  channel._addEL[type].push(obj);\n  _startListening(channel);\n}\nfunction _removeListenerObject(channel, type, obj) {\n  channel._addEL[type] = channel._addEL[type].filter(function (o) {\n    return o !== obj;\n  });\n  _stopListening(channel);\n}\nfunction _startListening(channel) {\n  if (!channel._iL && _hasMessageListeners(channel)) {\n    // someone is listening, start subscribing\n\n    var listenerFn = function listenerFn(msgObj) {\n      channel._addEL[msgObj.type].forEach(function (listenerObject) {\n        if (msgObj.time >= listenerObject.time) {\n          listenerObject.fn(msgObj.data);\n        }\n      });\n    };\n    var time = channel.method.microSeconds();\n    if (channel._prepP) {\n      channel._prepP.then(function () {\n        channel._iL = true;\n        channel.method.onMessage(channel._state, listenerFn, time);\n      });\n    } else {\n      channel._iL = true;\n      channel.method.onMessage(channel._state, listenerFn, time);\n    }\n  }\n}\nfunction _stopListening(channel) {\n  if (channel._iL && !_hasMessageListeners(channel)) {\n    // no one is listening, stop subscribing\n    channel._iL = false;\n    var time = channel.method.microSeconds();\n    channel.method.onMessage(channel._state, null, time);\n  }\n}","import { add as unloadAdd } from 'unload';\n\n/**\n * sends and internal message over the broadcast-channel\n */\nexport function sendLeaderMessage(leaderElector, action) {\n  var msgJson = {\n    context: 'leader',\n    action: action,\n    token: leaderElector.token\n  };\n  return leaderElector.broadcastChannel.postInternal(msgJson);\n}\nexport function beLeader(leaderElector) {\n  leaderElector.isLeader = true;\n  leaderElector._hasLeader = true;\n  var unloadFn = unloadAdd(function () {\n    return leaderElector.die();\n  });\n  leaderElector._unl.push(unloadFn);\n  var isLeaderListener = function isLeaderListener(msg) {\n    if (msg.context === 'leader' && msg.action === 'apply') {\n      sendLeaderMessage(leaderElector, 'tell');\n    }\n    if (msg.context === 'leader' && msg.action === 'tell' && !leaderElector._dpLC) {\n      /**\n       * another instance is also leader!\n       * This can happen on rare events\n       * like when the CPU is at 100% for long time\n       * or the tabs are open very long and the browser throttles them.\n       * @link https://github.com/pubkey/broadcast-channel/issues/414\n       * @link https://github.com/pubkey/broadcast-channel/issues/385\n       */\n      leaderElector._dpLC = true;\n      leaderElector._dpL(); // message the lib user so the app can handle the problem\n      sendLeaderMessage(leaderElector, 'tell'); // ensure other leader also knows the problem\n    }\n  };\n  leaderElector.broadcastChannel.addEventListener('internal', isLeaderListener);\n  leaderElector._lstns.push(isLeaderListener);\n  return sendLeaderMessage(leaderElector, 'tell');\n}","import { randomToken } from './util.js';\nimport { sendLeaderMessage, beLeader } from './leader-election-util.js';\n\n/**\n * A faster version of the leader elector that uses the WebLock API\n * @link https://developer.mozilla.org/en-US/docs/Web/API/Web_Locks_API\n */\nexport var LeaderElectionWebLock = function LeaderElectionWebLock(broadcastChannel, options) {\n  var _this = this;\n  this.broadcastChannel = broadcastChannel;\n  broadcastChannel._befC.push(function () {\n    return _this.die();\n  });\n  this._options = options;\n  this.isLeader = false;\n  this.isDead = false;\n  this.token = randomToken();\n  this._lstns = [];\n  this._unl = [];\n  this._dpL = function () {}; // onduplicate listener\n  this._dpLC = false; // true when onduplicate called\n\n  this._wKMC = {}; // stuff for cleanup\n\n  // lock name\n  this.lN = 'pubkey-bc||' + broadcastChannel.method.type + '||' + broadcastChannel.name;\n};\nLeaderElectionWebLock.prototype = {\n  hasLeader: function hasLeader() {\n    var _this2 = this;\n    return navigator.locks.query().then(function (locks) {\n      var relevantLocks = locks.held ? locks.held.filter(function (lock) {\n        return lock.name === _this2.lN;\n      }) : [];\n      if (relevantLocks && relevantLocks.length > 0) {\n        return true;\n      } else {\n        return false;\n      }\n    });\n  },\n  awaitLeadership: function awaitLeadership() {\n    var _this3 = this;\n    if (!this._wLMP) {\n      this._wKMC.c = new AbortController();\n      var returnPromise = new Promise(function (res, rej) {\n        _this3._wKMC.res = res;\n        _this3._wKMC.rej = rej;\n      });\n      this._wLMP = new Promise(function (res) {\n        navigator.locks.request(_this3.lN, {\n          signal: _this3._wKMC.c.signal\n        }, function () {\n          // if the lock resolved, we can drop the abort controller\n          _this3._wKMC.c = undefined;\n          beLeader(_this3);\n          res();\n          return returnPromise;\n        })[\"catch\"](function () {});\n      });\n    }\n    return this._wLMP;\n  },\n  set onduplicate(_fn) {\n    // Do nothing because there are no duplicates in the WebLock version\n  },\n  die: function die() {\n    var _this4 = this;\n    this._lstns.forEach(function (listener) {\n      return _this4.broadcastChannel.removeEventListener('internal', listener);\n    });\n    this._lstns = [];\n    this._unl.forEach(function (uFn) {\n      return uFn.remove();\n    });\n    this._unl = [];\n    if (this.isLeader) {\n      this.isLeader = false;\n    }\n    this.isDead = true;\n    if (this._wKMC.res) {\n      this._wKMC.res();\n    }\n    if (this._wKMC.c) {\n      this._wKMC.c.abort('LeaderElectionWebLock.die() called');\n    }\n    return sendLeaderMessage(this, 'death');\n  }\n};","import { sleep, randomToken, PROMISE_RESOLVED_VOID, PROMISE_RESOLVED_TRUE, supportsWebLockAPI } from './util.js';\nimport { sendLeaderMessage, beLeader } from './leader-election-util.js';\nimport { LeaderElectionWebLock } from './leader-election-web-lock.js';\nvar LeaderElection = function LeaderElection(broadcastChannel, options) {\n  var _this = this;\n  this.broadcastChannel = broadcastChannel;\n  this._options = options;\n  this.isLeader = false;\n  this._hasLeader = false;\n  this.isDead = false;\n  this.token = randomToken();\n\n  /**\n   * Apply Queue,\n   * used to ensure we do not run applyOnce()\n   * in parallel.\n   */\n  this._aplQ = PROMISE_RESOLVED_VOID;\n  // amount of unfinished applyOnce() calls\n  this._aplQC = 0;\n\n  // things to clean up\n  this._unl = []; // _unloads\n  this._lstns = []; // _listeners\n  this._dpL = function () {}; // onduplicate listener\n  this._dpLC = false; // true when onduplicate called\n\n  /**\n   * Even when the own instance is not applying,\n   * we still listen to messages to ensure the hasLeader flag\n   * is set correctly.\n   */\n  var hasLeaderListener = function hasLeaderListener(msg) {\n    if (msg.context === 'leader') {\n      if (msg.action === 'death') {\n        _this._hasLeader = false;\n      }\n      if (msg.action === 'tell') {\n        _this._hasLeader = true;\n      }\n    }\n  };\n  this.broadcastChannel.addEventListener('internal', hasLeaderListener);\n  this._lstns.push(hasLeaderListener);\n};\nLeaderElection.prototype = {\n  hasLeader: function hasLeader() {\n    return Promise.resolve(this._hasLeader);\n  },\n  /**\n   * Returns true if the instance is leader,\n   * false if not.\n   * @async\n   */\n  applyOnce: function applyOnce(\n  // true if the applyOnce() call came from the fallbackInterval cycle\n  isFromFallbackInterval) {\n    var _this2 = this;\n    if (this.isLeader) {\n      return sleep(0, true);\n    }\n    if (this.isDead) {\n      return sleep(0, false);\n    }\n\n    /**\n     * Already applying more than once,\n     * -> wait for the apply queue to be finished.\n     */\n    if (this._aplQC > 1) {\n      return this._aplQ;\n    }\n\n    /**\n     * Add a new apply-run\n     */\n    var applyRun = function applyRun() {\n      /**\n       * Optimization shortcuts.\n       * Directly return if a previous run\n       * has already elected a leader.\n       */\n      if (_this2.isLeader) {\n        return PROMISE_RESOLVED_TRUE;\n      }\n      var stopCriteria = false;\n      var stopCriteriaPromiseResolve;\n      /**\n       * Resolves when a stop criteria is reached.\n       * Uses as a performance shortcut so we do not\n       * have to await the responseTime when it is already clear\n       * that the election failed.\n       */\n      var stopCriteriaPromise = new Promise(function (res) {\n        stopCriteriaPromiseResolve = function stopCriteriaPromiseResolve() {\n          stopCriteria = true;\n          res();\n        };\n      });\n      var handleMessage = function handleMessage(msg) {\n        if (msg.context === 'leader' && msg.token != _this2.token) {\n          if (msg.action === 'apply') {\n            // other is applying\n            if (msg.token > _this2.token) {\n              /**\n               * other has higher token\n               * -> stop applying and let other become leader.\n               */\n              stopCriteriaPromiseResolve();\n            }\n          }\n          if (msg.action === 'tell') {\n            // other is already leader\n            stopCriteriaPromiseResolve();\n            _this2._hasLeader = true;\n          }\n        }\n      };\n      _this2.broadcastChannel.addEventListener('internal', handleMessage);\n\n      /**\n       * If the applyOnce() call came from the fallbackInterval,\n       * we can assume that the election runs in the background and\n       * not critical process is waiting for it.\n       * When this is true, we give the other instances\n       * more time to answer to messages in the election cycle.\n       * This makes it less likely to elect duplicate leaders.\n       * But also it takes longer which is not a problem because we anyway\n       * run in the background.\n       */\n      var waitForAnswerTime = isFromFallbackInterval ? _this2._options.responseTime * 4 : _this2._options.responseTime;\n      return sendLeaderMessage(_this2, 'apply') // send out that this one is applying\n      .then(function () {\n        return Promise.race([sleep(waitForAnswerTime), stopCriteriaPromise.then(function () {\n          return Promise.reject(new Error());\n        })]);\n      })\n      // send again in case another instance was just created\n      .then(function () {\n        return sendLeaderMessage(_this2, 'apply');\n      })\n      // let others time to respond\n      .then(function () {\n        return Promise.race([sleep(waitForAnswerTime), stopCriteriaPromise.then(function () {\n          return Promise.reject(new Error());\n        })]);\n      })[\"catch\"](function () {}).then(function () {\n        _this2.broadcastChannel.removeEventListener('internal', handleMessage);\n        if (!stopCriteria) {\n          // no stop criteria -> own is leader\n          return beLeader(_this2).then(function () {\n            return true;\n          });\n        } else {\n          // other is leader\n          return false;\n        }\n      });\n    };\n    this._aplQC = this._aplQC + 1;\n    this._aplQ = this._aplQ.then(function () {\n      return applyRun();\n    }).then(function () {\n      _this2._aplQC = _this2._aplQC - 1;\n    });\n    return this._aplQ.then(function () {\n      return _this2.isLeader;\n    });\n  },\n  awaitLeadership: function awaitLeadership() {\n    if (/* _awaitLeadershipPromise */\n    !this._aLP) {\n      this._aLP = _awaitLeadershipOnce(this);\n    }\n    return this._aLP;\n  },\n  set onduplicate(fn) {\n    this._dpL = fn;\n  },\n  die: function die() {\n    var _this3 = this;\n    this._lstns.forEach(function (listener) {\n      return _this3.broadcastChannel.removeEventListener('internal', listener);\n    });\n    this._lstns = [];\n    this._unl.forEach(function (uFn) {\n      return uFn.remove();\n    });\n    this._unl = [];\n    if (this.isLeader) {\n      this._hasLeader = false;\n      this.isLeader = false;\n    }\n    this.isDead = true;\n    return sendLeaderMessage(this, 'death');\n  }\n};\n\n/**\n * @param leaderElector {LeaderElector}\n */\nfunction _awaitLeadershipOnce(leaderElector) {\n  if (leaderElector.isLeader) {\n    return PROMISE_RESOLVED_VOID;\n  }\n  return new Promise(function (res) {\n    var resolved = false;\n    function finish() {\n      if (resolved) {\n        return;\n      }\n      resolved = true;\n      leaderElector.broadcastChannel.removeEventListener('internal', whenDeathListener);\n      res(true);\n    }\n\n    // try once now\n    leaderElector.applyOnce().then(function () {\n      if (leaderElector.isLeader) {\n        finish();\n      }\n    });\n\n    /**\n     * Try on fallbackInterval\n     * @recursive\n     */\n    var _tryOnFallBack = function tryOnFallBack() {\n      return sleep(leaderElector._options.fallbackInterval).then(function () {\n        if (leaderElector.isDead || resolved) {\n          return;\n        }\n        if (leaderElector.isLeader) {\n          finish();\n        } else {\n          return leaderElector.applyOnce(true).then(function () {\n            if (leaderElector.isLeader) {\n              finish();\n            } else {\n              _tryOnFallBack();\n            }\n          });\n        }\n      });\n    };\n    _tryOnFallBack();\n\n    // try when other leader dies\n    var whenDeathListener = function whenDeathListener(msg) {\n      if (msg.context === 'leader' && msg.action === 'death') {\n        leaderElector._hasLeader = false;\n        leaderElector.applyOnce().then(function () {\n          if (leaderElector.isLeader) {\n            finish();\n          }\n        });\n      }\n    };\n    leaderElector.broadcastChannel.addEventListener('internal', whenDeathListener);\n    leaderElector._lstns.push(whenDeathListener);\n  });\n}\nfunction fillOptionsWithDefaults(options, channel) {\n  if (!options) options = {};\n  options = JSON.parse(JSON.stringify(options));\n  if (!options.fallbackInterval) {\n    options.fallbackInterval = 3000;\n  }\n  if (!options.responseTime) {\n    options.responseTime = channel.method.averageResponseTime(channel.options);\n  }\n  return options;\n}\nexport function createLeaderElection(channel, options) {\n  if (channel._leaderElector) {\n    throw new Error('BroadcastChannel already has a leader-elector');\n  }\n  options = fillOptionsWithDefaults(options, channel);\n  var elector = supportsWebLockAPI() ? new LeaderElectionWebLock(channel, options) : new LeaderElection(channel, options);\n  channel._befC.push(function () {\n    return elector.die();\n  });\n  channel._leaderElector = elector;\n  return elector;\n}","import { NativeMethod } from './methods/native.js';\nimport { IndexedDBMethod } from './methods/indexed-db.js';\nimport { LocalstorageMethod } from './methods/localstorage.js';\nimport { SimulateMethod } from './methods/simulate.js';\n// the line below will be removed from es5/browser builds\n\n// order is important\nvar METHODS = [NativeMethod,\n// fastest\nIndexedDBMethod, LocalstorageMethod];\nexport function chooseMethod(options) {\n  var chooseMethods = [].concat(options.methods, METHODS).filter(Boolean);\n\n  // the line below will be removed from es5/browser builds\n\n  // directly chosen\n  if (options.type) {\n    if (options.type === 'simulate') {\n      // only use simulate-method if directly chosen\n      return SimulateMethod;\n    }\n    var ret = chooseMethods.find(function (m) {\n      return m.type === options.type;\n    });\n    if (!ret) throw new Error('method-type ' + options.type + ' not found');else return ret;\n  }\n\n  /**\n   * if no webworker support is needed,\n   * remove idb from the list so that localstorage will be chosen\n   */\n  if (!options.webWorkerSupport) {\n    chooseMethods = chooseMethods.filter(function (m) {\n      return m.type !== 'idb';\n    });\n  }\n  var useMethod = chooseMethods.find(function (method) {\n    return method.canBeUsed();\n  });\n  if (!useMethod) {\n    throw new Error(\"No usable method found in \" + JSON.stringify(METHODS.map(function (m) {\n      return m.type;\n    })));\n  } else {\n    return useMethod;\n  }\n}","/**\n * this method uses indexeddb to store the messages\n * There is currently no observerAPI for idb\n * @link https://github.com/w3c/IndexedDB/issues/51\n * \n * When working on this, ensure to use these performance optimizations:\n * @link https://rxdb.info/slow-indexeddb.html\n */\n\nimport { sleep, randomInt, randomToken, microSeconds as micro, PROMISE_RESOLVED_VOID } from '../util.js';\nexport var microSeconds = micro;\nimport { ObliviousSet } from 'oblivious-set';\nimport { fillOptionsWithDefaults } from '../options.js';\nvar DB_PREFIX = 'pubkey.broadcast-channel-0-';\nvar OBJECT_STORE_ID = 'messages';\n\n/**\n * Use relaxed durability for faster performance on all transactions.\n * @link https://nolanlawson.com/2021/08/22/speeding-up-indexeddb-reads-and-writes/\n */\nexport var TRANSACTION_SETTINGS = {\n  durability: 'relaxed'\n};\nexport var type = 'idb';\nexport function getIdb() {\n  if (typeof indexedDB !== 'undefined') return indexedDB;\n  if (typeof window !== 'undefined') {\n    if (typeof window.mozIndexedDB !== 'undefined') return window.mozIndexedDB;\n    if (typeof window.webkitIndexedDB !== 'undefined') return window.webkitIndexedDB;\n    if (typeof window.msIndexedDB !== 'undefined') return window.msIndexedDB;\n  }\n  return false;\n}\n\n/**\n * If possible, we should explicitly commit IndexedDB transactions\n * for better performance.\n * @link https://nolanlawson.com/2021/08/22/speeding-up-indexeddb-reads-and-writes/\n */\nexport function commitIndexedDBTransaction(tx) {\n  if (tx.commit) {\n    tx.commit();\n  }\n}\nexport function createDatabase(channelName) {\n  var IndexedDB = getIdb();\n\n  // create table\n  var dbName = DB_PREFIX + channelName;\n\n  /**\n   * All IndexedDB databases are opened without version\n   * because it is a bit faster, especially on firefox\n   * @link http://nparashuram.com/IndexedDB/perf/#Open%20Database%20with%20version\n   */\n  var openRequest = IndexedDB.open(dbName);\n  openRequest.onupgradeneeded = function (ev) {\n    var db = ev.target.result;\n    db.createObjectStore(OBJECT_STORE_ID, {\n      keyPath: 'id',\n      autoIncrement: true\n    });\n  };\n  return new Promise(function (res, rej) {\n    openRequest.onerror = function (ev) {\n      return rej(ev);\n    };\n    openRequest.onsuccess = function () {\n      res(openRequest.result);\n    };\n  });\n}\n\n/**\n * writes the new message to the database\n * so other readers can find it\n */\nexport function writeMessage(db, readerUuid, messageJson) {\n  var time = Date.now();\n  var writeObject = {\n    uuid: readerUuid,\n    time: time,\n    data: messageJson\n  };\n  var tx = db.transaction([OBJECT_STORE_ID], 'readwrite', TRANSACTION_SETTINGS);\n  return new Promise(function (res, rej) {\n    tx.oncomplete = function () {\n      return res();\n    };\n    tx.onerror = function (ev) {\n      return rej(ev);\n    };\n    var objectStore = tx.objectStore(OBJECT_STORE_ID);\n    objectStore.add(writeObject);\n    commitIndexedDBTransaction(tx);\n  });\n}\nexport function getAllMessages(db) {\n  var tx = db.transaction(OBJECT_STORE_ID, 'readonly', TRANSACTION_SETTINGS);\n  var objectStore = tx.objectStore(OBJECT_STORE_ID);\n  var ret = [];\n  return new Promise(function (res) {\n    objectStore.openCursor().onsuccess = function (ev) {\n      var cursor = ev.target.result;\n      if (cursor) {\n        ret.push(cursor.value);\n        //alert(\"Name for SSN \" + cursor.key + \" is \" + cursor.value.name);\n        cursor[\"continue\"]();\n      } else {\n        commitIndexedDBTransaction(tx);\n        res(ret);\n      }\n    };\n  });\n}\nexport function getMessagesHigherThan(db, lastCursorId) {\n  var tx = db.transaction(OBJECT_STORE_ID, 'readonly', TRANSACTION_SETTINGS);\n  var objectStore = tx.objectStore(OBJECT_STORE_ID);\n  var ret = [];\n  var keyRangeValue = IDBKeyRange.bound(lastCursorId + 1, Infinity);\n\n  /**\n   * Optimization shortcut,\n   * if getAll() can be used, do not use a cursor.\n   * @link https://rxdb.info/slow-indexeddb.html\n   */\n  if (objectStore.getAll) {\n    var getAllRequest = objectStore.getAll(keyRangeValue);\n    return new Promise(function (res, rej) {\n      getAllRequest.onerror = function (err) {\n        return rej(err);\n      };\n      getAllRequest.onsuccess = function (e) {\n        res(e.target.result);\n      };\n    });\n  }\n  function openCursor() {\n    // Occasionally Safari will fail on IDBKeyRange.bound, this\n    // catches that error, having it open the cursor to the first\n    // item. When it gets data it will advance to the desired key.\n    try {\n      keyRangeValue = IDBKeyRange.bound(lastCursorId + 1, Infinity);\n      return objectStore.openCursor(keyRangeValue);\n    } catch (e) {\n      return objectStore.openCursor();\n    }\n  }\n  return new Promise(function (res, rej) {\n    var openCursorRequest = openCursor();\n    openCursorRequest.onerror = function (err) {\n      return rej(err);\n    };\n    openCursorRequest.onsuccess = function (ev) {\n      var cursor = ev.target.result;\n      if (cursor) {\n        if (cursor.value.id < lastCursorId + 1) {\n          cursor[\"continue\"](lastCursorId + 1);\n        } else {\n          ret.push(cursor.value);\n          cursor[\"continue\"]();\n        }\n      } else {\n        commitIndexedDBTransaction(tx);\n        res(ret);\n      }\n    };\n  });\n}\nexport function removeMessagesById(channelState, ids) {\n  if (channelState.closed) {\n    return Promise.resolve([]);\n  }\n  var tx = channelState.db.transaction(OBJECT_STORE_ID, 'readwrite', TRANSACTION_SETTINGS);\n  var objectStore = tx.objectStore(OBJECT_STORE_ID);\n  return Promise.all(ids.map(function (id) {\n    var deleteRequest = objectStore[\"delete\"](id);\n    return new Promise(function (res) {\n      deleteRequest.onsuccess = function () {\n        return res();\n      };\n    });\n  }));\n}\nexport function getOldMessages(db, ttl) {\n  var olderThen = Date.now() - ttl;\n  var tx = db.transaction(OBJECT_STORE_ID, 'readonly', TRANSACTION_SETTINGS);\n  var objectStore = tx.objectStore(OBJECT_STORE_ID);\n  var ret = [];\n  return new Promise(function (res) {\n    objectStore.openCursor().onsuccess = function (ev) {\n      var cursor = ev.target.result;\n      if (cursor) {\n        var msgObk = cursor.value;\n        if (msgObk.time < olderThen) {\n          ret.push(msgObk);\n          //alert(\"Name for SSN \" + cursor.key + \" is \" + cursor.value.name);\n          cursor[\"continue\"]();\n        } else {\n          // no more old messages,\n          commitIndexedDBTransaction(tx);\n          res(ret);\n        }\n      } else {\n        res(ret);\n      }\n    };\n  });\n}\nexport function cleanOldMessages(channelState) {\n  return getOldMessages(channelState.db, channelState.options.idb.ttl).then(function (tooOld) {\n    return removeMessagesById(channelState, tooOld.map(function (msg) {\n      return msg.id;\n    }));\n  });\n}\nexport function create(channelName, options) {\n  options = fillOptionsWithDefaults(options);\n  return createDatabase(channelName).then(function (db) {\n    var state = {\n      closed: false,\n      lastCursorId: 0,\n      channelName: channelName,\n      options: options,\n      uuid: randomToken(),\n      /**\n       * emittedMessagesIds\n       * contains all messages that have been emitted before\n       * @type {ObliviousSet}\n       */\n      eMIs: new ObliviousSet(options.idb.ttl * 2),\n      // ensures we do not read messages in parallel\n      writeBlockPromise: PROMISE_RESOLVED_VOID,\n      messagesCallback: null,\n      readQueuePromises: [],\n      db: db\n    };\n\n    /**\n     * Handle abrupt closes that do not originate from db.close().\n     * This could happen, for example, if the underlying storage is\n     * removed or if the user clears the database in the browser's\n     * history preferences.\n     */\n    db.onclose = function () {\n      state.closed = true;\n      if (options.idb.onclose) options.idb.onclose();\n    };\n\n    /**\n     * if service-workers are used,\n     * we have no 'storage'-event if they post a message,\n     * therefore we also have to set an interval\n     */\n    _readLoop(state);\n    return state;\n  });\n}\nfunction _readLoop(state) {\n  if (state.closed) return;\n  readNewMessages(state).then(function () {\n    return sleep(state.options.idb.fallbackInterval);\n  }).then(function () {\n    return _readLoop(state);\n  });\n}\nfunction _filterMessage(msgObj, state) {\n  if (msgObj.uuid === state.uuid) return false; // send by own\n  if (state.eMIs.has(msgObj.id)) return false; // already emitted\n  if (msgObj.data.time < state.messagesCallbackTime) return false; // older then onMessageCallback\n  return true;\n}\n\n/**\n * reads all new messages from the database and emits them\n */\nfunction readNewMessages(state) {\n  // channel already closed\n  if (state.closed) return PROMISE_RESOLVED_VOID;\n\n  // if no one is listening, we do not need to scan for new messages\n  if (!state.messagesCallback) return PROMISE_RESOLVED_VOID;\n  return getMessagesHigherThan(state.db, state.lastCursorId).then(function (newerMessages) {\n    var useMessages = newerMessages\n    /**\n     * there is a bug in iOS where the msgObj can be undefined sometimes\n     * so we filter them out\n     * @link https://github.com/pubkey/broadcast-channel/issues/19\n     */.filter(function (msgObj) {\n      return !!msgObj;\n    }).map(function (msgObj) {\n      if (msgObj.id > state.lastCursorId) {\n        state.lastCursorId = msgObj.id;\n      }\n      return msgObj;\n    }).filter(function (msgObj) {\n      return _filterMessage(msgObj, state);\n    }).sort(function (msgObjA, msgObjB) {\n      return msgObjA.time - msgObjB.time;\n    }); // sort by time\n    useMessages.forEach(function (msgObj) {\n      if (state.messagesCallback) {\n        state.eMIs.add(msgObj.id);\n        state.messagesCallback(msgObj.data);\n      }\n    });\n    return PROMISE_RESOLVED_VOID;\n  });\n}\nexport function close(channelState) {\n  channelState.closed = true;\n  channelState.db.close();\n}\nexport function postMessage(channelState, messageJson) {\n  channelState.writeBlockPromise = channelState.writeBlockPromise.then(function () {\n    return writeMessage(channelState.db, channelState.uuid, messageJson);\n  }).then(function () {\n    if (randomInt(0, 10) === 0) {\n      /* await (do not await) */\n      cleanOldMessages(channelState);\n    }\n  });\n  return channelState.writeBlockPromise;\n}\nexport function onMessage(channelState, fn, time) {\n  channelState.messagesCallbackTime = time;\n  channelState.messagesCallback = fn;\n  readNewMessages(channelState);\n}\nexport function canBeUsed() {\n  return !!getIdb();\n}\nexport function averageResponseTime(options) {\n  return options.idb.fallbackInterval * 2;\n}\nexport var IndexedDBMethod = {\n  create: create,\n  close: close,\n  onMessage: onMessage,\n  postMessage: postMessage,\n  canBeUsed: canBeUsed,\n  type: type,\n  averageResponseTime: averageResponseTime,\n  microSeconds: microSeconds\n};","/**\n * A localStorage-only method which uses localstorage and its 'storage'-event\n * This does not work inside webworkers because they have no access to localstorage\n * This is basically implemented to support IE9 or your grandmother's toaster.\n * @link https://caniuse.com/#feat=namevalue-storage\n * @link https://caniuse.com/#feat=indexeddb\n */\n\nimport { ObliviousSet } from 'oblivious-set';\nimport { fillOptionsWithDefaults } from '../options.js';\nimport { sleep, randomToken, microSeconds as micro } from '../util.js';\nexport var microSeconds = micro;\nvar KEY_PREFIX = 'pubkey.broadcastChannel-';\nexport var type = 'localstorage';\n\n/**\n * copied from crosstab\n * @link https://github.com/tejacques/crosstab/blob/master/src/crosstab.js#L32\n */\nexport function getLocalStorage() {\n  var localStorage;\n  if (typeof window === 'undefined') return null;\n  try {\n    localStorage = window.localStorage;\n    localStorage = window['ie8-eventlistener/storage'] || window.localStorage;\n  } catch (e) {\n    // New versions of Firefox throw a Security exception\n    // if cookies are disabled. See\n    // https://bugzilla.mozilla.org/show_bug.cgi?id=1028153\n  }\n  return localStorage;\n}\nexport function storageKey(channelName) {\n  return KEY_PREFIX + channelName;\n}\n\n/**\n* writes the new message to the storage\n* and fires the storage-event so other readers can find it\n*/\nexport function postMessage(channelState, messageJson) {\n  return new Promise(function (res) {\n    sleep().then(function () {\n      var key = storageKey(channelState.channelName);\n      var writeObj = {\n        token: randomToken(),\n        time: Date.now(),\n        data: messageJson,\n        uuid: channelState.uuid\n      };\n      var value = JSON.stringify(writeObj);\n      getLocalStorage().setItem(key, value);\n\n      /**\n       * StorageEvent does not fire the 'storage' event\n       * in the window that changes the state of the local storage.\n       * So we fire it manually\n       */\n      var ev = document.createEvent('Event');\n      ev.initEvent('storage', true, true);\n      ev.key = key;\n      ev.newValue = value;\n      window.dispatchEvent(ev);\n      res();\n    });\n  });\n}\nexport function addStorageEventListener(channelName, fn) {\n  var key = storageKey(channelName);\n  var listener = function listener(ev) {\n    if (ev.key === key) {\n      fn(JSON.parse(ev.newValue));\n    }\n  };\n  window.addEventListener('storage', listener);\n  return listener;\n}\nexport function removeStorageEventListener(listener) {\n  window.removeEventListener('storage', listener);\n}\nexport function create(channelName, options) {\n  options = fillOptionsWithDefaults(options);\n  if (!canBeUsed()) {\n    throw new Error('BroadcastChannel: localstorage cannot be used');\n  }\n  var uuid = randomToken();\n\n  /**\n   * eMIs\n   * contains all messages that have been emitted before\n   * @type {ObliviousSet}\n   */\n  var eMIs = new ObliviousSet(options.localstorage.removeTimeout);\n  var state = {\n    channelName: channelName,\n    uuid: uuid,\n    eMIs: eMIs // emittedMessagesIds\n  };\n  state.listener = addStorageEventListener(channelName, function (msgObj) {\n    if (!state.messagesCallback) return; // no listener\n    if (msgObj.uuid === uuid) return; // own message\n    if (!msgObj.token || eMIs.has(msgObj.token)) return; // already emitted\n    if (msgObj.data.time && msgObj.data.time < state.messagesCallbackTime) return; // too old\n\n    eMIs.add(msgObj.token);\n    state.messagesCallback(msgObj.data);\n  });\n  return state;\n}\nexport function close(channelState) {\n  removeStorageEventListener(channelState.listener);\n}\nexport function onMessage(channelState, fn, time) {\n  channelState.messagesCallbackTime = time;\n  channelState.messagesCallback = fn;\n}\nexport function canBeUsed() {\n  var ls = getLocalStorage();\n  if (!ls) return false;\n  try {\n    var key = '__broadcastchannel_check';\n    ls.setItem(key, 'works');\n    ls.removeItem(key);\n  } catch (e) {\n    // Safari 10 in private mode will not allow write access to local\n    // storage and fail with a QuotaExceededError. See\n    // https://developer.mozilla.org/en-US/docs/Web/API/Web_Storage_API#Private_Browsing_Incognito_modes\n    return false;\n  }\n  return true;\n}\nexport function averageResponseTime() {\n  var defaultTime = 120;\n  var userAgent = navigator.userAgent.toLowerCase();\n  if (userAgent.includes('safari') && !userAgent.includes('chrome')) {\n    // safari is much slower so this time is higher\n    return defaultTime * 2;\n  }\n  return defaultTime;\n}\nexport var LocalstorageMethod = {\n  create: create,\n  close: close,\n  onMessage: onMessage,\n  postMessage: postMessage,\n  canBeUsed: canBeUsed,\n  type: type,\n  averageResponseTime: averageResponseTime,\n  microSeconds: microSeconds\n};","import { microSeconds as micro, PROMISE_RESOLVED_VOID } from '../util.js';\nexport var microSeconds = micro;\nexport var type = 'native';\nexport function create(channelName) {\n  var state = {\n    time: micro(),\n    messagesCallback: null,\n    bc: new BroadcastChannel(channelName),\n    subFns: [] // subscriberFunctions\n  };\n  state.bc.onmessage = function (msgEvent) {\n    if (state.messagesCallback) {\n      state.messagesCallback(msgEvent.data);\n    }\n  };\n  return state;\n}\nexport function close(channelState) {\n  channelState.bc.close();\n  channelState.subFns = [];\n}\nexport function postMessage(channelState, messageJson) {\n  try {\n    channelState.bc.postMessage(messageJson, false);\n    return PROMISE_RESOLVED_VOID;\n  } catch (err) {\n    return Promise.reject(err);\n  }\n}\nexport function onMessage(channelState, fn) {\n  channelState.messagesCallback = fn;\n}\nexport function canBeUsed() {\n  // Deno runtime\n  // eslint-disable-next-line\n  if (typeof globalThis !== 'undefined' && globalThis.Deno && globalThis.Deno.args) {\n    return true;\n  }\n\n  // Browser runtime\n  if ((typeof window !== 'undefined' || typeof self !== 'undefined') && typeof BroadcastChannel === 'function') {\n    if (BroadcastChannel._pubkey) {\n      throw new Error('BroadcastChannel: Do not overwrite window.BroadcastChannel with this module, this is not a polyfill');\n    }\n    return true;\n  } else {\n    return false;\n  }\n}\nexport function averageResponseTime() {\n  return 150;\n}\nexport var NativeMethod = {\n  create: create,\n  close: close,\n  onMessage: onMessage,\n  postMessage: postMessage,\n  canBeUsed: canBeUsed,\n  type: type,\n  averageResponseTime: averageResponseTime,\n  microSeconds: microSeconds\n};","import { microSeconds as micro } from '../util.js';\nexport var microSeconds = micro;\nexport var type = 'simulate';\nvar SIMULATE_CHANNELS = new Set();\nexport function create(channelName) {\n  var state = {\n    time: microSeconds(),\n    name: channelName,\n    messagesCallback: null\n  };\n  SIMULATE_CHANNELS.add(state);\n  return state;\n}\nexport function close(channelState) {\n  SIMULATE_CHANNELS[\"delete\"](channelState);\n}\nexport var SIMULATE_DELAY_TIME = 5;\nexport function postMessage(channelState, messageJson) {\n  return new Promise(function (res) {\n    return setTimeout(function () {\n      var channelArray = Array.from(SIMULATE_CHANNELS);\n      channelArray.forEach(function (channel) {\n        if (channel.name === channelState.name &&\n        // has same name\n        channel !== channelState &&\n        // not own channel\n        !!channel.messagesCallback &&\n        // has subscribers\n        channel.time < messageJson.time // channel not created after postMessage() call\n        ) {\n          channel.messagesCallback(messageJson);\n        }\n      });\n      res();\n    }, SIMULATE_DELAY_TIME);\n  });\n}\nexport function onMessage(channelState, fn) {\n  channelState.messagesCallback = fn;\n}\nexport function canBeUsed() {\n  return true;\n}\nexport function averageResponseTime() {\n  return SIMULATE_DELAY_TIME;\n}\nexport var SimulateMethod = {\n  create: create,\n  close: close,\n  onMessage: onMessage,\n  postMessage: postMessage,\n  canBeUsed: canBeUsed,\n  type: type,\n  averageResponseTime: averageResponseTime,\n  microSeconds: microSeconds\n};","export function fillOptionsWithDefaults() {\n  var originalOptions = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};\n  var options = JSON.parse(JSON.stringify(originalOptions));\n\n  // main\n  if (typeof options.webWorkerSupport === 'undefined') options.webWorkerSupport = true;\n\n  // indexed-db\n  if (!options.idb) options.idb = {};\n  //  after this time the messages get deleted\n  if (!options.idb.ttl) options.idb.ttl = 1000 * 45;\n  if (!options.idb.fallbackInterval) options.idb.fallbackInterval = 150;\n  //  handles abrupt db onclose events.\n  if (originalOptions.idb && typeof originalOptions.idb.onclose === 'function') options.idb.onclose = originalOptions.idb.onclose;\n\n  // localstorage\n  if (!options.localstorage) options.localstorage = {};\n  if (!options.localstorage.removeTimeout) options.localstorage.removeTimeout = 1000 * 60;\n\n  // custom methods\n  if (originalOptions.methods) options.methods = originalOptions.methods;\n\n  // node\n  if (!options.node) options.node = {};\n  if (!options.node.ttl) options.node.ttl = 1000 * 60 * 2; // 2 minutes;\n  /**\n   * On linux use 'ulimit -Hn' to get the limit of open files.\n   * On ubuntu this was 4096 for me, so we use half of that as maxParallelWrites default.\n   */\n  if (!options.node.maxParallelWrites) options.node.maxParallelWrites = 2048;\n  if (typeof options.node.useFastPath === 'undefined') options.node.useFastPath = true;\n  return options;\n}","/**\n * returns true if the given object is a promise\n */\nexport function isPromise(obj) {\n  return obj && typeof obj.then === 'function';\n}\nexport var PROMISE_RESOLVED_FALSE = Promise.resolve(false);\nexport var PROMISE_RESOLVED_TRUE = Promise.resolve(true);\nexport var PROMISE_RESOLVED_VOID = Promise.resolve();\nexport function sleep(time, resolveWith) {\n  if (!time) time = 0;\n  return new Promise(function (res) {\n    return setTimeout(function () {\n      return res(resolveWith);\n    }, time);\n  });\n}\nexport function randomInt(min, max) {\n  return Math.floor(Math.random() * (max - min + 1) + min);\n}\n\n/**\n * https://stackoverflow.com/a/8084248\n */\nexport function randomToken() {\n  return Math.random().toString(36).substring(2);\n}\nvar lastMs = 0;\n\n/**\n * Returns the current unix time in micro-seconds,\n * WARNING: This is a pseudo-function\n * Performance.now is not reliable in webworkers, so we just make sure to never return the same time.\n * This is enough in browsers, and this function will not be used in nodejs.\n * The main reason for this hack is to ensure that BroadcastChannel behaves equal to production when it is used in fast-running unit tests.\n */\nexport function microSeconds() {\n  var ret = Date.now() * 1000; // milliseconds to microseconds\n  if (ret <= lastMs) {\n    ret = lastMs + 1;\n  }\n  lastMs = ret;\n  return ret;\n}\n\n/**\n * Check if WebLock API is supported.\n * @link https://developer.mozilla.org/en-US/docs/Web/API/Web_Locks_API\n */\nexport function supportsWebLockAPI() {\n  if (typeof navigator !== 'undefined' && typeof navigator.locks !== 'undefined' && typeof navigator.locks.request === 'function') {\n    return true;\n  } else {\n    return false;\n  }\n}","/**\n * Creates a new Idle-Queue\n * @constructor\n * @param {number} [parallels=1] amount of parrallel runs of the limited-ressource\n */\nexport var IdleQueue = function IdleQueue() {\n  var parallels = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : 1;\n  this._parallels = parallels || 1;\n  /**\n   * _queueCounter\n   * each lock() increased this number\n   * each unlock() decreases this number\n   * If _qC==0, the state is in idle\n   * @type {Number}\n   */\n\n  this._qC = 0;\n  /**\n   * _idleCalls\n   * contains all promises that where added via requestIdlePromise()\n   * and not have been resolved\n   * @type {Set<Promise>} _iC with oldest promise first\n   */\n\n  this._iC = new Set();\n  /**\n   * _lastHandleNumber\n   * @type {Number}\n   */\n\n  this._lHN = 0;\n  /**\n   * _handlePromiseMap\n   * Contains the handleNumber on the left\n   * And the assigned promise on the right.\n   * This is stored so you can use cancelIdleCallback(handleNumber)\n   * to stop executing the callback.\n   * @type {Map<Number><Promise>}\n   */\n\n  this._hPM = new Map();\n  this._pHM = new Map(); // _promiseHandleMap\n};\nIdleQueue.prototype = {\n  isIdle: function isIdle() {\n    return this._qC < this._parallels;\n  },\n\n  /**\n   * creates a lock in the queue\n   * and returns an unlock-function to remove the lock from the queue\n   * @return {function} unlock function than must be called afterwards\n   */\n  lock: function lock() {\n    this._qC++;\n  },\n  unlock: function unlock() {\n    this._qC--;\n\n    _tryIdleCall(this);\n  },\n\n  /**\n   * wraps a function with lock/unlock and runs it\n   * @param  {function}  fun\n   * @return {Promise<any>}\n   */\n  wrapCall: function wrapCall(fun) {\n    var _this = this;\n\n    this.lock();\n    var maybePromise;\n\n    try {\n      maybePromise = fun();\n    } catch (err) {\n      this.unlock();\n      throw err;\n    }\n\n    if (!maybePromise.then || typeof maybePromise.then !== 'function') {\n      // no promise\n      this.unlock();\n      return maybePromise;\n    } else {\n      // promise\n      return maybePromise.then(function (ret) {\n        // sucessfull -> unlock before return\n        _this.unlock();\n\n        return ret;\n      })[\"catch\"](function (err) {\n        // not sucessfull -> unlock before throwing\n        _this.unlock();\n\n        throw err;\n      });\n    }\n  },\n\n  /**\n   * does the same as requestIdleCallback() but uses promises instead of the callback\n   * @param {{timeout?: number}} options like timeout\n   * @return {Promise<void>} promise that resolves when the database is in idle-mode\n   */\n  requestIdlePromise: function requestIdlePromise(options) {\n    var _this2 = this;\n\n    options = options || {};\n    var resolve;\n    var prom = new Promise(function (res) {\n      return resolve = res;\n    });\n\n    var resolveFromOutside = function resolveFromOutside() {\n      _removeIdlePromise(_this2, prom);\n\n      resolve();\n    };\n\n    prom._manRes = resolveFromOutside;\n\n    if (options.timeout) {\n      // if timeout has passed, resolve promise even if not idle\n      var timeoutObj = setTimeout(function () {\n        prom._manRes();\n      }, options.timeout);\n      prom._timeoutObj = timeoutObj;\n    }\n\n    this._iC.add(prom);\n\n    _tryIdleCall(this);\n\n    return prom;\n  },\n\n  /**\n   * remove the promise so it will never be resolved\n   * @param  {Promise} promise from requestIdlePromise()\n   * @return {void}\n   */\n  cancelIdlePromise: function cancelIdlePromise(promise) {\n    _removeIdlePromise(this, promise);\n  },\n\n  /**\n   * api equal to\n   * @link https://developer.mozilla.org/en-US/docs/Web/API/Window/requestIdleCallback\n   * @param  {Function} callback\n   * @param  {options}   options  [description]\n   * @return {number} handle which can be used with cancelIdleCallback()\n   */\n  requestIdleCallback: function requestIdleCallback(callback, options) {\n    var handle = this._lHN++;\n    var promise = this.requestIdlePromise(options);\n\n    this._hPM.set(handle, promise);\n\n    this._pHM.set(promise, handle);\n\n    promise.then(function () {\n      return callback();\n    });\n    return handle;\n  },\n\n  /**\n   * API equal to\n   * @link https://developer.mozilla.org/en-US/docs/Web/API/Window/cancelIdleCallback\n   * @param  {number} handle returned from requestIdleCallback()\n   * @return {void}\n   */\n  cancelIdleCallback: function cancelIdleCallback(handle) {\n    var promise = this._hPM.get(handle);\n\n    this.cancelIdlePromise(promise);\n  },\n\n  /**\n   * clears and resets everything\n   * @return {void}\n   */\n  clear: function clear() {\n    var _this3 = this;\n\n    // remove all non-cleared\n    this._iC.forEach(function (promise) {\n      return _removeIdlePromise(_this3, promise);\n    });\n\n    this._qC = 0;\n\n    this._iC.clear();\n\n    this._hPM = new Map();\n    this._pHM = new Map();\n  }\n};\n/**\n * processes the oldest call of the idleCalls-queue\n * @return {Promise<void>}\n */\n\nfunction _resolveOneIdleCall(idleQueue) {\n  if (idleQueue._iC.size === 0) return;\n\n  var iterator = idleQueue._iC.values();\n\n  var oldestPromise = iterator.next().value;\n\n  oldestPromise._manRes(); // try to call the next tick\n\n\n  setTimeout(function () {\n    return _tryIdleCall(idleQueue);\n  }, 0);\n}\n/**\n * removes the promise from the queue and maps and also its corresponding handle-number\n * @param  {Promise} promise from requestIdlePromise()\n * @return {void}\n */\n\n\nfunction _removeIdlePromise(idleQueue, promise) {\n  if (!promise) return; // remove timeout if exists\n\n  if (promise._timeoutObj) clearTimeout(promise._timeoutObj); // remove handle-nr if exists\n\n  if (idleQueue._pHM.has(promise)) {\n    var handle = idleQueue._pHM.get(promise);\n\n    idleQueue._hPM[\"delete\"](handle);\n\n    idleQueue._pHM[\"delete\"](promise);\n  } // remove from queue\n\n\n  idleQueue._iC[\"delete\"](promise);\n}\n/**\n * resolves the last entry of this._iC\n * but only if the queue is empty\n * @return {Promise}\n */\n\n\nfunction _tryIdleCall(idleQueue) {\n  // ensure this does not run in parallel\n  if (idleQueue._tryIR || idleQueue._iC.size === 0) return;\n  idleQueue._tryIR = true; // w8 one tick\n\n  setTimeout(function () {\n    // check if queue empty\n    if (!idleQueue.isIdle()) {\n      idleQueue._tryIR = false;\n      return;\n    }\n    /**\n     * wait 1 tick here\n     * because many functions do IO->CPU->IO\n     * which means the queue is empty for a short time\n     * but the ressource is not idle\n     */\n\n\n    setTimeout(function () {\n      // check if queue still empty\n      if (!idleQueue.isIdle()) {\n        idleQueue._tryIR = false;\n        return;\n      } // ressource is idle\n\n\n      _resolveOneIdleCall(idleQueue);\n\n      idleQueue._tryIR = false;\n    }, 0);\n  }, 0);\n}","/*\n * Dexie.js - a minimalistic wrapper for IndexedDB\n * ===============================================\n *\n * By David Fahlander, david.fahlander@gmail.com\n *\n * Version 4.0.10, Fri Nov 15 2024\n *\n * https://dexie.org\n *\n * Apache License Version 2.0, January 2004, http://www.apache.org/licenses/\n */\n \n(function (global, factory) {\n    typeof exports === 'object' && typeof module !== 'undefined' ? module.exports = factory() :\n    typeof define === 'function' && define.amd ? define(factory) :\n    (global = typeof globalThis !== 'undefined' ? globalThis : global || self, global.Dexie = factory());\n})(this, (function () { 'use strict';\n\n    /*! *****************************************************************************\n    Copyright (c) Microsoft Corporation.\n    Permission to use, copy, modify, and/or distribute this software for any\n    purpose with or without fee is hereby granted.\n    THE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH\n    REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY\n    AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT,\n    INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM\n    LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR\n    OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR\n    PERFORMANCE OF THIS SOFTWARE.\n    ***************************************************************************** */\n    var extendStatics = function(d, b) {\n        extendStatics = Object.setPrototypeOf ||\n            ({ __proto__: [] } instanceof Array && function (d, b) { d.__proto__ = b; }) ||\n            function (d, b) { for (var p in b) if (Object.prototype.hasOwnProperty.call(b, p)) d[p] = b[p]; };\n        return extendStatics(d, b);\n    };\n    function __extends(d, b) {\n        if (typeof b !== \"function\" && b !== null)\n            throw new TypeError(\"Class extends value \" + String(b) + \" is not a constructor or null\");\n        extendStatics(d, b);\n        function __() { this.constructor = d; }\n        d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n    }\n    var __assign = function() {\n        __assign = Object.assign || function __assign(t) {\n            for (var s, i = 1, n = arguments.length; i < n; i++) {\n                s = arguments[i];\n                for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p)) t[p] = s[p];\n            }\n            return t;\n        };\n        return __assign.apply(this, arguments);\n    };\n    function __spreadArray(to, from, pack) {\n        if (pack || arguments.length === 2) for (var i = 0, l = from.length, ar; i < l; i++) {\n            if (ar || !(i in from)) {\n                if (!ar) ar = Array.prototype.slice.call(from, 0, i);\n                ar[i] = from[i];\n            }\n        }\n        return to.concat(ar || Array.prototype.slice.call(from));\n    }\n\n    var _global = typeof globalThis !== 'undefined' ? globalThis :\n        typeof self !== 'undefined' ? self :\n            typeof window !== 'undefined' ? window :\n                global;\n\n    var keys = Object.keys;\n    var isArray = Array.isArray;\n    if (typeof Promise !== 'undefined' && !_global.Promise) {\n        _global.Promise = Promise;\n    }\n    function extend(obj, extension) {\n        if (typeof extension !== 'object')\n            return obj;\n        keys(extension).forEach(function (key) {\n            obj[key] = extension[key];\n        });\n        return obj;\n    }\n    var getProto = Object.getPrototypeOf;\n    var _hasOwn = {}.hasOwnProperty;\n    function hasOwn(obj, prop) {\n        return _hasOwn.call(obj, prop);\n    }\n    function props(proto, extension) {\n        if (typeof extension === 'function')\n            extension = extension(getProto(proto));\n        (typeof Reflect === \"undefined\" ? keys : Reflect.ownKeys)(extension).forEach(function (key) {\n            setProp(proto, key, extension[key]);\n        });\n    }\n    var defineProperty = Object.defineProperty;\n    function setProp(obj, prop, functionOrGetSet, options) {\n        defineProperty(obj, prop, extend(functionOrGetSet && hasOwn(functionOrGetSet, \"get\") && typeof functionOrGetSet.get === 'function' ?\n            { get: functionOrGetSet.get, set: functionOrGetSet.set, configurable: true } :\n            { value: functionOrGetSet, configurable: true, writable: true }, options));\n    }\n    function derive(Child) {\n        return {\n            from: function (Parent) {\n                Child.prototype = Object.create(Parent.prototype);\n                setProp(Child.prototype, \"constructor\", Child);\n                return {\n                    extend: props.bind(null, Child.prototype)\n                };\n            }\n        };\n    }\n    var getOwnPropertyDescriptor = Object.getOwnPropertyDescriptor;\n    function getPropertyDescriptor(obj, prop) {\n        var pd = getOwnPropertyDescriptor(obj, prop);\n        var proto;\n        return pd || (proto = getProto(obj)) && getPropertyDescriptor(proto, prop);\n    }\n    var _slice = [].slice;\n    function slice(args, start, end) {\n        return _slice.call(args, start, end);\n    }\n    function override(origFunc, overridedFactory) {\n        return overridedFactory(origFunc);\n    }\n    function assert(b) {\n        if (!b)\n            throw new Error(\"Assertion Failed\");\n    }\n    function asap$1(fn) {\n        if (_global.setImmediate)\n            setImmediate(fn);\n        else\n            setTimeout(fn, 0);\n    }\n    function arrayToObject(array, extractor) {\n        return array.reduce(function (result, item, i) {\n            var nameAndValue = extractor(item, i);\n            if (nameAndValue)\n                result[nameAndValue[0]] = nameAndValue[1];\n            return result;\n        }, {});\n    }\n    function getByKeyPath(obj, keyPath) {\n        if (typeof keyPath === 'string' && hasOwn(obj, keyPath))\n            return obj[keyPath];\n        if (!keyPath)\n            return obj;\n        if (typeof keyPath !== 'string') {\n            var rv = [];\n            for (var i = 0, l = keyPath.length; i < l; ++i) {\n                var val = getByKeyPath(obj, keyPath[i]);\n                rv.push(val);\n            }\n            return rv;\n        }\n        var period = keyPath.indexOf('.');\n        if (period !== -1) {\n            var innerObj = obj[keyPath.substr(0, period)];\n            return innerObj == null ? undefined : getByKeyPath(innerObj, keyPath.substr(period + 1));\n        }\n        return undefined;\n    }\n    function setByKeyPath(obj, keyPath, value) {\n        if (!obj || keyPath === undefined)\n            return;\n        if ('isFrozen' in Object && Object.isFrozen(obj))\n            return;\n        if (typeof keyPath !== 'string' && 'length' in keyPath) {\n            assert(typeof value !== 'string' && 'length' in value);\n            for (var i = 0, l = keyPath.length; i < l; ++i) {\n                setByKeyPath(obj, keyPath[i], value[i]);\n            }\n        }\n        else {\n            var period = keyPath.indexOf('.');\n            if (period !== -1) {\n                var currentKeyPath = keyPath.substr(0, period);\n                var remainingKeyPath = keyPath.substr(period + 1);\n                if (remainingKeyPath === \"\")\n                    if (value === undefined) {\n                        if (isArray(obj) && !isNaN(parseInt(currentKeyPath)))\n                            obj.splice(currentKeyPath, 1);\n                        else\n                            delete obj[currentKeyPath];\n                    }\n                    else\n                        obj[currentKeyPath] = value;\n                else {\n                    var innerObj = obj[currentKeyPath];\n                    if (!innerObj || !hasOwn(obj, currentKeyPath))\n                        innerObj = (obj[currentKeyPath] = {});\n                    setByKeyPath(innerObj, remainingKeyPath, value);\n                }\n            }\n            else {\n                if (value === undefined) {\n                    if (isArray(obj) && !isNaN(parseInt(keyPath)))\n                        obj.splice(keyPath, 1);\n                    else\n                        delete obj[keyPath];\n                }\n                else\n                    obj[keyPath] = value;\n            }\n        }\n    }\n    function delByKeyPath(obj, keyPath) {\n        if (typeof keyPath === 'string')\n            setByKeyPath(obj, keyPath, undefined);\n        else if ('length' in keyPath)\n            [].map.call(keyPath, function (kp) {\n                setByKeyPath(obj, kp, undefined);\n            });\n    }\n    function shallowClone(obj) {\n        var rv = {};\n        for (var m in obj) {\n            if (hasOwn(obj, m))\n                rv[m] = obj[m];\n        }\n        return rv;\n    }\n    var concat = [].concat;\n    function flatten(a) {\n        return concat.apply([], a);\n    }\n    var intrinsicTypeNames = \"BigUint64Array,BigInt64Array,Array,Boolean,String,Date,RegExp,Blob,File,FileList,FileSystemFileHandle,FileSystemDirectoryHandle,ArrayBuffer,DataView,Uint8ClampedArray,ImageBitmap,ImageData,Map,Set,CryptoKey\"\n        .split(',').concat(flatten([8, 16, 32, 64].map(function (num) { return [\"Int\", \"Uint\", \"Float\"].map(function (t) { return t + num + \"Array\"; }); }))).filter(function (t) { return _global[t]; });\n    var intrinsicTypes = new Set(intrinsicTypeNames.map(function (t) { return _global[t]; }));\n    function cloneSimpleObjectTree(o) {\n        var rv = {};\n        for (var k in o)\n            if (hasOwn(o, k)) {\n                var v = o[k];\n                rv[k] = !v || typeof v !== 'object' || intrinsicTypes.has(v.constructor) ? v : cloneSimpleObjectTree(v);\n            }\n        return rv;\n    }\n    function objectIsEmpty(o) {\n        for (var k in o)\n            if (hasOwn(o, k))\n                return false;\n        return true;\n    }\n    var circularRefs = null;\n    function deepClone(any) {\n        circularRefs = new WeakMap();\n        var rv = innerDeepClone(any);\n        circularRefs = null;\n        return rv;\n    }\n    function innerDeepClone(x) {\n        if (!x || typeof x !== 'object')\n            return x;\n        var rv = circularRefs.get(x);\n        if (rv)\n            return rv;\n        if (isArray(x)) {\n            rv = [];\n            circularRefs.set(x, rv);\n            for (var i = 0, l = x.length; i < l; ++i) {\n                rv.push(innerDeepClone(x[i]));\n            }\n        }\n        else if (intrinsicTypes.has(x.constructor)) {\n            rv = x;\n        }\n        else {\n            var proto = getProto(x);\n            rv = proto === Object.prototype ? {} : Object.create(proto);\n            circularRefs.set(x, rv);\n            for (var prop in x) {\n                if (hasOwn(x, prop)) {\n                    rv[prop] = innerDeepClone(x[prop]);\n                }\n            }\n        }\n        return rv;\n    }\n    var toString = {}.toString;\n    function toStringTag(o) {\n        return toString.call(o).slice(8, -1);\n    }\n    var iteratorSymbol = typeof Symbol !== 'undefined' ?\n        Symbol.iterator :\n        '@@iterator';\n    var getIteratorOf = typeof iteratorSymbol === \"symbol\" ? function (x) {\n        var i;\n        return x != null && (i = x[iteratorSymbol]) && i.apply(x);\n    } : function () { return null; };\n    function delArrayItem(a, x) {\n        var i = a.indexOf(x);\n        if (i >= 0)\n            a.splice(i, 1);\n        return i >= 0;\n    }\n    var NO_CHAR_ARRAY = {};\n    function getArrayOf(arrayLike) {\n        var i, a, x, it;\n        if (arguments.length === 1) {\n            if (isArray(arrayLike))\n                return arrayLike.slice();\n            if (this === NO_CHAR_ARRAY && typeof arrayLike === 'string')\n                return [arrayLike];\n            if ((it = getIteratorOf(arrayLike))) {\n                a = [];\n                while ((x = it.next()), !x.done)\n                    a.push(x.value);\n                return a;\n            }\n            if (arrayLike == null)\n                return [arrayLike];\n            i = arrayLike.length;\n            if (typeof i === 'number') {\n                a = new Array(i);\n                while (i--)\n                    a[i] = arrayLike[i];\n                return a;\n            }\n            return [arrayLike];\n        }\n        i = arguments.length;\n        a = new Array(i);\n        while (i--)\n            a[i] = arguments[i];\n        return a;\n    }\n    var isAsyncFunction = typeof Symbol !== 'undefined'\n        ? function (fn) { return fn[Symbol.toStringTag] === 'AsyncFunction'; }\n        : function () { return false; };\n\n    var dexieErrorNames = [\n        'Modify',\n        'Bulk',\n        'OpenFailed',\n        'VersionChange',\n        'Schema',\n        'Upgrade',\n        'InvalidTable',\n        'MissingAPI',\n        'NoSuchDatabase',\n        'InvalidArgument',\n        'SubTransaction',\n        'Unsupported',\n        'Internal',\n        'DatabaseClosed',\n        'PrematureCommit',\n        'ForeignAwait'\n    ];\n    var idbDomErrorNames = [\n        'Unknown',\n        'Constraint',\n        'Data',\n        'TransactionInactive',\n        'ReadOnly',\n        'Version',\n        'NotFound',\n        'InvalidState',\n        'InvalidAccess',\n        'Abort',\n        'Timeout',\n        'QuotaExceeded',\n        'Syntax',\n        'DataClone'\n    ];\n    var errorList = dexieErrorNames.concat(idbDomErrorNames);\n    var defaultTexts = {\n        VersionChanged: \"Database version changed by other database connection\",\n        DatabaseClosed: \"Database has been closed\",\n        Abort: \"Transaction aborted\",\n        TransactionInactive: \"Transaction has already completed or failed\",\n        MissingAPI: \"IndexedDB API missing. Please visit https://tinyurl.com/y2uuvskb\"\n    };\n    function DexieError(name, msg) {\n        this.name = name;\n        this.message = msg;\n    }\n    derive(DexieError).from(Error).extend({\n        toString: function () { return this.name + \": \" + this.message; }\n    });\n    function getMultiErrorMessage(msg, failures) {\n        return msg + \". Errors: \" + Object.keys(failures)\n            .map(function (key) { return failures[key].toString(); })\n            .filter(function (v, i, s) { return s.indexOf(v) === i; })\n            .join('\\n');\n    }\n    function ModifyError(msg, failures, successCount, failedKeys) {\n        this.failures = failures;\n        this.failedKeys = failedKeys;\n        this.successCount = successCount;\n        this.message = getMultiErrorMessage(msg, failures);\n    }\n    derive(ModifyError).from(DexieError);\n    function BulkError(msg, failures) {\n        this.name = \"BulkError\";\n        this.failures = Object.keys(failures).map(function (pos) { return failures[pos]; });\n        this.failuresByPos = failures;\n        this.message = getMultiErrorMessage(msg, this.failures);\n    }\n    derive(BulkError).from(DexieError);\n    var errnames = errorList.reduce(function (obj, name) { return (obj[name] = name + \"Error\", obj); }, {});\n    var BaseException = DexieError;\n    var exceptions = errorList.reduce(function (obj, name) {\n        var fullName = name + \"Error\";\n        function DexieError(msgOrInner, inner) {\n            this.name = fullName;\n            if (!msgOrInner) {\n                this.message = defaultTexts[name] || fullName;\n                this.inner = null;\n            }\n            else if (typeof msgOrInner === 'string') {\n                this.message = \"\".concat(msgOrInner).concat(!inner ? '' : '\\n ' + inner);\n                this.inner = inner || null;\n            }\n            else if (typeof msgOrInner === 'object') {\n                this.message = \"\".concat(msgOrInner.name, \" \").concat(msgOrInner.message);\n                this.inner = msgOrInner;\n            }\n        }\n        derive(DexieError).from(BaseException);\n        obj[name] = DexieError;\n        return obj;\n    }, {});\n    exceptions.Syntax = SyntaxError;\n    exceptions.Type = TypeError;\n    exceptions.Range = RangeError;\n    var exceptionMap = idbDomErrorNames.reduce(function (obj, name) {\n        obj[name + \"Error\"] = exceptions[name];\n        return obj;\n    }, {});\n    function mapError(domError, message) {\n        if (!domError || domError instanceof DexieError || domError instanceof TypeError || domError instanceof SyntaxError || !domError.name || !exceptionMap[domError.name])\n            return domError;\n        var rv = new exceptionMap[domError.name](message || domError.message, domError);\n        if (\"stack\" in domError) {\n            setProp(rv, \"stack\", { get: function () {\n                    return this.inner.stack;\n                } });\n        }\n        return rv;\n    }\n    var fullNameExceptions = errorList.reduce(function (obj, name) {\n        if ([\"Syntax\", \"Type\", \"Range\"].indexOf(name) === -1)\n            obj[name + \"Error\"] = exceptions[name];\n        return obj;\n    }, {});\n    fullNameExceptions.ModifyError = ModifyError;\n    fullNameExceptions.DexieError = DexieError;\n    fullNameExceptions.BulkError = BulkError;\n\n    function nop() { }\n    function mirror(val) { return val; }\n    function pureFunctionChain(f1, f2) {\n        if (f1 == null || f1 === mirror)\n            return f2;\n        return function (val) {\n            return f2(f1(val));\n        };\n    }\n    function callBoth(on1, on2) {\n        return function () {\n            on1.apply(this, arguments);\n            on2.apply(this, arguments);\n        };\n    }\n    function hookCreatingChain(f1, f2) {\n        if (f1 === nop)\n            return f2;\n        return function () {\n            var res = f1.apply(this, arguments);\n            if (res !== undefined)\n                arguments[0] = res;\n            var onsuccess = this.onsuccess,\n            onerror = this.onerror;\n            this.onsuccess = null;\n            this.onerror = null;\n            var res2 = f2.apply(this, arguments);\n            if (onsuccess)\n                this.onsuccess = this.onsuccess ? callBoth(onsuccess, this.onsuccess) : onsuccess;\n            if (onerror)\n                this.onerror = this.onerror ? callBoth(onerror, this.onerror) : onerror;\n            return res2 !== undefined ? res2 : res;\n        };\n    }\n    function hookDeletingChain(f1, f2) {\n        if (f1 === nop)\n            return f2;\n        return function () {\n            f1.apply(this, arguments);\n            var onsuccess = this.onsuccess,\n            onerror = this.onerror;\n            this.onsuccess = this.onerror = null;\n            f2.apply(this, arguments);\n            if (onsuccess)\n                this.onsuccess = this.onsuccess ? callBoth(onsuccess, this.onsuccess) : onsuccess;\n            if (onerror)\n                this.onerror = this.onerror ? callBoth(onerror, this.onerror) : onerror;\n        };\n    }\n    function hookUpdatingChain(f1, f2) {\n        if (f1 === nop)\n            return f2;\n        return function (modifications) {\n            var res = f1.apply(this, arguments);\n            extend(modifications, res);\n            var onsuccess = this.onsuccess,\n            onerror = this.onerror;\n            this.onsuccess = null;\n            this.onerror = null;\n            var res2 = f2.apply(this, arguments);\n            if (onsuccess)\n                this.onsuccess = this.onsuccess ? callBoth(onsuccess, this.onsuccess) : onsuccess;\n            if (onerror)\n                this.onerror = this.onerror ? callBoth(onerror, this.onerror) : onerror;\n            return res === undefined ?\n                (res2 === undefined ? undefined : res2) :\n                (extend(res, res2));\n        };\n    }\n    function reverseStoppableEventChain(f1, f2) {\n        if (f1 === nop)\n            return f2;\n        return function () {\n            if (f2.apply(this, arguments) === false)\n                return false;\n            return f1.apply(this, arguments);\n        };\n    }\n    function promisableChain(f1, f2) {\n        if (f1 === nop)\n            return f2;\n        return function () {\n            var res = f1.apply(this, arguments);\n            if (res && typeof res.then === 'function') {\n                var thiz = this, i = arguments.length, args = new Array(i);\n                while (i--)\n                    args[i] = arguments[i];\n                return res.then(function () {\n                    return f2.apply(thiz, args);\n                });\n            }\n            return f2.apply(this, arguments);\n        };\n    }\n\n    var debug = typeof location !== 'undefined' &&\n        /^(http|https):\\/\\/(localhost|127\\.0\\.0\\.1)/.test(location.href);\n    function setDebug(value, filter) {\n        debug = value;\n    }\n\n    var INTERNAL = {};\n    var ZONE_ECHO_LIMIT = 100, _a$1 = typeof Promise === 'undefined' ?\n        [] :\n        (function () {\n            var globalP = Promise.resolve();\n            if (typeof crypto === 'undefined' || !crypto.subtle)\n                return [globalP, getProto(globalP), globalP];\n            var nativeP = crypto.subtle.digest(\"SHA-512\", new Uint8Array([0]));\n            return [\n                nativeP,\n                getProto(nativeP),\n                globalP\n            ];\n        })(), resolvedNativePromise = _a$1[0], nativePromiseProto = _a$1[1], resolvedGlobalPromise = _a$1[2], nativePromiseThen = nativePromiseProto && nativePromiseProto.then;\n    var NativePromise = resolvedNativePromise && resolvedNativePromise.constructor;\n    var patchGlobalPromise = !!resolvedGlobalPromise;\n    function schedulePhysicalTick() {\n        queueMicrotask(physicalTick);\n    }\n    var asap = function (callback, args) {\n        microtickQueue.push([callback, args]);\n        if (needsNewPhysicalTick) {\n            schedulePhysicalTick();\n            needsNewPhysicalTick = false;\n        }\n    };\n    var isOutsideMicroTick = true,\n    needsNewPhysicalTick = true,\n    unhandledErrors = [],\n    rejectingErrors = [],\n    rejectionMapper = mirror;\n    var globalPSD = {\n        id: 'global',\n        global: true,\n        ref: 0,\n        unhandleds: [],\n        onunhandled: nop,\n        pgp: false,\n        env: {},\n        finalize: nop\n    };\n    var PSD = globalPSD;\n    var microtickQueue = [];\n    var numScheduledCalls = 0;\n    var tickFinalizers = [];\n    function DexiePromise(fn) {\n        if (typeof this !== 'object')\n            throw new TypeError('Promises must be constructed via new');\n        this._listeners = [];\n        this._lib = false;\n        var psd = (this._PSD = PSD);\n        if (typeof fn !== 'function') {\n            if (fn !== INTERNAL)\n                throw new TypeError('Not a function');\n            this._state = arguments[1];\n            this._value = arguments[2];\n            if (this._state === false)\n                handleRejection(this, this._value);\n            return;\n        }\n        this._state = null;\n        this._value = null;\n        ++psd.ref;\n        executePromiseTask(this, fn);\n    }\n    var thenProp = {\n        get: function () {\n            var psd = PSD, microTaskId = totalEchoes;\n            function then(onFulfilled, onRejected) {\n                var _this = this;\n                var possibleAwait = !psd.global && (psd !== PSD || microTaskId !== totalEchoes);\n                var cleanup = possibleAwait && !decrementExpectedAwaits();\n                var rv = new DexiePromise(function (resolve, reject) {\n                    propagateToListener(_this, new Listener(nativeAwaitCompatibleWrap(onFulfilled, psd, possibleAwait, cleanup), nativeAwaitCompatibleWrap(onRejected, psd, possibleAwait, cleanup), resolve, reject, psd));\n                });\n                if (this._consoleTask)\n                    rv._consoleTask = this._consoleTask;\n                return rv;\n            }\n            then.prototype = INTERNAL;\n            return then;\n        },\n        set: function (value) {\n            setProp(this, 'then', value && value.prototype === INTERNAL ?\n                thenProp :\n                {\n                    get: function () {\n                        return value;\n                    },\n                    set: thenProp.set\n                });\n        }\n    };\n    props(DexiePromise.prototype, {\n        then: thenProp,\n        _then: function (onFulfilled, onRejected) {\n            propagateToListener(this, new Listener(null, null, onFulfilled, onRejected, PSD));\n        },\n        catch: function (onRejected) {\n            if (arguments.length === 1)\n                return this.then(null, onRejected);\n            var type = arguments[0], handler = arguments[1];\n            return typeof type === 'function' ? this.then(null, function (err) {\n                return err instanceof type ? handler(err) : PromiseReject(err);\n            })\n                : this.then(null, function (err) {\n                    return err && err.name === type ? handler(err) : PromiseReject(err);\n                });\n        },\n        finally: function (onFinally) {\n            return this.then(function (value) {\n                return DexiePromise.resolve(onFinally()).then(function () { return value; });\n            }, function (err) {\n                return DexiePromise.resolve(onFinally()).then(function () { return PromiseReject(err); });\n            });\n        },\n        timeout: function (ms, msg) {\n            var _this = this;\n            return ms < Infinity ?\n                new DexiePromise(function (resolve, reject) {\n                    var handle = setTimeout(function () { return reject(new exceptions.Timeout(msg)); }, ms);\n                    _this.then(resolve, reject).finally(clearTimeout.bind(null, handle));\n                }) : this;\n        }\n    });\n    if (typeof Symbol !== 'undefined' && Symbol.toStringTag)\n        setProp(DexiePromise.prototype, Symbol.toStringTag, 'Dexie.Promise');\n    globalPSD.env = snapShot();\n    function Listener(onFulfilled, onRejected, resolve, reject, zone) {\n        this.onFulfilled = typeof onFulfilled === 'function' ? onFulfilled : null;\n        this.onRejected = typeof onRejected === 'function' ? onRejected : null;\n        this.resolve = resolve;\n        this.reject = reject;\n        this.psd = zone;\n    }\n    props(DexiePromise, {\n        all: function () {\n            var values = getArrayOf.apply(null, arguments)\n                .map(onPossibleParallellAsync);\n            return new DexiePromise(function (resolve, reject) {\n                if (values.length === 0)\n                    resolve([]);\n                var remaining = values.length;\n                values.forEach(function (a, i) { return DexiePromise.resolve(a).then(function (x) {\n                    values[i] = x;\n                    if (!--remaining)\n                        resolve(values);\n                }, reject); });\n            });\n        },\n        resolve: function (value) {\n            if (value instanceof DexiePromise)\n                return value;\n            if (value && typeof value.then === 'function')\n                return new DexiePromise(function (resolve, reject) {\n                    value.then(resolve, reject);\n                });\n            var rv = new DexiePromise(INTERNAL, true, value);\n            return rv;\n        },\n        reject: PromiseReject,\n        race: function () {\n            var values = getArrayOf.apply(null, arguments).map(onPossibleParallellAsync);\n            return new DexiePromise(function (resolve, reject) {\n                values.map(function (value) { return DexiePromise.resolve(value).then(resolve, reject); });\n            });\n        },\n        PSD: {\n            get: function () { return PSD; },\n            set: function (value) { return PSD = value; }\n        },\n        totalEchoes: { get: function () { return totalEchoes; } },\n        newPSD: newScope,\n        usePSD: usePSD,\n        scheduler: {\n            get: function () { return asap; },\n            set: function (value) { asap = value; }\n        },\n        rejectionMapper: {\n            get: function () { return rejectionMapper; },\n            set: function (value) { rejectionMapper = value; }\n        },\n        follow: function (fn, zoneProps) {\n            return new DexiePromise(function (resolve, reject) {\n                return newScope(function (resolve, reject) {\n                    var psd = PSD;\n                    psd.unhandleds = [];\n                    psd.onunhandled = reject;\n                    psd.finalize = callBoth(function () {\n                        var _this = this;\n                        run_at_end_of_this_or_next_physical_tick(function () {\n                            _this.unhandleds.length === 0 ? resolve() : reject(_this.unhandleds[0]);\n                        });\n                    }, psd.finalize);\n                    fn();\n                }, zoneProps, resolve, reject);\n            });\n        }\n    });\n    if (NativePromise) {\n        if (NativePromise.allSettled)\n            setProp(DexiePromise, \"allSettled\", function () {\n                var possiblePromises = getArrayOf.apply(null, arguments).map(onPossibleParallellAsync);\n                return new DexiePromise(function (resolve) {\n                    if (possiblePromises.length === 0)\n                        resolve([]);\n                    var remaining = possiblePromises.length;\n                    var results = new Array(remaining);\n                    possiblePromises.forEach(function (p, i) { return DexiePromise.resolve(p).then(function (value) { return results[i] = { status: \"fulfilled\", value: value }; }, function (reason) { return results[i] = { status: \"rejected\", reason: reason }; })\n                        .then(function () { return --remaining || resolve(results); }); });\n                });\n            });\n        if (NativePromise.any && typeof AggregateError !== 'undefined')\n            setProp(DexiePromise, \"any\", function () {\n                var possiblePromises = getArrayOf.apply(null, arguments).map(onPossibleParallellAsync);\n                return new DexiePromise(function (resolve, reject) {\n                    if (possiblePromises.length === 0)\n                        reject(new AggregateError([]));\n                    var remaining = possiblePromises.length;\n                    var failures = new Array(remaining);\n                    possiblePromises.forEach(function (p, i) { return DexiePromise.resolve(p).then(function (value) { return resolve(value); }, function (failure) {\n                        failures[i] = failure;\n                        if (!--remaining)\n                            reject(new AggregateError(failures));\n                    }); });\n                });\n            });\n        if (NativePromise.withResolvers)\n            DexiePromise.withResolvers = NativePromise.withResolvers;\n    }\n    function executePromiseTask(promise, fn) {\n        try {\n            fn(function (value) {\n                if (promise._state !== null)\n                    return;\n                if (value === promise)\n                    throw new TypeError('A promise cannot be resolved with itself.');\n                var shouldExecuteTick = promise._lib && beginMicroTickScope();\n                if (value && typeof value.then === 'function') {\n                    executePromiseTask(promise, function (resolve, reject) {\n                        value instanceof DexiePromise ?\n                            value._then(resolve, reject) :\n                            value.then(resolve, reject);\n                    });\n                }\n                else {\n                    promise._state = true;\n                    promise._value = value;\n                    propagateAllListeners(promise);\n                }\n                if (shouldExecuteTick)\n                    endMicroTickScope();\n            }, handleRejection.bind(null, promise));\n        }\n        catch (ex) {\n            handleRejection(promise, ex);\n        }\n    }\n    function handleRejection(promise, reason) {\n        rejectingErrors.push(reason);\n        if (promise._state !== null)\n            return;\n        var shouldExecuteTick = promise._lib && beginMicroTickScope();\n        reason = rejectionMapper(reason);\n        promise._state = false;\n        promise._value = reason;\n        addPossiblyUnhandledError(promise);\n        propagateAllListeners(promise);\n        if (shouldExecuteTick)\n            endMicroTickScope();\n    }\n    function propagateAllListeners(promise) {\n        var listeners = promise._listeners;\n        promise._listeners = [];\n        for (var i = 0, len = listeners.length; i < len; ++i) {\n            propagateToListener(promise, listeners[i]);\n        }\n        var psd = promise._PSD;\n        --psd.ref || psd.finalize();\n        if (numScheduledCalls === 0) {\n            ++numScheduledCalls;\n            asap(function () {\n                if (--numScheduledCalls === 0)\n                    finalizePhysicalTick();\n            }, []);\n        }\n    }\n    function propagateToListener(promise, listener) {\n        if (promise._state === null) {\n            promise._listeners.push(listener);\n            return;\n        }\n        var cb = promise._state ? listener.onFulfilled : listener.onRejected;\n        if (cb === null) {\n            return (promise._state ? listener.resolve : listener.reject)(promise._value);\n        }\n        ++listener.psd.ref;\n        ++numScheduledCalls;\n        asap(callListener, [cb, promise, listener]);\n    }\n    function callListener(cb, promise, listener) {\n        try {\n            var ret, value = promise._value;\n            if (!promise._state && rejectingErrors.length)\n                rejectingErrors = [];\n            ret = debug && promise._consoleTask ? promise._consoleTask.run(function () { return cb(value); }) : cb(value);\n            if (!promise._state && rejectingErrors.indexOf(value) === -1) {\n                markErrorAsHandled(promise);\n            }\n            listener.resolve(ret);\n        }\n        catch (e) {\n            listener.reject(e);\n        }\n        finally {\n            if (--numScheduledCalls === 0)\n                finalizePhysicalTick();\n            --listener.psd.ref || listener.psd.finalize();\n        }\n    }\n    function physicalTick() {\n        usePSD(globalPSD, function () {\n            beginMicroTickScope() && endMicroTickScope();\n        });\n    }\n    function beginMicroTickScope() {\n        var wasRootExec = isOutsideMicroTick;\n        isOutsideMicroTick = false;\n        needsNewPhysicalTick = false;\n        return wasRootExec;\n    }\n    function endMicroTickScope() {\n        var callbacks, i, l;\n        do {\n            while (microtickQueue.length > 0) {\n                callbacks = microtickQueue;\n                microtickQueue = [];\n                l = callbacks.length;\n                for (i = 0; i < l; ++i) {\n                    var item = callbacks[i];\n                    item[0].apply(null, item[1]);\n                }\n            }\n        } while (microtickQueue.length > 0);\n        isOutsideMicroTick = true;\n        needsNewPhysicalTick = true;\n    }\n    function finalizePhysicalTick() {\n        var unhandledErrs = unhandledErrors;\n        unhandledErrors = [];\n        unhandledErrs.forEach(function (p) {\n            p._PSD.onunhandled.call(null, p._value, p);\n        });\n        var finalizers = tickFinalizers.slice(0);\n        var i = finalizers.length;\n        while (i)\n            finalizers[--i]();\n    }\n    function run_at_end_of_this_or_next_physical_tick(fn) {\n        function finalizer() {\n            fn();\n            tickFinalizers.splice(tickFinalizers.indexOf(finalizer), 1);\n        }\n        tickFinalizers.push(finalizer);\n        ++numScheduledCalls;\n        asap(function () {\n            if (--numScheduledCalls === 0)\n                finalizePhysicalTick();\n        }, []);\n    }\n    function addPossiblyUnhandledError(promise) {\n        if (!unhandledErrors.some(function (p) { return p._value === promise._value; }))\n            unhandledErrors.push(promise);\n    }\n    function markErrorAsHandled(promise) {\n        var i = unhandledErrors.length;\n        while (i)\n            if (unhandledErrors[--i]._value === promise._value) {\n                unhandledErrors.splice(i, 1);\n                return;\n            }\n    }\n    function PromiseReject(reason) {\n        return new DexiePromise(INTERNAL, false, reason);\n    }\n    function wrap(fn, errorCatcher) {\n        var psd = PSD;\n        return function () {\n            var wasRootExec = beginMicroTickScope(), outerScope = PSD;\n            try {\n                switchToZone(psd, true);\n                return fn.apply(this, arguments);\n            }\n            catch (e) {\n                errorCatcher && errorCatcher(e);\n            }\n            finally {\n                switchToZone(outerScope, false);\n                if (wasRootExec)\n                    endMicroTickScope();\n            }\n        };\n    }\n    var task = { awaits: 0, echoes: 0, id: 0 };\n    var taskCounter = 0;\n    var zoneStack = [];\n    var zoneEchoes = 0;\n    var totalEchoes = 0;\n    var zone_id_counter = 0;\n    function newScope(fn, props, a1, a2) {\n        var parent = PSD, psd = Object.create(parent);\n        psd.parent = parent;\n        psd.ref = 0;\n        psd.global = false;\n        psd.id = ++zone_id_counter;\n        globalPSD.env;\n        psd.env = patchGlobalPromise ? {\n            Promise: DexiePromise,\n            PromiseProp: { value: DexiePromise, configurable: true, writable: true },\n            all: DexiePromise.all,\n            race: DexiePromise.race,\n            allSettled: DexiePromise.allSettled,\n            any: DexiePromise.any,\n            resolve: DexiePromise.resolve,\n            reject: DexiePromise.reject,\n        } : {};\n        if (props)\n            extend(psd, props);\n        ++parent.ref;\n        psd.finalize = function () {\n            --this.parent.ref || this.parent.finalize();\n        };\n        var rv = usePSD(psd, fn, a1, a2);\n        if (psd.ref === 0)\n            psd.finalize();\n        return rv;\n    }\n    function incrementExpectedAwaits() {\n        if (!task.id)\n            task.id = ++taskCounter;\n        ++task.awaits;\n        task.echoes += ZONE_ECHO_LIMIT;\n        return task.id;\n    }\n    function decrementExpectedAwaits() {\n        if (!task.awaits)\n            return false;\n        if (--task.awaits === 0)\n            task.id = 0;\n        task.echoes = task.awaits * ZONE_ECHO_LIMIT;\n        return true;\n    }\n    if (('' + nativePromiseThen).indexOf('[native code]') === -1) {\n        incrementExpectedAwaits = decrementExpectedAwaits = nop;\n    }\n    function onPossibleParallellAsync(possiblePromise) {\n        if (task.echoes && possiblePromise && possiblePromise.constructor === NativePromise) {\n            incrementExpectedAwaits();\n            return possiblePromise.then(function (x) {\n                decrementExpectedAwaits();\n                return x;\n            }, function (e) {\n                decrementExpectedAwaits();\n                return rejection(e);\n            });\n        }\n        return possiblePromise;\n    }\n    function zoneEnterEcho(targetZone) {\n        ++totalEchoes;\n        if (!task.echoes || --task.echoes === 0) {\n            task.echoes = task.awaits = task.id = 0;\n        }\n        zoneStack.push(PSD);\n        switchToZone(targetZone, true);\n    }\n    function zoneLeaveEcho() {\n        var zone = zoneStack[zoneStack.length - 1];\n        zoneStack.pop();\n        switchToZone(zone, false);\n    }\n    function switchToZone(targetZone, bEnteringZone) {\n        var currentZone = PSD;\n        if (bEnteringZone ? task.echoes && (!zoneEchoes++ || targetZone !== PSD) : zoneEchoes && (!--zoneEchoes || targetZone !== PSD)) {\n            queueMicrotask(bEnteringZone ? zoneEnterEcho.bind(null, targetZone) : zoneLeaveEcho);\n        }\n        if (targetZone === PSD)\n            return;\n        PSD = targetZone;\n        if (currentZone === globalPSD)\n            globalPSD.env = snapShot();\n        if (patchGlobalPromise) {\n            var GlobalPromise = globalPSD.env.Promise;\n            var targetEnv = targetZone.env;\n            if (currentZone.global || targetZone.global) {\n                Object.defineProperty(_global, 'Promise', targetEnv.PromiseProp);\n                GlobalPromise.all = targetEnv.all;\n                GlobalPromise.race = targetEnv.race;\n                GlobalPromise.resolve = targetEnv.resolve;\n                GlobalPromise.reject = targetEnv.reject;\n                if (targetEnv.allSettled)\n                    GlobalPromise.allSettled = targetEnv.allSettled;\n                if (targetEnv.any)\n                    GlobalPromise.any = targetEnv.any;\n            }\n        }\n    }\n    function snapShot() {\n        var GlobalPromise = _global.Promise;\n        return patchGlobalPromise ? {\n            Promise: GlobalPromise,\n            PromiseProp: Object.getOwnPropertyDescriptor(_global, \"Promise\"),\n            all: GlobalPromise.all,\n            race: GlobalPromise.race,\n            allSettled: GlobalPromise.allSettled,\n            any: GlobalPromise.any,\n            resolve: GlobalPromise.resolve,\n            reject: GlobalPromise.reject,\n        } : {};\n    }\n    function usePSD(psd, fn, a1, a2, a3) {\n        var outerScope = PSD;\n        try {\n            switchToZone(psd, true);\n            return fn(a1, a2, a3);\n        }\n        finally {\n            switchToZone(outerScope, false);\n        }\n    }\n    function nativeAwaitCompatibleWrap(fn, zone, possibleAwait, cleanup) {\n        return typeof fn !== 'function' ? fn : function () {\n            var outerZone = PSD;\n            if (possibleAwait)\n                incrementExpectedAwaits();\n            switchToZone(zone, true);\n            try {\n                return fn.apply(this, arguments);\n            }\n            finally {\n                switchToZone(outerZone, false);\n                if (cleanup)\n                    queueMicrotask(decrementExpectedAwaits);\n            }\n        };\n    }\n    function execInGlobalContext(cb) {\n        if (Promise === NativePromise && task.echoes === 0) {\n            if (zoneEchoes === 0) {\n                cb();\n            }\n            else {\n                enqueueNativeMicroTask(cb);\n            }\n        }\n        else {\n            setTimeout(cb, 0);\n        }\n    }\n    var rejection = DexiePromise.reject;\n\n    function tempTransaction(db, mode, storeNames, fn) {\n        if (!db.idbdb || (!db._state.openComplete && (!PSD.letThrough && !db._vip))) {\n            if (db._state.openComplete) {\n                return rejection(new exceptions.DatabaseClosed(db._state.dbOpenError));\n            }\n            if (!db._state.isBeingOpened) {\n                if (!db._state.autoOpen)\n                    return rejection(new exceptions.DatabaseClosed());\n                db.open().catch(nop);\n            }\n            return db._state.dbReadyPromise.then(function () { return tempTransaction(db, mode, storeNames, fn); });\n        }\n        else {\n            var trans = db._createTransaction(mode, storeNames, db._dbSchema);\n            try {\n                trans.create();\n                db._state.PR1398_maxLoop = 3;\n            }\n            catch (ex) {\n                if (ex.name === errnames.InvalidState && db.isOpen() && --db._state.PR1398_maxLoop > 0) {\n                    console.warn('Dexie: Need to reopen db');\n                    db.close({ disableAutoOpen: false });\n                    return db.open().then(function () { return tempTransaction(db, mode, storeNames, fn); });\n                }\n                return rejection(ex);\n            }\n            return trans._promise(mode, function (resolve, reject) {\n                return newScope(function () {\n                    PSD.trans = trans;\n                    return fn(resolve, reject, trans);\n                });\n            }).then(function (result) {\n                if (mode === 'readwrite')\n                    try {\n                        trans.idbtrans.commit();\n                    }\n                    catch (_a) { }\n                return mode === 'readonly' ? result : trans._completion.then(function () { return result; });\n            });\n        }\n    }\n\n    var DEXIE_VERSION = '4.0.10';\n    var maxString = String.fromCharCode(65535);\n    var minKey = -Infinity;\n    var INVALID_KEY_ARGUMENT = \"Invalid key provided. Keys must be of type string, number, Date or Array<string | number | Date>.\";\n    var STRING_EXPECTED = \"String expected.\";\n    var connections = [];\n    var DBNAMES_DB = '__dbnames';\n    var READONLY = 'readonly';\n    var READWRITE = 'readwrite';\n\n    function combine(filter1, filter2) {\n        return filter1 ?\n            filter2 ?\n                function () { return filter1.apply(this, arguments) && filter2.apply(this, arguments); } :\n                filter1 :\n            filter2;\n    }\n\n    var AnyRange = {\n        type: 3 ,\n        lower: -Infinity,\n        lowerOpen: false,\n        upper: [[]],\n        upperOpen: false\n    };\n\n    function workaroundForUndefinedPrimKey(keyPath) {\n        return typeof keyPath === \"string\" && !/\\./.test(keyPath)\n            ? function (obj) {\n                if (obj[keyPath] === undefined && (keyPath in obj)) {\n                    obj = deepClone(obj);\n                    delete obj[keyPath];\n                }\n                return obj;\n            }\n            : function (obj) { return obj; };\n    }\n\n    function Entity() {\n        throw exceptions.Type();\n    }\n\n    function cmp(a, b) {\n        try {\n            var ta = type(a);\n            var tb = type(b);\n            if (ta !== tb) {\n                if (ta === 'Array')\n                    return 1;\n                if (tb === 'Array')\n                    return -1;\n                if (ta === 'binary')\n                    return 1;\n                if (tb === 'binary')\n                    return -1;\n                if (ta === 'string')\n                    return 1;\n                if (tb === 'string')\n                    return -1;\n                if (ta === 'Date')\n                    return 1;\n                if (tb !== 'Date')\n                    return NaN;\n                return -1;\n            }\n            switch (ta) {\n                case 'number':\n                case 'Date':\n                case 'string':\n                    return a > b ? 1 : a < b ? -1 : 0;\n                case 'binary': {\n                    return compareUint8Arrays(getUint8Array(a), getUint8Array(b));\n                }\n                case 'Array':\n                    return compareArrays(a, b);\n            }\n        }\n        catch (_a) { }\n        return NaN;\n    }\n    function compareArrays(a, b) {\n        var al = a.length;\n        var bl = b.length;\n        var l = al < bl ? al : bl;\n        for (var i = 0; i < l; ++i) {\n            var res = cmp(a[i], b[i]);\n            if (res !== 0)\n                return res;\n        }\n        return al === bl ? 0 : al < bl ? -1 : 1;\n    }\n    function compareUint8Arrays(a, b) {\n        var al = a.length;\n        var bl = b.length;\n        var l = al < bl ? al : bl;\n        for (var i = 0; i < l; ++i) {\n            if (a[i] !== b[i])\n                return a[i] < b[i] ? -1 : 1;\n        }\n        return al === bl ? 0 : al < bl ? -1 : 1;\n    }\n    function type(x) {\n        var t = typeof x;\n        if (t !== 'object')\n            return t;\n        if (ArrayBuffer.isView(x))\n            return 'binary';\n        var tsTag = toStringTag(x);\n        return tsTag === 'ArrayBuffer' ? 'binary' : tsTag;\n    }\n    function getUint8Array(a) {\n        if (a instanceof Uint8Array)\n            return a;\n        if (ArrayBuffer.isView(a))\n            return new Uint8Array(a.buffer, a.byteOffset, a.byteLength);\n        return new Uint8Array(a);\n    }\n\n    var Table =  (function () {\n        function Table() {\n        }\n        Table.prototype._trans = function (mode, fn, writeLocked) {\n            var trans = this._tx || PSD.trans;\n            var tableName = this.name;\n            var task = debug && typeof console !== 'undefined' && console.createTask && console.createTask(\"Dexie: \".concat(mode === 'readonly' ? 'read' : 'write', \" \").concat(this.name));\n            function checkTableInTransaction(resolve, reject, trans) {\n                if (!trans.schema[tableName])\n                    throw new exceptions.NotFound(\"Table \" + tableName + \" not part of transaction\");\n                return fn(trans.idbtrans, trans);\n            }\n            var wasRootExec = beginMicroTickScope();\n            try {\n                var p = trans && trans.db._novip === this.db._novip ?\n                    trans === PSD.trans ?\n                        trans._promise(mode, checkTableInTransaction, writeLocked) :\n                        newScope(function () { return trans._promise(mode, checkTableInTransaction, writeLocked); }, { trans: trans, transless: PSD.transless || PSD }) :\n                    tempTransaction(this.db, mode, [this.name], checkTableInTransaction);\n                if (task) {\n                    p._consoleTask = task;\n                    p = p.catch(function (err) {\n                        console.trace(err);\n                        return rejection(err);\n                    });\n                }\n                return p;\n            }\n            finally {\n                if (wasRootExec)\n                    endMicroTickScope();\n            }\n        };\n        Table.prototype.get = function (keyOrCrit, cb) {\n            var _this = this;\n            if (keyOrCrit && keyOrCrit.constructor === Object)\n                return this.where(keyOrCrit).first(cb);\n            if (keyOrCrit == null)\n                return rejection(new exceptions.Type(\"Invalid argument to Table.get()\"));\n            return this._trans('readonly', function (trans) {\n                return _this.core.get({ trans: trans, key: keyOrCrit })\n                    .then(function (res) { return _this.hook.reading.fire(res); });\n            }).then(cb);\n        };\n        Table.prototype.where = function (indexOrCrit) {\n            if (typeof indexOrCrit === 'string')\n                return new this.db.WhereClause(this, indexOrCrit);\n            if (isArray(indexOrCrit))\n                return new this.db.WhereClause(this, \"[\".concat(indexOrCrit.join('+'), \"]\"));\n            var keyPaths = keys(indexOrCrit);\n            if (keyPaths.length === 1)\n                return this\n                    .where(keyPaths[0])\n                    .equals(indexOrCrit[keyPaths[0]]);\n            var compoundIndex = this.schema.indexes.concat(this.schema.primKey).filter(function (ix) {\n                if (ix.compound &&\n                    keyPaths.every(function (keyPath) { return ix.keyPath.indexOf(keyPath) >= 0; })) {\n                    for (var i = 0; i < keyPaths.length; ++i) {\n                        if (keyPaths.indexOf(ix.keyPath[i]) === -1)\n                            return false;\n                    }\n                    return true;\n                }\n                return false;\n            }).sort(function (a, b) { return a.keyPath.length - b.keyPath.length; })[0];\n            if (compoundIndex && this.db._maxKey !== maxString) {\n                var keyPathsInValidOrder = compoundIndex.keyPath.slice(0, keyPaths.length);\n                return this\n                    .where(keyPathsInValidOrder)\n                    .equals(keyPathsInValidOrder.map(function (kp) { return indexOrCrit[kp]; }));\n            }\n            if (!compoundIndex && debug)\n                console.warn(\"The query \".concat(JSON.stringify(indexOrCrit), \" on \").concat(this.name, \" would benefit from a \") +\n                    \"compound index [\".concat(keyPaths.join('+'), \"]\"));\n            var idxByName = this.schema.idxByName;\n            function equals(a, b) {\n                return cmp(a, b) === 0;\n            }\n            var _a = keyPaths.reduce(function (_a, keyPath) {\n                var prevIndex = _a[0], prevFilterFn = _a[1];\n                var index = idxByName[keyPath];\n                var value = indexOrCrit[keyPath];\n                return [\n                    prevIndex || index,\n                    prevIndex || !index ?\n                        combine(prevFilterFn, index && index.multi ?\n                            function (x) {\n                                var prop = getByKeyPath(x, keyPath);\n                                return isArray(prop) && prop.some(function (item) { return equals(value, item); });\n                            } : function (x) { return equals(value, getByKeyPath(x, keyPath)); })\n                        : prevFilterFn\n                ];\n            }, [null, null]), idx = _a[0], filterFunction = _a[1];\n            return idx ?\n                this.where(idx.name).equals(indexOrCrit[idx.keyPath])\n                    .filter(filterFunction) :\n                compoundIndex ?\n                    this.filter(filterFunction) :\n                    this.where(keyPaths).equals('');\n        };\n        Table.prototype.filter = function (filterFunction) {\n            return this.toCollection().and(filterFunction);\n        };\n        Table.prototype.count = function (thenShortcut) {\n            return this.toCollection().count(thenShortcut);\n        };\n        Table.prototype.offset = function (offset) {\n            return this.toCollection().offset(offset);\n        };\n        Table.prototype.limit = function (numRows) {\n            return this.toCollection().limit(numRows);\n        };\n        Table.prototype.each = function (callback) {\n            return this.toCollection().each(callback);\n        };\n        Table.prototype.toArray = function (thenShortcut) {\n            return this.toCollection().toArray(thenShortcut);\n        };\n        Table.prototype.toCollection = function () {\n            return new this.db.Collection(new this.db.WhereClause(this));\n        };\n        Table.prototype.orderBy = function (index) {\n            return new this.db.Collection(new this.db.WhereClause(this, isArray(index) ?\n                \"[\".concat(index.join('+'), \"]\") :\n                index));\n        };\n        Table.prototype.reverse = function () {\n            return this.toCollection().reverse();\n        };\n        Table.prototype.mapToClass = function (constructor) {\n            var _a = this, db = _a.db, tableName = _a.name;\n            this.schema.mappedClass = constructor;\n            if (constructor.prototype instanceof Entity) {\n                constructor =  (function (_super) {\n                    __extends(class_1, _super);\n                    function class_1() {\n                        return _super !== null && _super.apply(this, arguments) || this;\n                    }\n                    Object.defineProperty(class_1.prototype, \"db\", {\n                        get: function () { return db; },\n                        enumerable: false,\n                        configurable: true\n                    });\n                    class_1.prototype.table = function () { return tableName; };\n                    return class_1;\n                }(constructor));\n            }\n            var inheritedProps = new Set();\n            for (var proto = constructor.prototype; proto; proto = getProto(proto)) {\n                Object.getOwnPropertyNames(proto).forEach(function (propName) { return inheritedProps.add(propName); });\n            }\n            var readHook = function (obj) {\n                if (!obj)\n                    return obj;\n                var res = Object.create(constructor.prototype);\n                for (var m in obj)\n                    if (!inheritedProps.has(m))\n                        try {\n                            res[m] = obj[m];\n                        }\n                        catch (_) { }\n                return res;\n            };\n            if (this.schema.readHook) {\n                this.hook.reading.unsubscribe(this.schema.readHook);\n            }\n            this.schema.readHook = readHook;\n            this.hook(\"reading\", readHook);\n            return constructor;\n        };\n        Table.prototype.defineClass = function () {\n            function Class(content) {\n                extend(this, content);\n            }\n            return this.mapToClass(Class);\n        };\n        Table.prototype.add = function (obj, key) {\n            var _this = this;\n            var _a = this.schema.primKey, auto = _a.auto, keyPath = _a.keyPath;\n            var objToAdd = obj;\n            if (keyPath && auto) {\n                objToAdd = workaroundForUndefinedPrimKey(keyPath)(obj);\n            }\n            return this._trans('readwrite', function (trans) {\n                return _this.core.mutate({ trans: trans, type: 'add', keys: key != null ? [key] : null, values: [objToAdd] });\n            }).then(function (res) { return res.numFailures ? DexiePromise.reject(res.failures[0]) : res.lastResult; })\n                .then(function (lastResult) {\n                if (keyPath) {\n                    try {\n                        setByKeyPath(obj, keyPath, lastResult);\n                    }\n                    catch (_) { }\n                }\n                return lastResult;\n            });\n        };\n        Table.prototype.update = function (keyOrObject, modifications) {\n            if (typeof keyOrObject === 'object' && !isArray(keyOrObject)) {\n                var key = getByKeyPath(keyOrObject, this.schema.primKey.keyPath);\n                if (key === undefined)\n                    return rejection(new exceptions.InvalidArgument(\"Given object does not contain its primary key\"));\n                return this.where(\":id\").equals(key).modify(modifications);\n            }\n            else {\n                return this.where(\":id\").equals(keyOrObject).modify(modifications);\n            }\n        };\n        Table.prototype.put = function (obj, key) {\n            var _this = this;\n            var _a = this.schema.primKey, auto = _a.auto, keyPath = _a.keyPath;\n            var objToAdd = obj;\n            if (keyPath && auto) {\n                objToAdd = workaroundForUndefinedPrimKey(keyPath)(obj);\n            }\n            return this._trans('readwrite', function (trans) { return _this.core.mutate({ trans: trans, type: 'put', values: [objToAdd], keys: key != null ? [key] : null }); })\n                .then(function (res) { return res.numFailures ? DexiePromise.reject(res.failures[0]) : res.lastResult; })\n                .then(function (lastResult) {\n                if (keyPath) {\n                    try {\n                        setByKeyPath(obj, keyPath, lastResult);\n                    }\n                    catch (_) { }\n                }\n                return lastResult;\n            });\n        };\n        Table.prototype.delete = function (key) {\n            var _this = this;\n            return this._trans('readwrite', function (trans) { return _this.core.mutate({ trans: trans, type: 'delete', keys: [key] }); })\n                .then(function (res) { return res.numFailures ? DexiePromise.reject(res.failures[0]) : undefined; });\n        };\n        Table.prototype.clear = function () {\n            var _this = this;\n            return this._trans('readwrite', function (trans) { return _this.core.mutate({ trans: trans, type: 'deleteRange', range: AnyRange }); })\n                .then(function (res) { return res.numFailures ? DexiePromise.reject(res.failures[0]) : undefined; });\n        };\n        Table.prototype.bulkGet = function (keys) {\n            var _this = this;\n            return this._trans('readonly', function (trans) {\n                return _this.core.getMany({\n                    keys: keys,\n                    trans: trans\n                }).then(function (result) { return result.map(function (res) { return _this.hook.reading.fire(res); }); });\n            });\n        };\n        Table.prototype.bulkAdd = function (objects, keysOrOptions, options) {\n            var _this = this;\n            var keys = Array.isArray(keysOrOptions) ? keysOrOptions : undefined;\n            options = options || (keys ? undefined : keysOrOptions);\n            var wantResults = options ? options.allKeys : undefined;\n            return this._trans('readwrite', function (trans) {\n                var _a = _this.schema.primKey, auto = _a.auto, keyPath = _a.keyPath;\n                if (keyPath && keys)\n                    throw new exceptions.InvalidArgument(\"bulkAdd(): keys argument invalid on tables with inbound keys\");\n                if (keys && keys.length !== objects.length)\n                    throw new exceptions.InvalidArgument(\"Arguments objects and keys must have the same length\");\n                var numObjects = objects.length;\n                var objectsToAdd = keyPath && auto ?\n                    objects.map(workaroundForUndefinedPrimKey(keyPath)) :\n                    objects;\n                return _this.core.mutate({ trans: trans, type: 'add', keys: keys, values: objectsToAdd, wantResults: wantResults })\n                    .then(function (_a) {\n                    var numFailures = _a.numFailures, results = _a.results, lastResult = _a.lastResult, failures = _a.failures;\n                    var result = wantResults ? results : lastResult;\n                    if (numFailures === 0)\n                        return result;\n                    throw new BulkError(\"\".concat(_this.name, \".bulkAdd(): \").concat(numFailures, \" of \").concat(numObjects, \" operations failed\"), failures);\n                });\n            });\n        };\n        Table.prototype.bulkPut = function (objects, keysOrOptions, options) {\n            var _this = this;\n            var keys = Array.isArray(keysOrOptions) ? keysOrOptions : undefined;\n            options = options || (keys ? undefined : keysOrOptions);\n            var wantResults = options ? options.allKeys : undefined;\n            return this._trans('readwrite', function (trans) {\n                var _a = _this.schema.primKey, auto = _a.auto, keyPath = _a.keyPath;\n                if (keyPath && keys)\n                    throw new exceptions.InvalidArgument(\"bulkPut(): keys argument invalid on tables with inbound keys\");\n                if (keys && keys.length !== objects.length)\n                    throw new exceptions.InvalidArgument(\"Arguments objects and keys must have the same length\");\n                var numObjects = objects.length;\n                var objectsToPut = keyPath && auto ?\n                    objects.map(workaroundForUndefinedPrimKey(keyPath)) :\n                    objects;\n                return _this.core.mutate({ trans: trans, type: 'put', keys: keys, values: objectsToPut, wantResults: wantResults })\n                    .then(function (_a) {\n                    var numFailures = _a.numFailures, results = _a.results, lastResult = _a.lastResult, failures = _a.failures;\n                    var result = wantResults ? results : lastResult;\n                    if (numFailures === 0)\n                        return result;\n                    throw new BulkError(\"\".concat(_this.name, \".bulkPut(): \").concat(numFailures, \" of \").concat(numObjects, \" operations failed\"), failures);\n                });\n            });\n        };\n        Table.prototype.bulkUpdate = function (keysAndChanges) {\n            var _this = this;\n            var coreTable = this.core;\n            var keys = keysAndChanges.map(function (entry) { return entry.key; });\n            var changeSpecs = keysAndChanges.map(function (entry) { return entry.changes; });\n            var offsetMap = [];\n            return this._trans('readwrite', function (trans) {\n                return coreTable.getMany({ trans: trans, keys: keys, cache: 'clone' }).then(function (objs) {\n                    var resultKeys = [];\n                    var resultObjs = [];\n                    keysAndChanges.forEach(function (_a, idx) {\n                        var key = _a.key, changes = _a.changes;\n                        var obj = objs[idx];\n                        if (obj) {\n                            for (var _i = 0, _b = Object.keys(changes); _i < _b.length; _i++) {\n                                var keyPath = _b[_i];\n                                var value = changes[keyPath];\n                                if (keyPath === _this.schema.primKey.keyPath) {\n                                    if (cmp(value, key) !== 0) {\n                                        throw new exceptions.Constraint(\"Cannot update primary key in bulkUpdate()\");\n                                    }\n                                }\n                                else {\n                                    setByKeyPath(obj, keyPath, value);\n                                }\n                            }\n                            offsetMap.push(idx);\n                            resultKeys.push(key);\n                            resultObjs.push(obj);\n                        }\n                    });\n                    var numEntries = resultKeys.length;\n                    return coreTable\n                        .mutate({\n                        trans: trans,\n                        type: 'put',\n                        keys: resultKeys,\n                        values: resultObjs,\n                        updates: {\n                            keys: keys,\n                            changeSpecs: changeSpecs\n                        }\n                    })\n                        .then(function (_a) {\n                        var numFailures = _a.numFailures, failures = _a.failures;\n                        if (numFailures === 0)\n                            return numEntries;\n                        for (var _i = 0, _b = Object.keys(failures); _i < _b.length; _i++) {\n                            var offset = _b[_i];\n                            var mappedOffset = offsetMap[Number(offset)];\n                            if (mappedOffset != null) {\n                                var failure = failures[offset];\n                                delete failures[offset];\n                                failures[mappedOffset] = failure;\n                            }\n                        }\n                        throw new BulkError(\"\".concat(_this.name, \".bulkUpdate(): \").concat(numFailures, \" of \").concat(numEntries, \" operations failed\"), failures);\n                    });\n                });\n            });\n        };\n        Table.prototype.bulkDelete = function (keys) {\n            var _this = this;\n            var numKeys = keys.length;\n            return this._trans('readwrite', function (trans) {\n                return _this.core.mutate({ trans: trans, type: 'delete', keys: keys });\n            }).then(function (_a) {\n                var numFailures = _a.numFailures, lastResult = _a.lastResult, failures = _a.failures;\n                if (numFailures === 0)\n                    return lastResult;\n                throw new BulkError(\"\".concat(_this.name, \".bulkDelete(): \").concat(numFailures, \" of \").concat(numKeys, \" operations failed\"), failures);\n            });\n        };\n        return Table;\n    }());\n\n    function Events(ctx) {\n        var evs = {};\n        var rv = function (eventName, subscriber) {\n            if (subscriber) {\n                var i = arguments.length, args = new Array(i - 1);\n                while (--i)\n                    args[i - 1] = arguments[i];\n                evs[eventName].subscribe.apply(null, args);\n                return ctx;\n            }\n            else if (typeof (eventName) === 'string') {\n                return evs[eventName];\n            }\n        };\n        rv.addEventType = add;\n        for (var i = 1, l = arguments.length; i < l; ++i) {\n            add(arguments[i]);\n        }\n        return rv;\n        function add(eventName, chainFunction, defaultFunction) {\n            if (typeof eventName === 'object')\n                return addConfiguredEvents(eventName);\n            if (!chainFunction)\n                chainFunction = reverseStoppableEventChain;\n            if (!defaultFunction)\n                defaultFunction = nop;\n            var context = {\n                subscribers: [],\n                fire: defaultFunction,\n                subscribe: function (cb) {\n                    if (context.subscribers.indexOf(cb) === -1) {\n                        context.subscribers.push(cb);\n                        context.fire = chainFunction(context.fire, cb);\n                    }\n                },\n                unsubscribe: function (cb) {\n                    context.subscribers = context.subscribers.filter(function (fn) { return fn !== cb; });\n                    context.fire = context.subscribers.reduce(chainFunction, defaultFunction);\n                }\n            };\n            evs[eventName] = rv[eventName] = context;\n            return context;\n        }\n        function addConfiguredEvents(cfg) {\n            keys(cfg).forEach(function (eventName) {\n                var args = cfg[eventName];\n                if (isArray(args)) {\n                    add(eventName, cfg[eventName][0], cfg[eventName][1]);\n                }\n                else if (args === 'asap') {\n                    var context = add(eventName, mirror, function fire() {\n                        var i = arguments.length, args = new Array(i);\n                        while (i--)\n                            args[i] = arguments[i];\n                        context.subscribers.forEach(function (fn) {\n                            asap$1(function fireEvent() {\n                                fn.apply(null, args);\n                            });\n                        });\n                    });\n                }\n                else\n                    throw new exceptions.InvalidArgument(\"Invalid event config\");\n            });\n        }\n    }\n\n    function makeClassConstructor(prototype, constructor) {\n        derive(constructor).from({ prototype: prototype });\n        return constructor;\n    }\n\n    function createTableConstructor(db) {\n        return makeClassConstructor(Table.prototype, function Table(name, tableSchema, trans) {\n            this.db = db;\n            this._tx = trans;\n            this.name = name;\n            this.schema = tableSchema;\n            this.hook = db._allTables[name] ? db._allTables[name].hook : Events(null, {\n                \"creating\": [hookCreatingChain, nop],\n                \"reading\": [pureFunctionChain, mirror],\n                \"updating\": [hookUpdatingChain, nop],\n                \"deleting\": [hookDeletingChain, nop]\n            });\n        });\n    }\n\n    function isPlainKeyRange(ctx, ignoreLimitFilter) {\n        return !(ctx.filter || ctx.algorithm || ctx.or) &&\n            (ignoreLimitFilter ? ctx.justLimit : !ctx.replayFilter);\n    }\n    function addFilter(ctx, fn) {\n        ctx.filter = combine(ctx.filter, fn);\n    }\n    function addReplayFilter(ctx, factory, isLimitFilter) {\n        var curr = ctx.replayFilter;\n        ctx.replayFilter = curr ? function () { return combine(curr(), factory()); } : factory;\n        ctx.justLimit = isLimitFilter && !curr;\n    }\n    function addMatchFilter(ctx, fn) {\n        ctx.isMatch = combine(ctx.isMatch, fn);\n    }\n    function getIndexOrStore(ctx, coreSchema) {\n        if (ctx.isPrimKey)\n            return coreSchema.primaryKey;\n        var index = coreSchema.getIndexByKeyPath(ctx.index);\n        if (!index)\n            throw new exceptions.Schema(\"KeyPath \" + ctx.index + \" on object store \" + coreSchema.name + \" is not indexed\");\n        return index;\n    }\n    function openCursor(ctx, coreTable, trans) {\n        var index = getIndexOrStore(ctx, coreTable.schema);\n        return coreTable.openCursor({\n            trans: trans,\n            values: !ctx.keysOnly,\n            reverse: ctx.dir === 'prev',\n            unique: !!ctx.unique,\n            query: {\n                index: index,\n                range: ctx.range\n            }\n        });\n    }\n    function iter(ctx, fn, coreTrans, coreTable) {\n        var filter = ctx.replayFilter ? combine(ctx.filter, ctx.replayFilter()) : ctx.filter;\n        if (!ctx.or) {\n            return iterate(openCursor(ctx, coreTable, coreTrans), combine(ctx.algorithm, filter), fn, !ctx.keysOnly && ctx.valueMapper);\n        }\n        else {\n            var set_1 = {};\n            var union = function (item, cursor, advance) {\n                if (!filter || filter(cursor, advance, function (result) { return cursor.stop(result); }, function (err) { return cursor.fail(err); })) {\n                    var primaryKey = cursor.primaryKey;\n                    var key = '' + primaryKey;\n                    if (key === '[object ArrayBuffer]')\n                        key = '' + new Uint8Array(primaryKey);\n                    if (!hasOwn(set_1, key)) {\n                        set_1[key] = true;\n                        fn(item, cursor, advance);\n                    }\n                }\n            };\n            return Promise.all([\n                ctx.or._iterate(union, coreTrans),\n                iterate(openCursor(ctx, coreTable, coreTrans), ctx.algorithm, union, !ctx.keysOnly && ctx.valueMapper)\n            ]);\n        }\n    }\n    function iterate(cursorPromise, filter, fn, valueMapper) {\n        var mappedFn = valueMapper ? function (x, c, a) { return fn(valueMapper(x), c, a); } : fn;\n        var wrappedFn = wrap(mappedFn);\n        return cursorPromise.then(function (cursor) {\n            if (cursor) {\n                return cursor.start(function () {\n                    var c = function () { return cursor.continue(); };\n                    if (!filter || filter(cursor, function (advancer) { return c = advancer; }, function (val) { cursor.stop(val); c = nop; }, function (e) { cursor.fail(e); c = nop; }))\n                        wrappedFn(cursor.value, cursor, function (advancer) { return c = advancer; });\n                    c();\n                });\n            }\n        });\n    }\n\n    var PropModSymbol = Symbol();\n    var PropModification =  (function () {\n        function PropModification(spec) {\n            Object.assign(this, spec);\n        }\n        PropModification.prototype.execute = function (value) {\n            var _a;\n            if (this.add !== undefined) {\n                var term = this.add;\n                if (isArray(term)) {\n                    return __spreadArray(__spreadArray([], (isArray(value) ? value : []), true), term, true).sort();\n                }\n                if (typeof term === 'number')\n                    return (Number(value) || 0) + term;\n                if (typeof term === 'bigint') {\n                    try {\n                        return BigInt(value) + term;\n                    }\n                    catch (_b) {\n                        return BigInt(0) + term;\n                    }\n                }\n                throw new TypeError(\"Invalid term \".concat(term));\n            }\n            if (this.remove !== undefined) {\n                var subtrahend_1 = this.remove;\n                if (isArray(subtrahend_1)) {\n                    return isArray(value) ? value.filter(function (item) { return !subtrahend_1.includes(item); }).sort() : [];\n                }\n                if (typeof subtrahend_1 === 'number')\n                    return Number(value) - subtrahend_1;\n                if (typeof subtrahend_1 === 'bigint') {\n                    try {\n                        return BigInt(value) - subtrahend_1;\n                    }\n                    catch (_c) {\n                        return BigInt(0) - subtrahend_1;\n                    }\n                }\n                throw new TypeError(\"Invalid subtrahend \".concat(subtrahend_1));\n            }\n            var prefixToReplace = (_a = this.replacePrefix) === null || _a === void 0 ? void 0 : _a[0];\n            if (prefixToReplace && typeof value === 'string' && value.startsWith(prefixToReplace)) {\n                return this.replacePrefix[1] + value.substring(prefixToReplace.length);\n            }\n            return value;\n        };\n        return PropModification;\n    }());\n\n    var Collection =  (function () {\n        function Collection() {\n        }\n        Collection.prototype._read = function (fn, cb) {\n            var ctx = this._ctx;\n            return ctx.error ?\n                ctx.table._trans(null, rejection.bind(null, ctx.error)) :\n                ctx.table._trans('readonly', fn).then(cb);\n        };\n        Collection.prototype._write = function (fn) {\n            var ctx = this._ctx;\n            return ctx.error ?\n                ctx.table._trans(null, rejection.bind(null, ctx.error)) :\n                ctx.table._trans('readwrite', fn, \"locked\");\n        };\n        Collection.prototype._addAlgorithm = function (fn) {\n            var ctx = this._ctx;\n            ctx.algorithm = combine(ctx.algorithm, fn);\n        };\n        Collection.prototype._iterate = function (fn, coreTrans) {\n            return iter(this._ctx, fn, coreTrans, this._ctx.table.core);\n        };\n        Collection.prototype.clone = function (props) {\n            var rv = Object.create(this.constructor.prototype), ctx = Object.create(this._ctx);\n            if (props)\n                extend(ctx, props);\n            rv._ctx = ctx;\n            return rv;\n        };\n        Collection.prototype.raw = function () {\n            this._ctx.valueMapper = null;\n            return this;\n        };\n        Collection.prototype.each = function (fn) {\n            var ctx = this._ctx;\n            return this._read(function (trans) { return iter(ctx, fn, trans, ctx.table.core); });\n        };\n        Collection.prototype.count = function (cb) {\n            var _this = this;\n            return this._read(function (trans) {\n                var ctx = _this._ctx;\n                var coreTable = ctx.table.core;\n                if (isPlainKeyRange(ctx, true)) {\n                    return coreTable.count({\n                        trans: trans,\n                        query: {\n                            index: getIndexOrStore(ctx, coreTable.schema),\n                            range: ctx.range\n                        }\n                    }).then(function (count) { return Math.min(count, ctx.limit); });\n                }\n                else {\n                    var count = 0;\n                    return iter(ctx, function () { ++count; return false; }, trans, coreTable)\n                        .then(function () { return count; });\n                }\n            }).then(cb);\n        };\n        Collection.prototype.sortBy = function (keyPath, cb) {\n            var parts = keyPath.split('.').reverse(), lastPart = parts[0], lastIndex = parts.length - 1;\n            function getval(obj, i) {\n                if (i)\n                    return getval(obj[parts[i]], i - 1);\n                return obj[lastPart];\n            }\n            var order = this._ctx.dir === \"next\" ? 1 : -1;\n            function sorter(a, b) {\n                var aVal = getval(a, lastIndex), bVal = getval(b, lastIndex);\n                return cmp(aVal, bVal) * order;\n            }\n            return this.toArray(function (a) {\n                return a.sort(sorter);\n            }).then(cb);\n        };\n        Collection.prototype.toArray = function (cb) {\n            var _this = this;\n            return this._read(function (trans) {\n                var ctx = _this._ctx;\n                if (ctx.dir === 'next' && isPlainKeyRange(ctx, true) && ctx.limit > 0) {\n                    var valueMapper_1 = ctx.valueMapper;\n                    var index = getIndexOrStore(ctx, ctx.table.core.schema);\n                    return ctx.table.core.query({\n                        trans: trans,\n                        limit: ctx.limit,\n                        values: true,\n                        query: {\n                            index: index,\n                            range: ctx.range\n                        }\n                    }).then(function (_a) {\n                        var result = _a.result;\n                        return valueMapper_1 ? result.map(valueMapper_1) : result;\n                    });\n                }\n                else {\n                    var a_1 = [];\n                    return iter(ctx, function (item) { return a_1.push(item); }, trans, ctx.table.core).then(function () { return a_1; });\n                }\n            }, cb);\n        };\n        Collection.prototype.offset = function (offset) {\n            var ctx = this._ctx;\n            if (offset <= 0)\n                return this;\n            ctx.offset += offset;\n            if (isPlainKeyRange(ctx)) {\n                addReplayFilter(ctx, function () {\n                    var offsetLeft = offset;\n                    return function (cursor, advance) {\n                        if (offsetLeft === 0)\n                            return true;\n                        if (offsetLeft === 1) {\n                            --offsetLeft;\n                            return false;\n                        }\n                        advance(function () {\n                            cursor.advance(offsetLeft);\n                            offsetLeft = 0;\n                        });\n                        return false;\n                    };\n                });\n            }\n            else {\n                addReplayFilter(ctx, function () {\n                    var offsetLeft = offset;\n                    return function () { return (--offsetLeft < 0); };\n                });\n            }\n            return this;\n        };\n        Collection.prototype.limit = function (numRows) {\n            this._ctx.limit = Math.min(this._ctx.limit, numRows);\n            addReplayFilter(this._ctx, function () {\n                var rowsLeft = numRows;\n                return function (cursor, advance, resolve) {\n                    if (--rowsLeft <= 0)\n                        advance(resolve);\n                    return rowsLeft >= 0;\n                };\n            }, true);\n            return this;\n        };\n        Collection.prototype.until = function (filterFunction, bIncludeStopEntry) {\n            addFilter(this._ctx, function (cursor, advance, resolve) {\n                if (filterFunction(cursor.value)) {\n                    advance(resolve);\n                    return bIncludeStopEntry;\n                }\n                else {\n                    return true;\n                }\n            });\n            return this;\n        };\n        Collection.prototype.first = function (cb) {\n            return this.limit(1).toArray(function (a) { return a[0]; }).then(cb);\n        };\n        Collection.prototype.last = function (cb) {\n            return this.reverse().first(cb);\n        };\n        Collection.prototype.filter = function (filterFunction) {\n            addFilter(this._ctx, function (cursor) {\n                return filterFunction(cursor.value);\n            });\n            addMatchFilter(this._ctx, filterFunction);\n            return this;\n        };\n        Collection.prototype.and = function (filter) {\n            return this.filter(filter);\n        };\n        Collection.prototype.or = function (indexName) {\n            return new this.db.WhereClause(this._ctx.table, indexName, this);\n        };\n        Collection.prototype.reverse = function () {\n            this._ctx.dir = (this._ctx.dir === \"prev\" ? \"next\" : \"prev\");\n            if (this._ondirectionchange)\n                this._ondirectionchange(this._ctx.dir);\n            return this;\n        };\n        Collection.prototype.desc = function () {\n            return this.reverse();\n        };\n        Collection.prototype.eachKey = function (cb) {\n            var ctx = this._ctx;\n            ctx.keysOnly = !ctx.isMatch;\n            return this.each(function (val, cursor) { cb(cursor.key, cursor); });\n        };\n        Collection.prototype.eachUniqueKey = function (cb) {\n            this._ctx.unique = \"unique\";\n            return this.eachKey(cb);\n        };\n        Collection.prototype.eachPrimaryKey = function (cb) {\n            var ctx = this._ctx;\n            ctx.keysOnly = !ctx.isMatch;\n            return this.each(function (val, cursor) { cb(cursor.primaryKey, cursor); });\n        };\n        Collection.prototype.keys = function (cb) {\n            var ctx = this._ctx;\n            ctx.keysOnly = !ctx.isMatch;\n            var a = [];\n            return this.each(function (item, cursor) {\n                a.push(cursor.key);\n            }).then(function () {\n                return a;\n            }).then(cb);\n        };\n        Collection.prototype.primaryKeys = function (cb) {\n            var ctx = this._ctx;\n            if (ctx.dir === 'next' && isPlainKeyRange(ctx, true) && ctx.limit > 0) {\n                return this._read(function (trans) {\n                    var index = getIndexOrStore(ctx, ctx.table.core.schema);\n                    return ctx.table.core.query({\n                        trans: trans,\n                        values: false,\n                        limit: ctx.limit,\n                        query: {\n                            index: index,\n                            range: ctx.range\n                        }\n                    });\n                }).then(function (_a) {\n                    var result = _a.result;\n                    return result;\n                }).then(cb);\n            }\n            ctx.keysOnly = !ctx.isMatch;\n            var a = [];\n            return this.each(function (item, cursor) {\n                a.push(cursor.primaryKey);\n            }).then(function () {\n                return a;\n            }).then(cb);\n        };\n        Collection.prototype.uniqueKeys = function (cb) {\n            this._ctx.unique = \"unique\";\n            return this.keys(cb);\n        };\n        Collection.prototype.firstKey = function (cb) {\n            return this.limit(1).keys(function (a) { return a[0]; }).then(cb);\n        };\n        Collection.prototype.lastKey = function (cb) {\n            return this.reverse().firstKey(cb);\n        };\n        Collection.prototype.distinct = function () {\n            var ctx = this._ctx, idx = ctx.index && ctx.table.schema.idxByName[ctx.index];\n            if (!idx || !idx.multi)\n                return this;\n            var set = {};\n            addFilter(this._ctx, function (cursor) {\n                var strKey = cursor.primaryKey.toString();\n                var found = hasOwn(set, strKey);\n                set[strKey] = true;\n                return !found;\n            });\n            return this;\n        };\n        Collection.prototype.modify = function (changes) {\n            var _this = this;\n            var ctx = this._ctx;\n            return this._write(function (trans) {\n                var modifyer;\n                if (typeof changes === 'function') {\n                    modifyer = changes;\n                }\n                else {\n                    var keyPaths = keys(changes);\n                    var numKeys = keyPaths.length;\n                    modifyer = function (item) {\n                        var anythingModified = false;\n                        for (var i = 0; i < numKeys; ++i) {\n                            var keyPath = keyPaths[i];\n                            var val = changes[keyPath];\n                            var origVal = getByKeyPath(item, keyPath);\n                            if (val instanceof PropModification) {\n                                setByKeyPath(item, keyPath, val.execute(origVal));\n                                anythingModified = true;\n                            }\n                            else if (origVal !== val) {\n                                setByKeyPath(item, keyPath, val);\n                                anythingModified = true;\n                            }\n                        }\n                        return anythingModified;\n                    };\n                }\n                var coreTable = ctx.table.core;\n                var _a = coreTable.schema.primaryKey, outbound = _a.outbound, extractKey = _a.extractKey;\n                var limit = 200;\n                var modifyChunkSize = _this.db._options.modifyChunkSize;\n                if (modifyChunkSize) {\n                    if (typeof modifyChunkSize == 'object') {\n                        limit = modifyChunkSize[coreTable.name] || modifyChunkSize['*'] || 200;\n                    }\n                    else {\n                        limit = modifyChunkSize;\n                    }\n                }\n                var totalFailures = [];\n                var successCount = 0;\n                var failedKeys = [];\n                var applyMutateResult = function (expectedCount, res) {\n                    var failures = res.failures, numFailures = res.numFailures;\n                    successCount += expectedCount - numFailures;\n                    for (var _i = 0, _a = keys(failures); _i < _a.length; _i++) {\n                        var pos = _a[_i];\n                        totalFailures.push(failures[pos]);\n                    }\n                };\n                return _this.clone().primaryKeys().then(function (keys) {\n                    var criteria = isPlainKeyRange(ctx) &&\n                        ctx.limit === Infinity &&\n                        (typeof changes !== 'function' || changes === deleteCallback) && {\n                        index: ctx.index,\n                        range: ctx.range\n                    };\n                    var nextChunk = function (offset) {\n                        var count = Math.min(limit, keys.length - offset);\n                        return coreTable.getMany({\n                            trans: trans,\n                            keys: keys.slice(offset, offset + count),\n                            cache: \"immutable\"\n                        }).then(function (values) {\n                            var addValues = [];\n                            var putValues = [];\n                            var putKeys = outbound ? [] : null;\n                            var deleteKeys = [];\n                            for (var i = 0; i < count; ++i) {\n                                var origValue = values[i];\n                                var ctx_1 = {\n                                    value: deepClone(origValue),\n                                    primKey: keys[offset + i]\n                                };\n                                if (modifyer.call(ctx_1, ctx_1.value, ctx_1) !== false) {\n                                    if (ctx_1.value == null) {\n                                        deleteKeys.push(keys[offset + i]);\n                                    }\n                                    else if (!outbound && cmp(extractKey(origValue), extractKey(ctx_1.value)) !== 0) {\n                                        deleteKeys.push(keys[offset + i]);\n                                        addValues.push(ctx_1.value);\n                                    }\n                                    else {\n                                        putValues.push(ctx_1.value);\n                                        if (outbound)\n                                            putKeys.push(keys[offset + i]);\n                                    }\n                                }\n                            }\n                            return Promise.resolve(addValues.length > 0 &&\n                                coreTable.mutate({ trans: trans, type: 'add', values: addValues })\n                                    .then(function (res) {\n                                    for (var pos in res.failures) {\n                                        deleteKeys.splice(parseInt(pos), 1);\n                                    }\n                                    applyMutateResult(addValues.length, res);\n                                })).then(function () { return (putValues.length > 0 || (criteria && typeof changes === 'object')) &&\n                                coreTable.mutate({\n                                    trans: trans,\n                                    type: 'put',\n                                    keys: putKeys,\n                                    values: putValues,\n                                    criteria: criteria,\n                                    changeSpec: typeof changes !== 'function'\n                                        && changes,\n                                    isAdditionalChunk: offset > 0\n                                }).then(function (res) { return applyMutateResult(putValues.length, res); }); }).then(function () { return (deleteKeys.length > 0 || (criteria && changes === deleteCallback)) &&\n                                coreTable.mutate({\n                                    trans: trans,\n                                    type: 'delete',\n                                    keys: deleteKeys,\n                                    criteria: criteria,\n                                    isAdditionalChunk: offset > 0\n                                }).then(function (res) { return applyMutateResult(deleteKeys.length, res); }); }).then(function () {\n                                return keys.length > offset + count && nextChunk(offset + limit);\n                            });\n                        });\n                    };\n                    return nextChunk(0).then(function () {\n                        if (totalFailures.length > 0)\n                            throw new ModifyError(\"Error modifying one or more objects\", totalFailures, successCount, failedKeys);\n                        return keys.length;\n                    });\n                });\n            });\n        };\n        Collection.prototype.delete = function () {\n            var ctx = this._ctx, range = ctx.range;\n            if (isPlainKeyRange(ctx) &&\n                (ctx.isPrimKey || range.type === 3 ))\n             {\n                return this._write(function (trans) {\n                    var primaryKey = ctx.table.core.schema.primaryKey;\n                    var coreRange = range;\n                    return ctx.table.core.count({ trans: trans, query: { index: primaryKey, range: coreRange } }).then(function (count) {\n                        return ctx.table.core.mutate({ trans: trans, type: 'deleteRange', range: coreRange })\n                            .then(function (_a) {\n                            var failures = _a.failures; _a.lastResult; _a.results; var numFailures = _a.numFailures;\n                            if (numFailures)\n                                throw new ModifyError(\"Could not delete some values\", Object.keys(failures).map(function (pos) { return failures[pos]; }), count - numFailures);\n                            return count - numFailures;\n                        });\n                    });\n                });\n            }\n            return this.modify(deleteCallback);\n        };\n        return Collection;\n    }());\n    var deleteCallback = function (value, ctx) { return ctx.value = null; };\n\n    function createCollectionConstructor(db) {\n        return makeClassConstructor(Collection.prototype, function Collection(whereClause, keyRangeGenerator) {\n            this.db = db;\n            var keyRange = AnyRange, error = null;\n            if (keyRangeGenerator)\n                try {\n                    keyRange = keyRangeGenerator();\n                }\n                catch (ex) {\n                    error = ex;\n                }\n            var whereCtx = whereClause._ctx;\n            var table = whereCtx.table;\n            var readingHook = table.hook.reading.fire;\n            this._ctx = {\n                table: table,\n                index: whereCtx.index,\n                isPrimKey: (!whereCtx.index || (table.schema.primKey.keyPath && whereCtx.index === table.schema.primKey.name)),\n                range: keyRange,\n                keysOnly: false,\n                dir: \"next\",\n                unique: \"\",\n                algorithm: null,\n                filter: null,\n                replayFilter: null,\n                justLimit: true,\n                isMatch: null,\n                offset: 0,\n                limit: Infinity,\n                error: error,\n                or: whereCtx.or,\n                valueMapper: readingHook !== mirror ? readingHook : null\n            };\n        });\n    }\n\n    function simpleCompare(a, b) {\n        return a < b ? -1 : a === b ? 0 : 1;\n    }\n    function simpleCompareReverse(a, b) {\n        return a > b ? -1 : a === b ? 0 : 1;\n    }\n\n    function fail(collectionOrWhereClause, err, T) {\n        var collection = collectionOrWhereClause instanceof WhereClause ?\n            new collectionOrWhereClause.Collection(collectionOrWhereClause) :\n            collectionOrWhereClause;\n        collection._ctx.error = T ? new T(err) : new TypeError(err);\n        return collection;\n    }\n    function emptyCollection(whereClause) {\n        return new whereClause.Collection(whereClause, function () { return rangeEqual(\"\"); }).limit(0);\n    }\n    function upperFactory(dir) {\n        return dir === \"next\" ?\n            function (s) { return s.toUpperCase(); } :\n            function (s) { return s.toLowerCase(); };\n    }\n    function lowerFactory(dir) {\n        return dir === \"next\" ?\n            function (s) { return s.toLowerCase(); } :\n            function (s) { return s.toUpperCase(); };\n    }\n    function nextCasing(key, lowerKey, upperNeedle, lowerNeedle, cmp, dir) {\n        var length = Math.min(key.length, lowerNeedle.length);\n        var llp = -1;\n        for (var i = 0; i < length; ++i) {\n            var lwrKeyChar = lowerKey[i];\n            if (lwrKeyChar !== lowerNeedle[i]) {\n                if (cmp(key[i], upperNeedle[i]) < 0)\n                    return key.substr(0, i) + upperNeedle[i] + upperNeedle.substr(i + 1);\n                if (cmp(key[i], lowerNeedle[i]) < 0)\n                    return key.substr(0, i) + lowerNeedle[i] + upperNeedle.substr(i + 1);\n                if (llp >= 0)\n                    return key.substr(0, llp) + lowerKey[llp] + upperNeedle.substr(llp + 1);\n                return null;\n            }\n            if (cmp(key[i], lwrKeyChar) < 0)\n                llp = i;\n        }\n        if (length < lowerNeedle.length && dir === \"next\")\n            return key + upperNeedle.substr(key.length);\n        if (length < key.length && dir === \"prev\")\n            return key.substr(0, upperNeedle.length);\n        return (llp < 0 ? null : key.substr(0, llp) + lowerNeedle[llp] + upperNeedle.substr(llp + 1));\n    }\n    function addIgnoreCaseAlgorithm(whereClause, match, needles, suffix) {\n        var upper, lower, compare, upperNeedles, lowerNeedles, direction, nextKeySuffix, needlesLen = needles.length;\n        if (!needles.every(function (s) { return typeof s === 'string'; })) {\n            return fail(whereClause, STRING_EXPECTED);\n        }\n        function initDirection(dir) {\n            upper = upperFactory(dir);\n            lower = lowerFactory(dir);\n            compare = (dir === \"next\" ? simpleCompare : simpleCompareReverse);\n            var needleBounds = needles.map(function (needle) {\n                return { lower: lower(needle), upper: upper(needle) };\n            }).sort(function (a, b) {\n                return compare(a.lower, b.lower);\n            });\n            upperNeedles = needleBounds.map(function (nb) { return nb.upper; });\n            lowerNeedles = needleBounds.map(function (nb) { return nb.lower; });\n            direction = dir;\n            nextKeySuffix = (dir === \"next\" ? \"\" : suffix);\n        }\n        initDirection(\"next\");\n        var c = new whereClause.Collection(whereClause, function () { return createRange(upperNeedles[0], lowerNeedles[needlesLen - 1] + suffix); });\n        c._ondirectionchange = function (direction) {\n            initDirection(direction);\n        };\n        var firstPossibleNeedle = 0;\n        c._addAlgorithm(function (cursor, advance, resolve) {\n            var key = cursor.key;\n            if (typeof key !== 'string')\n                return false;\n            var lowerKey = lower(key);\n            if (match(lowerKey, lowerNeedles, firstPossibleNeedle)) {\n                return true;\n            }\n            else {\n                var lowestPossibleCasing = null;\n                for (var i = firstPossibleNeedle; i < needlesLen; ++i) {\n                    var casing = nextCasing(key, lowerKey, upperNeedles[i], lowerNeedles[i], compare, direction);\n                    if (casing === null && lowestPossibleCasing === null)\n                        firstPossibleNeedle = i + 1;\n                    else if (lowestPossibleCasing === null || compare(lowestPossibleCasing, casing) > 0) {\n                        lowestPossibleCasing = casing;\n                    }\n                }\n                if (lowestPossibleCasing !== null) {\n                    advance(function () { cursor.continue(lowestPossibleCasing + nextKeySuffix); });\n                }\n                else {\n                    advance(resolve);\n                }\n                return false;\n            }\n        });\n        return c;\n    }\n    function createRange(lower, upper, lowerOpen, upperOpen) {\n        return {\n            type: 2 ,\n            lower: lower,\n            upper: upper,\n            lowerOpen: lowerOpen,\n            upperOpen: upperOpen\n        };\n    }\n    function rangeEqual(value) {\n        return {\n            type: 1 ,\n            lower: value,\n            upper: value\n        };\n    }\n\n    var WhereClause =  (function () {\n        function WhereClause() {\n        }\n        Object.defineProperty(WhereClause.prototype, \"Collection\", {\n            get: function () {\n                return this._ctx.table.db.Collection;\n            },\n            enumerable: false,\n            configurable: true\n        });\n        WhereClause.prototype.between = function (lower, upper, includeLower, includeUpper) {\n            includeLower = includeLower !== false;\n            includeUpper = includeUpper === true;\n            try {\n                if ((this._cmp(lower, upper) > 0) ||\n                    (this._cmp(lower, upper) === 0 && (includeLower || includeUpper) && !(includeLower && includeUpper)))\n                    return emptyCollection(this);\n                return new this.Collection(this, function () { return createRange(lower, upper, !includeLower, !includeUpper); });\n            }\n            catch (e) {\n                return fail(this, INVALID_KEY_ARGUMENT);\n            }\n        };\n        WhereClause.prototype.equals = function (value) {\n            if (value == null)\n                return fail(this, INVALID_KEY_ARGUMENT);\n            return new this.Collection(this, function () { return rangeEqual(value); });\n        };\n        WhereClause.prototype.above = function (value) {\n            if (value == null)\n                return fail(this, INVALID_KEY_ARGUMENT);\n            return new this.Collection(this, function () { return createRange(value, undefined, true); });\n        };\n        WhereClause.prototype.aboveOrEqual = function (value) {\n            if (value == null)\n                return fail(this, INVALID_KEY_ARGUMENT);\n            return new this.Collection(this, function () { return createRange(value, undefined, false); });\n        };\n        WhereClause.prototype.below = function (value) {\n            if (value == null)\n                return fail(this, INVALID_KEY_ARGUMENT);\n            return new this.Collection(this, function () { return createRange(undefined, value, false, true); });\n        };\n        WhereClause.prototype.belowOrEqual = function (value) {\n            if (value == null)\n                return fail(this, INVALID_KEY_ARGUMENT);\n            return new this.Collection(this, function () { return createRange(undefined, value); });\n        };\n        WhereClause.prototype.startsWith = function (str) {\n            if (typeof str !== 'string')\n                return fail(this, STRING_EXPECTED);\n            return this.between(str, str + maxString, true, true);\n        };\n        WhereClause.prototype.startsWithIgnoreCase = function (str) {\n            if (str === \"\")\n                return this.startsWith(str);\n            return addIgnoreCaseAlgorithm(this, function (x, a) { return x.indexOf(a[0]) === 0; }, [str], maxString);\n        };\n        WhereClause.prototype.equalsIgnoreCase = function (str) {\n            return addIgnoreCaseAlgorithm(this, function (x, a) { return x === a[0]; }, [str], \"\");\n        };\n        WhereClause.prototype.anyOfIgnoreCase = function () {\n            var set = getArrayOf.apply(NO_CHAR_ARRAY, arguments);\n            if (set.length === 0)\n                return emptyCollection(this);\n            return addIgnoreCaseAlgorithm(this, function (x, a) { return a.indexOf(x) !== -1; }, set, \"\");\n        };\n        WhereClause.prototype.startsWithAnyOfIgnoreCase = function () {\n            var set = getArrayOf.apply(NO_CHAR_ARRAY, arguments);\n            if (set.length === 0)\n                return emptyCollection(this);\n            return addIgnoreCaseAlgorithm(this, function (x, a) { return a.some(function (n) { return x.indexOf(n) === 0; }); }, set, maxString);\n        };\n        WhereClause.prototype.anyOf = function () {\n            var _this = this;\n            var set = getArrayOf.apply(NO_CHAR_ARRAY, arguments);\n            var compare = this._cmp;\n            try {\n                set.sort(compare);\n            }\n            catch (e) {\n                return fail(this, INVALID_KEY_ARGUMENT);\n            }\n            if (set.length === 0)\n                return emptyCollection(this);\n            var c = new this.Collection(this, function () { return createRange(set[0], set[set.length - 1]); });\n            c._ondirectionchange = function (direction) {\n                compare = (direction === \"next\" ?\n                    _this._ascending :\n                    _this._descending);\n                set.sort(compare);\n            };\n            var i = 0;\n            c._addAlgorithm(function (cursor, advance, resolve) {\n                var key = cursor.key;\n                while (compare(key, set[i]) > 0) {\n                    ++i;\n                    if (i === set.length) {\n                        advance(resolve);\n                        return false;\n                    }\n                }\n                if (compare(key, set[i]) === 0) {\n                    return true;\n                }\n                else {\n                    advance(function () { cursor.continue(set[i]); });\n                    return false;\n                }\n            });\n            return c;\n        };\n        WhereClause.prototype.notEqual = function (value) {\n            return this.inAnyRange([[minKey, value], [value, this.db._maxKey]], { includeLowers: false, includeUppers: false });\n        };\n        WhereClause.prototype.noneOf = function () {\n            var set = getArrayOf.apply(NO_CHAR_ARRAY, arguments);\n            if (set.length === 0)\n                return new this.Collection(this);\n            try {\n                set.sort(this._ascending);\n            }\n            catch (e) {\n                return fail(this, INVALID_KEY_ARGUMENT);\n            }\n            var ranges = set.reduce(function (res, val) { return res ?\n                res.concat([[res[res.length - 1][1], val]]) :\n                [[minKey, val]]; }, null);\n            ranges.push([set[set.length - 1], this.db._maxKey]);\n            return this.inAnyRange(ranges, { includeLowers: false, includeUppers: false });\n        };\n        WhereClause.prototype.inAnyRange = function (ranges, options) {\n            var _this = this;\n            var cmp = this._cmp, ascending = this._ascending, descending = this._descending, min = this._min, max = this._max;\n            if (ranges.length === 0)\n                return emptyCollection(this);\n            if (!ranges.every(function (range) {\n                return range[0] !== undefined &&\n                    range[1] !== undefined &&\n                    ascending(range[0], range[1]) <= 0;\n            })) {\n                return fail(this, \"First argument to inAnyRange() must be an Array of two-value Arrays [lower,upper] where upper must not be lower than lower\", exceptions.InvalidArgument);\n            }\n            var includeLowers = !options || options.includeLowers !== false;\n            var includeUppers = options && options.includeUppers === true;\n            function addRange(ranges, newRange) {\n                var i = 0, l = ranges.length;\n                for (; i < l; ++i) {\n                    var range = ranges[i];\n                    if (cmp(newRange[0], range[1]) < 0 && cmp(newRange[1], range[0]) > 0) {\n                        range[0] = min(range[0], newRange[0]);\n                        range[1] = max(range[1], newRange[1]);\n                        break;\n                    }\n                }\n                if (i === l)\n                    ranges.push(newRange);\n                return ranges;\n            }\n            var sortDirection = ascending;\n            function rangeSorter(a, b) { return sortDirection(a[0], b[0]); }\n            var set;\n            try {\n                set = ranges.reduce(addRange, []);\n                set.sort(rangeSorter);\n            }\n            catch (ex) {\n                return fail(this, INVALID_KEY_ARGUMENT);\n            }\n            var rangePos = 0;\n            var keyIsBeyondCurrentEntry = includeUppers ?\n                function (key) { return ascending(key, set[rangePos][1]) > 0; } :\n                function (key) { return ascending(key, set[rangePos][1]) >= 0; };\n            var keyIsBeforeCurrentEntry = includeLowers ?\n                function (key) { return descending(key, set[rangePos][0]) > 0; } :\n                function (key) { return descending(key, set[rangePos][0]) >= 0; };\n            function keyWithinCurrentRange(key) {\n                return !keyIsBeyondCurrentEntry(key) && !keyIsBeforeCurrentEntry(key);\n            }\n            var checkKey = keyIsBeyondCurrentEntry;\n            var c = new this.Collection(this, function () { return createRange(set[0][0], set[set.length - 1][1], !includeLowers, !includeUppers); });\n            c._ondirectionchange = function (direction) {\n                if (direction === \"next\") {\n                    checkKey = keyIsBeyondCurrentEntry;\n                    sortDirection = ascending;\n                }\n                else {\n                    checkKey = keyIsBeforeCurrentEntry;\n                    sortDirection = descending;\n                }\n                set.sort(rangeSorter);\n            };\n            c._addAlgorithm(function (cursor, advance, resolve) {\n                var key = cursor.key;\n                while (checkKey(key)) {\n                    ++rangePos;\n                    if (rangePos === set.length) {\n                        advance(resolve);\n                        return false;\n                    }\n                }\n                if (keyWithinCurrentRange(key)) {\n                    return true;\n                }\n                else if (_this._cmp(key, set[rangePos][1]) === 0 || _this._cmp(key, set[rangePos][0]) === 0) {\n                    return false;\n                }\n                else {\n                    advance(function () {\n                        if (sortDirection === ascending)\n                            cursor.continue(set[rangePos][0]);\n                        else\n                            cursor.continue(set[rangePos][1]);\n                    });\n                    return false;\n                }\n            });\n            return c;\n        };\n        WhereClause.prototype.startsWithAnyOf = function () {\n            var set = getArrayOf.apply(NO_CHAR_ARRAY, arguments);\n            if (!set.every(function (s) { return typeof s === 'string'; })) {\n                return fail(this, \"startsWithAnyOf() only works with strings\");\n            }\n            if (set.length === 0)\n                return emptyCollection(this);\n            return this.inAnyRange(set.map(function (str) { return [str, str + maxString]; }));\n        };\n        return WhereClause;\n    }());\n\n    function createWhereClauseConstructor(db) {\n        return makeClassConstructor(WhereClause.prototype, function WhereClause(table, index, orCollection) {\n            this.db = db;\n            this._ctx = {\n                table: table,\n                index: index === \":id\" ? null : index,\n                or: orCollection\n            };\n            this._cmp = this._ascending = cmp;\n            this._descending = function (a, b) { return cmp(b, a); };\n            this._max = function (a, b) { return cmp(a, b) > 0 ? a : b; };\n            this._min = function (a, b) { return cmp(a, b) < 0 ? a : b; };\n            this._IDBKeyRange = db._deps.IDBKeyRange;\n            if (!this._IDBKeyRange)\n                throw new exceptions.MissingAPI();\n        });\n    }\n\n    function eventRejectHandler(reject) {\n        return wrap(function (event) {\n            preventDefault(event);\n            reject(event.target.error);\n            return false;\n        });\n    }\n    function preventDefault(event) {\n        if (event.stopPropagation)\n            event.stopPropagation();\n        if (event.preventDefault)\n            event.preventDefault();\n    }\n\n    var DEXIE_STORAGE_MUTATED_EVENT_NAME = 'storagemutated';\n    var STORAGE_MUTATED_DOM_EVENT_NAME = 'x-storagemutated-1';\n    var globalEvents = Events(null, DEXIE_STORAGE_MUTATED_EVENT_NAME);\n\n    var Transaction =  (function () {\n        function Transaction() {\n        }\n        Transaction.prototype._lock = function () {\n            assert(!PSD.global);\n            ++this._reculock;\n            if (this._reculock === 1 && !PSD.global)\n                PSD.lockOwnerFor = this;\n            return this;\n        };\n        Transaction.prototype._unlock = function () {\n            assert(!PSD.global);\n            if (--this._reculock === 0) {\n                if (!PSD.global)\n                    PSD.lockOwnerFor = null;\n                while (this._blockedFuncs.length > 0 && !this._locked()) {\n                    var fnAndPSD = this._blockedFuncs.shift();\n                    try {\n                        usePSD(fnAndPSD[1], fnAndPSD[0]);\n                    }\n                    catch (e) { }\n                }\n            }\n            return this;\n        };\n        Transaction.prototype._locked = function () {\n            return this._reculock && PSD.lockOwnerFor !== this;\n        };\n        Transaction.prototype.create = function (idbtrans) {\n            var _this = this;\n            if (!this.mode)\n                return this;\n            var idbdb = this.db.idbdb;\n            var dbOpenError = this.db._state.dbOpenError;\n            assert(!this.idbtrans);\n            if (!idbtrans && !idbdb) {\n                switch (dbOpenError && dbOpenError.name) {\n                    case \"DatabaseClosedError\":\n                        throw new exceptions.DatabaseClosed(dbOpenError);\n                    case \"MissingAPIError\":\n                        throw new exceptions.MissingAPI(dbOpenError.message, dbOpenError);\n                    default:\n                        throw new exceptions.OpenFailed(dbOpenError);\n                }\n            }\n            if (!this.active)\n                throw new exceptions.TransactionInactive();\n            assert(this._completion._state === null);\n            idbtrans = this.idbtrans = idbtrans ||\n                (this.db.core\n                    ? this.db.core.transaction(this.storeNames, this.mode, { durability: this.chromeTransactionDurability })\n                    : idbdb.transaction(this.storeNames, this.mode, { durability: this.chromeTransactionDurability }));\n            idbtrans.onerror = wrap(function (ev) {\n                preventDefault(ev);\n                _this._reject(idbtrans.error);\n            });\n            idbtrans.onabort = wrap(function (ev) {\n                preventDefault(ev);\n                _this.active && _this._reject(new exceptions.Abort(idbtrans.error));\n                _this.active = false;\n                _this.on(\"abort\").fire(ev);\n            });\n            idbtrans.oncomplete = wrap(function () {\n                _this.active = false;\n                _this._resolve();\n                if ('mutatedParts' in idbtrans) {\n                    globalEvents.storagemutated.fire(idbtrans[\"mutatedParts\"]);\n                }\n            });\n            return this;\n        };\n        Transaction.prototype._promise = function (mode, fn, bWriteLock) {\n            var _this = this;\n            if (mode === 'readwrite' && this.mode !== 'readwrite')\n                return rejection(new exceptions.ReadOnly(\"Transaction is readonly\"));\n            if (!this.active)\n                return rejection(new exceptions.TransactionInactive());\n            if (this._locked()) {\n                return new DexiePromise(function (resolve, reject) {\n                    _this._blockedFuncs.push([function () {\n                            _this._promise(mode, fn, bWriteLock).then(resolve, reject);\n                        }, PSD]);\n                });\n            }\n            else if (bWriteLock) {\n                return newScope(function () {\n                    var p = new DexiePromise(function (resolve, reject) {\n                        _this._lock();\n                        var rv = fn(resolve, reject, _this);\n                        if (rv && rv.then)\n                            rv.then(resolve, reject);\n                    });\n                    p.finally(function () { return _this._unlock(); });\n                    p._lib = true;\n                    return p;\n                });\n            }\n            else {\n                var p = new DexiePromise(function (resolve, reject) {\n                    var rv = fn(resolve, reject, _this);\n                    if (rv && rv.then)\n                        rv.then(resolve, reject);\n                });\n                p._lib = true;\n                return p;\n            }\n        };\n        Transaction.prototype._root = function () {\n            return this.parent ? this.parent._root() : this;\n        };\n        Transaction.prototype.waitFor = function (promiseLike) {\n            var root = this._root();\n            var promise = DexiePromise.resolve(promiseLike);\n            if (root._waitingFor) {\n                root._waitingFor = root._waitingFor.then(function () { return promise; });\n            }\n            else {\n                root._waitingFor = promise;\n                root._waitingQueue = [];\n                var store = root.idbtrans.objectStore(root.storeNames[0]);\n                (function spin() {\n                    ++root._spinCount;\n                    while (root._waitingQueue.length)\n                        (root._waitingQueue.shift())();\n                    if (root._waitingFor)\n                        store.get(-Infinity).onsuccess = spin;\n                }());\n            }\n            var currentWaitPromise = root._waitingFor;\n            return new DexiePromise(function (resolve, reject) {\n                promise.then(function (res) { return root._waitingQueue.push(wrap(resolve.bind(null, res))); }, function (err) { return root._waitingQueue.push(wrap(reject.bind(null, err))); }).finally(function () {\n                    if (root._waitingFor === currentWaitPromise) {\n                        root._waitingFor = null;\n                    }\n                });\n            });\n        };\n        Transaction.prototype.abort = function () {\n            if (this.active) {\n                this.active = false;\n                if (this.idbtrans)\n                    this.idbtrans.abort();\n                this._reject(new exceptions.Abort());\n            }\n        };\n        Transaction.prototype.table = function (tableName) {\n            var memoizedTables = (this._memoizedTables || (this._memoizedTables = {}));\n            if (hasOwn(memoizedTables, tableName))\n                return memoizedTables[tableName];\n            var tableSchema = this.schema[tableName];\n            if (!tableSchema) {\n                throw new exceptions.NotFound(\"Table \" + tableName + \" not part of transaction\");\n            }\n            var transactionBoundTable = new this.db.Table(tableName, tableSchema, this);\n            transactionBoundTable.core = this.db.core.table(tableName);\n            memoizedTables[tableName] = transactionBoundTable;\n            return transactionBoundTable;\n        };\n        return Transaction;\n    }());\n\n    function createTransactionConstructor(db) {\n        return makeClassConstructor(Transaction.prototype, function Transaction(mode, storeNames, dbschema, chromeTransactionDurability, parent) {\n            var _this = this;\n            this.db = db;\n            this.mode = mode;\n            this.storeNames = storeNames;\n            this.schema = dbschema;\n            this.chromeTransactionDurability = chromeTransactionDurability;\n            this.idbtrans = null;\n            this.on = Events(this, \"complete\", \"error\", \"abort\");\n            this.parent = parent || null;\n            this.active = true;\n            this._reculock = 0;\n            this._blockedFuncs = [];\n            this._resolve = null;\n            this._reject = null;\n            this._waitingFor = null;\n            this._waitingQueue = null;\n            this._spinCount = 0;\n            this._completion = new DexiePromise(function (resolve, reject) {\n                _this._resolve = resolve;\n                _this._reject = reject;\n            });\n            this._completion.then(function () {\n                _this.active = false;\n                _this.on.complete.fire();\n            }, function (e) {\n                var wasActive = _this.active;\n                _this.active = false;\n                _this.on.error.fire(e);\n                _this.parent ?\n                    _this.parent._reject(e) :\n                    wasActive && _this.idbtrans && _this.idbtrans.abort();\n                return rejection(e);\n            });\n        });\n    }\n\n    function createIndexSpec(name, keyPath, unique, multi, auto, compound, isPrimKey) {\n        return {\n            name: name,\n            keyPath: keyPath,\n            unique: unique,\n            multi: multi,\n            auto: auto,\n            compound: compound,\n            src: (unique && !isPrimKey ? '&' : '') + (multi ? '*' : '') + (auto ? \"++\" : \"\") + nameFromKeyPath(keyPath)\n        };\n    }\n    function nameFromKeyPath(keyPath) {\n        return typeof keyPath === 'string' ?\n            keyPath :\n            keyPath ? ('[' + [].join.call(keyPath, '+') + ']') : \"\";\n    }\n\n    function createTableSchema(name, primKey, indexes) {\n        return {\n            name: name,\n            primKey: primKey,\n            indexes: indexes,\n            mappedClass: null,\n            idxByName: arrayToObject(indexes, function (index) { return [index.name, index]; })\n        };\n    }\n\n    function safariMultiStoreFix(storeNames) {\n        return storeNames.length === 1 ? storeNames[0] : storeNames;\n    }\n    var getMaxKey = function (IdbKeyRange) {\n        try {\n            IdbKeyRange.only([[]]);\n            getMaxKey = function () { return [[]]; };\n            return [[]];\n        }\n        catch (e) {\n            getMaxKey = function () { return maxString; };\n            return maxString;\n        }\n    };\n\n    function getKeyExtractor(keyPath) {\n        if (keyPath == null) {\n            return function () { return undefined; };\n        }\n        else if (typeof keyPath === 'string') {\n            return getSinglePathKeyExtractor(keyPath);\n        }\n        else {\n            return function (obj) { return getByKeyPath(obj, keyPath); };\n        }\n    }\n    function getSinglePathKeyExtractor(keyPath) {\n        var split = keyPath.split('.');\n        if (split.length === 1) {\n            return function (obj) { return obj[keyPath]; };\n        }\n        else {\n            return function (obj) { return getByKeyPath(obj, keyPath); };\n        }\n    }\n\n    function arrayify(arrayLike) {\n        return [].slice.call(arrayLike);\n    }\n    var _id_counter = 0;\n    function getKeyPathAlias(keyPath) {\n        return keyPath == null ?\n            \":id\" :\n            typeof keyPath === 'string' ?\n                keyPath :\n                \"[\".concat(keyPath.join('+'), \"]\");\n    }\n    function createDBCore(db, IdbKeyRange, tmpTrans) {\n        function extractSchema(db, trans) {\n            var tables = arrayify(db.objectStoreNames);\n            return {\n                schema: {\n                    name: db.name,\n                    tables: tables.map(function (table) { return trans.objectStore(table); }).map(function (store) {\n                        var keyPath = store.keyPath, autoIncrement = store.autoIncrement;\n                        var compound = isArray(keyPath);\n                        var outbound = keyPath == null;\n                        var indexByKeyPath = {};\n                        var result = {\n                            name: store.name,\n                            primaryKey: {\n                                name: null,\n                                isPrimaryKey: true,\n                                outbound: outbound,\n                                compound: compound,\n                                keyPath: keyPath,\n                                autoIncrement: autoIncrement,\n                                unique: true,\n                                extractKey: getKeyExtractor(keyPath)\n                            },\n                            indexes: arrayify(store.indexNames).map(function (indexName) { return store.index(indexName); })\n                                .map(function (index) {\n                                var name = index.name, unique = index.unique, multiEntry = index.multiEntry, keyPath = index.keyPath;\n                                var compound = isArray(keyPath);\n                                var result = {\n                                    name: name,\n                                    compound: compound,\n                                    keyPath: keyPath,\n                                    unique: unique,\n                                    multiEntry: multiEntry,\n                                    extractKey: getKeyExtractor(keyPath)\n                                };\n                                indexByKeyPath[getKeyPathAlias(keyPath)] = result;\n                                return result;\n                            }),\n                            getIndexByKeyPath: function (keyPath) { return indexByKeyPath[getKeyPathAlias(keyPath)]; }\n                        };\n                        indexByKeyPath[\":id\"] = result.primaryKey;\n                        if (keyPath != null) {\n                            indexByKeyPath[getKeyPathAlias(keyPath)] = result.primaryKey;\n                        }\n                        return result;\n                    })\n                },\n                hasGetAll: tables.length > 0 && ('getAll' in trans.objectStore(tables[0])) &&\n                    !(typeof navigator !== 'undefined' && /Safari/.test(navigator.userAgent) &&\n                        !/(Chrome\\/|Edge\\/)/.test(navigator.userAgent) &&\n                        [].concat(navigator.userAgent.match(/Safari\\/(\\d*)/))[1] < 604)\n            };\n        }\n        function makeIDBKeyRange(range) {\n            if (range.type === 3 )\n                return null;\n            if (range.type === 4 )\n                throw new Error(\"Cannot convert never type to IDBKeyRange\");\n            var lower = range.lower, upper = range.upper, lowerOpen = range.lowerOpen, upperOpen = range.upperOpen;\n            var idbRange = lower === undefined ?\n                upper === undefined ?\n                    null :\n                    IdbKeyRange.upperBound(upper, !!upperOpen) :\n                upper === undefined ?\n                    IdbKeyRange.lowerBound(lower, !!lowerOpen) :\n                    IdbKeyRange.bound(lower, upper, !!lowerOpen, !!upperOpen);\n            return idbRange;\n        }\n        function createDbCoreTable(tableSchema) {\n            var tableName = tableSchema.name;\n            function mutate(_a) {\n                var trans = _a.trans, type = _a.type, keys = _a.keys, values = _a.values, range = _a.range;\n                return new Promise(function (resolve, reject) {\n                    resolve = wrap(resolve);\n                    var store = trans.objectStore(tableName);\n                    var outbound = store.keyPath == null;\n                    var isAddOrPut = type === \"put\" || type === \"add\";\n                    if (!isAddOrPut && type !== 'delete' && type !== 'deleteRange')\n                        throw new Error(\"Invalid operation type: \" + type);\n                    var length = (keys || values || { length: 1 }).length;\n                    if (keys && values && keys.length !== values.length) {\n                        throw new Error(\"Given keys array must have same length as given values array.\");\n                    }\n                    if (length === 0)\n                        return resolve({ numFailures: 0, failures: {}, results: [], lastResult: undefined });\n                    var req;\n                    var reqs = [];\n                    var failures = [];\n                    var numFailures = 0;\n                    var errorHandler = function (event) {\n                        ++numFailures;\n                        preventDefault(event);\n                    };\n                    if (type === 'deleteRange') {\n                        if (range.type === 4 )\n                            return resolve({ numFailures: numFailures, failures: failures, results: [], lastResult: undefined });\n                        if (range.type === 3 )\n                            reqs.push(req = store.clear());\n                        else\n                            reqs.push(req = store.delete(makeIDBKeyRange(range)));\n                    }\n                    else {\n                        var _a = isAddOrPut ?\n                            outbound ?\n                                [values, keys] :\n                                [values, null] :\n                            [keys, null], args1 = _a[0], args2 = _a[1];\n                        if (isAddOrPut) {\n                            for (var i = 0; i < length; ++i) {\n                                reqs.push(req = (args2 && args2[i] !== undefined ?\n                                    store[type](args1[i], args2[i]) :\n                                    store[type](args1[i])));\n                                req.onerror = errorHandler;\n                            }\n                        }\n                        else {\n                            for (var i = 0; i < length; ++i) {\n                                reqs.push(req = store[type](args1[i]));\n                                req.onerror = errorHandler;\n                            }\n                        }\n                    }\n                    var done = function (event) {\n                        var lastResult = event.target.result;\n                        reqs.forEach(function (req, i) { return req.error != null && (failures[i] = req.error); });\n                        resolve({\n                            numFailures: numFailures,\n                            failures: failures,\n                            results: type === \"delete\" ? keys : reqs.map(function (req) { return req.result; }),\n                            lastResult: lastResult\n                        });\n                    };\n                    req.onerror = function (event) {\n                        errorHandler(event);\n                        done(event);\n                    };\n                    req.onsuccess = done;\n                });\n            }\n            function openCursor(_a) {\n                var trans = _a.trans, values = _a.values, query = _a.query, reverse = _a.reverse, unique = _a.unique;\n                return new Promise(function (resolve, reject) {\n                    resolve = wrap(resolve);\n                    var index = query.index, range = query.range;\n                    var store = trans.objectStore(tableName);\n                    var source = index.isPrimaryKey ?\n                        store :\n                        store.index(index.name);\n                    var direction = reverse ?\n                        unique ?\n                            \"prevunique\" :\n                            \"prev\" :\n                        unique ?\n                            \"nextunique\" :\n                            \"next\";\n                    var req = values || !('openKeyCursor' in source) ?\n                        source.openCursor(makeIDBKeyRange(range), direction) :\n                        source.openKeyCursor(makeIDBKeyRange(range), direction);\n                    req.onerror = eventRejectHandler(reject);\n                    req.onsuccess = wrap(function (ev) {\n                        var cursor = req.result;\n                        if (!cursor) {\n                            resolve(null);\n                            return;\n                        }\n                        cursor.___id = ++_id_counter;\n                        cursor.done = false;\n                        var _cursorContinue = cursor.continue.bind(cursor);\n                        var _cursorContinuePrimaryKey = cursor.continuePrimaryKey;\n                        if (_cursorContinuePrimaryKey)\n                            _cursorContinuePrimaryKey = _cursorContinuePrimaryKey.bind(cursor);\n                        var _cursorAdvance = cursor.advance.bind(cursor);\n                        var doThrowCursorIsNotStarted = function () { throw new Error(\"Cursor not started\"); };\n                        var doThrowCursorIsStopped = function () { throw new Error(\"Cursor not stopped\"); };\n                        cursor.trans = trans;\n                        cursor.stop = cursor.continue = cursor.continuePrimaryKey = cursor.advance = doThrowCursorIsNotStarted;\n                        cursor.fail = wrap(reject);\n                        cursor.next = function () {\n                            var _this = this;\n                            var gotOne = 1;\n                            return this.start(function () { return gotOne-- ? _this.continue() : _this.stop(); }).then(function () { return _this; });\n                        };\n                        cursor.start = function (callback) {\n                            var iterationPromise = new Promise(function (resolveIteration, rejectIteration) {\n                                resolveIteration = wrap(resolveIteration);\n                                req.onerror = eventRejectHandler(rejectIteration);\n                                cursor.fail = rejectIteration;\n                                cursor.stop = function (value) {\n                                    cursor.stop = cursor.continue = cursor.continuePrimaryKey = cursor.advance = doThrowCursorIsStopped;\n                                    resolveIteration(value);\n                                };\n                            });\n                            var guardedCallback = function () {\n                                if (req.result) {\n                                    try {\n                                        callback();\n                                    }\n                                    catch (err) {\n                                        cursor.fail(err);\n                                    }\n                                }\n                                else {\n                                    cursor.done = true;\n                                    cursor.start = function () { throw new Error(\"Cursor behind last entry\"); };\n                                    cursor.stop();\n                                }\n                            };\n                            req.onsuccess = wrap(function (ev) {\n                                req.onsuccess = guardedCallback;\n                                guardedCallback();\n                            });\n                            cursor.continue = _cursorContinue;\n                            cursor.continuePrimaryKey = _cursorContinuePrimaryKey;\n                            cursor.advance = _cursorAdvance;\n                            guardedCallback();\n                            return iterationPromise;\n                        };\n                        resolve(cursor);\n                    }, reject);\n                });\n            }\n            function query(hasGetAll) {\n                return function (request) {\n                    return new Promise(function (resolve, reject) {\n                        resolve = wrap(resolve);\n                        var trans = request.trans, values = request.values, limit = request.limit, query = request.query;\n                        var nonInfinitLimit = limit === Infinity ? undefined : limit;\n                        var index = query.index, range = query.range;\n                        var store = trans.objectStore(tableName);\n                        var source = index.isPrimaryKey ? store : store.index(index.name);\n                        var idbKeyRange = makeIDBKeyRange(range);\n                        if (limit === 0)\n                            return resolve({ result: [] });\n                        if (hasGetAll) {\n                            var req = values ?\n                                source.getAll(idbKeyRange, nonInfinitLimit) :\n                                source.getAllKeys(idbKeyRange, nonInfinitLimit);\n                            req.onsuccess = function (event) { return resolve({ result: event.target.result }); };\n                            req.onerror = eventRejectHandler(reject);\n                        }\n                        else {\n                            var count_1 = 0;\n                            var req_1 = values || !('openKeyCursor' in source) ?\n                                source.openCursor(idbKeyRange) :\n                                source.openKeyCursor(idbKeyRange);\n                            var result_1 = [];\n                            req_1.onsuccess = function (event) {\n                                var cursor = req_1.result;\n                                if (!cursor)\n                                    return resolve({ result: result_1 });\n                                result_1.push(values ? cursor.value : cursor.primaryKey);\n                                if (++count_1 === limit)\n                                    return resolve({ result: result_1 });\n                                cursor.continue();\n                            };\n                            req_1.onerror = eventRejectHandler(reject);\n                        }\n                    });\n                };\n            }\n            return {\n                name: tableName,\n                schema: tableSchema,\n                mutate: mutate,\n                getMany: function (_a) {\n                    var trans = _a.trans, keys = _a.keys;\n                    return new Promise(function (resolve, reject) {\n                        resolve = wrap(resolve);\n                        var store = trans.objectStore(tableName);\n                        var length = keys.length;\n                        var result = new Array(length);\n                        var keyCount = 0;\n                        var callbackCount = 0;\n                        var req;\n                        var successHandler = function (event) {\n                            var req = event.target;\n                            if ((result[req._pos] = req.result) != null)\n                                ;\n                            if (++callbackCount === keyCount)\n                                resolve(result);\n                        };\n                        var errorHandler = eventRejectHandler(reject);\n                        for (var i = 0; i < length; ++i) {\n                            var key = keys[i];\n                            if (key != null) {\n                                req = store.get(keys[i]);\n                                req._pos = i;\n                                req.onsuccess = successHandler;\n                                req.onerror = errorHandler;\n                                ++keyCount;\n                            }\n                        }\n                        if (keyCount === 0)\n                            resolve(result);\n                    });\n                },\n                get: function (_a) {\n                    var trans = _a.trans, key = _a.key;\n                    return new Promise(function (resolve, reject) {\n                        resolve = wrap(resolve);\n                        var store = trans.objectStore(tableName);\n                        var req = store.get(key);\n                        req.onsuccess = function (event) { return resolve(event.target.result); };\n                        req.onerror = eventRejectHandler(reject);\n                    });\n                },\n                query: query(hasGetAll),\n                openCursor: openCursor,\n                count: function (_a) {\n                    var query = _a.query, trans = _a.trans;\n                    var index = query.index, range = query.range;\n                    return new Promise(function (resolve, reject) {\n                        var store = trans.objectStore(tableName);\n                        var source = index.isPrimaryKey ? store : store.index(index.name);\n                        var idbKeyRange = makeIDBKeyRange(range);\n                        var req = idbKeyRange ? source.count(idbKeyRange) : source.count();\n                        req.onsuccess = wrap(function (ev) { return resolve(ev.target.result); });\n                        req.onerror = eventRejectHandler(reject);\n                    });\n                }\n            };\n        }\n        var _a = extractSchema(db, tmpTrans), schema = _a.schema, hasGetAll = _a.hasGetAll;\n        var tables = schema.tables.map(function (tableSchema) { return createDbCoreTable(tableSchema); });\n        var tableMap = {};\n        tables.forEach(function (table) { return tableMap[table.name] = table; });\n        return {\n            stack: \"dbcore\",\n            transaction: db.transaction.bind(db),\n            table: function (name) {\n                var result = tableMap[name];\n                if (!result)\n                    throw new Error(\"Table '\".concat(name, \"' not found\"));\n                return tableMap[name];\n            },\n            MIN_KEY: -Infinity,\n            MAX_KEY: getMaxKey(IdbKeyRange),\n            schema: schema\n        };\n    }\n\n    function createMiddlewareStack(stackImpl, middlewares) {\n        return middlewares.reduce(function (down, _a) {\n            var create = _a.create;\n            return (__assign(__assign({}, down), create(down)));\n        }, stackImpl);\n    }\n    function createMiddlewareStacks(middlewares, idbdb, _a, tmpTrans) {\n        var IDBKeyRange = _a.IDBKeyRange; _a.indexedDB;\n        var dbcore = createMiddlewareStack(createDBCore(idbdb, IDBKeyRange, tmpTrans), middlewares.dbcore);\n        return {\n            dbcore: dbcore\n        };\n    }\n    function generateMiddlewareStacks(db, tmpTrans) {\n        var idbdb = tmpTrans.db;\n        var stacks = createMiddlewareStacks(db._middlewares, idbdb, db._deps, tmpTrans);\n        db.core = stacks.dbcore;\n        db.tables.forEach(function (table) {\n            var tableName = table.name;\n            if (db.core.schema.tables.some(function (tbl) { return tbl.name === tableName; })) {\n                table.core = db.core.table(tableName);\n                if (db[tableName] instanceof db.Table) {\n                    db[tableName].core = table.core;\n                }\n            }\n        });\n    }\n\n    function setApiOnPlace(db, objs, tableNames, dbschema) {\n        tableNames.forEach(function (tableName) {\n            var schema = dbschema[tableName];\n            objs.forEach(function (obj) {\n                var propDesc = getPropertyDescriptor(obj, tableName);\n                if (!propDesc || (\"value\" in propDesc && propDesc.value === undefined)) {\n                    if (obj === db.Transaction.prototype || obj instanceof db.Transaction) {\n                        setProp(obj, tableName, {\n                            get: function () { return this.table(tableName); },\n                            set: function (value) {\n                                defineProperty(this, tableName, { value: value, writable: true, configurable: true, enumerable: true });\n                            }\n                        });\n                    }\n                    else {\n                        obj[tableName] = new db.Table(tableName, schema);\n                    }\n                }\n            });\n        });\n    }\n    function removeTablesApi(db, objs) {\n        objs.forEach(function (obj) {\n            for (var key in obj) {\n                if (obj[key] instanceof db.Table)\n                    delete obj[key];\n            }\n        });\n    }\n    function lowerVersionFirst(a, b) {\n        return a._cfg.version - b._cfg.version;\n    }\n    function runUpgraders(db, oldVersion, idbUpgradeTrans, reject) {\n        var globalSchema = db._dbSchema;\n        if (idbUpgradeTrans.objectStoreNames.contains('$meta') && !globalSchema.$meta) {\n            globalSchema.$meta = createTableSchema(\"$meta\", parseIndexSyntax(\"\")[0], []);\n            db._storeNames.push('$meta');\n        }\n        var trans = db._createTransaction('readwrite', db._storeNames, globalSchema);\n        trans.create(idbUpgradeTrans);\n        trans._completion.catch(reject);\n        var rejectTransaction = trans._reject.bind(trans);\n        var transless = PSD.transless || PSD;\n        newScope(function () {\n            PSD.trans = trans;\n            PSD.transless = transless;\n            if (oldVersion === 0) {\n                keys(globalSchema).forEach(function (tableName) {\n                    createTable(idbUpgradeTrans, tableName, globalSchema[tableName].primKey, globalSchema[tableName].indexes);\n                });\n                generateMiddlewareStacks(db, idbUpgradeTrans);\n                DexiePromise.follow(function () { return db.on.populate.fire(trans); }).catch(rejectTransaction);\n            }\n            else {\n                generateMiddlewareStacks(db, idbUpgradeTrans);\n                return getExistingVersion(db, trans, oldVersion)\n                    .then(function (oldVersion) { return updateTablesAndIndexes(db, oldVersion, trans, idbUpgradeTrans); })\n                    .catch(rejectTransaction);\n            }\n        });\n    }\n    function patchCurrentVersion(db, idbUpgradeTrans) {\n        createMissingTables(db._dbSchema, idbUpgradeTrans);\n        if (idbUpgradeTrans.db.version % 10 === 0 && !idbUpgradeTrans.objectStoreNames.contains('$meta')) {\n            idbUpgradeTrans.db.createObjectStore('$meta').add(Math.ceil((idbUpgradeTrans.db.version / 10) - 1), 'version');\n        }\n        var globalSchema = buildGlobalSchema(db, db.idbdb, idbUpgradeTrans);\n        adjustToExistingIndexNames(db, db._dbSchema, idbUpgradeTrans);\n        var diff = getSchemaDiff(globalSchema, db._dbSchema);\n        var _loop_1 = function (tableChange) {\n            if (tableChange.change.length || tableChange.recreate) {\n                console.warn(\"Unable to patch indexes of table \".concat(tableChange.name, \" because it has changes on the type of index or primary key.\"));\n                return { value: void 0 };\n            }\n            var store = idbUpgradeTrans.objectStore(tableChange.name);\n            tableChange.add.forEach(function (idx) {\n                if (debug)\n                    console.debug(\"Dexie upgrade patch: Creating missing index \".concat(tableChange.name, \".\").concat(idx.src));\n                addIndex(store, idx);\n            });\n        };\n        for (var _i = 0, _a = diff.change; _i < _a.length; _i++) {\n            var tableChange = _a[_i];\n            var state_1 = _loop_1(tableChange);\n            if (typeof state_1 === \"object\")\n                return state_1.value;\n        }\n    }\n    function getExistingVersion(db, trans, oldVersion) {\n        if (trans.storeNames.includes('$meta')) {\n            return trans.table('$meta').get('version').then(function (metaVersion) {\n                return metaVersion != null ? metaVersion : oldVersion;\n            });\n        }\n        else {\n            return DexiePromise.resolve(oldVersion);\n        }\n    }\n    function updateTablesAndIndexes(db, oldVersion, trans, idbUpgradeTrans) {\n        var queue = [];\n        var versions = db._versions;\n        var globalSchema = db._dbSchema = buildGlobalSchema(db, db.idbdb, idbUpgradeTrans);\n        var versToRun = versions.filter(function (v) { return v._cfg.version >= oldVersion; });\n        if (versToRun.length === 0) {\n            return DexiePromise.resolve();\n        }\n        versToRun.forEach(function (version) {\n            queue.push(function () {\n                var oldSchema = globalSchema;\n                var newSchema = version._cfg.dbschema;\n                adjustToExistingIndexNames(db, oldSchema, idbUpgradeTrans);\n                adjustToExistingIndexNames(db, newSchema, idbUpgradeTrans);\n                globalSchema = db._dbSchema = newSchema;\n                var diff = getSchemaDiff(oldSchema, newSchema);\n                diff.add.forEach(function (tuple) {\n                    createTable(idbUpgradeTrans, tuple[0], tuple[1].primKey, tuple[1].indexes);\n                });\n                diff.change.forEach(function (change) {\n                    if (change.recreate) {\n                        throw new exceptions.Upgrade(\"Not yet support for changing primary key\");\n                    }\n                    else {\n                        var store_1 = idbUpgradeTrans.objectStore(change.name);\n                        change.add.forEach(function (idx) { return addIndex(store_1, idx); });\n                        change.change.forEach(function (idx) {\n                            store_1.deleteIndex(idx.name);\n                            addIndex(store_1, idx);\n                        });\n                        change.del.forEach(function (idxName) { return store_1.deleteIndex(idxName); });\n                    }\n                });\n                var contentUpgrade = version._cfg.contentUpgrade;\n                if (contentUpgrade && version._cfg.version > oldVersion) {\n                    generateMiddlewareStacks(db, idbUpgradeTrans);\n                    trans._memoizedTables = {};\n                    var upgradeSchema_1 = shallowClone(newSchema);\n                    diff.del.forEach(function (table) {\n                        upgradeSchema_1[table] = oldSchema[table];\n                    });\n                    removeTablesApi(db, [db.Transaction.prototype]);\n                    setApiOnPlace(db, [db.Transaction.prototype], keys(upgradeSchema_1), upgradeSchema_1);\n                    trans.schema = upgradeSchema_1;\n                    var contentUpgradeIsAsync_1 = isAsyncFunction(contentUpgrade);\n                    if (contentUpgradeIsAsync_1) {\n                        incrementExpectedAwaits();\n                    }\n                    var returnValue_1;\n                    var promiseFollowed = DexiePromise.follow(function () {\n                        returnValue_1 = contentUpgrade(trans);\n                        if (returnValue_1) {\n                            if (contentUpgradeIsAsync_1) {\n                                var decrementor = decrementExpectedAwaits.bind(null, null);\n                                returnValue_1.then(decrementor, decrementor);\n                            }\n                        }\n                    });\n                    return (returnValue_1 && typeof returnValue_1.then === 'function' ?\n                        DexiePromise.resolve(returnValue_1) : promiseFollowed.then(function () { return returnValue_1; }));\n                }\n            });\n            queue.push(function (idbtrans) {\n                var newSchema = version._cfg.dbschema;\n                deleteRemovedTables(newSchema, idbtrans);\n                removeTablesApi(db, [db.Transaction.prototype]);\n                setApiOnPlace(db, [db.Transaction.prototype], db._storeNames, db._dbSchema);\n                trans.schema = db._dbSchema;\n            });\n            queue.push(function (idbtrans) {\n                if (db.idbdb.objectStoreNames.contains('$meta')) {\n                    if (Math.ceil(db.idbdb.version / 10) === version._cfg.version) {\n                        db.idbdb.deleteObjectStore('$meta');\n                        delete db._dbSchema.$meta;\n                        db._storeNames = db._storeNames.filter(function (name) { return name !== '$meta'; });\n                    }\n                    else {\n                        idbtrans.objectStore('$meta').put(version._cfg.version, 'version');\n                    }\n                }\n            });\n        });\n        function runQueue() {\n            return queue.length ? DexiePromise.resolve(queue.shift()(trans.idbtrans)).then(runQueue) :\n                DexiePromise.resolve();\n        }\n        return runQueue().then(function () {\n            createMissingTables(globalSchema, idbUpgradeTrans);\n        });\n    }\n    function getSchemaDiff(oldSchema, newSchema) {\n        var diff = {\n            del: [],\n            add: [],\n            change: []\n        };\n        var table;\n        for (table in oldSchema) {\n            if (!newSchema[table])\n                diff.del.push(table);\n        }\n        for (table in newSchema) {\n            var oldDef = oldSchema[table], newDef = newSchema[table];\n            if (!oldDef) {\n                diff.add.push([table, newDef]);\n            }\n            else {\n                var change = {\n                    name: table,\n                    def: newDef,\n                    recreate: false,\n                    del: [],\n                    add: [],\n                    change: []\n                };\n                if ((\n                '' + (oldDef.primKey.keyPath || '')) !== ('' + (newDef.primKey.keyPath || '')) ||\n                    (oldDef.primKey.auto !== newDef.primKey.auto)) {\n                    change.recreate = true;\n                    diff.change.push(change);\n                }\n                else {\n                    var oldIndexes = oldDef.idxByName;\n                    var newIndexes = newDef.idxByName;\n                    var idxName = void 0;\n                    for (idxName in oldIndexes) {\n                        if (!newIndexes[idxName])\n                            change.del.push(idxName);\n                    }\n                    for (idxName in newIndexes) {\n                        var oldIdx = oldIndexes[idxName], newIdx = newIndexes[idxName];\n                        if (!oldIdx)\n                            change.add.push(newIdx);\n                        else if (oldIdx.src !== newIdx.src)\n                            change.change.push(newIdx);\n                    }\n                    if (change.del.length > 0 || change.add.length > 0 || change.change.length > 0) {\n                        diff.change.push(change);\n                    }\n                }\n            }\n        }\n        return diff;\n    }\n    function createTable(idbtrans, tableName, primKey, indexes) {\n        var store = idbtrans.db.createObjectStore(tableName, primKey.keyPath ?\n            { keyPath: primKey.keyPath, autoIncrement: primKey.auto } :\n            { autoIncrement: primKey.auto });\n        indexes.forEach(function (idx) { return addIndex(store, idx); });\n        return store;\n    }\n    function createMissingTables(newSchema, idbtrans) {\n        keys(newSchema).forEach(function (tableName) {\n            if (!idbtrans.db.objectStoreNames.contains(tableName)) {\n                if (debug)\n                    console.debug('Dexie: Creating missing table', tableName);\n                createTable(idbtrans, tableName, newSchema[tableName].primKey, newSchema[tableName].indexes);\n            }\n        });\n    }\n    function deleteRemovedTables(newSchema, idbtrans) {\n        [].slice.call(idbtrans.db.objectStoreNames).forEach(function (storeName) {\n            return newSchema[storeName] == null && idbtrans.db.deleteObjectStore(storeName);\n        });\n    }\n    function addIndex(store, idx) {\n        store.createIndex(idx.name, idx.keyPath, { unique: idx.unique, multiEntry: idx.multi });\n    }\n    function buildGlobalSchema(db, idbdb, tmpTrans) {\n        var globalSchema = {};\n        var dbStoreNames = slice(idbdb.objectStoreNames, 0);\n        dbStoreNames.forEach(function (storeName) {\n            var store = tmpTrans.objectStore(storeName);\n            var keyPath = store.keyPath;\n            var primKey = createIndexSpec(nameFromKeyPath(keyPath), keyPath || \"\", true, false, !!store.autoIncrement, keyPath && typeof keyPath !== \"string\", true);\n            var indexes = [];\n            for (var j = 0; j < store.indexNames.length; ++j) {\n                var idbindex = store.index(store.indexNames[j]);\n                keyPath = idbindex.keyPath;\n                var index = createIndexSpec(idbindex.name, keyPath, !!idbindex.unique, !!idbindex.multiEntry, false, keyPath && typeof keyPath !== \"string\", false);\n                indexes.push(index);\n            }\n            globalSchema[storeName] = createTableSchema(storeName, primKey, indexes);\n        });\n        return globalSchema;\n    }\n    function readGlobalSchema(db, idbdb, tmpTrans) {\n        db.verno = idbdb.version / 10;\n        var globalSchema = db._dbSchema = buildGlobalSchema(db, idbdb, tmpTrans);\n        db._storeNames = slice(idbdb.objectStoreNames, 0);\n        setApiOnPlace(db, [db._allTables], keys(globalSchema), globalSchema);\n    }\n    function verifyInstalledSchema(db, tmpTrans) {\n        var installedSchema = buildGlobalSchema(db, db.idbdb, tmpTrans);\n        var diff = getSchemaDiff(installedSchema, db._dbSchema);\n        return !(diff.add.length || diff.change.some(function (ch) { return ch.add.length || ch.change.length; }));\n    }\n    function adjustToExistingIndexNames(db, schema, idbtrans) {\n        var storeNames = idbtrans.db.objectStoreNames;\n        for (var i = 0; i < storeNames.length; ++i) {\n            var storeName = storeNames[i];\n            var store = idbtrans.objectStore(storeName);\n            db._hasGetAll = 'getAll' in store;\n            for (var j = 0; j < store.indexNames.length; ++j) {\n                var indexName = store.indexNames[j];\n                var keyPath = store.index(indexName).keyPath;\n                var dexieName = typeof keyPath === 'string' ? keyPath : \"[\" + slice(keyPath).join('+') + \"]\";\n                if (schema[storeName]) {\n                    var indexSpec = schema[storeName].idxByName[dexieName];\n                    if (indexSpec) {\n                        indexSpec.name = indexName;\n                        delete schema[storeName].idxByName[dexieName];\n                        schema[storeName].idxByName[indexName] = indexSpec;\n                    }\n                }\n            }\n        }\n        if (typeof navigator !== 'undefined' && /Safari/.test(navigator.userAgent) &&\n            !/(Chrome\\/|Edge\\/)/.test(navigator.userAgent) &&\n            _global.WorkerGlobalScope && _global instanceof _global.WorkerGlobalScope &&\n            [].concat(navigator.userAgent.match(/Safari\\/(\\d*)/))[1] < 604) {\n            db._hasGetAll = false;\n        }\n    }\n    function parseIndexSyntax(primKeyAndIndexes) {\n        return primKeyAndIndexes.split(',').map(function (index, indexNum) {\n            index = index.trim();\n            var name = index.replace(/([&*]|\\+\\+)/g, \"\");\n            var keyPath = /^\\[/.test(name) ? name.match(/^\\[(.*)\\]$/)[1].split('+') : name;\n            return createIndexSpec(name, keyPath || null, /\\&/.test(index), /\\*/.test(index), /\\+\\+/.test(index), isArray(keyPath), indexNum === 0);\n        });\n    }\n\n    var Version =  (function () {\n        function Version() {\n        }\n        Version.prototype._parseStoresSpec = function (stores, outSchema) {\n            keys(stores).forEach(function (tableName) {\n                if (stores[tableName] !== null) {\n                    var indexes = parseIndexSyntax(stores[tableName]);\n                    var primKey = indexes.shift();\n                    primKey.unique = true;\n                    if (primKey.multi)\n                        throw new exceptions.Schema(\"Primary key cannot be multi-valued\");\n                    indexes.forEach(function (idx) {\n                        if (idx.auto)\n                            throw new exceptions.Schema(\"Only primary key can be marked as autoIncrement (++)\");\n                        if (!idx.keyPath)\n                            throw new exceptions.Schema(\"Index must have a name and cannot be an empty string\");\n                    });\n                    outSchema[tableName] = createTableSchema(tableName, primKey, indexes);\n                }\n            });\n        };\n        Version.prototype.stores = function (stores) {\n            var db = this.db;\n            this._cfg.storesSource = this._cfg.storesSource ?\n                extend(this._cfg.storesSource, stores) :\n                stores;\n            var versions = db._versions;\n            var storesSpec = {};\n            var dbschema = {};\n            versions.forEach(function (version) {\n                extend(storesSpec, version._cfg.storesSource);\n                dbschema = (version._cfg.dbschema = {});\n                version._parseStoresSpec(storesSpec, dbschema);\n            });\n            db._dbSchema = dbschema;\n            removeTablesApi(db, [db._allTables, db, db.Transaction.prototype]);\n            setApiOnPlace(db, [db._allTables, db, db.Transaction.prototype, this._cfg.tables], keys(dbschema), dbschema);\n            db._storeNames = keys(dbschema);\n            return this;\n        };\n        Version.prototype.upgrade = function (upgradeFunction) {\n            this._cfg.contentUpgrade = promisableChain(this._cfg.contentUpgrade || nop, upgradeFunction);\n            return this;\n        };\n        return Version;\n    }());\n\n    function createVersionConstructor(db) {\n        return makeClassConstructor(Version.prototype, function Version(versionNumber) {\n            this.db = db;\n            this._cfg = {\n                version: versionNumber,\n                storesSource: null,\n                dbschema: {},\n                tables: {},\n                contentUpgrade: null\n            };\n        });\n    }\n\n    function getDbNamesTable(indexedDB, IDBKeyRange) {\n        var dbNamesDB = indexedDB[\"_dbNamesDB\"];\n        if (!dbNamesDB) {\n            dbNamesDB = indexedDB[\"_dbNamesDB\"] = new Dexie$1(DBNAMES_DB, {\n                addons: [],\n                indexedDB: indexedDB,\n                IDBKeyRange: IDBKeyRange,\n            });\n            dbNamesDB.version(1).stores({ dbnames: \"name\" });\n        }\n        return dbNamesDB.table(\"dbnames\");\n    }\n    function hasDatabasesNative(indexedDB) {\n        return indexedDB && typeof indexedDB.databases === \"function\";\n    }\n    function getDatabaseNames(_a) {\n        var indexedDB = _a.indexedDB, IDBKeyRange = _a.IDBKeyRange;\n        return hasDatabasesNative(indexedDB)\n            ? Promise.resolve(indexedDB.databases()).then(function (infos) {\n                return infos\n                    .map(function (info) { return info.name; })\n                    .filter(function (name) { return name !== DBNAMES_DB; });\n            })\n            : getDbNamesTable(indexedDB, IDBKeyRange).toCollection().primaryKeys();\n    }\n    function _onDatabaseCreated(_a, name) {\n        var indexedDB = _a.indexedDB, IDBKeyRange = _a.IDBKeyRange;\n        !hasDatabasesNative(indexedDB) &&\n            name !== DBNAMES_DB &&\n            getDbNamesTable(indexedDB, IDBKeyRange).put({ name: name }).catch(nop);\n    }\n    function _onDatabaseDeleted(_a, name) {\n        var indexedDB = _a.indexedDB, IDBKeyRange = _a.IDBKeyRange;\n        !hasDatabasesNative(indexedDB) &&\n            name !== DBNAMES_DB &&\n            getDbNamesTable(indexedDB, IDBKeyRange).delete(name).catch(nop);\n    }\n\n    function vip(fn) {\n        return newScope(function () {\n            PSD.letThrough = true;\n            return fn();\n        });\n    }\n\n    function idbReady() {\n        var isSafari = !navigator.userAgentData &&\n            /Safari\\//.test(navigator.userAgent) &&\n            !/Chrom(e|ium)\\//.test(navigator.userAgent);\n        if (!isSafari || !indexedDB.databases)\n            return Promise.resolve();\n        var intervalId;\n        return new Promise(function (resolve) {\n            var tryIdb = function () { return indexedDB.databases().finally(resolve); };\n            intervalId = setInterval(tryIdb, 100);\n            tryIdb();\n        }).finally(function () { return clearInterval(intervalId); });\n    }\n\n    var _a;\n    function isEmptyRange(node) {\n        return !(\"from\" in node);\n    }\n    var RangeSet = function (fromOrTree, to) {\n        if (this) {\n            extend(this, arguments.length ? { d: 1, from: fromOrTree, to: arguments.length > 1 ? to : fromOrTree } : { d: 0 });\n        }\n        else {\n            var rv = new RangeSet();\n            if (fromOrTree && (\"d\" in fromOrTree)) {\n                extend(rv, fromOrTree);\n            }\n            return rv;\n        }\n    };\n    props(RangeSet.prototype, (_a = {\n            add: function (rangeSet) {\n                mergeRanges(this, rangeSet);\n                return this;\n            },\n            addKey: function (key) {\n                addRange(this, key, key);\n                return this;\n            },\n            addKeys: function (keys) {\n                var _this = this;\n                keys.forEach(function (key) { return addRange(_this, key, key); });\n                return this;\n            },\n            hasKey: function (key) {\n                var node = getRangeSetIterator(this).next(key).value;\n                return node && cmp(node.from, key) <= 0 && cmp(node.to, key) >= 0;\n            }\n        },\n        _a[iteratorSymbol] = function () {\n            return getRangeSetIterator(this);\n        },\n        _a));\n    function addRange(target, from, to) {\n        var diff = cmp(from, to);\n        if (isNaN(diff))\n            return;\n        if (diff > 0)\n            throw RangeError();\n        if (isEmptyRange(target))\n            return extend(target, { from: from, to: to, d: 1 });\n        var left = target.l;\n        var right = target.r;\n        if (cmp(to, target.from) < 0) {\n            left\n                ? addRange(left, from, to)\n                : (target.l = { from: from, to: to, d: 1, l: null, r: null });\n            return rebalance(target);\n        }\n        if (cmp(from, target.to) > 0) {\n            right\n                ? addRange(right, from, to)\n                : (target.r = { from: from, to: to, d: 1, l: null, r: null });\n            return rebalance(target);\n        }\n        if (cmp(from, target.from) < 0) {\n            target.from = from;\n            target.l = null;\n            target.d = right ? right.d + 1 : 1;\n        }\n        if (cmp(to, target.to) > 0) {\n            target.to = to;\n            target.r = null;\n            target.d = target.l ? target.l.d + 1 : 1;\n        }\n        var rightWasCutOff = !target.r;\n        if (left && !target.l) {\n            mergeRanges(target, left);\n        }\n        if (right && rightWasCutOff) {\n            mergeRanges(target, right);\n        }\n    }\n    function mergeRanges(target, newSet) {\n        function _addRangeSet(target, _a) {\n            var from = _a.from, to = _a.to, l = _a.l, r = _a.r;\n            addRange(target, from, to);\n            if (l)\n                _addRangeSet(target, l);\n            if (r)\n                _addRangeSet(target, r);\n        }\n        if (!isEmptyRange(newSet))\n            _addRangeSet(target, newSet);\n    }\n    function rangesOverlap(rangeSet1, rangeSet2) {\n        var i1 = getRangeSetIterator(rangeSet2);\n        var nextResult1 = i1.next();\n        if (nextResult1.done)\n            return false;\n        var a = nextResult1.value;\n        var i2 = getRangeSetIterator(rangeSet1);\n        var nextResult2 = i2.next(a.from);\n        var b = nextResult2.value;\n        while (!nextResult1.done && !nextResult2.done) {\n            if (cmp(b.from, a.to) <= 0 && cmp(b.to, a.from) >= 0)\n                return true;\n            cmp(a.from, b.from) < 0\n                ? (a = (nextResult1 = i1.next(b.from)).value)\n                : (b = (nextResult2 = i2.next(a.from)).value);\n        }\n        return false;\n    }\n    function getRangeSetIterator(node) {\n        var state = isEmptyRange(node) ? null : { s: 0, n: node };\n        return {\n            next: function (key) {\n                var keyProvided = arguments.length > 0;\n                while (state) {\n                    switch (state.s) {\n                        case 0:\n                            state.s = 1;\n                            if (keyProvided) {\n                                while (state.n.l && cmp(key, state.n.from) < 0)\n                                    state = { up: state, n: state.n.l, s: 1 };\n                            }\n                            else {\n                                while (state.n.l)\n                                    state = { up: state, n: state.n.l, s: 1 };\n                            }\n                        case 1:\n                            state.s = 2;\n                            if (!keyProvided || cmp(key, state.n.to) <= 0)\n                                return { value: state.n, done: false };\n                        case 2:\n                            if (state.n.r) {\n                                state.s = 3;\n                                state = { up: state, n: state.n.r, s: 0 };\n                                continue;\n                            }\n                        case 3:\n                            state = state.up;\n                    }\n                }\n                return { done: true };\n            },\n        };\n    }\n    function rebalance(target) {\n        var _a, _b;\n        var diff = (((_a = target.r) === null || _a === void 0 ? void 0 : _a.d) || 0) - (((_b = target.l) === null || _b === void 0 ? void 0 : _b.d) || 0);\n        var r = diff > 1 ? \"r\" : diff < -1 ? \"l\" : \"\";\n        if (r) {\n            var l = r === \"r\" ? \"l\" : \"r\";\n            var rootClone = __assign({}, target);\n            var oldRootRight = target[r];\n            target.from = oldRootRight.from;\n            target.to = oldRootRight.to;\n            target[r] = oldRootRight[r];\n            rootClone[r] = oldRootRight[l];\n            target[l] = rootClone;\n            rootClone.d = computeDepth(rootClone);\n        }\n        target.d = computeDepth(target);\n    }\n    function computeDepth(_a) {\n        var r = _a.r, l = _a.l;\n        return (r ? (l ? Math.max(r.d, l.d) : r.d) : l ? l.d : 0) + 1;\n    }\n\n    function extendObservabilitySet(target, newSet) {\n        keys(newSet).forEach(function (part) {\n            if (target[part])\n                mergeRanges(target[part], newSet[part]);\n            else\n                target[part] = cloneSimpleObjectTree(newSet[part]);\n        });\n        return target;\n    }\n\n    function obsSetsOverlap(os1, os2) {\n        return os1.all || os2.all || Object.keys(os1).some(function (key) { return os2[key] && rangesOverlap(os2[key], os1[key]); });\n    }\n\n    var cache = {};\n\n    var unsignaledParts = {};\n    var isTaskEnqueued = false;\n    function signalSubscribersLazily(part, optimistic) {\n        extendObservabilitySet(unsignaledParts, part);\n        if (!isTaskEnqueued) {\n            isTaskEnqueued = true;\n            setTimeout(function () {\n                isTaskEnqueued = false;\n                var parts = unsignaledParts;\n                unsignaledParts = {};\n                signalSubscribersNow(parts, false);\n            }, 0);\n        }\n    }\n    function signalSubscribersNow(updatedParts, deleteAffectedCacheEntries) {\n        if (deleteAffectedCacheEntries === void 0) { deleteAffectedCacheEntries = false; }\n        var queriesToSignal = new Set();\n        if (updatedParts.all) {\n            for (var _i = 0, _a = Object.values(cache); _i < _a.length; _i++) {\n                var tblCache = _a[_i];\n                collectTableSubscribers(tblCache, updatedParts, queriesToSignal, deleteAffectedCacheEntries);\n            }\n        }\n        else {\n            for (var key in updatedParts) {\n                var parts = /^idb\\:\\/\\/(.*)\\/(.*)\\//.exec(key);\n                if (parts) {\n                    var dbName = parts[1], tableName = parts[2];\n                    var tblCache = cache[\"idb://\".concat(dbName, \"/\").concat(tableName)];\n                    if (tblCache)\n                        collectTableSubscribers(tblCache, updatedParts, queriesToSignal, deleteAffectedCacheEntries);\n                }\n            }\n        }\n        queriesToSignal.forEach(function (requery) { return requery(); });\n    }\n    function collectTableSubscribers(tblCache, updatedParts, outQueriesToSignal, deleteAffectedCacheEntries) {\n        var updatedEntryLists = [];\n        for (var _i = 0, _a = Object.entries(tblCache.queries.query); _i < _a.length; _i++) {\n            var _b = _a[_i], indexName = _b[0], entries = _b[1];\n            var filteredEntries = [];\n            for (var _c = 0, entries_1 = entries; _c < entries_1.length; _c++) {\n                var entry = entries_1[_c];\n                if (obsSetsOverlap(updatedParts, entry.obsSet)) {\n                    entry.subscribers.forEach(function (requery) { return outQueriesToSignal.add(requery); });\n                }\n                else if (deleteAffectedCacheEntries) {\n                    filteredEntries.push(entry);\n                }\n            }\n            if (deleteAffectedCacheEntries)\n                updatedEntryLists.push([indexName, filteredEntries]);\n        }\n        if (deleteAffectedCacheEntries) {\n            for (var _d = 0, updatedEntryLists_1 = updatedEntryLists; _d < updatedEntryLists_1.length; _d++) {\n                var _e = updatedEntryLists_1[_d], indexName = _e[0], filteredEntries = _e[1];\n                tblCache.queries.query[indexName] = filteredEntries;\n            }\n        }\n    }\n\n    function dexieOpen(db) {\n        var state = db._state;\n        var indexedDB = db._deps.indexedDB;\n        if (state.isBeingOpened || db.idbdb)\n            return state.dbReadyPromise.then(function () { return state.dbOpenError ?\n                rejection(state.dbOpenError) :\n                db; });\n        state.isBeingOpened = true;\n        state.dbOpenError = null;\n        state.openComplete = false;\n        var openCanceller = state.openCanceller;\n        var nativeVerToOpen = Math.round(db.verno * 10);\n        var schemaPatchMode = false;\n        function throwIfCancelled() {\n            if (state.openCanceller !== openCanceller)\n                throw new exceptions.DatabaseClosed('db.open() was cancelled');\n        }\n        var resolveDbReady = state.dbReadyResolve,\n        upgradeTransaction = null, wasCreated = false;\n        var tryOpenDB = function () { return new DexiePromise(function (resolve, reject) {\n            throwIfCancelled();\n            if (!indexedDB)\n                throw new exceptions.MissingAPI();\n            var dbName = db.name;\n            var req = state.autoSchema || !nativeVerToOpen ?\n                indexedDB.open(dbName) :\n                indexedDB.open(dbName, nativeVerToOpen);\n            if (!req)\n                throw new exceptions.MissingAPI();\n            req.onerror = eventRejectHandler(reject);\n            req.onblocked = wrap(db._fireOnBlocked);\n            req.onupgradeneeded = wrap(function (e) {\n                upgradeTransaction = req.transaction;\n                if (state.autoSchema && !db._options.allowEmptyDB) {\n                    req.onerror = preventDefault;\n                    upgradeTransaction.abort();\n                    req.result.close();\n                    var delreq = indexedDB.deleteDatabase(dbName);\n                    delreq.onsuccess = delreq.onerror = wrap(function () {\n                        reject(new exceptions.NoSuchDatabase(\"Database \".concat(dbName, \" doesnt exist\")));\n                    });\n                }\n                else {\n                    upgradeTransaction.onerror = eventRejectHandler(reject);\n                    var oldVer = e.oldVersion > Math.pow(2, 62) ? 0 : e.oldVersion;\n                    wasCreated = oldVer < 1;\n                    db.idbdb = req.result;\n                    if (schemaPatchMode) {\n                        patchCurrentVersion(db, upgradeTransaction);\n                    }\n                    runUpgraders(db, oldVer / 10, upgradeTransaction, reject);\n                }\n            }, reject);\n            req.onsuccess = wrap(function () {\n                upgradeTransaction = null;\n                var idbdb = db.idbdb = req.result;\n                var objectStoreNames = slice(idbdb.objectStoreNames);\n                if (objectStoreNames.length > 0)\n                    try {\n                        var tmpTrans = idbdb.transaction(safariMultiStoreFix(objectStoreNames), 'readonly');\n                        if (state.autoSchema)\n                            readGlobalSchema(db, idbdb, tmpTrans);\n                        else {\n                            adjustToExistingIndexNames(db, db._dbSchema, tmpTrans);\n                            if (!verifyInstalledSchema(db, tmpTrans) && !schemaPatchMode) {\n                                console.warn(\"Dexie SchemaDiff: Schema was extended without increasing the number passed to db.version(). Dexie will add missing parts and increment native version number to workaround this.\");\n                                idbdb.close();\n                                nativeVerToOpen = idbdb.version + 1;\n                                schemaPatchMode = true;\n                                return resolve(tryOpenDB());\n                            }\n                        }\n                        generateMiddlewareStacks(db, tmpTrans);\n                    }\n                    catch (e) {\n                    }\n                connections.push(db);\n                idbdb.onversionchange = wrap(function (ev) {\n                    state.vcFired = true;\n                    db.on(\"versionchange\").fire(ev);\n                });\n                idbdb.onclose = wrap(function (ev) {\n                    db.on(\"close\").fire(ev);\n                });\n                if (wasCreated)\n                    _onDatabaseCreated(db._deps, dbName);\n                resolve();\n            }, reject);\n        }).catch(function (err) {\n            switch (err === null || err === void 0 ? void 0 : err.name) {\n                case \"UnknownError\":\n                    if (state.PR1398_maxLoop > 0) {\n                        state.PR1398_maxLoop--;\n                        console.warn('Dexie: Workaround for Chrome UnknownError on open()');\n                        return tryOpenDB();\n                    }\n                    break;\n                case \"VersionError\":\n                    if (nativeVerToOpen > 0) {\n                        nativeVerToOpen = 0;\n                        return tryOpenDB();\n                    }\n                    break;\n            }\n            return DexiePromise.reject(err);\n        }); };\n        return DexiePromise.race([\n            openCanceller,\n            (typeof navigator === 'undefined' ? DexiePromise.resolve() : idbReady()).then(tryOpenDB)\n        ]).then(function () {\n            throwIfCancelled();\n            state.onReadyBeingFired = [];\n            return DexiePromise.resolve(vip(function () { return db.on.ready.fire(db.vip); })).then(function fireRemainders() {\n                if (state.onReadyBeingFired.length > 0) {\n                    var remainders_1 = state.onReadyBeingFired.reduce(promisableChain, nop);\n                    state.onReadyBeingFired = [];\n                    return DexiePromise.resolve(vip(function () { return remainders_1(db.vip); })).then(fireRemainders);\n                }\n            });\n        }).finally(function () {\n            if (state.openCanceller === openCanceller) {\n                state.onReadyBeingFired = null;\n                state.isBeingOpened = false;\n            }\n        }).catch(function (err) {\n            state.dbOpenError = err;\n            try {\n                upgradeTransaction && upgradeTransaction.abort();\n            }\n            catch (_a) { }\n            if (openCanceller === state.openCanceller) {\n                db._close();\n            }\n            return rejection(err);\n        }).finally(function () {\n            state.openComplete = true;\n            resolveDbReady();\n        }).then(function () {\n            if (wasCreated) {\n                var everything_1 = {};\n                db.tables.forEach(function (table) {\n                    table.schema.indexes.forEach(function (idx) {\n                        if (idx.name)\n                            everything_1[\"idb://\".concat(db.name, \"/\").concat(table.name, \"/\").concat(idx.name)] = new RangeSet(-Infinity, [[[]]]);\n                    });\n                    everything_1[\"idb://\".concat(db.name, \"/\").concat(table.name, \"/\")] = everything_1[\"idb://\".concat(db.name, \"/\").concat(table.name, \"/:dels\")] = new RangeSet(-Infinity, [[[]]]);\n                });\n                globalEvents(DEXIE_STORAGE_MUTATED_EVENT_NAME).fire(everything_1);\n                signalSubscribersNow(everything_1, true);\n            }\n            return db;\n        });\n    }\n\n    function awaitIterator(iterator) {\n        var callNext = function (result) { return iterator.next(result); }, doThrow = function (error) { return iterator.throw(error); }, onSuccess = step(callNext), onError = step(doThrow);\n        function step(getNext) {\n            return function (val) {\n                var next = getNext(val), value = next.value;\n                return next.done ? value :\n                    (!value || typeof value.then !== 'function' ?\n                        isArray(value) ? Promise.all(value).then(onSuccess, onError) : onSuccess(value) :\n                        value.then(onSuccess, onError));\n            };\n        }\n        return step(callNext)();\n    }\n\n    function extractTransactionArgs(mode, _tableArgs_, scopeFunc) {\n        var i = arguments.length;\n        if (i < 2)\n            throw new exceptions.InvalidArgument(\"Too few arguments\");\n        var args = new Array(i - 1);\n        while (--i)\n            args[i - 1] = arguments[i];\n        scopeFunc = args.pop();\n        var tables = flatten(args);\n        return [mode, tables, scopeFunc];\n    }\n    function enterTransactionScope(db, mode, storeNames, parentTransaction, scopeFunc) {\n        return DexiePromise.resolve().then(function () {\n            var transless = PSD.transless || PSD;\n            var trans = db._createTransaction(mode, storeNames, db._dbSchema, parentTransaction);\n            trans.explicit = true;\n            var zoneProps = {\n                trans: trans,\n                transless: transless\n            };\n            if (parentTransaction) {\n                trans.idbtrans = parentTransaction.idbtrans;\n            }\n            else {\n                try {\n                    trans.create();\n                    trans.idbtrans._explicit = true;\n                    db._state.PR1398_maxLoop = 3;\n                }\n                catch (ex) {\n                    if (ex.name === errnames.InvalidState && db.isOpen() && --db._state.PR1398_maxLoop > 0) {\n                        console.warn('Dexie: Need to reopen db');\n                        db.close({ disableAutoOpen: false });\n                        return db.open().then(function () { return enterTransactionScope(db, mode, storeNames, null, scopeFunc); });\n                    }\n                    return rejection(ex);\n                }\n            }\n            var scopeFuncIsAsync = isAsyncFunction(scopeFunc);\n            if (scopeFuncIsAsync) {\n                incrementExpectedAwaits();\n            }\n            var returnValue;\n            var promiseFollowed = DexiePromise.follow(function () {\n                returnValue = scopeFunc.call(trans, trans);\n                if (returnValue) {\n                    if (scopeFuncIsAsync) {\n                        var decrementor = decrementExpectedAwaits.bind(null, null);\n                        returnValue.then(decrementor, decrementor);\n                    }\n                    else if (typeof returnValue.next === 'function' && typeof returnValue.throw === 'function') {\n                        returnValue = awaitIterator(returnValue);\n                    }\n                }\n            }, zoneProps);\n            return (returnValue && typeof returnValue.then === 'function' ?\n                DexiePromise.resolve(returnValue).then(function (x) { return trans.active ?\n                    x\n                    : rejection(new exceptions.PrematureCommit(\"Transaction committed too early. See http://bit.ly/2kdckMn\")); })\n                : promiseFollowed.then(function () { return returnValue; })).then(function (x) {\n                if (parentTransaction)\n                    trans._resolve();\n                return trans._completion.then(function () { return x; });\n            }).catch(function (e) {\n                trans._reject(e);\n                return rejection(e);\n            });\n        });\n    }\n\n    function pad(a, value, count) {\n        var result = isArray(a) ? a.slice() : [a];\n        for (var i = 0; i < count; ++i)\n            result.push(value);\n        return result;\n    }\n    function createVirtualIndexMiddleware(down) {\n        return __assign(__assign({}, down), { table: function (tableName) {\n                var table = down.table(tableName);\n                var schema = table.schema;\n                var indexLookup = {};\n                var allVirtualIndexes = [];\n                function addVirtualIndexes(keyPath, keyTail, lowLevelIndex) {\n                    var keyPathAlias = getKeyPathAlias(keyPath);\n                    var indexList = (indexLookup[keyPathAlias] = indexLookup[keyPathAlias] || []);\n                    var keyLength = keyPath == null ? 0 : typeof keyPath === 'string' ? 1 : keyPath.length;\n                    var isVirtual = keyTail > 0;\n                    var virtualIndex = __assign(__assign({}, lowLevelIndex), { name: isVirtual\n                            ? \"\".concat(keyPathAlias, \"(virtual-from:\").concat(lowLevelIndex.name, \")\")\n                            : lowLevelIndex.name, lowLevelIndex: lowLevelIndex, isVirtual: isVirtual, keyTail: keyTail, keyLength: keyLength, extractKey: getKeyExtractor(keyPath), unique: !isVirtual && lowLevelIndex.unique });\n                    indexList.push(virtualIndex);\n                    if (!virtualIndex.isPrimaryKey) {\n                        allVirtualIndexes.push(virtualIndex);\n                    }\n                    if (keyLength > 1) {\n                        var virtualKeyPath = keyLength === 2 ?\n                            keyPath[0] :\n                            keyPath.slice(0, keyLength - 1);\n                        addVirtualIndexes(virtualKeyPath, keyTail + 1, lowLevelIndex);\n                    }\n                    indexList.sort(function (a, b) { return a.keyTail - b.keyTail; });\n                    return virtualIndex;\n                }\n                var primaryKey = addVirtualIndexes(schema.primaryKey.keyPath, 0, schema.primaryKey);\n                indexLookup[\":id\"] = [primaryKey];\n                for (var _i = 0, _a = schema.indexes; _i < _a.length; _i++) {\n                    var index = _a[_i];\n                    addVirtualIndexes(index.keyPath, 0, index);\n                }\n                function findBestIndex(keyPath) {\n                    var result = indexLookup[getKeyPathAlias(keyPath)];\n                    return result && result[0];\n                }\n                function translateRange(range, keyTail) {\n                    return {\n                        type: range.type === 1  ?\n                            2  :\n                            range.type,\n                        lower: pad(range.lower, range.lowerOpen ? down.MAX_KEY : down.MIN_KEY, keyTail),\n                        lowerOpen: true,\n                        upper: pad(range.upper, range.upperOpen ? down.MIN_KEY : down.MAX_KEY, keyTail),\n                        upperOpen: true\n                    };\n                }\n                function translateRequest(req) {\n                    var index = req.query.index;\n                    return index.isVirtual ? __assign(__assign({}, req), { query: {\n                            index: index.lowLevelIndex,\n                            range: translateRange(req.query.range, index.keyTail)\n                        } }) : req;\n                }\n                var result = __assign(__assign({}, table), { schema: __assign(__assign({}, schema), { primaryKey: primaryKey, indexes: allVirtualIndexes, getIndexByKeyPath: findBestIndex }), count: function (req) {\n                        return table.count(translateRequest(req));\n                    }, query: function (req) {\n                        return table.query(translateRequest(req));\n                    }, openCursor: function (req) {\n                        var _a = req.query.index, keyTail = _a.keyTail, isVirtual = _a.isVirtual, keyLength = _a.keyLength;\n                        if (!isVirtual)\n                            return table.openCursor(req);\n                        function createVirtualCursor(cursor) {\n                            function _continue(key) {\n                                key != null ?\n                                    cursor.continue(pad(key, req.reverse ? down.MAX_KEY : down.MIN_KEY, keyTail)) :\n                                    req.unique ?\n                                        cursor.continue(cursor.key.slice(0, keyLength)\n                                            .concat(req.reverse\n                                            ? down.MIN_KEY\n                                            : down.MAX_KEY, keyTail)) :\n                                        cursor.continue();\n                            }\n                            var virtualCursor = Object.create(cursor, {\n                                continue: { value: _continue },\n                                continuePrimaryKey: {\n                                    value: function (key, primaryKey) {\n                                        cursor.continuePrimaryKey(pad(key, down.MAX_KEY, keyTail), primaryKey);\n                                    }\n                                },\n                                primaryKey: {\n                                    get: function () {\n                                        return cursor.primaryKey;\n                                    }\n                                },\n                                key: {\n                                    get: function () {\n                                        var key = cursor.key;\n                                        return keyLength === 1 ?\n                                            key[0] :\n                                            key.slice(0, keyLength);\n                                    }\n                                },\n                                value: {\n                                    get: function () {\n                                        return cursor.value;\n                                    }\n                                }\n                            });\n                            return virtualCursor;\n                        }\n                        return table.openCursor(translateRequest(req))\n                            .then(function (cursor) { return cursor && createVirtualCursor(cursor); });\n                    } });\n                return result;\n            } });\n    }\n    var virtualIndexMiddleware = {\n        stack: \"dbcore\",\n        name: \"VirtualIndexMiddleware\",\n        level: 1,\n        create: createVirtualIndexMiddleware\n    };\n\n    function getObjectDiff(a, b, rv, prfx) {\n        rv = rv || {};\n        prfx = prfx || '';\n        keys(a).forEach(function (prop) {\n            if (!hasOwn(b, prop)) {\n                rv[prfx + prop] = undefined;\n            }\n            else {\n                var ap = a[prop], bp = b[prop];\n                if (typeof ap === 'object' && typeof bp === 'object' && ap && bp) {\n                    var apTypeName = toStringTag(ap);\n                    var bpTypeName = toStringTag(bp);\n                    if (apTypeName !== bpTypeName) {\n                        rv[prfx + prop] = b[prop];\n                    }\n                    else if (apTypeName === 'Object') {\n                        getObjectDiff(ap, bp, rv, prfx + prop + '.');\n                    }\n                    else if (ap !== bp) {\n                        rv[prfx + prop] = b[prop];\n                    }\n                }\n                else if (ap !== bp)\n                    rv[prfx + prop] = b[prop];\n            }\n        });\n        keys(b).forEach(function (prop) {\n            if (!hasOwn(a, prop)) {\n                rv[prfx + prop] = b[prop];\n            }\n        });\n        return rv;\n    }\n\n    function getEffectiveKeys(primaryKey, req) {\n        if (req.type === 'delete')\n            return req.keys;\n        return req.keys || req.values.map(primaryKey.extractKey);\n    }\n\n    var hooksMiddleware = {\n        stack: \"dbcore\",\n        name: \"HooksMiddleware\",\n        level: 2,\n        create: function (downCore) { return (__assign(__assign({}, downCore), { table: function (tableName) {\n                var downTable = downCore.table(tableName);\n                var primaryKey = downTable.schema.primaryKey;\n                var tableMiddleware = __assign(__assign({}, downTable), { mutate: function (req) {\n                        var dxTrans = PSD.trans;\n                        var _a = dxTrans.table(tableName).hook, deleting = _a.deleting, creating = _a.creating, updating = _a.updating;\n                        switch (req.type) {\n                            case 'add':\n                                if (creating.fire === nop)\n                                    break;\n                                return dxTrans._promise('readwrite', function () { return addPutOrDelete(req); }, true);\n                            case 'put':\n                                if (creating.fire === nop && updating.fire === nop)\n                                    break;\n                                return dxTrans._promise('readwrite', function () { return addPutOrDelete(req); }, true);\n                            case 'delete':\n                                if (deleting.fire === nop)\n                                    break;\n                                return dxTrans._promise('readwrite', function () { return addPutOrDelete(req); }, true);\n                            case 'deleteRange':\n                                if (deleting.fire === nop)\n                                    break;\n                                return dxTrans._promise('readwrite', function () { return deleteRange(req); }, true);\n                        }\n                        return downTable.mutate(req);\n                        function addPutOrDelete(req) {\n                            var dxTrans = PSD.trans;\n                            var keys = req.keys || getEffectiveKeys(primaryKey, req);\n                            if (!keys)\n                                throw new Error(\"Keys missing\");\n                            req = req.type === 'add' || req.type === 'put' ? __assign(__assign({}, req), { keys: keys }) : __assign({}, req);\n                            if (req.type !== 'delete')\n                                req.values = __spreadArray([], req.values, true);\n                            if (req.keys)\n                                req.keys = __spreadArray([], req.keys, true);\n                            return getExistingValues(downTable, req, keys).then(function (existingValues) {\n                                var contexts = keys.map(function (key, i) {\n                                    var existingValue = existingValues[i];\n                                    var ctx = { onerror: null, onsuccess: null };\n                                    if (req.type === 'delete') {\n                                        deleting.fire.call(ctx, key, existingValue, dxTrans);\n                                    }\n                                    else if (req.type === 'add' || existingValue === undefined) {\n                                        var generatedPrimaryKey = creating.fire.call(ctx, key, req.values[i], dxTrans);\n                                        if (key == null && generatedPrimaryKey != null) {\n                                            key = generatedPrimaryKey;\n                                            req.keys[i] = key;\n                                            if (!primaryKey.outbound) {\n                                                setByKeyPath(req.values[i], primaryKey.keyPath, key);\n                                            }\n                                        }\n                                    }\n                                    else {\n                                        var objectDiff = getObjectDiff(existingValue, req.values[i]);\n                                        var additionalChanges_1 = updating.fire.call(ctx, objectDiff, key, existingValue, dxTrans);\n                                        if (additionalChanges_1) {\n                                            var requestedValue_1 = req.values[i];\n                                            Object.keys(additionalChanges_1).forEach(function (keyPath) {\n                                                if (hasOwn(requestedValue_1, keyPath)) {\n                                                    requestedValue_1[keyPath] = additionalChanges_1[keyPath];\n                                                }\n                                                else {\n                                                    setByKeyPath(requestedValue_1, keyPath, additionalChanges_1[keyPath]);\n                                                }\n                                            });\n                                        }\n                                    }\n                                    return ctx;\n                                });\n                                return downTable.mutate(req).then(function (_a) {\n                                    var failures = _a.failures, results = _a.results, numFailures = _a.numFailures, lastResult = _a.lastResult;\n                                    for (var i = 0; i < keys.length; ++i) {\n                                        var primKey = results ? results[i] : keys[i];\n                                        var ctx = contexts[i];\n                                        if (primKey == null) {\n                                            ctx.onerror && ctx.onerror(failures[i]);\n                                        }\n                                        else {\n                                            ctx.onsuccess && ctx.onsuccess(req.type === 'put' && existingValues[i] ?\n                                                req.values[i] :\n                                                primKey\n                                            );\n                                        }\n                                    }\n                                    return { failures: failures, results: results, numFailures: numFailures, lastResult: lastResult };\n                                }).catch(function (error) {\n                                    contexts.forEach(function (ctx) { return ctx.onerror && ctx.onerror(error); });\n                                    return Promise.reject(error);\n                                });\n                            });\n                        }\n                        function deleteRange(req) {\n                            return deleteNextChunk(req.trans, req.range, 10000);\n                        }\n                        function deleteNextChunk(trans, range, limit) {\n                            return downTable.query({ trans: trans, values: false, query: { index: primaryKey, range: range }, limit: limit })\n                                .then(function (_a) {\n                                var result = _a.result;\n                                return addPutOrDelete({ type: 'delete', keys: result, trans: trans }).then(function (res) {\n                                    if (res.numFailures > 0)\n                                        return Promise.reject(res.failures[0]);\n                                    if (result.length < limit) {\n                                        return { failures: [], numFailures: 0, lastResult: undefined };\n                                    }\n                                    else {\n                                        return deleteNextChunk(trans, __assign(__assign({}, range), { lower: result[result.length - 1], lowerOpen: true }), limit);\n                                    }\n                                });\n                            });\n                        }\n                    } });\n                return tableMiddleware;\n            } })); }\n    };\n    function getExistingValues(table, req, effectiveKeys) {\n        return req.type === \"add\"\n            ? Promise.resolve([])\n            : table.getMany({ trans: req.trans, keys: effectiveKeys, cache: \"immutable\" });\n    }\n\n    function getFromTransactionCache(keys, cache, clone) {\n        try {\n            if (!cache)\n                return null;\n            if (cache.keys.length < keys.length)\n                return null;\n            var result = [];\n            for (var i = 0, j = 0; i < cache.keys.length && j < keys.length; ++i) {\n                if (cmp(cache.keys[i], keys[j]) !== 0)\n                    continue;\n                result.push(clone ? deepClone(cache.values[i]) : cache.values[i]);\n                ++j;\n            }\n            return result.length === keys.length ? result : null;\n        }\n        catch (_a) {\n            return null;\n        }\n    }\n    var cacheExistingValuesMiddleware = {\n        stack: \"dbcore\",\n        level: -1,\n        create: function (core) {\n            return {\n                table: function (tableName) {\n                    var table = core.table(tableName);\n                    return __assign(__assign({}, table), { getMany: function (req) {\n                            if (!req.cache) {\n                                return table.getMany(req);\n                            }\n                            var cachedResult = getFromTransactionCache(req.keys, req.trans[\"_cache\"], req.cache === \"clone\");\n                            if (cachedResult) {\n                                return DexiePromise.resolve(cachedResult);\n                            }\n                            return table.getMany(req).then(function (res) {\n                                req.trans[\"_cache\"] = {\n                                    keys: req.keys,\n                                    values: req.cache === \"clone\" ? deepClone(res) : res,\n                                };\n                                return res;\n                            });\n                        }, mutate: function (req) {\n                            if (req.type !== \"add\")\n                                req.trans[\"_cache\"] = null;\n                            return table.mutate(req);\n                        } });\n                },\n            };\n        },\n    };\n\n    function isCachableContext(ctx, table) {\n        return (ctx.trans.mode === 'readonly' &&\n            !!ctx.subscr &&\n            !ctx.trans.explicit &&\n            ctx.trans.db._options.cache !== 'disabled' &&\n            !table.schema.primaryKey.outbound);\n    }\n\n    function isCachableRequest(type, req) {\n        switch (type) {\n            case 'query':\n                return req.values && !req.unique;\n            case 'get':\n                return false;\n            case 'getMany':\n                return false;\n            case 'count':\n                return false;\n            case 'openCursor':\n                return false;\n        }\n    }\n\n    var observabilityMiddleware = {\n        stack: \"dbcore\",\n        level: 0,\n        name: \"Observability\",\n        create: function (core) {\n            var dbName = core.schema.name;\n            var FULL_RANGE = new RangeSet(core.MIN_KEY, core.MAX_KEY);\n            return __assign(__assign({}, core), { transaction: function (stores, mode, options) {\n                    if (PSD.subscr && mode !== 'readonly') {\n                        throw new exceptions.ReadOnly(\"Readwrite transaction in liveQuery context. Querier source: \".concat(PSD.querier));\n                    }\n                    return core.transaction(stores, mode, options);\n                }, table: function (tableName) {\n                    var table = core.table(tableName);\n                    var schema = table.schema;\n                    var primaryKey = schema.primaryKey, indexes = schema.indexes;\n                    var extractKey = primaryKey.extractKey, outbound = primaryKey.outbound;\n                    var indexesWithAutoIncPK = primaryKey.autoIncrement && indexes.filter(function (index) { return index.compound && index.keyPath.includes(primaryKey.keyPath); });\n                    var tableClone = __assign(__assign({}, table), { mutate: function (req) {\n                            var _a, _b;\n                            var trans = req.trans;\n                            var mutatedParts = req.mutatedParts || (req.mutatedParts = {});\n                            var getRangeSet = function (indexName) {\n                                var part = \"idb://\".concat(dbName, \"/\").concat(tableName, \"/\").concat(indexName);\n                                return (mutatedParts[part] ||\n                                    (mutatedParts[part] = new RangeSet()));\n                            };\n                            var pkRangeSet = getRangeSet(\"\");\n                            var delsRangeSet = getRangeSet(\":dels\");\n                            var type = req.type;\n                            var _c = req.type === \"deleteRange\"\n                                ? [req.range]\n                                : req.type === \"delete\"\n                                    ? [req.keys]\n                                    : req.values.length < 50\n                                        ? [getEffectiveKeys(primaryKey, req).filter(function (id) { return id; }), req.values]\n                                        : [], keys = _c[0], newObjs = _c[1];\n                            var oldCache = req.trans[\"_cache\"];\n                            if (isArray(keys)) {\n                                pkRangeSet.addKeys(keys);\n                                var oldObjs = type === 'delete' || keys.length === newObjs.length ? getFromTransactionCache(keys, oldCache) : null;\n                                if (!oldObjs) {\n                                    delsRangeSet.addKeys(keys);\n                                }\n                                if (oldObjs || newObjs) {\n                                    trackAffectedIndexes(getRangeSet, schema, oldObjs, newObjs);\n                                }\n                            }\n                            else if (keys) {\n                                var range = {\n                                    from: (_a = keys.lower) !== null && _a !== void 0 ? _a : core.MIN_KEY,\n                                    to: (_b = keys.upper) !== null && _b !== void 0 ? _b : core.MAX_KEY\n                                };\n                                delsRangeSet.add(range);\n                                pkRangeSet.add(range);\n                            }\n                            else {\n                                pkRangeSet.add(FULL_RANGE);\n                                delsRangeSet.add(FULL_RANGE);\n                                schema.indexes.forEach(function (idx) { return getRangeSet(idx.name).add(FULL_RANGE); });\n                            }\n                            return table.mutate(req).then(function (res) {\n                                if (keys && (req.type === 'add' || req.type === 'put')) {\n                                    pkRangeSet.addKeys(res.results);\n                                    if (indexesWithAutoIncPK) {\n                                        indexesWithAutoIncPK.forEach(function (idx) {\n                                            var idxVals = req.values.map(function (v) { return idx.extractKey(v); });\n                                            var pkPos = idx.keyPath.findIndex(function (prop) { return prop === primaryKey.keyPath; });\n                                            for (var i = 0, len = res.results.length; i < len; ++i) {\n                                                idxVals[i][pkPos] = res.results[i];\n                                            }\n                                            getRangeSet(idx.name).addKeys(idxVals);\n                                        });\n                                    }\n                                }\n                                trans.mutatedParts = extendObservabilitySet(trans.mutatedParts || {}, mutatedParts);\n                                return res;\n                            });\n                        } });\n                    var getRange = function (_a) {\n                        var _b, _c;\n                        var _d = _a.query, index = _d.index, range = _d.range;\n                        return [\n                            index,\n                            new RangeSet((_b = range.lower) !== null && _b !== void 0 ? _b : core.MIN_KEY, (_c = range.upper) !== null && _c !== void 0 ? _c : core.MAX_KEY),\n                        ];\n                    };\n                    var readSubscribers = {\n                        get: function (req) { return [primaryKey, new RangeSet(req.key)]; },\n                        getMany: function (req) { return [primaryKey, new RangeSet().addKeys(req.keys)]; },\n                        count: getRange,\n                        query: getRange,\n                        openCursor: getRange,\n                    };\n                    keys(readSubscribers).forEach(function (method) {\n                        tableClone[method] = function (req) {\n                            var subscr = PSD.subscr;\n                            var isLiveQuery = !!subscr;\n                            var cachable = isCachableContext(PSD, table) && isCachableRequest(method, req);\n                            var obsSet = cachable\n                                ? req.obsSet = {}\n                                : subscr;\n                            if (isLiveQuery) {\n                                var getRangeSet = function (indexName) {\n                                    var part = \"idb://\".concat(dbName, \"/\").concat(tableName, \"/\").concat(indexName);\n                                    return (obsSet[part] ||\n                                        (obsSet[part] = new RangeSet()));\n                                };\n                                var pkRangeSet_1 = getRangeSet(\"\");\n                                var delsRangeSet_1 = getRangeSet(\":dels\");\n                                var _a = readSubscribers[method](req), queriedIndex = _a[0], queriedRanges = _a[1];\n                                if (method === 'query' && queriedIndex.isPrimaryKey && !req.values) {\n                                    delsRangeSet_1.add(queriedRanges);\n                                }\n                                else {\n                                    getRangeSet(queriedIndex.name || \"\").add(queriedRanges);\n                                }\n                                if (!queriedIndex.isPrimaryKey) {\n                                    if (method === \"count\") {\n                                        delsRangeSet_1.add(FULL_RANGE);\n                                    }\n                                    else {\n                                        var keysPromise_1 = method === \"query\" &&\n                                            outbound &&\n                                            req.values &&\n                                            table.query(__assign(__assign({}, req), { values: false }));\n                                        return table[method].apply(this, arguments).then(function (res) {\n                                            if (method === \"query\") {\n                                                if (outbound && req.values) {\n                                                    return keysPromise_1.then(function (_a) {\n                                                        var resultingKeys = _a.result;\n                                                        pkRangeSet_1.addKeys(resultingKeys);\n                                                        return res;\n                                                    });\n                                                }\n                                                var pKeys = req.values\n                                                    ? res.result.map(extractKey)\n                                                    : res.result;\n                                                if (req.values) {\n                                                    pkRangeSet_1.addKeys(pKeys);\n                                                }\n                                                else {\n                                                    delsRangeSet_1.addKeys(pKeys);\n                                                }\n                                            }\n                                            else if (method === \"openCursor\") {\n                                                var cursor_1 = res;\n                                                var wantValues_1 = req.values;\n                                                return (cursor_1 &&\n                                                    Object.create(cursor_1, {\n                                                        key: {\n                                                            get: function () {\n                                                                delsRangeSet_1.addKey(cursor_1.primaryKey);\n                                                                return cursor_1.key;\n                                                            },\n                                                        },\n                                                        primaryKey: {\n                                                            get: function () {\n                                                                var pkey = cursor_1.primaryKey;\n                                                                delsRangeSet_1.addKey(pkey);\n                                                                return pkey;\n                                                            },\n                                                        },\n                                                        value: {\n                                                            get: function () {\n                                                                wantValues_1 && pkRangeSet_1.addKey(cursor_1.primaryKey);\n                                                                return cursor_1.value;\n                                                            },\n                                                        },\n                                                    }));\n                                            }\n                                            return res;\n                                        });\n                                    }\n                                }\n                            }\n                            return table[method].apply(this, arguments);\n                        };\n                    });\n                    return tableClone;\n                } });\n        },\n    };\n    function trackAffectedIndexes(getRangeSet, schema, oldObjs, newObjs) {\n        function addAffectedIndex(ix) {\n            var rangeSet = getRangeSet(ix.name || \"\");\n            function extractKey(obj) {\n                return obj != null ? ix.extractKey(obj) : null;\n            }\n            var addKeyOrKeys = function (key) { return ix.multiEntry && isArray(key)\n                ? key.forEach(function (key) { return rangeSet.addKey(key); })\n                : rangeSet.addKey(key); };\n            (oldObjs || newObjs).forEach(function (_, i) {\n                var oldKey = oldObjs && extractKey(oldObjs[i]);\n                var newKey = newObjs && extractKey(newObjs[i]);\n                if (cmp(oldKey, newKey) !== 0) {\n                    if (oldKey != null)\n                        addKeyOrKeys(oldKey);\n                    if (newKey != null)\n                        addKeyOrKeys(newKey);\n                }\n            });\n        }\n        schema.indexes.forEach(addAffectedIndex);\n    }\n\n    function adjustOptimisticFromFailures(tblCache, req, res) {\n        if (res.numFailures === 0)\n            return req;\n        if (req.type === 'deleteRange') {\n            return null;\n        }\n        var numBulkOps = req.keys\n            ? req.keys.length\n            : 'values' in req && req.values\n                ? req.values.length\n                : 1;\n        if (res.numFailures === numBulkOps) {\n            return null;\n        }\n        var clone = __assign({}, req);\n        if (isArray(clone.keys)) {\n            clone.keys = clone.keys.filter(function (_, i) { return !(i in res.failures); });\n        }\n        if ('values' in clone && isArray(clone.values)) {\n            clone.values = clone.values.filter(function (_, i) { return !(i in res.failures); });\n        }\n        return clone;\n    }\n\n    function isAboveLower(key, range) {\n        return range.lower === undefined\n            ? true\n            : range.lowerOpen\n                ? cmp(key, range.lower) > 0\n                : cmp(key, range.lower) >= 0;\n    }\n    function isBelowUpper(key, range) {\n        return range.upper === undefined\n            ? true\n            : range.upperOpen\n                ? cmp(key, range.upper) < 0\n                : cmp(key, range.upper) <= 0;\n    }\n    function isWithinRange(key, range) {\n        return isAboveLower(key, range) && isBelowUpper(key, range);\n    }\n\n    function applyOptimisticOps(result, req, ops, table, cacheEntry, immutable) {\n        if (!ops || ops.length === 0)\n            return result;\n        var index = req.query.index;\n        var multiEntry = index.multiEntry;\n        var queryRange = req.query.range;\n        var primaryKey = table.schema.primaryKey;\n        var extractPrimKey = primaryKey.extractKey;\n        var extractIndex = index.extractKey;\n        var extractLowLevelIndex = (index.lowLevelIndex || index).extractKey;\n        var finalResult = ops.reduce(function (result, op) {\n            var modifedResult = result;\n            var includedValues = [];\n            if (op.type === 'add' || op.type === 'put') {\n                var includedPKs = new RangeSet();\n                for (var i = op.values.length - 1; i >= 0; --i) {\n                    var value = op.values[i];\n                    var pk = extractPrimKey(value);\n                    if (includedPKs.hasKey(pk))\n                        continue;\n                    var key = extractIndex(value);\n                    if (multiEntry && isArray(key)\n                        ? key.some(function (k) { return isWithinRange(k, queryRange); })\n                        : isWithinRange(key, queryRange)) {\n                        includedPKs.addKey(pk);\n                        includedValues.push(value);\n                    }\n                }\n            }\n            switch (op.type) {\n                case 'add': {\n                    var existingKeys_1 = new RangeSet().addKeys(req.values ? result.map(function (v) { return extractPrimKey(v); }) : result);\n                    modifedResult = result.concat(req.values\n                        ? includedValues.filter(function (v) {\n                            var key = extractPrimKey(v);\n                            if (existingKeys_1.hasKey(key))\n                                return false;\n                            existingKeys_1.addKey(key);\n                            return true;\n                        })\n                        : includedValues\n                            .map(function (v) { return extractPrimKey(v); })\n                            .filter(function (k) {\n                            if (existingKeys_1.hasKey(k))\n                                return false;\n                            existingKeys_1.addKey(k);\n                            return true;\n                        }));\n                    break;\n                }\n                case 'put': {\n                    var keySet_1 = new RangeSet().addKeys(op.values.map(function (v) { return extractPrimKey(v); }));\n                    modifedResult = result\n                        .filter(\n                    function (item) { return !keySet_1.hasKey(req.values ? extractPrimKey(item) : item); })\n                        .concat(\n                    req.values\n                        ? includedValues\n                        : includedValues.map(function (v) { return extractPrimKey(v); }));\n                    break;\n                }\n                case 'delete':\n                    var keysToDelete_1 = new RangeSet().addKeys(op.keys);\n                    modifedResult = result.filter(function (item) {\n                        return !keysToDelete_1.hasKey(req.values ? extractPrimKey(item) : item);\n                    });\n                    break;\n                case 'deleteRange':\n                    var range_1 = op.range;\n                    modifedResult = result.filter(function (item) { return !isWithinRange(extractPrimKey(item), range_1); });\n                    break;\n            }\n            return modifedResult;\n        }, result);\n        if (finalResult === result)\n            return result;\n        finalResult.sort(function (a, b) {\n            return cmp(extractLowLevelIndex(a), extractLowLevelIndex(b)) ||\n                cmp(extractPrimKey(a), extractPrimKey(b));\n        });\n        if (req.limit && req.limit < Infinity) {\n            if (finalResult.length > req.limit) {\n                finalResult.length = req.limit;\n            }\n            else if (result.length === req.limit && finalResult.length < req.limit) {\n                cacheEntry.dirty = true;\n            }\n        }\n        return immutable ? Object.freeze(finalResult) : finalResult;\n    }\n\n    function areRangesEqual(r1, r2) {\n        return (cmp(r1.lower, r2.lower) === 0 &&\n            cmp(r1.upper, r2.upper) === 0 &&\n            !!r1.lowerOpen === !!r2.lowerOpen &&\n            !!r1.upperOpen === !!r2.upperOpen);\n    }\n\n    function compareLowers(lower1, lower2, lowerOpen1, lowerOpen2) {\n        if (lower1 === undefined)\n            return lower2 !== undefined ? -1 : 0;\n        if (lower2 === undefined)\n            return 1;\n        var c = cmp(lower1, lower2);\n        if (c === 0) {\n            if (lowerOpen1 && lowerOpen2)\n                return 0;\n            if (lowerOpen1)\n                return 1;\n            if (lowerOpen2)\n                return -1;\n        }\n        return c;\n    }\n    function compareUppers(upper1, upper2, upperOpen1, upperOpen2) {\n        if (upper1 === undefined)\n            return upper2 !== undefined ? 1 : 0;\n        if (upper2 === undefined)\n            return -1;\n        var c = cmp(upper1, upper2);\n        if (c === 0) {\n            if (upperOpen1 && upperOpen2)\n                return 0;\n            if (upperOpen1)\n                return -1;\n            if (upperOpen2)\n                return 1;\n        }\n        return c;\n    }\n    function isSuperRange(r1, r2) {\n        return (compareLowers(r1.lower, r2.lower, r1.lowerOpen, r2.lowerOpen) <= 0 &&\n            compareUppers(r1.upper, r2.upper, r1.upperOpen, r2.upperOpen) >= 0);\n    }\n\n    function findCompatibleQuery(dbName, tableName, type, req) {\n        var tblCache = cache[\"idb://\".concat(dbName, \"/\").concat(tableName)];\n        if (!tblCache)\n            return [];\n        var queries = tblCache.queries[type];\n        if (!queries)\n            return [null, false, tblCache, null];\n        var indexName = req.query ? req.query.index.name : null;\n        var entries = queries[indexName || ''];\n        if (!entries)\n            return [null, false, tblCache, null];\n        switch (type) {\n            case 'query':\n                var equalEntry = entries.find(function (entry) {\n                    return entry.req.limit === req.limit &&\n                        entry.req.values === req.values &&\n                        areRangesEqual(entry.req.query.range, req.query.range);\n                });\n                if (equalEntry)\n                    return [\n                        equalEntry,\n                        true,\n                        tblCache,\n                        entries,\n                    ];\n                var superEntry = entries.find(function (entry) {\n                    var limit = 'limit' in entry.req ? entry.req.limit : Infinity;\n                    return (limit >= req.limit &&\n                        (req.values ? entry.req.values : true) &&\n                        isSuperRange(entry.req.query.range, req.query.range));\n                });\n                return [superEntry, false, tblCache, entries];\n            case 'count':\n                var countQuery = entries.find(function (entry) {\n                    return areRangesEqual(entry.req.query.range, req.query.range);\n                });\n                return [countQuery, !!countQuery, tblCache, entries];\n        }\n    }\n\n    function subscribeToCacheEntry(cacheEntry, container, requery, signal) {\n        cacheEntry.subscribers.add(requery);\n        signal.addEventListener(\"abort\", function () {\n            cacheEntry.subscribers.delete(requery);\n            if (cacheEntry.subscribers.size === 0) {\n                enqueForDeletion(cacheEntry, container);\n            }\n        });\n    }\n    function enqueForDeletion(cacheEntry, container) {\n        setTimeout(function () {\n            if (cacheEntry.subscribers.size === 0) {\n                delArrayItem(container, cacheEntry);\n            }\n        }, 3000);\n    }\n\n    var cacheMiddleware = {\n        stack: 'dbcore',\n        level: 0,\n        name: 'Cache',\n        create: function (core) {\n            var dbName = core.schema.name;\n            var coreMW = __assign(__assign({}, core), { transaction: function (stores, mode, options) {\n                    var idbtrans = core.transaction(stores, mode, options);\n                    if (mode === 'readwrite') {\n                        var ac_1 = new AbortController();\n                        var signal = ac_1.signal;\n                        var endTransaction = function (wasCommitted) { return function () {\n                            ac_1.abort();\n                            if (mode === 'readwrite') {\n                                var affectedSubscribers_1 = new Set();\n                                for (var _i = 0, stores_1 = stores; _i < stores_1.length; _i++) {\n                                    var storeName = stores_1[_i];\n                                    var tblCache = cache[\"idb://\".concat(dbName, \"/\").concat(storeName)];\n                                    if (tblCache) {\n                                        var table = core.table(storeName);\n                                        var ops = tblCache.optimisticOps.filter(function (op) { return op.trans === idbtrans; });\n                                        if (idbtrans._explicit && wasCommitted && idbtrans.mutatedParts) {\n                                            for (var _a = 0, _b = Object.values(tblCache.queries.query); _a < _b.length; _a++) {\n                                                var entries = _b[_a];\n                                                for (var _c = 0, _d = entries.slice(); _c < _d.length; _c++) {\n                                                    var entry = _d[_c];\n                                                    if (obsSetsOverlap(entry.obsSet, idbtrans.mutatedParts)) {\n                                                        delArrayItem(entries, entry);\n                                                        entry.subscribers.forEach(function (requery) { return affectedSubscribers_1.add(requery); });\n                                                    }\n                                                }\n                                            }\n                                        }\n                                        else if (ops.length > 0) {\n                                            tblCache.optimisticOps = tblCache.optimisticOps.filter(function (op) { return op.trans !== idbtrans; });\n                                            for (var _e = 0, _f = Object.values(tblCache.queries.query); _e < _f.length; _e++) {\n                                                var entries = _f[_e];\n                                                for (var _g = 0, _h = entries.slice(); _g < _h.length; _g++) {\n                                                    var entry = _h[_g];\n                                                    if (entry.res != null &&\n                                                        idbtrans.mutatedParts\n    ) {\n                                                        if (wasCommitted && !entry.dirty) {\n                                                            var freezeResults = Object.isFrozen(entry.res);\n                                                            var modRes = applyOptimisticOps(entry.res, entry.req, ops, table, entry, freezeResults);\n                                                            if (entry.dirty) {\n                                                                delArrayItem(entries, entry);\n                                                                entry.subscribers.forEach(function (requery) { return affectedSubscribers_1.add(requery); });\n                                                            }\n                                                            else if (modRes !== entry.res) {\n                                                                entry.res = modRes;\n                                                                entry.promise = DexiePromise.resolve({ result: modRes });\n                                                            }\n                                                        }\n                                                        else {\n                                                            if (entry.dirty) {\n                                                                delArrayItem(entries, entry);\n                                                            }\n                                                            entry.subscribers.forEach(function (requery) { return affectedSubscribers_1.add(requery); });\n                                                        }\n                                                    }\n                                                }\n                                            }\n                                        }\n                                    }\n                                }\n                                affectedSubscribers_1.forEach(function (requery) { return requery(); });\n                            }\n                        }; };\n                        idbtrans.addEventListener('abort', endTransaction(false), {\n                            signal: signal,\n                        });\n                        idbtrans.addEventListener('error', endTransaction(false), {\n                            signal: signal,\n                        });\n                        idbtrans.addEventListener('complete', endTransaction(true), {\n                            signal: signal,\n                        });\n                    }\n                    return idbtrans;\n                }, table: function (tableName) {\n                    var downTable = core.table(tableName);\n                    var primKey = downTable.schema.primaryKey;\n                    var tableMW = __assign(__assign({}, downTable), { mutate: function (req) {\n                            var trans = PSD.trans;\n                            if (primKey.outbound ||\n                                trans.db._options.cache === 'disabled' ||\n                                trans.explicit ||\n                                trans.idbtrans.mode !== 'readwrite'\n                            ) {\n                                return downTable.mutate(req);\n                            }\n                            var tblCache = cache[\"idb://\".concat(dbName, \"/\").concat(tableName)];\n                            if (!tblCache)\n                                return downTable.mutate(req);\n                            var promise = downTable.mutate(req);\n                            if ((req.type === 'add' || req.type === 'put') && (req.values.length >= 50 || getEffectiveKeys(primKey, req).some(function (key) { return key == null; }))) {\n                                promise.then(function (res) {\n                                    var reqWithResolvedKeys = __assign(__assign({}, req), { values: req.values.map(function (value, i) {\n                                            var _a;\n                                            if (res.failures[i])\n                                                return value;\n                                            var valueWithKey = ((_a = primKey.keyPath) === null || _a === void 0 ? void 0 : _a.includes('.'))\n                                                ? deepClone(value)\n                                                : __assign({}, value);\n                                            setByKeyPath(valueWithKey, primKey.keyPath, res.results[i]);\n                                            return valueWithKey;\n                                        }) });\n                                    var adjustedReq = adjustOptimisticFromFailures(tblCache, reqWithResolvedKeys, res);\n                                    tblCache.optimisticOps.push(adjustedReq);\n                                    queueMicrotask(function () { return req.mutatedParts && signalSubscribersLazily(req.mutatedParts); });\n                                });\n                            }\n                            else {\n                                tblCache.optimisticOps.push(req);\n                                req.mutatedParts && signalSubscribersLazily(req.mutatedParts);\n                                promise.then(function (res) {\n                                    if (res.numFailures > 0) {\n                                        delArrayItem(tblCache.optimisticOps, req);\n                                        var adjustedReq = adjustOptimisticFromFailures(tblCache, req, res);\n                                        if (adjustedReq) {\n                                            tblCache.optimisticOps.push(adjustedReq);\n                                        }\n                                        req.mutatedParts && signalSubscribersLazily(req.mutatedParts);\n                                    }\n                                });\n                                promise.catch(function () {\n                                    delArrayItem(tblCache.optimisticOps, req);\n                                    req.mutatedParts && signalSubscribersLazily(req.mutatedParts);\n                                });\n                            }\n                            return promise;\n                        }, query: function (req) {\n                            var _a;\n                            if (!isCachableContext(PSD, downTable) || !isCachableRequest(\"query\", req))\n                                return downTable.query(req);\n                            var freezeResults = ((_a = PSD.trans) === null || _a === void 0 ? void 0 : _a.db._options.cache) === 'immutable';\n                            var _b = PSD, requery = _b.requery, signal = _b.signal;\n                            var _c = findCompatibleQuery(dbName, tableName, 'query', req), cacheEntry = _c[0], exactMatch = _c[1], tblCache = _c[2], container = _c[3];\n                            if (cacheEntry && exactMatch) {\n                                cacheEntry.obsSet = req.obsSet;\n                            }\n                            else {\n                                var promise = downTable.query(req).then(function (res) {\n                                    var result = res.result;\n                                    if (cacheEntry)\n                                        cacheEntry.res = result;\n                                    if (freezeResults) {\n                                        for (var i = 0, l = result.length; i < l; ++i) {\n                                            Object.freeze(result[i]);\n                                        }\n                                        Object.freeze(result);\n                                    }\n                                    else {\n                                        res.result = deepClone(result);\n                                    }\n                                    return res;\n                                }).catch(function (error) {\n                                    if (container && cacheEntry)\n                                        delArrayItem(container, cacheEntry);\n                                    return Promise.reject(error);\n                                });\n                                cacheEntry = {\n                                    obsSet: req.obsSet,\n                                    promise: promise,\n                                    subscribers: new Set(),\n                                    type: 'query',\n                                    req: req,\n                                    dirty: false,\n                                };\n                                if (container) {\n                                    container.push(cacheEntry);\n                                }\n                                else {\n                                    container = [cacheEntry];\n                                    if (!tblCache) {\n                                        tblCache = cache[\"idb://\".concat(dbName, \"/\").concat(tableName)] = {\n                                            queries: {\n                                                query: {},\n                                                count: {},\n                                            },\n                                            objs: new Map(),\n                                            optimisticOps: [],\n                                            unsignaledParts: {}\n                                        };\n                                    }\n                                    tblCache.queries.query[req.query.index.name || ''] = container;\n                                }\n                            }\n                            subscribeToCacheEntry(cacheEntry, container, requery, signal);\n                            return cacheEntry.promise.then(function (res) {\n                                return {\n                                    result: applyOptimisticOps(res.result, req, tblCache === null || tblCache === void 0 ? void 0 : tblCache.optimisticOps, downTable, cacheEntry, freezeResults),\n                                };\n                            });\n                        } });\n                    return tableMW;\n                } });\n            return coreMW;\n        },\n    };\n\n    function vipify(target, vipDb) {\n        return new Proxy(target, {\n            get: function (target, prop, receiver) {\n                if (prop === 'db')\n                    return vipDb;\n                return Reflect.get(target, prop, receiver);\n            }\n        });\n    }\n\n    var Dexie$1 =  (function () {\n        function Dexie(name, options) {\n            var _this = this;\n            this._middlewares = {};\n            this.verno = 0;\n            var deps = Dexie.dependencies;\n            this._options = options = __assign({\n                addons: Dexie.addons, autoOpen: true,\n                indexedDB: deps.indexedDB, IDBKeyRange: deps.IDBKeyRange, cache: 'cloned' }, options);\n            this._deps = {\n                indexedDB: options.indexedDB,\n                IDBKeyRange: options.IDBKeyRange\n            };\n            var addons = options.addons;\n            this._dbSchema = {};\n            this._versions = [];\n            this._storeNames = [];\n            this._allTables = {};\n            this.idbdb = null;\n            this._novip = this;\n            var state = {\n                dbOpenError: null,\n                isBeingOpened: false,\n                onReadyBeingFired: null,\n                openComplete: false,\n                dbReadyResolve: nop,\n                dbReadyPromise: null,\n                cancelOpen: nop,\n                openCanceller: null,\n                autoSchema: true,\n                PR1398_maxLoop: 3,\n                autoOpen: options.autoOpen,\n            };\n            state.dbReadyPromise = new DexiePromise(function (resolve) {\n                state.dbReadyResolve = resolve;\n            });\n            state.openCanceller = new DexiePromise(function (_, reject) {\n                state.cancelOpen = reject;\n            });\n            this._state = state;\n            this.name = name;\n            this.on = Events(this, \"populate\", \"blocked\", \"versionchange\", \"close\", { ready: [promisableChain, nop] });\n            this.on.ready.subscribe = override(this.on.ready.subscribe, function (subscribe) {\n                return function (subscriber, bSticky) {\n                    Dexie.vip(function () {\n                        var state = _this._state;\n                        if (state.openComplete) {\n                            if (!state.dbOpenError)\n                                DexiePromise.resolve().then(subscriber);\n                            if (bSticky)\n                                subscribe(subscriber);\n                        }\n                        else if (state.onReadyBeingFired) {\n                            state.onReadyBeingFired.push(subscriber);\n                            if (bSticky)\n                                subscribe(subscriber);\n                        }\n                        else {\n                            subscribe(subscriber);\n                            var db_1 = _this;\n                            if (!bSticky)\n                                subscribe(function unsubscribe() {\n                                    db_1.on.ready.unsubscribe(subscriber);\n                                    db_1.on.ready.unsubscribe(unsubscribe);\n                                });\n                        }\n                    });\n                };\n            });\n            this.Collection = createCollectionConstructor(this);\n            this.Table = createTableConstructor(this);\n            this.Transaction = createTransactionConstructor(this);\n            this.Version = createVersionConstructor(this);\n            this.WhereClause = createWhereClauseConstructor(this);\n            this.on(\"versionchange\", function (ev) {\n                if (ev.newVersion > 0)\n                    console.warn(\"Another connection wants to upgrade database '\".concat(_this.name, \"'. Closing db now to resume the upgrade.\"));\n                else\n                    console.warn(\"Another connection wants to delete database '\".concat(_this.name, \"'. Closing db now to resume the delete request.\"));\n                _this.close({ disableAutoOpen: false });\n            });\n            this.on(\"blocked\", function (ev) {\n                if (!ev.newVersion || ev.newVersion < ev.oldVersion)\n                    console.warn(\"Dexie.delete('\".concat(_this.name, \"') was blocked\"));\n                else\n                    console.warn(\"Upgrade '\".concat(_this.name, \"' blocked by other connection holding version \").concat(ev.oldVersion / 10));\n            });\n            this._maxKey = getMaxKey(options.IDBKeyRange);\n            this._createTransaction = function (mode, storeNames, dbschema, parentTransaction) { return new _this.Transaction(mode, storeNames, dbschema, _this._options.chromeTransactionDurability, parentTransaction); };\n            this._fireOnBlocked = function (ev) {\n                _this.on(\"blocked\").fire(ev);\n                connections\n                    .filter(function (c) { return c.name === _this.name && c !== _this && !c._state.vcFired; })\n                    .map(function (c) { return c.on(\"versionchange\").fire(ev); });\n            };\n            this.use(cacheExistingValuesMiddleware);\n            this.use(cacheMiddleware);\n            this.use(observabilityMiddleware);\n            this.use(virtualIndexMiddleware);\n            this.use(hooksMiddleware);\n            var vipDB = new Proxy(this, {\n                get: function (_, prop, receiver) {\n                    if (prop === '_vip')\n                        return true;\n                    if (prop === 'table')\n                        return function (tableName) { return vipify(_this.table(tableName), vipDB); };\n                    var rv = Reflect.get(_, prop, receiver);\n                    if (rv instanceof Table)\n                        return vipify(rv, vipDB);\n                    if (prop === 'tables')\n                        return rv.map(function (t) { return vipify(t, vipDB); });\n                    if (prop === '_createTransaction')\n                        return function () {\n                            var tx = rv.apply(this, arguments);\n                            return vipify(tx, vipDB);\n                        };\n                    return rv;\n                }\n            });\n            this.vip = vipDB;\n            addons.forEach(function (addon) { return addon(_this); });\n        }\n        Dexie.prototype.version = function (versionNumber) {\n            if (isNaN(versionNumber) || versionNumber < 0.1)\n                throw new exceptions.Type(\"Given version is not a positive number\");\n            versionNumber = Math.round(versionNumber * 10) / 10;\n            if (this.idbdb || this._state.isBeingOpened)\n                throw new exceptions.Schema(\"Cannot add version when database is open\");\n            this.verno = Math.max(this.verno, versionNumber);\n            var versions = this._versions;\n            var versionInstance = versions.filter(function (v) { return v._cfg.version === versionNumber; })[0];\n            if (versionInstance)\n                return versionInstance;\n            versionInstance = new this.Version(versionNumber);\n            versions.push(versionInstance);\n            versions.sort(lowerVersionFirst);\n            versionInstance.stores({});\n            this._state.autoSchema = false;\n            return versionInstance;\n        };\n        Dexie.prototype._whenReady = function (fn) {\n            var _this = this;\n            return (this.idbdb && (this._state.openComplete || PSD.letThrough || this._vip)) ? fn() : new DexiePromise(function (resolve, reject) {\n                if (_this._state.openComplete) {\n                    return reject(new exceptions.DatabaseClosed(_this._state.dbOpenError));\n                }\n                if (!_this._state.isBeingOpened) {\n                    if (!_this._state.autoOpen) {\n                        reject(new exceptions.DatabaseClosed());\n                        return;\n                    }\n                    _this.open().catch(nop);\n                }\n                _this._state.dbReadyPromise.then(resolve, reject);\n            }).then(fn);\n        };\n        Dexie.prototype.use = function (_a) {\n            var stack = _a.stack, create = _a.create, level = _a.level, name = _a.name;\n            if (name)\n                this.unuse({ stack: stack, name: name });\n            var middlewares = this._middlewares[stack] || (this._middlewares[stack] = []);\n            middlewares.push({ stack: stack, create: create, level: level == null ? 10 : level, name: name });\n            middlewares.sort(function (a, b) { return a.level - b.level; });\n            return this;\n        };\n        Dexie.prototype.unuse = function (_a) {\n            var stack = _a.stack, name = _a.name, create = _a.create;\n            if (stack && this._middlewares[stack]) {\n                this._middlewares[stack] = this._middlewares[stack].filter(function (mw) {\n                    return create ? mw.create !== create :\n                        name ? mw.name !== name :\n                            false;\n                });\n            }\n            return this;\n        };\n        Dexie.prototype.open = function () {\n            var _this = this;\n            return usePSD(globalPSD,\n            function () { return dexieOpen(_this); });\n        };\n        Dexie.prototype._close = function () {\n            var state = this._state;\n            var idx = connections.indexOf(this);\n            if (idx >= 0)\n                connections.splice(idx, 1);\n            if (this.idbdb) {\n                try {\n                    this.idbdb.close();\n                }\n                catch (e) { }\n                this.idbdb = null;\n            }\n            if (!state.isBeingOpened) {\n                state.dbReadyPromise = new DexiePromise(function (resolve) {\n                    state.dbReadyResolve = resolve;\n                });\n                state.openCanceller = new DexiePromise(function (_, reject) {\n                    state.cancelOpen = reject;\n                });\n            }\n        };\n        Dexie.prototype.close = function (_a) {\n            var _b = _a === void 0 ? { disableAutoOpen: true } : _a, disableAutoOpen = _b.disableAutoOpen;\n            var state = this._state;\n            if (disableAutoOpen) {\n                if (state.isBeingOpened) {\n                    state.cancelOpen(new exceptions.DatabaseClosed());\n                }\n                this._close();\n                state.autoOpen = false;\n                state.dbOpenError = new exceptions.DatabaseClosed();\n            }\n            else {\n                this._close();\n                state.autoOpen = this._options.autoOpen ||\n                    state.isBeingOpened;\n                state.openComplete = false;\n                state.dbOpenError = null;\n            }\n        };\n        Dexie.prototype.delete = function (closeOptions) {\n            var _this = this;\n            if (closeOptions === void 0) { closeOptions = { disableAutoOpen: true }; }\n            var hasInvalidArguments = arguments.length > 0 && typeof arguments[0] !== 'object';\n            var state = this._state;\n            return new DexiePromise(function (resolve, reject) {\n                var doDelete = function () {\n                    _this.close(closeOptions);\n                    var req = _this._deps.indexedDB.deleteDatabase(_this.name);\n                    req.onsuccess = wrap(function () {\n                        _onDatabaseDeleted(_this._deps, _this.name);\n                        resolve();\n                    });\n                    req.onerror = eventRejectHandler(reject);\n                    req.onblocked = _this._fireOnBlocked;\n                };\n                if (hasInvalidArguments)\n                    throw new exceptions.InvalidArgument(\"Invalid closeOptions argument to db.delete()\");\n                if (state.isBeingOpened) {\n                    state.dbReadyPromise.then(doDelete);\n                }\n                else {\n                    doDelete();\n                }\n            });\n        };\n        Dexie.prototype.backendDB = function () {\n            return this.idbdb;\n        };\n        Dexie.prototype.isOpen = function () {\n            return this.idbdb !== null;\n        };\n        Dexie.prototype.hasBeenClosed = function () {\n            var dbOpenError = this._state.dbOpenError;\n            return dbOpenError && (dbOpenError.name === 'DatabaseClosed');\n        };\n        Dexie.prototype.hasFailed = function () {\n            return this._state.dbOpenError !== null;\n        };\n        Dexie.prototype.dynamicallyOpened = function () {\n            return this._state.autoSchema;\n        };\n        Object.defineProperty(Dexie.prototype, \"tables\", {\n            get: function () {\n                var _this = this;\n                return keys(this._allTables).map(function (name) { return _this._allTables[name]; });\n            },\n            enumerable: false,\n            configurable: true\n        });\n        Dexie.prototype.transaction = function () {\n            var args = extractTransactionArgs.apply(this, arguments);\n            return this._transaction.apply(this, args);\n        };\n        Dexie.prototype._transaction = function (mode, tables, scopeFunc) {\n            var _this = this;\n            var parentTransaction = PSD.trans;\n            if (!parentTransaction || parentTransaction.db !== this || mode.indexOf('!') !== -1)\n                parentTransaction = null;\n            var onlyIfCompatible = mode.indexOf('?') !== -1;\n            mode = mode.replace('!', '').replace('?', '');\n            var idbMode, storeNames;\n            try {\n                storeNames = tables.map(function (table) {\n                    var storeName = table instanceof _this.Table ? table.name : table;\n                    if (typeof storeName !== 'string')\n                        throw new TypeError(\"Invalid table argument to Dexie.transaction(). Only Table or String are allowed\");\n                    return storeName;\n                });\n                if (mode == \"r\" || mode === READONLY)\n                    idbMode = READONLY;\n                else if (mode == \"rw\" || mode == READWRITE)\n                    idbMode = READWRITE;\n                else\n                    throw new exceptions.InvalidArgument(\"Invalid transaction mode: \" + mode);\n                if (parentTransaction) {\n                    if (parentTransaction.mode === READONLY && idbMode === READWRITE) {\n                        if (onlyIfCompatible) {\n                            parentTransaction = null;\n                        }\n                        else\n                            throw new exceptions.SubTransaction(\"Cannot enter a sub-transaction with READWRITE mode when parent transaction is READONLY\");\n                    }\n                    if (parentTransaction) {\n                        storeNames.forEach(function (storeName) {\n                            if (parentTransaction && parentTransaction.storeNames.indexOf(storeName) === -1) {\n                                if (onlyIfCompatible) {\n                                    parentTransaction = null;\n                                }\n                                else\n                                    throw new exceptions.SubTransaction(\"Table \" + storeName +\n                                        \" not included in parent transaction.\");\n                            }\n                        });\n                    }\n                    if (onlyIfCompatible && parentTransaction && !parentTransaction.active) {\n                        parentTransaction = null;\n                    }\n                }\n            }\n            catch (e) {\n                return parentTransaction ?\n                    parentTransaction._promise(null, function (_, reject) { reject(e); }) :\n                    rejection(e);\n            }\n            var enterTransaction = enterTransactionScope.bind(null, this, idbMode, storeNames, parentTransaction, scopeFunc);\n            return (parentTransaction ?\n                parentTransaction._promise(idbMode, enterTransaction, \"lock\") :\n                PSD.trans ?\n                    usePSD(PSD.transless, function () { return _this._whenReady(enterTransaction); }) :\n                    this._whenReady(enterTransaction));\n        };\n        Dexie.prototype.table = function (tableName) {\n            if (!hasOwn(this._allTables, tableName)) {\n                throw new exceptions.InvalidTable(\"Table \".concat(tableName, \" does not exist\"));\n            }\n            return this._allTables[tableName];\n        };\n        return Dexie;\n    }());\n\n    var symbolObservable = typeof Symbol !== \"undefined\" && \"observable\" in Symbol\n        ? Symbol.observable\n        : \"@@observable\";\n    var Observable =  (function () {\n        function Observable(subscribe) {\n            this._subscribe = subscribe;\n        }\n        Observable.prototype.subscribe = function (x, error, complete) {\n            return this._subscribe(!x || typeof x === \"function\" ? { next: x, error: error, complete: complete } : x);\n        };\n        Observable.prototype[symbolObservable] = function () {\n            return this;\n        };\n        return Observable;\n    }());\n\n    var domDeps;\n    try {\n        domDeps = {\n            indexedDB: _global.indexedDB || _global.mozIndexedDB || _global.webkitIndexedDB || _global.msIndexedDB,\n            IDBKeyRange: _global.IDBKeyRange || _global.webkitIDBKeyRange\n        };\n    }\n    catch (e) {\n        domDeps = { indexedDB: null, IDBKeyRange: null };\n    }\n\n    function liveQuery(querier) {\n        var hasValue = false;\n        var currentValue;\n        var observable = new Observable(function (observer) {\n            var scopeFuncIsAsync = isAsyncFunction(querier);\n            function execute(ctx) {\n                var wasRootExec = beginMicroTickScope();\n                try {\n                    if (scopeFuncIsAsync) {\n                        incrementExpectedAwaits();\n                    }\n                    var rv = newScope(querier, ctx);\n                    if (scopeFuncIsAsync) {\n                        rv = rv.finally(decrementExpectedAwaits);\n                    }\n                    return rv;\n                }\n                finally {\n                    wasRootExec && endMicroTickScope();\n                }\n            }\n            var closed = false;\n            var abortController;\n            var accumMuts = {};\n            var currentObs = {};\n            var subscription = {\n                get closed() {\n                    return closed;\n                },\n                unsubscribe: function () {\n                    if (closed)\n                        return;\n                    closed = true;\n                    if (abortController)\n                        abortController.abort();\n                    if (startedListening)\n                        globalEvents.storagemutated.unsubscribe(mutationListener);\n                },\n            };\n            observer.start && observer.start(subscription);\n            var startedListening = false;\n            var doQuery = function () { return execInGlobalContext(_doQuery); };\n            function shouldNotify() {\n                return obsSetsOverlap(currentObs, accumMuts);\n            }\n            var mutationListener = function (parts) {\n                extendObservabilitySet(accumMuts, parts);\n                if (shouldNotify()) {\n                    doQuery();\n                }\n            };\n            var _doQuery = function () {\n                if (closed ||\n                    !domDeps.indexedDB)\n                 {\n                    return;\n                }\n                accumMuts = {};\n                var subscr = {};\n                if (abortController)\n                    abortController.abort();\n                abortController = new AbortController();\n                var ctx = {\n                    subscr: subscr,\n                    signal: abortController.signal,\n                    requery: doQuery,\n                    querier: querier,\n                    trans: null\n                };\n                var ret = execute(ctx);\n                Promise.resolve(ret).then(function (result) {\n                    hasValue = true;\n                    currentValue = result;\n                    if (closed || ctx.signal.aborted) {\n                        return;\n                    }\n                    accumMuts = {};\n                    currentObs = subscr;\n                    if (!objectIsEmpty(currentObs) && !startedListening) {\n                        globalEvents(DEXIE_STORAGE_MUTATED_EVENT_NAME, mutationListener);\n                        startedListening = true;\n                    }\n                    execInGlobalContext(function () { return !closed && observer.next && observer.next(result); });\n                }, function (err) {\n                    hasValue = false;\n                    if (!['DatabaseClosedError', 'AbortError'].includes(err === null || err === void 0 ? void 0 : err.name)) {\n                        if (!closed)\n                            execInGlobalContext(function () {\n                                if (closed)\n                                    return;\n                                observer.error && observer.error(err);\n                            });\n                    }\n                });\n            };\n            setTimeout(doQuery, 0);\n            return subscription;\n        });\n        observable.hasValue = function () { return hasValue; };\n        observable.getValue = function () { return currentValue; };\n        return observable;\n    }\n\n    var Dexie = Dexie$1;\n    props(Dexie, __assign(__assign({}, fullNameExceptions), {\n        delete: function (databaseName) {\n            var db = new Dexie(databaseName, { addons: [] });\n            return db.delete();\n        },\n        exists: function (name) {\n            return new Dexie(name, { addons: [] }).open().then(function (db) {\n                db.close();\n                return true;\n            }).catch('NoSuchDatabaseError', function () { return false; });\n        },\n        getDatabaseNames: function (cb) {\n            try {\n                return getDatabaseNames(Dexie.dependencies).then(cb);\n            }\n            catch (_a) {\n                return rejection(new exceptions.MissingAPI());\n            }\n        },\n        defineClass: function () {\n            function Class(content) {\n                extend(this, content);\n            }\n            return Class;\n        }, ignoreTransaction: function (scopeFunc) {\n            return PSD.trans ?\n                usePSD(PSD.transless, scopeFunc) :\n                scopeFunc();\n        }, vip: vip, async: function (generatorFn) {\n            return function () {\n                try {\n                    var rv = awaitIterator(generatorFn.apply(this, arguments));\n                    if (!rv || typeof rv.then !== 'function')\n                        return DexiePromise.resolve(rv);\n                    return rv;\n                }\n                catch (e) {\n                    return rejection(e);\n                }\n            };\n        }, spawn: function (generatorFn, args, thiz) {\n            try {\n                var rv = awaitIterator(generatorFn.apply(thiz, args || []));\n                if (!rv || typeof rv.then !== 'function')\n                    return DexiePromise.resolve(rv);\n                return rv;\n            }\n            catch (e) {\n                return rejection(e);\n            }\n        },\n        currentTransaction: {\n            get: function () { return PSD.trans || null; }\n        }, waitFor: function (promiseOrFunction, optionalTimeout) {\n            var promise = DexiePromise.resolve(typeof promiseOrFunction === 'function' ?\n                Dexie.ignoreTransaction(promiseOrFunction) :\n                promiseOrFunction)\n                .timeout(optionalTimeout || 60000);\n            return PSD.trans ?\n                PSD.trans.waitFor(promise) :\n                promise;\n        },\n        Promise: DexiePromise,\n        debug: {\n            get: function () { return debug; },\n            set: function (value) {\n                setDebug(value);\n            }\n        },\n        derive: derive, extend: extend, props: props, override: override,\n        Events: Events, on: globalEvents, liveQuery: liveQuery, extendObservabilitySet: extendObservabilitySet,\n        getByKeyPath: getByKeyPath, setByKeyPath: setByKeyPath, delByKeyPath: delByKeyPath, shallowClone: shallowClone, deepClone: deepClone, getObjectDiff: getObjectDiff, cmp: cmp, asap: asap$1,\n        minKey: minKey,\n        addons: [],\n        connections: connections,\n        errnames: errnames,\n        dependencies: domDeps, cache: cache,\n        semVer: DEXIE_VERSION, version: DEXIE_VERSION.split('.')\n            .map(function (n) { return parseInt(n); })\n            .reduce(function (p, c, i) { return p + (c / Math.pow(10, i * 2)); }) }));\n    Dexie.maxKey = getMaxKey(Dexie.dependencies.IDBKeyRange);\n\n    if (typeof dispatchEvent !== 'undefined' && typeof addEventListener !== 'undefined') {\n        globalEvents(DEXIE_STORAGE_MUTATED_EVENT_NAME, function (updatedParts) {\n            if (!propagatingLocally) {\n                var event_1;\n                event_1 = new CustomEvent(STORAGE_MUTATED_DOM_EVENT_NAME, {\n                    detail: updatedParts\n                });\n                propagatingLocally = true;\n                dispatchEvent(event_1);\n                propagatingLocally = false;\n            }\n        });\n        addEventListener(STORAGE_MUTATED_DOM_EVENT_NAME, function (_a) {\n            var detail = _a.detail;\n            if (!propagatingLocally) {\n                propagateLocally(detail);\n            }\n        });\n    }\n    function propagateLocally(updateParts) {\n        var wasMe = propagatingLocally;\n        try {\n            propagatingLocally = true;\n            globalEvents.storagemutated.fire(updateParts);\n            signalSubscribersNow(updateParts, true);\n        }\n        finally {\n            propagatingLocally = wasMe;\n        }\n    }\n    var propagatingLocally = false;\n\n    var bc;\n    var createBC = function () { };\n    if (typeof BroadcastChannel !== 'undefined') {\n        createBC = function () {\n            bc = new BroadcastChannel(STORAGE_MUTATED_DOM_EVENT_NAME);\n            bc.onmessage = function (ev) { return ev.data && propagateLocally(ev.data); };\n        };\n        createBC();\n        if (typeof bc.unref === 'function') {\n            bc.unref();\n        }\n        globalEvents(DEXIE_STORAGE_MUTATED_EVENT_NAME, function (changedParts) {\n            if (!propagatingLocally) {\n                bc.postMessage(changedParts);\n            }\n        });\n    }\n\n    if (typeof addEventListener !== 'undefined') {\n        addEventListener('pagehide', function (event) {\n            if (!Dexie$1.disableBfCache && event.persisted) {\n                if (debug)\n                    console.debug('Dexie: handling persisted pagehide');\n                bc === null || bc === void 0 ? void 0 : bc.close();\n                for (var _i = 0, connections_1 = connections; _i < connections_1.length; _i++) {\n                    var db = connections_1[_i];\n                    db.close({ disableAutoOpen: false });\n                }\n            }\n        });\n        addEventListener('pageshow', function (event) {\n            if (!Dexie$1.disableBfCache && event.persisted) {\n                if (debug)\n                    console.debug('Dexie: handling persisted pageshow');\n                createBC();\n                propagateLocally({ all: new RangeSet(-Infinity, [[]]) });\n            }\n        });\n    }\n\n    function add(value) {\n        return new PropModification({ add: value });\n    }\n\n    function remove(value) {\n        return new PropModification({ remove: value });\n    }\n\n    function replacePrefix(a, b) {\n        return new PropModification({ replacePrefix: [a, b] });\n    }\n\n    DexiePromise.rejectionMapper = mapError;\n    setDebug(debug);\n\n    var namedExports = /*#__PURE__*/Object.freeze({\n        __proto__: null,\n        Dexie: Dexie$1,\n        liveQuery: liveQuery,\n        Entity: Entity,\n        cmp: cmp,\n        PropModSymbol: PropModSymbol,\n        PropModification: PropModification,\n        replacePrefix: replacePrefix,\n        add: add,\n        remove: remove,\n        'default': Dexie$1,\n        RangeSet: RangeSet,\n        mergeRanges: mergeRanges,\n        rangesOverlap: rangesOverlap\n    });\n\n    __assign(Dexie$1, namedExports, { default: Dexie$1 });\n\n    return Dexie$1;\n\n}));\n//# sourceMappingURL=dexie.js.map\n","// Making the module version consumable via require - to prohibit\n// multiple occurrancies of the same module in the same app\n// (dual package hazard, https://nodejs.org/api/packages.html#dual-package-hazard)\nimport _Dexie from \"./dist/dexie.js\";\nconst DexieSymbol = Symbol.for(\"Dexie\");\nconst Dexie = globalThis[DexieSymbol] || (globalThis[DexieSymbol] = _Dexie);\nif (_Dexie.semVer !== Dexie.semVer) {\n    throw new Error(`Two different versions of Dexie loaded in the same app: ${_Dexie.semVer} and ${Dexie.semVer}`);\n}\nconst { liveQuery, mergeRanges, rangesOverlap, RangeSet, cmp, Entity,\n    PropModSymbol, PropModification, replacePrefix, add, remove } = Dexie;\nexport { liveQuery, mergeRanges, rangesOverlap, RangeSet, cmp, Dexie, Entity,\n    PropModSymbol, PropModification, replacePrefix, add, remove };\nexport default Dexie;\n","import { pushAtSortPosition } from 'array-push-at-sort-position';\nexport const doNothing = (_input) => { };\nexport const insertFirst = (input) => {\n    input.previousResults.unshift(input.changeEvent.doc);\n    if (input.keyDocumentMap) {\n        input.keyDocumentMap.set(input.changeEvent.id, input.changeEvent.doc);\n    }\n};\nexport const insertLast = (input) => {\n    input.previousResults.push(input.changeEvent.doc);\n    if (input.keyDocumentMap) {\n        input.keyDocumentMap.set(input.changeEvent.id, input.changeEvent.doc);\n    }\n};\nexport const removeFirstItem = (input) => {\n    const first = input.previousResults.shift();\n    if (input.keyDocumentMap && first) {\n        input.keyDocumentMap.delete(first[input.queryParams.primaryKey]);\n    }\n};\nexport const removeLastItem = (input) => {\n    const last = input.previousResults.pop();\n    if (input.keyDocumentMap && last) {\n        input.keyDocumentMap.delete(last[input.queryParams.primaryKey]);\n    }\n};\nexport const removeFirstInsertLast = (input) => {\n    removeFirstItem(input);\n    insertLast(input);\n};\nexport const removeLastInsertFirst = (input) => {\n    removeLastItem(input);\n    insertFirst(input);\n};\nexport const removeFirstInsertFirst = (input) => {\n    removeFirstItem(input);\n    insertFirst(input);\n};\nexport const removeLastInsertLast = (input) => {\n    removeLastItem(input);\n    insertLast(input);\n};\nexport const removeExisting = (input) => {\n    if (input.keyDocumentMap) {\n        input.keyDocumentMap.delete(input.changeEvent.id);\n    }\n    // find index of document\n    const primary = input.queryParams.primaryKey;\n    const results = input.previousResults;\n    for (let i = 0; i < results.length; i++) {\n        const item = results[i];\n        // remove\n        if (item[primary] === input.changeEvent.id) {\n            results.splice(i, 1);\n            break;\n        }\n    }\n};\nexport const replaceExisting = (input) => {\n    // find index of document\n    const doc = input.changeEvent.doc;\n    const primary = input.queryParams.primaryKey;\n    const results = input.previousResults;\n    for (let i = 0; i < results.length; i++) {\n        const item = results[i];\n        // replace\n        if (item[primary] === input.changeEvent.id) {\n            results[i] = doc;\n            if (input.keyDocumentMap) {\n                input.keyDocumentMap.set(input.changeEvent.id, doc);\n            }\n            break;\n        }\n    }\n};\n/**\n * this function always returns wrong results\n * it must be later optimised out\n * otherwise there is something broken\n */\nexport const alwaysWrong = (input) => {\n    const wrongHuman = {\n        _id: 'wrongHuman' + new Date().getTime()\n    };\n    input.previousResults.length = 0; // clear array\n    input.previousResults.push(wrongHuman);\n    if (input.keyDocumentMap) {\n        input.keyDocumentMap.clear();\n        input.keyDocumentMap.set(wrongHuman._id, wrongHuman);\n    }\n};\nexport const insertAtSortPosition = (input) => {\n    const docId = input.changeEvent.id;\n    const doc = input.changeEvent.doc;\n    if (input.keyDocumentMap) {\n        if (input.keyDocumentMap.has(docId)) {\n            /**\n             * If document is already in results,\n             * we cannot add it again because it would throw on non-deterministic ordering.\n             */\n            return;\n        }\n        input.keyDocumentMap.set(docId, doc);\n    }\n    else {\n        const isDocInResults = input.previousResults.find((d) => d[input.queryParams.primaryKey] === docId);\n        /**\n         * If document is already in results,\n         * we cannot add it again because it would throw on non-deterministic ordering.\n         */\n        if (isDocInResults) {\n            return;\n        }\n    }\n    pushAtSortPosition(input.previousResults, doc, input.queryParams.sortComparator, 0);\n};\nexport const removeExistingAndInsertAtSortPosition = (input) => {\n    removeExisting(input);\n    insertAtSortPosition(input);\n};\nexport const runFullQueryAgain = (_input) => {\n    throw new Error('Action runFullQueryAgain must be implemented by yourself');\n};\nexport const unknownAction = (_input) => {\n    throw new Error('Action unknownAction should never be called');\n};\n//# sourceMappingURL=action-functions.js.map","import { doNothing, insertFirst, insertLast, removeFirstItem, removeLastItem, removeFirstInsertLast, removeLastInsertFirst, removeExisting, replaceExisting, alwaysWrong, insertAtSortPosition, removeExistingAndInsertAtSortPosition, runFullQueryAgain, unknownAction, removeFirstInsertFirst, removeLastInsertLast } from './action-functions.js';\nexport * from './action-functions.js';\n/**\n * all actions ordered by performance-cost\n * cheapest first\n * TODO run tests on which is really the fastest\n */\nexport const orderedActionList = [\n    'doNothing',\n    'insertFirst',\n    'insertLast',\n    'removeFirstItem',\n    'removeLastItem',\n    'removeFirstInsertLast',\n    'removeLastInsertFirst',\n    'removeFirstInsertFirst',\n    'removeLastInsertLast',\n    'removeExisting',\n    'replaceExisting',\n    'alwaysWrong',\n    'insertAtSortPosition',\n    'removeExistingAndInsertAtSortPosition',\n    'runFullQueryAgain',\n    'unknownAction'\n];\nexport const actionFunctions = {\n    doNothing,\n    insertFirst,\n    insertLast,\n    removeFirstItem,\n    removeLastItem,\n    removeFirstInsertLast,\n    removeLastInsertFirst,\n    removeFirstInsertFirst,\n    removeLastInsertLast,\n    removeExisting,\n    replaceExisting,\n    alwaysWrong,\n    insertAtSortPosition,\n    removeExistingAndInsertAtSortPosition,\n    runFullQueryAgain,\n    unknownAction\n};\n//# sourceMappingURL=index.js.map","import { minimalStringToSimpleBdd, resolveWithSimpleBdd } from 'binary-decision-diagram';\nimport { stateResolveFunctionByIndex } from '../states/index.js';\nexport const minimalBddString = '14a1b,c+d2e5f0g/h.i4j*k-l)m(n6oeh6pnm6qen6ril6snh6tin6ubo9vce9wmh9xns9yne9zmi9{cm9|ad9}cp9~aq9ae9¡bf9¢bq9£cg9¤ck9¥cn9¦nd9§np9¨nq9©nf9ªng9«nm9¬nk9­mr9®ms9¯mt9°mj9±mk9²ml9³mn9´mc8µ³{8¶¯}8·°¤8¸³§8¹mn8º³«8»³m8¼m´4½z²4¾³w4¿zµ4À¯¶4Á°·4Â³º4Ã³¸4Äm¹4Åv¤7Æyn7ÇÀÁ7È~7É¥¤7ÊÃÄ7Ë¨n7Ìº¹7Í­°7Î®m7Ï¯°7Ð±m7Ñ³m7Ò¼m5ÓÄm5Ô¹m5Õ½°5Ö¾m5×¿°5ØÇÏ5ÙÂm5ÚÊÑ5Û±m5Üºm5ÝÌÑ5ÞÕÍ2ß|2à¡u2á£Å2âÖÎ2ã¦Æ2ä©x2åªÆ2æ×Ø2ç|È2è¡¢2é£É2ê¤¥2ëÙÚ2ì¦Ë2í©n2îªn2ïÛÐ2ðÜÝ2ñ¬n2òÒÓ/óan/ôbn/õcn/öÞâ/÷ßã/øàä/ùáå/úæë/ûçì/üèí/ýéî/þÍÎ/ÿÏÑ/ĀòÔ,ācn,Ăöï,ă¤ñ,Ąúð,ąêñ,ĆþÐ,ćÿÑ,Ĉac0ĉbc0Ċóõ0ċôā0Čßá0čà¤0Ďçé0ďèê0Đ÷ù0đøă0Ēûý0ēüą0ĔmÒ-ĕmĀ-ĖÞæ-ėČĎ-Ęčď-ęĂĄ-ĚĐĒ-ěđē-Ĝ²»-ĝÍÏ-ĞĆć-ğ²³-ĠĔĈ3ġĕĊ3ĢĖė3ģęĚ3ĤĢĝ(ĥĜğ(ĦģĞ(ħĠġ+Ĩĉċ+ĩĤĦ+ĪĘě+īħĨ1ĬĩĪ1ĭĬī*Įĥm*ĭĮ.';\nlet simpleBdd;\nexport function getSimpleBdd() {\n    if (!simpleBdd) {\n        simpleBdd = minimalStringToSimpleBdd(minimalBddString);\n    }\n    return simpleBdd;\n}\nexport const resolveInput = (input) => {\n    return resolveWithSimpleBdd(getSimpleBdd(), stateResolveFunctionByIndex, input);\n};\n//# sourceMappingURL=bdd.generated.js.map","import { getStateSet } from './states/index.js';\nimport { actionFunctions, orderedActionList } from './actions/index.js';\nimport { resolveInput } from './bdd/bdd.generated.js';\nexport * from './states/index.js';\nexport * from './util.js';\nexport * from './actions/index.js';\nexport function calculateActionFromMap(stateSetToActionMap, input) {\n    const stateSet = getStateSet(input);\n    const actionName = stateSetToActionMap.get(stateSet);\n    if (!actionName) {\n        return {\n            action: 'runFullQueryAgain',\n            stateSet\n        };\n    }\n    else {\n        return {\n            action: actionName,\n            stateSet\n        };\n    }\n}\nexport function calculateActionName(input) {\n    const resolvedActionId = resolveInput(input);\n    return orderedActionList[resolvedActionId];\n}\nexport function calculateActionFunction(input) {\n    const actionName = calculateActionName(input);\n    return actionFunctions[actionName];\n}\n/**\n * for performance reasons,\n * @mutates the input\n * @returns the new results\n */\nexport function runAction(action, queryParams, changeEvent, previousResults, keyDocumentMap) {\n    const fn = actionFunctions[action];\n    fn({\n        queryParams,\n        changeEvent,\n        previousResults,\n        keyDocumentMap\n    });\n    return previousResults;\n}\n//# sourceMappingURL=index.js.map","import { hasLimit, isFindOne, hasSkip, wasResultsEmpty, isDelete, isInsert, isUpdate, wasLimitReached, sortParamsChanged, wasInResult, wasFirst, wasLast, wasSortedBeforeFirst, wasSortedAfterLast, isSortedBeforeFirst, isSortedAfterLast, wasMatching, doesMatchNow } from './state-resolver.js';\nexport * from './state-resolver.js';\n/**\n * all states ordered by performance-cost\n * cheapest first\n * TODO run tests on which is really the fastest\n */\nexport const orderedStateList = [\n    'isInsert',\n    'isUpdate',\n    'isDelete',\n    'hasLimit',\n    'isFindOne',\n    'hasSkip',\n    'wasResultsEmpty',\n    'wasLimitReached',\n    'wasFirst',\n    'wasLast',\n    'sortParamsChanged',\n    'wasInResult',\n    'wasSortedBeforeFirst',\n    'wasSortedAfterLast',\n    'isSortedBeforeFirst',\n    'isSortedAfterLast',\n    'wasMatching',\n    'doesMatchNow'\n];\nexport const stateResolveFunctions = {\n    isInsert,\n    isUpdate,\n    isDelete,\n    hasLimit,\n    isFindOne,\n    hasSkip,\n    wasResultsEmpty,\n    wasLimitReached,\n    wasFirst,\n    wasLast,\n    sortParamsChanged,\n    wasInResult,\n    wasSortedBeforeFirst,\n    wasSortedAfterLast,\n    isSortedBeforeFirst,\n    isSortedAfterLast,\n    wasMatching,\n    doesMatchNow\n};\nexport const stateResolveFunctionByIndex = {\n    0: isInsert,\n    1: isUpdate,\n    2: isDelete,\n    3: hasLimit,\n    4: isFindOne,\n    5: hasSkip,\n    6: wasResultsEmpty,\n    7: wasLimitReached,\n    8: wasFirst,\n    9: wasLast,\n    10: sortParamsChanged,\n    11: wasInResult,\n    12: wasSortedBeforeFirst,\n    13: wasSortedAfterLast,\n    14: isSortedBeforeFirst,\n    15: isSortedAfterLast,\n    16: wasMatching,\n    17: doesMatchNow\n};\nexport function resolveState(stateName, input) {\n    const fn = stateResolveFunctions[stateName];\n    if (!fn) {\n        throw new Error('resolveState() has no function for ' + stateName);\n    }\n    return fn(input);\n}\nexport function getStateSet(input) {\n    let set = '';\n    for (let i = 0; i < orderedStateList.length; i++) {\n        const name = orderedStateList[i];\n        const value = resolveState(name, input);\n        const add = value ? '1' : '0';\n        set += add;\n    }\n    return set;\n}\nexport function logStateSet(stateSet) {\n    orderedStateList.forEach((state, index) => {\n        console.log('state: ' + state + ' : ' + stateSet[index]);\n    });\n}\n//# sourceMappingURL=index.js.map","import { getProperty, lastOfArray } from '../util.js';\nexport const hasLimit = (input) => {\n    return !!input.queryParams.limit;\n};\nexport const isFindOne = (input) => {\n    return input.queryParams.limit === 1;\n};\nexport const hasSkip = (input) => {\n    if (input.queryParams.skip && input.queryParams.skip > 0) {\n        return true;\n    }\n    else {\n        return false;\n    }\n};\nexport const isDelete = (input) => {\n    return input.changeEvent.operation === 'DELETE';\n};\nexport const isInsert = (input) => {\n    return input.changeEvent.operation === 'INSERT';\n};\nexport const isUpdate = (input) => {\n    return input.changeEvent.operation === 'UPDATE';\n};\nexport const wasLimitReached = (input) => {\n    return hasLimit(input) && input.previousResults.length >= input.queryParams.limit;\n};\nexport const sortParamsChanged = (input) => {\n    const sortFields = input.queryParams.sortFields;\n    const prev = input.changeEvent.previous;\n    const doc = input.changeEvent.doc;\n    if (!doc) {\n        return false;\n    }\n    if (!prev) {\n        return true;\n    }\n    for (let i = 0; i < sortFields.length; i++) {\n        const field = sortFields[i];\n        const beforeData = getProperty(prev, field);\n        const afterData = getProperty(doc, field);\n        if (beforeData !== afterData) {\n            return true;\n        }\n    }\n    return false;\n};\nexport const wasInResult = (input) => {\n    const id = input.changeEvent.id;\n    if (input.keyDocumentMap) {\n        const has = input.keyDocumentMap.has(id);\n        return has;\n    }\n    else {\n        const primary = input.queryParams.primaryKey;\n        const results = input.previousResults;\n        for (let i = 0; i < results.length; i++) {\n            const item = results[i];\n            if (item[primary] === id) {\n                return true;\n            }\n        }\n        return false;\n    }\n};\nexport const wasFirst = (input) => {\n    const first = input.previousResults[0];\n    if (first && first[input.queryParams.primaryKey] === input.changeEvent.id) {\n        return true;\n    }\n    else {\n        return false;\n    }\n};\nexport const wasLast = (input) => {\n    const last = lastOfArray(input.previousResults);\n    if (last && last[input.queryParams.primaryKey] === input.changeEvent.id) {\n        return true;\n    }\n    else {\n        return false;\n    }\n};\nexport const wasSortedBeforeFirst = (input) => {\n    const prev = input.changeEvent.previous;\n    if (!prev) {\n        return false;\n    }\n    const first = input.previousResults[0];\n    if (!first) {\n        return false;\n    }\n    /**\n     * If the changed document is the same as the first,\n     * we cannot sort-compare them, because it might end in a non-deterministic\n     * sort order. Because both document could be equal.\n     * So instead we have to return true.\n     */\n    if (first[input.queryParams.primaryKey] === input.changeEvent.id) {\n        return true;\n    }\n    const comp = input.queryParams.sortComparator(prev, first);\n    return comp < 0;\n};\nexport const wasSortedAfterLast = (input) => {\n    const prev = input.changeEvent.previous;\n    if (!prev) {\n        return false;\n    }\n    const last = lastOfArray(input.previousResults);\n    if (!last) {\n        return false;\n    }\n    if (last[input.queryParams.primaryKey] === input.changeEvent.id) {\n        return true;\n    }\n    const comp = input.queryParams.sortComparator(prev, last);\n    return comp > 0;\n};\nexport const isSortedBeforeFirst = (input) => {\n    const doc = input.changeEvent.doc;\n    if (!doc) {\n        return false;\n    }\n    const first = input.previousResults[0];\n    if (!first) {\n        return false;\n    }\n    if (first[input.queryParams.primaryKey] === input.changeEvent.id) {\n        return true;\n    }\n    const comp = input.queryParams.sortComparator(doc, first);\n    return comp < 0;\n};\nexport const isSortedAfterLast = (input) => {\n    const doc = input.changeEvent.doc;\n    if (!doc) {\n        return false;\n    }\n    const last = lastOfArray(input.previousResults);\n    if (!last) {\n        return false;\n    }\n    if (last[input.queryParams.primaryKey] === input.changeEvent.id) {\n        return true;\n    }\n    const comp = input.queryParams.sortComparator(doc, last);\n    return comp > 0;\n};\nexport const wasMatching = (input) => {\n    const prev = input.changeEvent.previous;\n    if (!prev) {\n        return false;\n    }\n    return input.queryParams.queryMatcher(prev);\n};\nexport const doesMatchNow = (input) => {\n    const doc = input.changeEvent.doc;\n    if (!doc) {\n        return false;\n    }\n    const ret = input.queryParams.queryMatcher(doc);\n    return ret;\n};\nexport const wasResultsEmpty = (input) => {\n    return input.previousResults.length === 0;\n};\n//# sourceMappingURL=state-resolver.js.map","export function lastOfArray(ar) {\n    return ar[ar.length - 1];\n}\n/**\n * @link https://stackoverflow.com/a/5915122\n */\nexport function randomOfArray(items) {\n    return items[Math.floor(Math.random() * items.length)];\n}\nexport function shuffleArray(arr) {\n    return arr.slice().sort(() => (Math.random() - 0.5));\n}\n/**\n * normalizes sort-field\n * in: '-age'\n * out: 'age'\n */\nexport function normalizeSortField(field) {\n    if (field.startsWith('-')) {\n        return field.substr(1);\n    }\n    else {\n        return field;\n    }\n}\nexport function getSortFieldsOfQuery(query) {\n    if (!query.sort) {\n        // if no sort-order is set, use the primary key\n        return ['_id'];\n    }\n    return query.sort.map(maybeArray => {\n        if (Array.isArray(maybeArray)) {\n            return maybeArray[0].map((field) => normalizeSortField(field));\n        }\n        else {\n            return normalizeSortField(maybeArray);\n        }\n    });\n}\n/**\n *  @link https://stackoverflow.com/a/1431113\n */\nexport function replaceCharAt(str, index, replacement) {\n    return str.substr(0, index) + replacement + str.substr(index + replacement.length);\n}\nexport function mapToObject(map) {\n    const ret = {};\n    map.forEach((value, key) => {\n        ret[key] = value;\n    });\n    return ret;\n}\nexport function objectToMap(object) {\n    const ret = new Map();\n    Object.entries(object).forEach(([k, v]) => {\n        ret.set(k, v);\n    });\n    return ret;\n}\nexport function cloneMap(map) {\n    const ret = new Map();\n    map.forEach((value, key) => {\n        ret[key] = value;\n    });\n    return ret;\n}\n/**\n * does a flat copy on the objects,\n * is about 3 times faster then using deepClone\n * @link https://jsperf.com/object-rest-spread-vs-clone/2\n */\nexport function flatClone(obj) {\n    return Object.assign({}, obj);\n}\nexport function ensureNotFalsy(obj) {\n    if (!obj) {\n        throw new Error('ensureNotFalsy() is falsy');\n    }\n    return obj;\n}\nexport function mergeSets(sets) {\n    let ret = new Set();\n    sets.forEach(set => {\n        ret = new Set([...ret, ...set]);\n    });\n    return ret;\n}\n/**\n * @link https://stackoverflow.com/a/12830454/3443137\n */\nexport function roundToTwoDecimals(num) {\n    return parseFloat(num.toFixed(2));\n}\nexport function isObject(value) {\n    const type = typeof value;\n    return value !== null && (type === 'object' || type === 'function');\n}\nexport function getProperty(object, path, value) {\n    if (Array.isArray(path)) {\n        path = path.join('.');\n    }\n    if (!isObject(object) || typeof path !== 'string') {\n        return value === undefined ? object : value;\n    }\n    const pathArray = path.split('.');\n    if (pathArray.length === 0) {\n        return value;\n    }\n    for (let index = 0; index < pathArray.length; index++) {\n        const key = pathArray[index];\n        if (isStringIndex(object, key)) {\n            object = index === pathArray.length - 1 ? undefined : null;\n        }\n        else {\n            object = object[key];\n        }\n        if (object === undefined || object === null) {\n            // `object` is either `undefined` or `null` so we want to stop the loop, and\n            // if this is not the last bit of the path, and\n            // if it didn't return `undefined`\n            // it would return `null` if `object` is `null`\n            // but we want `get({foo: null}, 'foo.bar')` to equal `undefined`, or the supplied value, not `null`\n            if (index !== pathArray.length - 1) {\n                return value;\n            }\n            break;\n        }\n    }\n    return object === undefined ? value : object;\n}\nfunction isStringIndex(object, key) {\n    if (typeof key !== 'number' && Array.isArray(object)) {\n        const index = Number.parseInt(key, 10);\n        return Number.isInteger(index) && object[index] === object[key];\n    }\n    return false;\n}\n//# sourceMappingURL=util.js.map","import {\n  getOperator,\n  initOptions,\n  ProcessingMode\n} from \"./core\";\nimport { Lazy } from \"./lazy\";\nimport { assert, cloneDeep, isEmpty } from \"./util\";\nclass Aggregator {\n  #pipeline;\n  #options;\n  constructor(pipeline, options) {\n    this.#pipeline = pipeline;\n    this.#options = initOptions(options);\n  }\n  /**\n   * Returns an {@link Iterator} for lazy evaluation of the pipeline.\n   *\n   * @param collection An array or iterator object\n   * @returns {Iterator} an iterator object\n   */\n  stream(collection, options) {\n    let iter = Lazy(collection);\n    const opts = options ?? this.#options;\n    const mode = opts.processingMode;\n    if (mode & ProcessingMode.CLONE_INPUT) iter.map(cloneDeep);\n    const stages = new Array();\n    if (!isEmpty(this.#pipeline)) {\n      for (const opExpr of this.#pipeline) {\n        const opKeys = Object.keys(opExpr);\n        const opName = opKeys[0];\n        const call = getOperator(\"pipeline\", opName, opts);\n        assert(\n          opKeys.length === 1 && !!call,\n          `invalid pipeline operator ${opName}`\n        );\n        stages.push(opName);\n        iter = call(iter, opExpr[opName], opts);\n      }\n    }\n    if (mode & ProcessingMode.CLONE_OUTPUT) iter.map(cloneDeep);\n    return iter;\n  }\n  /**\n   * Return the results of the aggregation as an array.\n   *\n   * @param collection\n   */\n  run(collection, options) {\n    return this.stream(collection, options).value();\n  }\n}\nexport {\n  Aggregator\n};\n","import {\n  assert,\n  has,\n  isArray,\n  isFunction,\n  isNil,\n  isObject,\n  isOperator,\n  isString,\n  resolve\n} from \"./util\";\nvar ProcessingMode = /* @__PURE__ */ ((ProcessingMode2) => {\n  ProcessingMode2[ProcessingMode2[\"CLONE_OFF\"] = 0] = \"CLONE_OFF\";\n  ProcessingMode2[ProcessingMode2[\"CLONE_INPUT\"] = 1] = \"CLONE_INPUT\";\n  ProcessingMode2[ProcessingMode2[\"CLONE_OUTPUT\"] = 2] = \"CLONE_OUTPUT\";\n  ProcessingMode2[ProcessingMode2[\"CLONE_ALL\"] = 3] = \"CLONE_ALL\";\n  return ProcessingMode2;\n})(ProcessingMode || {});\nclass ComputeOptions {\n  #options;\n  /** Reference to the root object when processing subgraphs of the object. */\n  #root;\n  #local;\n  constructor(options, root, local) {\n    this.#options = options;\n    this.update(root, local);\n  }\n  /**\n   * Initialize new ComputeOptions.\n   * @returns {ComputeOptions}\n   */\n  static init(options, root, local) {\n    return !(options instanceof ComputeOptions) ? new ComputeOptions(options, root, local) : new ComputeOptions(options.#options, options.root ?? root, {\n      ...options.#local,\n      ...local,\n      variables: Object.assign(\n        {},\n        options.#local?.variables,\n        local?.variables\n      )\n    });\n  }\n  /**\n   * Updates the internal state.\n   *\n   * @param root The new root context for this object.\n   * @param local The new local state to merge into current if it exists.\n   * @returns\n   */\n  update(root, local) {\n    this.#root = root;\n    const variables = Object.assign(\n      {},\n      this.#local?.variables,\n      local?.variables\n    );\n    if (Object.keys(variables).length) {\n      this.#local = { ...local, variables };\n    } else {\n      this.#local = local ?? {};\n    }\n    return this;\n  }\n  getOptions() {\n    return Object.freeze({\n      ...this.#options,\n      context: Context.from(this.#options.context)\n    });\n  }\n  get root() {\n    return this.#root;\n  }\n  get local() {\n    return this.#local;\n  }\n  get idKey() {\n    return this.#options.idKey;\n  }\n  get collation() {\n    return this.#options?.collation;\n  }\n  get processingMode() {\n    return this.#options?.processingMode || 0 /* CLONE_OFF */;\n  }\n  get useStrictMode() {\n    return this.#options?.useStrictMode;\n  }\n  get scriptEnabled() {\n    return this.#options?.scriptEnabled;\n  }\n  get useGlobalContext() {\n    return this.#options?.useGlobalContext;\n  }\n  get hashFunction() {\n    return this.#options?.hashFunction;\n  }\n  get collectionResolver() {\n    return this.#options?.collectionResolver;\n  }\n  get jsonSchemaValidator() {\n    return this.#options?.jsonSchemaValidator;\n  }\n  get variables() {\n    return this.#options?.variables;\n  }\n  get context() {\n    return this.#options?.context;\n  }\n}\nfunction initOptions(options) {\n  return options instanceof ComputeOptions ? options.getOptions() : Object.freeze({\n    idKey: \"_id\",\n    scriptEnabled: true,\n    useStrictMode: true,\n    useGlobalContext: true,\n    processingMode: 0 /* CLONE_OFF */,\n    ...options,\n    context: options?.context ? Context.from(options?.context) : Context.init()\n  });\n}\nvar OperatorType = /* @__PURE__ */ ((OperatorType2) => {\n  OperatorType2[\"ACCUMULATOR\"] = \"accumulator\";\n  OperatorType2[\"EXPRESSION\"] = \"expression\";\n  OperatorType2[\"PIPELINE\"] = \"pipeline\";\n  OperatorType2[\"PROJECTION\"] = \"projection\";\n  OperatorType2[\"QUERY\"] = \"query\";\n  OperatorType2[\"WINDOW\"] = \"window\";\n  return OperatorType2;\n})(OperatorType || {});\nclass Context {\n  #operators = /* @__PURE__ */ new Map();\n  constructor() {\n  }\n  static init() {\n    return new Context();\n  }\n  static from(ctx) {\n    const instance = Context.init();\n    if (isNil(ctx)) return instance;\n    ctx.#operators.forEach((v, k) => instance.addOperators(k, v));\n    return instance;\n  }\n  addOperators(type, operators) {\n    if (!this.#operators.has(type)) this.#operators.set(type, {});\n    for (const [name, fn] of Object.entries(operators)) {\n      if (!this.getOperator(type, name)) {\n        this.#operators.get(type)[name] = fn;\n      }\n    }\n    return this;\n  }\n  getOperator(type, name) {\n    const ops = this.#operators.get(type) ?? {};\n    return ops[name] ?? null;\n  }\n  addAccumulatorOps(ops) {\n    return this.addOperators(\"accumulator\", ops);\n  }\n  addExpressionOps(ops) {\n    return this.addOperators(\"expression\", ops);\n  }\n  addQueryOps(ops) {\n    return this.addOperators(\"query\", ops);\n  }\n  addPipelineOps(ops) {\n    return this.addOperators(\"pipeline\", ops);\n  }\n  addProjectionOps(ops) {\n    return this.addOperators(\"projection\", ops);\n  }\n  addWindowOps(ops) {\n    return this.addOperators(\"window\", ops);\n  }\n}\nconst GLOBAL_CONTEXT = Context.init();\nfunction useOperators(type, operators) {\n  for (const [name, fn] of Object.entries(operators)) {\n    assert(\n      isFunction(fn) && isOperator(name),\n      `'${name}' is not a valid operator`\n    );\n    const currentFn = getOperator(type, name, null);\n    assert(\n      !currentFn || fn === currentFn,\n      `${name} already exists for '${type}' operators. Cannot change operator function once registered.`\n    );\n  }\n  switch (type) {\n    case \"accumulator\":\n      GLOBAL_CONTEXT.addAccumulatorOps(operators);\n      break;\n    case \"expression\":\n      GLOBAL_CONTEXT.addExpressionOps(operators);\n      break;\n    case \"pipeline\":\n      GLOBAL_CONTEXT.addPipelineOps(operators);\n      break;\n    case \"projection\":\n      GLOBAL_CONTEXT.addProjectionOps(operators);\n      break;\n    case \"query\":\n      GLOBAL_CONTEXT.addQueryOps(operators);\n      break;\n    case \"window\":\n      GLOBAL_CONTEXT.addWindowOps(operators);\n      break;\n  }\n}\nfunction getOperator(type, name, options) {\n  const { context: ctx, useGlobalContext: fallback } = options || {};\n  const fn = ctx ? ctx.getOperator(type, name) : null;\n  return !fn && fallback ? GLOBAL_CONTEXT.getOperator(type, name) : fn;\n}\nfunction computeValue(obj, expr, operator, options) {\n  const copts = ComputeOptions.init(options, obj);\n  return !!operator && isOperator(operator) ? computeOperator(obj, expr, operator, copts) : computeExpression(obj, expr, copts);\n}\nconst SYSTEM_VARS = [\"$$ROOT\", \"$$CURRENT\", \"$$REMOVE\", \"$$NOW\"];\nfunction computeExpression(obj, expr, options) {\n  if (isString(expr) && expr.length > 0 && expr[0] === \"$\") {\n    if (REDACT_ACTIONS.includes(expr)) return expr;\n    let ctx = options.root;\n    const arr = expr.split(\".\");\n    if (SYSTEM_VARS.includes(arr[0])) {\n      switch (arr[0]) {\n        case \"$$ROOT\":\n          break;\n        case \"$$CURRENT\":\n          ctx = obj;\n          break;\n        case \"$$REMOVE\":\n          ctx = void 0;\n          break;\n        case \"$$NOW\":\n          ctx = /* @__PURE__ */ new Date();\n          break;\n      }\n      expr = expr.slice(arr[0].length + 1);\n    } else if (arr[0].slice(0, 2) === \"$$\") {\n      ctx = Object.assign(\n        {},\n        // global vars\n        options.variables,\n        // current item is added before local variables because the binding may be changed.\n        { this: obj },\n        // local vars\n        options?.local?.variables\n      );\n      const name = arr[0].slice(2);\n      assert(has(ctx, name), `Use of undefined variable: ${name}`);\n      expr = expr.slice(2);\n    } else {\n      expr = expr.slice(1);\n    }\n    return expr === \"\" ? ctx : resolve(ctx, expr);\n  }\n  if (isArray(expr)) {\n    return expr.map((item) => computeExpression(obj, item, options));\n  }\n  if (isObject(expr)) {\n    const result = {};\n    const elems = Object.entries(expr);\n    for (const [key, val] of elems) {\n      if (isOperator(key)) {\n        assert(elems.length == 1, \"expression must have single operator.\");\n        return computeOperator(obj, val, key, options);\n      }\n      result[key] = computeExpression(obj, val, options);\n    }\n    return result;\n  }\n  return expr;\n}\nfunction computeOperator(obj, expr, operator, options) {\n  const callExpression = getOperator(\n    \"expression\",\n    operator,\n    options\n  );\n  if (callExpression) return callExpression(obj, expr, options);\n  const callAccumulator = getOperator(\n    \"accumulator\",\n    operator,\n    options\n  );\n  assert(!!callAccumulator, `accumulator '${operator}' is not registered.`);\n  if (!isArray(obj)) {\n    obj = computeExpression(obj, expr, options);\n    expr = null;\n  }\n  assert(isArray(obj), `arguments must resolve to array for ${operator}.`);\n  return callAccumulator(obj, expr, options);\n}\nconst REDACT_ACTIONS = [\"$$KEEP\", \"$$PRUNE\", \"$$DESCEND\"];\nfunction redact(obj, expr, options) {\n  const action = computeValue(obj, expr, null, options);\n  switch (action) {\n    case \"$$KEEP\":\n      return obj;\n    case \"$$PRUNE\":\n      return void 0;\n    case \"$$DESCEND\": {\n      if (!has(expr, \"$cond\")) return obj;\n      const output = {};\n      for (const [key, value] of Object.entries(obj)) {\n        if (isArray(value)) {\n          const res = new Array();\n          for (let elem of value) {\n            if (isObject(elem)) {\n              elem = redact(elem, expr, options.update(elem));\n            }\n            if (!isNil(elem)) res.push(elem);\n          }\n          output[key] = res;\n        } else if (isObject(value)) {\n          const res = redact(\n            value,\n            expr,\n            options.update(value)\n          );\n          if (!isNil(res)) output[key] = res;\n        } else {\n          output[key] = value;\n        }\n      }\n      return output;\n    }\n    default:\n      return action;\n  }\n}\nexport {\n  ComputeOptions,\n  Context,\n  OperatorType,\n  ProcessingMode,\n  computeValue,\n  getOperator,\n  initOptions,\n  redact,\n  useOperators\n};\n","import {\n  ProcessingMode\n} from \"./core\";\nimport { concat, Lazy } from \"./lazy\";\nimport { $limit } from \"./operators/pipeline/limit\";\nimport { $project } from \"./operators/pipeline/project\";\nimport { $skip } from \"./operators/pipeline/skip\";\nimport { $sort } from \"./operators/pipeline/sort\";\nimport { cloneDeep, has } from \"./util\";\nconst OPERATORS = { $sort, $skip, $limit };\nclass Cursor {\n  #source;\n  #predicate;\n  #projection;\n  #options;\n  #operators = {};\n  #result = null;\n  #buffer = [];\n  constructor(source, predicate, projection, options) {\n    this.#source = source;\n    this.#predicate = predicate;\n    this.#projection = projection;\n    this.#options = options;\n  }\n  /** Returns the iterator from running the query */\n  fetch() {\n    if (this.#result) return this.#result;\n    this.#result = Lazy(this.#source).filter(this.#predicate);\n    const mode = this.#options.processingMode;\n    if (mode & ProcessingMode.CLONE_INPUT) this.#result.map(cloneDeep);\n    for (const op of [\"$sort\", \"$skip\", \"$limit\"]) {\n      if (has(this.#operators, op)) {\n        this.#result = OPERATORS[op](\n          this.#result,\n          this.#operators[op],\n          this.#options\n        );\n      }\n    }\n    if (Object.keys(this.#projection).length) {\n      this.#result = $project(this.#result, this.#projection, this.#options);\n    }\n    if (mode & ProcessingMode.CLONE_OUTPUT) this.#result.map(cloneDeep);\n    return this.#result;\n  }\n  /** Returns an iterator with the buffered data included */\n  fetchAll() {\n    const buffered = Lazy([...this.#buffer]);\n    this.#buffer = [];\n    return concat(buffered, this.fetch());\n  }\n  /**\n   * Return remaining objects in the cursor as an array. This method exhausts the cursor\n   * @returns {Array}\n   */\n  all() {\n    return this.fetchAll().value();\n  }\n  /**\n   * Returns the number of objects return in the cursor. This method exhausts the cursor\n   * @returns {Number}\n   */\n  count() {\n    return this.all().length;\n  }\n  /**\n   * Returns a cursor that begins returning results only after passing or skipping a number of documents.\n   * @param {Number} n the number of results to skip.\n   * @return {Cursor} Returns the cursor, so you can chain this call.\n   */\n  skip(n) {\n    this.#operators[\"$skip\"] = n;\n    return this;\n  }\n  /**\n   * Constrains the size of a cursor's result set.\n   * @param {Number} n the number of results to limit to.\n   * @return {Cursor} Returns the cursor, so you can chain this call.\n   */\n  limit(n) {\n    this.#operators[\"$limit\"] = n;\n    return this;\n  }\n  /**\n   * Returns results ordered according to a sort specification.\n   * @param {AnyObject} modifier an object of key and values specifying the sort order. 1 for ascending and -1 for descending\n   * @return {Cursor} Returns the cursor, so you can chain this call.\n   */\n  sort(modifier) {\n    this.#operators[\"$sort\"] = modifier;\n    return this;\n  }\n  /**\n   * Specifies the collation for the cursor returned by the `mingo.Query.find`\n   * @param {*} spec\n   */\n  collation(spec) {\n    this.#options = { ...this.#options, collation: spec };\n    return this;\n  }\n  /**\n   * Returns the next document in a cursor.\n   * @returns {AnyObject | Boolean}\n   */\n  next() {\n    if (this.#buffer.length > 0) {\n      return this.#buffer.pop();\n    }\n    const o = this.fetch().next();\n    if (o.done) return;\n    return o.value;\n  }\n  /**\n   * Returns true if the cursor has documents and can be iterated.\n   * @returns {boolean}\n   */\n  hasNext() {\n    if (this.#buffer.length > 0) return true;\n    const o = this.fetch().next();\n    if (o.done) return false;\n    this.#buffer.push(o.value);\n    return true;\n  }\n  /**\n   * Applies a function to each document in a cursor and collects the return values in an array.\n   * @param fn\n   * @returns {Array}\n   */\n  map(fn) {\n    return this.all().map(fn);\n  }\n  /**\n   * Applies a JavaScript function for every document in a cursor.\n   * @param fn\n   */\n  forEach(fn) {\n    this.all().forEach(fn);\n  }\n  [Symbol.iterator]() {\n    return this.fetchAll();\n  }\n}\nexport {\n  Cursor\n};\n","import { isArray, MingoError } from \"./util\";\nfunction Lazy(source) {\n  return source instanceof Iterator ? source : new Iterator(source);\n}\nfunction concat(...iterators) {\n  let index = 0;\n  return Lazy(() => {\n    while (index < iterators.length) {\n      const o = iterators[index].next();\n      if (!o.done) return o;\n      index++;\n    }\n    return { done: true };\n  });\n}\nfunction isGenerator(o) {\n  return !!o && typeof o === \"object\" && o?.next instanceof Function;\n}\nfunction dropItem(array, i) {\n  const rest = array.slice(i + 1);\n  array.splice(i);\n  Array.prototype.push.apply(array, rest);\n}\nconst DONE = new Error();\nvar Action = /* @__PURE__ */ ((Action2) => {\n  Action2[Action2[\"MAP\"] = 0] = \"MAP\";\n  Action2[Action2[\"FILTER\"] = 1] = \"FILTER\";\n  Action2[Action2[\"TAKE\"] = 2] = \"TAKE\";\n  Action2[Action2[\"DROP\"] = 3] = \"DROP\";\n  return Action2;\n})(Action || {});\nfunction createCallback(nextFn, iteratees, buffer) {\n  let done = false;\n  let index = -1;\n  let bufferIndex = 0;\n  return function(storeResult) {\n    try {\n      outer: while (!done) {\n        let o = nextFn();\n        index++;\n        let i = -1;\n        const size = iteratees.length;\n        let innerDone = false;\n        while (++i < size) {\n          const r = iteratees[i];\n          switch (r.action) {\n            case 0 /* MAP */:\n              o = r.func(o, index);\n              break;\n            case 1 /* FILTER */:\n              if (!r.func(o, index)) continue outer;\n              break;\n            case 2 /* TAKE */:\n              --r.count;\n              if (!r.count) innerDone = true;\n              break;\n            case 3 /* DROP */:\n              --r.count;\n              if (!r.count) dropItem(iteratees, i);\n              continue outer;\n            default:\n              break outer;\n          }\n        }\n        done = innerDone;\n        if (storeResult) {\n          buffer[bufferIndex++] = o;\n        } else {\n          return { value: o, done: false };\n        }\n      }\n    } catch (e) {\n      if (e !== DONE) throw e;\n    }\n    done = true;\n    return { done };\n  };\n}\nclass Iterator {\n  /**\n   * @param {*} source An iterable object or function.\n   *    Array - return one element per cycle\n   *    Object{next:Function} - call next() for the next value (this also handles generator functions)\n   *    Function - call to return the next value\n   * @param {Function} fn An optional transformation function\n   */\n  constructor(source) {\n    this.#iteratees = [];\n    this.#yieldedValues = [];\n    this.isDone = false;\n    let nextVal;\n    if (source instanceof Function) {\n      source = { next: source };\n    }\n    if (isGenerator(source)) {\n      const src = source;\n      nextVal = () => {\n        const o = src.next();\n        if (o.done) throw DONE;\n        return o.value;\n      };\n    } else if (isArray(source)) {\n      const data = source;\n      const size = data.length;\n      let index = 0;\n      nextVal = () => {\n        if (index < size) return data[index++];\n        throw DONE;\n      };\n    } else if (!(source instanceof Function)) {\n      throw new MingoError(\n        `Lazy must be initialized with an array, generator, or function.`\n      );\n    }\n    this.#getNext = createCallback(\n      nextVal,\n      this.#iteratees,\n      this.#yieldedValues\n    );\n  }\n  #iteratees;\n  #yieldedValues;\n  #getNext;\n  /**\n   * Add an iteratee to this lazy sequence\n   */\n  push(action, value) {\n    if (typeof value === \"function\") {\n      this.#iteratees.push({ action, func: value });\n    } else if (typeof value === \"number\") {\n      this.#iteratees.push({ action, count: value });\n    }\n    return this;\n  }\n  next() {\n    return this.#getNext();\n  }\n  // Iteratees methods\n  /**\n   * Transform each item in the sequence to a new value\n   * @param {Function} f\n   */\n  map(f) {\n    return this.push(0 /* MAP */, f);\n  }\n  /**\n   * Select only items matching the given predicate\n   * @param {Function} pred\n   */\n  filter(predicate) {\n    return this.push(1 /* FILTER */, predicate);\n  }\n  /**\n   * Take given numbe for values from sequence\n   * @param {Number} n A number greater than 0\n   */\n  take(n) {\n    return n > 0 ? this.push(2 /* TAKE */, n) : this;\n  }\n  /**\n   * Drop a number of values from the sequence\n   * @param {Number} n Number of items to drop greater than 0\n   */\n  drop(n) {\n    return n > 0 ? this.push(3 /* DROP */, n) : this;\n  }\n  // Transformations\n  /**\n   * Returns a new lazy object with results of the transformation\n   * The entire sequence is realized.\n   *\n   * @param {Callback<Source, Any[]>} fn Tranform function of type (Array) => (Any)\n   */\n  transform(fn) {\n    const self = this;\n    let iter;\n    return Lazy(() => {\n      if (!iter) {\n        iter = Lazy(fn(self.value()));\n      }\n      return iter.next();\n    });\n  }\n  // Terminal methods\n  /**\n   * Returns the fully realized values of the iterators.\n   * The return value will be an array unless `lazy.first()` was used.\n   * The realized values are cached for subsequent calls.\n   */\n  value() {\n    if (!this.isDone) {\n      this.isDone = this.#getNext(true).done;\n    }\n    return this.#yieldedValues;\n  }\n  /**\n   * Execute the funcion for each value. Will stop when an execution returns false.\n   * @param {Function} f\n   * @returns {Boolean} false iff `f` return false for AnyVal execution, otherwise true\n   */\n  each(f) {\n    for (; ; ) {\n      const o = this.next();\n      if (o.done) break;\n      if (f(o.value) === false) return false;\n    }\n    return true;\n  }\n  /**\n   * Returns the reduction of sequence according the reducing function\n   *\n   * @param {*} f a reducing function\n   * @param {*} initialValue\n   */\n  reduce(f, initialValue) {\n    let o = this.next();\n    if (initialValue === void 0 && !o.done) {\n      initialValue = o.value;\n      o = this.next();\n    }\n    while (!o.done) {\n      initialValue = f(initialValue, o.value);\n      o = this.next();\n    }\n    return initialValue;\n  }\n  /**\n   * Returns the number of matched items in the sequence\n   */\n  size() {\n    return this.reduce(\n      (acc, _) => ++acc,\n      0\n    );\n  }\n  [Symbol.iterator]() {\n    return this;\n  }\n}\nexport {\n  Iterator,\n  Lazy,\n  concat\n};\n","import {\n  computeValue\n} from \"../core\";\nimport { Query } from \"../query\";\nimport {\n  compare as mingoCmp,\n  ensureArray,\n  flatten,\n  intersection,\n  isArray,\n  isBoolean,\n  isDate,\n  isEmpty,\n  isEqual,\n  isNil,\n  isNumber,\n  isObject,\n  isOperator,\n  isRegExp,\n  isString,\n  MingoError,\n  resolve,\n  truthy,\n  typeOf\n} from \"../util\";\nfunction createQueryOperator(predicate) {\n  const f = (selector, value, options) => {\n    const opts = { unwrapArray: true };\n    const depth = Math.max(1, selector.split(\".\").length - 1);\n    return (obj) => {\n      const lhs = resolve(obj, selector, opts);\n      return predicate(lhs, value, { ...options, depth });\n    };\n  };\n  return f;\n}\nfunction createExpressionOperator(predicate) {\n  return (obj, expr, options) => {\n    const args = computeValue(obj, expr, null, options);\n    return predicate(...args);\n  };\n}\nfunction $eq(a, b, options) {\n  if (isEqual(a, b)) return true;\n  if (isNil(a) && isNil(b)) return true;\n  if (isArray(a)) {\n    return a.some((v) => isEqual(v, b)) || flatten(a, options?.depth).some((v) => isEqual(v, b));\n  }\n  return false;\n}\nfunction $ne(a, b, options) {\n  return !$eq(a, b, options);\n}\nfunction $in(a, b, options) {\n  if (isNil(a)) return b.some((v) => v === null);\n  return intersection([ensureArray(a), b], options?.hashFunction).length > 0;\n}\nfunction $nin(a, b, options) {\n  return !$in(a, b, options);\n}\nfunction $lt(a, b, _options) {\n  return compare(a, b, (x, y) => mingoCmp(x, y) < 0);\n}\nfunction $lte(a, b, _options) {\n  return compare(a, b, (x, y) => mingoCmp(x, y) <= 0);\n}\nfunction $gt(a, b, _options) {\n  return compare(a, b, (x, y) => mingoCmp(x, y) > 0);\n}\nfunction $gte(a, b, _options) {\n  return compare(a, b, (x, y) => mingoCmp(x, y) >= 0);\n}\nfunction $mod(a, b, _options) {\n  return ensureArray(a).some(\n    (x) => b.length === 2 && x % b[0] === b[1]\n  );\n}\nfunction $regex(a, b, options) {\n  const lhs = ensureArray(a);\n  const match = (x) => isString(x) && truthy(b.exec(x), options?.useStrictMode);\n  return lhs.some(match) || flatten(lhs, 1).some(match);\n}\nfunction $all(values, queries, options) {\n  if (!isArray(values) || !isArray(queries) || !values.length || !queries.length) {\n    return false;\n  }\n  let matched = true;\n  for (const query of queries) {\n    if (!matched) break;\n    if (isObject(query) && Object.keys(query).includes(\"$elemMatch\")) {\n      matched = $elemMatch(values, query[\"$elemMatch\"], options);\n    } else if (isRegExp(query)) {\n      matched = values.some((s) => typeof s === \"string\" && query.test(s));\n    } else {\n      matched = values.some((v) => isEqual(query, v));\n    }\n  }\n  return matched;\n}\nfunction $size(a, b, _options) {\n  return Array.isArray(a) && a.length === b;\n}\nfunction isNonBooleanOperator(name) {\n  return isOperator(name) && [\"$and\", \"$or\", \"$nor\"].indexOf(name) === -1;\n}\nfunction $elemMatch(a, b, options) {\n  if (isArray(a) && !isEmpty(a)) {\n    let format = (x) => x;\n    let criteria = b;\n    if (Object.keys(b).every(isNonBooleanOperator)) {\n      criteria = { temp: b };\n      format = (x) => ({ temp: x });\n    }\n    const query = new Query(criteria, options);\n    for (let i = 0, len = a.length; i < len; i++) {\n      if (query.test(format(a[i]))) {\n        return true;\n      }\n    }\n  }\n  return false;\n}\nconst isNull = (a) => a === null;\nconst compareFuncs = {\n  array: isArray,\n  boolean: isBoolean,\n  bool: isBoolean,\n  date: isDate,\n  number: isNumber,\n  int: isNumber,\n  long: isNumber,\n  double: isNumber,\n  decimal: isNumber,\n  null: isNull,\n  object: isObject,\n  regexp: isRegExp,\n  regex: isRegExp,\n  string: isString,\n  // added for completeness\n  undefined: isNil,\n  // deprecated\n  function: (_) => {\n    throw new MingoError(\"unsupported type key `function`.\");\n  },\n  // Mongo identifiers\n  1: isNumber,\n  //double\n  2: isString,\n  3: isObject,\n  4: isArray,\n  6: isNil,\n  // deprecated\n  8: isBoolean,\n  9: isDate,\n  10: isNull,\n  11: isRegExp,\n  16: isNumber,\n  //int\n  18: isNumber,\n  //long\n  19: isNumber\n  //decimal\n};\nfunction compareType(a, b, _) {\n  const f = compareFuncs[b];\n  return f ? f(a) : false;\n}\nfunction $type(a, b, options) {\n  return isArray(b) ? b.findIndex((t) => compareType(a, t, options)) >= 0 : compareType(a, b, options);\n}\nfunction compare(a, b, f) {\n  return ensureArray(a).some((x) => typeOf(x) === typeOf(b) && f(x, b));\n}\nexport {\n  $all,\n  $elemMatch,\n  $eq,\n  $gt,\n  $gte,\n  $in,\n  $lt,\n  $lte,\n  $mod,\n  $ne,\n  $nin,\n  $regex,\n  $size,\n  $type,\n  createExpressionOperator,\n  createQueryOperator\n};\n","function stddev(data, sampled = true) {\n  const sum = data.reduce((acc, n) => acc + n, 0);\n  const N = data.length || 1;\n  const avg = sum / N;\n  return Math.sqrt(\n    data.reduce((acc, n) => acc + Math.pow(n - avg, 2), 0) / (N - Number(sampled))\n  );\n}\nfunction covariance(dataset, sampled = true) {\n  if (!dataset) return null;\n  if (dataset.length < 2) return sampled ? null : 0;\n  let meanX = 0;\n  let meanY = 0;\n  for (const [x, y] of dataset) {\n    meanX += x;\n    meanY += y;\n  }\n  meanX /= dataset.length;\n  meanY /= dataset.length;\n  let result = 0;\n  for (const [x, y] of dataset) {\n    result += (x - meanX) * (y - meanY);\n  }\n  return result / (dataset.length - Number(sampled));\n}\nexport {\n  covariance,\n  stddev\n};\n","import {\n  ComputeOptions,\n  computeValue\n} from \"../../core\";\nimport { assert } from \"../../util\";\nconst $accumulator = (collection, expr, options) => {\n  assert(\n    !!options && options.scriptEnabled,\n    \"$accumulator operator requires 'scriptEnabled' option to be true\"\n  );\n  if (collection.length == 0) return expr.initArgs;\n  const copts = ComputeOptions.init(options);\n  const initArgs = computeValue(\n    {},\n    expr.initArgs || [],\n    null,\n    copts.update(copts?.local?.groupId || {})\n  );\n  let state = expr.init.call(null, ...initArgs);\n  for (const doc of collection) {\n    const args = computeValue(\n      doc,\n      expr.accumulateArgs,\n      null,\n      copts.update(doc)\n    );\n    state = expr.accumulate.call(null, ...[state, ...args]);\n  }\n  return expr.finalize ? expr.finalize.call(null, state) : state;\n};\nexport {\n  $accumulator\n};\n","import { unique } from \"../../util\";\nimport { $push } from \"./push\";\nconst $addToSet = (collection, expr, options) => {\n  return unique(\n    $push(collection, expr, options),\n    options?.hashFunction\n  );\n};\nexport {\n  $addToSet\n};\n","import { isNumber } from \"../../util\";\nimport { $push } from \"./push\";\nconst $avg = (collection, expr, options) => {\n  const data = $push(collection, expr, options).filter(isNumber);\n  const sum = data.reduce((acc, n) => acc + n, 0);\n  return sum / (data.length || 1);\n};\nexport {\n  $avg\n};\n","import { $bottomN } from \"./bottomN\";\nconst $bottom = (collection, expr, options) => $bottomN(collection, { ...expr, n: 1 }, options);\nexport {\n  $bottom\n};\n","import {\n  ComputeOptions,\n  computeValue\n} from \"../../core\";\nimport { Lazy } from \"../../lazy\";\nimport { $sort } from \"../pipeline/sort\";\nimport { $push } from \"./push\";\nconst $bottomN = (collection, expr, options) => {\n  const copts = ComputeOptions.init(options);\n  const { n, sortBy } = computeValue(\n    copts.local.groupId,\n    expr,\n    null,\n    copts\n  );\n  const result = $sort(Lazy(collection), sortBy, options).value();\n  const m = result.length;\n  const p = n;\n  return $push(m <= p ? result : result.slice(m - p), expr.output, copts);\n};\nexport {\n  $bottomN\n};\n","const $count = (collection, _expr, _options) => collection.length;\nexport {\n  $count\n};\n","import { covariance } from \"./_internal\";\nimport { $push } from \"./push\";\nconst $covariancePop = (collection, expr, options) => covariance($push(collection, expr, options), false);\nexport {\n  $covariancePop\n};\n","import { covariance } from \"./_internal\";\nimport { $push } from \"./push\";\nconst $covarianceSamp = (collection, expr, options) => covariance($push(collection, expr, options), true);\nexport {\n  $covarianceSamp\n};\n","import {\n  ComputeOptions,\n  computeValue\n} from \"../../core\";\nconst $first = (collection, expr, options) => {\n  if (collection.length === 0) return void 0;\n  const copts = ComputeOptions.init(options).update(collection[0]);\n  return computeValue(collection[0], expr, null, copts);\n};\nexport {\n  $first\n};\n","import {\n  ComputeOptions,\n  computeValue\n} from \"../../core\";\nimport { $push } from \"./push\";\nconst $firstN = (collection, expr, options) => {\n  const copts = ComputeOptions.init(options);\n  const m = collection.length;\n  const n = computeValue(copts?.local?.groupId, expr.n, null, copts);\n  return $push(\n    m <= n ? collection : collection.slice(0, n),\n    expr.input,\n    options\n  );\n};\nexport {\n  $firstN\n};\n","export * from \"./accumulator\";\nexport * from \"./addToSet\";\nexport * from \"./avg\";\nexport * from \"./bottom\";\nexport * from \"./bottomN\";\nexport * from \"./count\";\nexport * from \"./covariancePop\";\nexport * from \"./covarianceSamp\";\nexport * from \"./first\";\nexport * from \"./firstN\";\nexport * from \"./last\";\nexport * from \"./lastN\";\nexport * from \"./max\";\nexport * from \"./maxN\";\nexport * from \"./median\";\nexport * from \"./mergeObjects\";\nexport * from \"./min\";\nexport * from \"./minN\";\nexport * from \"./percentile\";\nexport * from \"./push\";\nexport * from \"./stdDevPop\";\nexport * from \"./stdDevSamp\";\nexport * from \"./sum\";\nexport * from \"./top\";\nexport * from \"./topN\";\n","import {\n  ComputeOptions,\n  computeValue\n} from \"../../core\";\nconst $last = (collection, expr, options) => {\n  if (collection.length === 0) return void 0;\n  const obj = collection[collection.length - 1];\n  const copts = ComputeOptions.init(options).update(obj);\n  return computeValue(obj, expr, null, copts);\n};\nexport {\n  $last\n};\n","import {\n  ComputeOptions,\n  computeValue\n} from \"../../core\";\nimport { $push } from \"./push\";\nconst $lastN = (collection, expr, options) => {\n  const copts = ComputeOptions.init(options);\n  const m = collection.length;\n  const n = computeValue(copts?.local?.groupId, expr.n, null, copts);\n  return $push(\n    m <= n ? collection : collection.slice(m - n),\n    expr.input,\n    options\n  );\n};\nexport {\n  $lastN\n};\n","import { assert, compare, isArray, isEmpty, isNil } from \"../../util\";\nimport { $push } from \"./push\";\nconst $max = (collection, expr, options) => {\n  const items = $push(collection, expr, options);\n  if (isEmpty(items)) return null;\n  assert(isArray(items), \"$max: input must resolve to array\");\n  let max = items[0];\n  for (const n of items) {\n    if (isNil(n) || isNaN(n)) continue;\n    if (compare(n, max) >= 0) max = n;\n  }\n  return max;\n};\nexport {\n  $max\n};\n","import {\n  ComputeOptions,\n  computeValue\n} from \"../../core\";\nimport { compare, isNil } from \"../../util\";\nimport { $push } from \"./push\";\nconst $maxN = (collection, expr, options) => {\n  const copts = ComputeOptions.init(options);\n  const m = collection.length;\n  const n = computeValue(copts?.local?.groupId, expr.n, null, copts);\n  const arr = $push(collection, expr.input, options).filter((o) => !isNil(o));\n  arr.sort((a, b) => -1 * compare(a, b));\n  return m <= n ? arr : arr.slice(0, n);\n};\nexport {\n  $maxN\n};\n","import { $percentile } from \"./percentile\";\nconst $median = (collection, expr, options) => $percentile(collection, { ...expr, p: [0.5] }, options).pop();\nexport {\n  $median\n};\n","import { computeValue } from \"../../core\";\nimport { $mergeObjects as __mergeObjects } from \"../expression/object/mergeObjects\";\nconst $mergeObjects = (collection, expr, options) => {\n  const arr = computeValue(collection, expr, null, options);\n  return __mergeObjects(null, arr, options);\n};\nexport {\n  $mergeObjects\n};\n","import { assert, compare, isArray, isEmpty, isNil } from \"../../util\";\nimport { $push } from \"./push\";\nconst $min = (collection, expr, options) => {\n  const items = $push(collection, expr, options);\n  if (isEmpty(items)) return null;\n  assert(isArray(items), \"$min: input must resolve to array\");\n  let min = items[0];\n  for (const n of items) {\n    if (isNil(n) || isNaN(n)) continue;\n    if (compare(n, min) <= 0) min = n;\n  }\n  return min;\n};\nexport {\n  $min\n};\n","import {\n  ComputeOptions,\n  computeValue\n} from \"../../core\";\nimport { compare, isNil } from \"../../util\";\nimport { $push } from \"./push\";\nconst $minN = (collection, expr, options) => {\n  const copts = ComputeOptions.init(options);\n  const m = collection.length;\n  const n = computeValue(copts?.local?.groupId, expr.n, null, copts);\n  const arr = $push(collection, expr.input, options).filter((o) => !isNil(o));\n  arr.sort(compare);\n  return m <= n ? arr : arr.slice(0, n);\n};\nexport {\n  $minN\n};\n","import { assert, findInsertIndex, isNumber } from \"../../util\";\nimport { $push } from \"./push\";\nconst $percentile = (collection, expr, options) => {\n  const X = $push(collection, expr.input, options).filter(isNumber).sort();\n  const centiles = $push(expr.p, \"$$CURRENT\", options).filter(isNumber);\n  const method = expr.method || \"approximate\";\n  return centiles.map((p) => {\n    assert(\n      p > 0 && p <= 1,\n      `percentile value must be between 0 (exclusive) and 1 (inclusive): invalid '${p}'.`\n    );\n    const r = p * (X.length - 1) + 1;\n    const ri = Math.floor(r);\n    const result = r === ri ? X[r - 1] : X[ri - 1] + r % 1 * (X[ri] - X[ri - 1] || 0);\n    switch (method) {\n      case \"exact\":\n        return result;\n      case \"approximate\": {\n        const i = findInsertIndex(X, result);\n        return i / X.length >= p ? X[Math.max(i - 1, 0)] : X[i];\n      }\n    }\n  });\n};\nexport {\n  $percentile\n};\n","import {\n  ComputeOptions,\n  computeValue\n} from \"../../core\";\nimport { isNil } from \"../../util\";\nconst $push = (collection, expr, options) => {\n  if (isNil(expr)) return collection;\n  const copts = ComputeOptions.init(options);\n  return collection.map(\n    (obj) => computeValue(obj, expr, null, copts.update(obj))\n  );\n};\nexport {\n  $push\n};\n","import { isNumber } from \"../../util\";\nimport { stddev } from \"./_internal\";\nimport { $push } from \"./push\";\nconst $stdDevPop = (collection, expr, options) => stddev($push(collection, expr, options).filter(isNumber), false);\nexport {\n  $stdDevPop\n};\n","import { isNumber } from \"../../util\";\nimport { stddev } from \"./_internal\";\nimport { $push } from \"./push\";\nconst $stdDevSamp = (collection, expr, options) => stddev($push(collection, expr, options).filter(isNumber), true);\nexport {\n  $stdDevSamp\n};\n","import { isArray, isNumber } from \"../../util\";\nimport { $push } from \"./push\";\nconst $sum = (collection, expr, options) => {\n  if (!isArray(collection)) return 0;\n  if (isNumber(expr)) return collection.length * expr;\n  const nums = $push(collection, expr, options).filter(isNumber);\n  return nums.reduce((acc, n) => acc + n, 0);\n};\nexport {\n  $sum\n};\n","import { $topN } from \"./topN\";\nconst $top = (collection, expr, options) => $topN(collection, { ...expr, n: 1 }, options);\nexport {\n  $top\n};\n","import {\n  ComputeOptions,\n  computeValue\n} from \"../../core\";\nimport { Lazy } from \"../../lazy\";\nimport { $sort } from \"../pipeline/sort\";\nimport { $push } from \"./push\";\nconst $topN = (collection, expr, options) => {\n  const copts = ComputeOptions.init(options);\n  const { n, sortBy } = computeValue(\n    copts.local.groupId,\n    expr,\n    null,\n    copts\n  );\n  const result = $sort(Lazy(collection), sortBy, options).take(n).value();\n  return $push(result, expr.output, copts);\n};\nexport {\n  $topN\n};\n","function truncate(num, places = 0, roundOff = false) {\n  const sign = Math.abs(num) === num ? 1 : -1;\n  num = Math.abs(num);\n  let result = Math.trunc(num);\n  const decimals = parseFloat((num - result).toFixed(places + 1));\n  if (places === 0) {\n    const firstDigit = Math.trunc(10 * decimals);\n    if (roundOff && ((result & 1) === 1 && firstDigit >= 5 || firstDigit > 5)) {\n      result++;\n    }\n  } else if (places > 0) {\n    const offset = Math.pow(10, places);\n    let remainder = Math.trunc(decimals * offset);\n    const lastDigit = Math.trunc(decimals * offset * 10) % 10;\n    if (roundOff && lastDigit > 5) {\n      remainder += 1;\n    }\n    result = (result * offset + remainder) / offset;\n  } else if (places < 0) {\n    const offset = Math.pow(10, -1 * places);\n    let excess = result % offset;\n    result = Math.max(0, result - excess);\n    if (roundOff && sign === -1) {\n      while (excess > 10) {\n        excess -= excess % 10;\n      }\n      if (result > 0 && excess >= 5) {\n        result += offset;\n      }\n    }\n  }\n  return result * sign;\n}\nexport {\n  truncate\n};\n","import { computeValue } from \"../../../core\";\nimport { isNil } from \"../../../util\";\nconst $abs = (obj, expr, options) => {\n  const n = computeValue(obj, expr, null, options);\n  return isNil(n) ? null : Math.abs(n);\n};\nexport {\n  $abs\n};\n","import { computeValue } from \"../../../core\";\nimport { assert, isDate } from \"../../../util\";\nconst $add = (obj, expr, options) => {\n  const args = computeValue(obj, expr, null, options);\n  let hasDate = false;\n  let sum = 0;\n  for (const n of args) {\n    if (isDate(n)) {\n      assert(!hasDate, \"'$add' can only have one date value\");\n      hasDate = true;\n    }\n    sum += +n;\n  }\n  return hasDate ? new Date(sum) : sum;\n};\nexport {\n  $add\n};\n","import { computeValue } from \"../../../core\";\nimport { assert, isNil, isNumber } from \"../../../util\";\nconst $ceil = (obj, expr, options) => {\n  const n = computeValue(obj, expr, null, options);\n  if (isNil(n)) return null;\n  assert(isNumber(n) || isNaN(n), \"$ceil expression must resolve to a number.\");\n  return Math.ceil(n);\n};\nexport {\n  $ceil\n};\n","import { computeValue } from \"../../../core\";\nconst $divide = (obj, expr, options) => {\n  const args = computeValue(obj, expr, null, options);\n  return args[0] / args[1];\n};\nexport {\n  $divide\n};\n","import { computeValue } from \"../../../core\";\nimport { assert, isNil, isNumber } from \"../../../util\";\nconst $exp = (obj, expr, options) => {\n  const n = computeValue(obj, expr, null, options);\n  if (isNil(n)) return null;\n  assert(isNumber(n) || isNaN(n), \"$exp expression must resolve to a number.\");\n  return Math.exp(n);\n};\nexport {\n  $exp\n};\n","import { computeValue } from \"../../../core\";\nimport { assert, isNil, isNumber } from \"../../../util\";\nconst $floor = (obj, expr, options) => {\n  const n = computeValue(obj, expr, null, options);\n  if (isNil(n)) return null;\n  assert(\n    isNumber(n) || isNaN(n),\n    \"$floor expression must resolve to a number.\"\n  );\n  return Math.floor(n);\n};\nexport {\n  $floor\n};\n","export * from \"./abs\";\nexport * from \"./add\";\nexport * from \"./ceil\";\nexport * from \"./divide\";\nexport * from \"./exp\";\nexport * from \"./floor\";\nexport * from \"./ln\";\nexport * from \"./log\";\nexport * from \"./log10\";\nexport * from \"./mod\";\nexport * from \"./multiply\";\nexport * from \"./pow\";\nexport * from \"./round\";\nexport * from \"./sqrt\";\nexport * from \"./subtract\";\nexport * from \"./trunc\";\n","import { computeValue } from \"../../../core\";\nimport { assert, isNil, isNumber } from \"../../../util\";\nconst $ln = (obj, expr, options) => {\n  const n = computeValue(obj, expr, null, options);\n  if (isNil(n)) return null;\n  assert(isNumber(n) || isNaN(n), \"$ln expression must resolve to a number.\");\n  return Math.log(n);\n};\nexport {\n  $ln\n};\n","import { computeValue } from \"../../../core\";\nimport { assert, isArray, isNil, isNumber } from \"../../../util\";\nconst $log = (obj, expr, options) => {\n  const args = computeValue(obj, expr, null, options);\n  const msg = \"$log expression must resolve to array(2) of numbers\";\n  assert(isArray(args) && args.length === 2, msg);\n  if (args.some(isNil)) return null;\n  assert(args.some(isNaN) || args.every(isNumber), msg);\n  return Math.log10(args[0]) / Math.log10(args[1]);\n};\nexport {\n  $log\n};\n","import { computeValue } from \"../../../core\";\nimport { assert, isNil, isNumber } from \"../../../util\";\nconst $log10 = (obj, expr, options) => {\n  const n = computeValue(obj, expr, null, options);\n  if (isNil(n)) return null;\n  assert(\n    isNumber(n) || isNaN(n),\n    \"$log10 expression must resolve to a number.\"\n  );\n  return Math.log10(n);\n};\nexport {\n  $log10\n};\n","import { computeValue } from \"../../../core\";\nconst $mod = (obj, expr, options) => {\n  const args = computeValue(obj, expr, null, options);\n  return args[0] % args[1];\n};\nexport {\n  $mod\n};\n","import { computeValue } from \"../../../core\";\nconst $multiply = (obj, expr, options) => {\n  const args = computeValue(obj, expr, null, options);\n  return args.reduce((acc, num) => acc * num, 1);\n};\nexport {\n  $multiply\n};\n","import { computeValue } from \"../../../core\";\nimport { assert, isArray, isNumber } from \"../../../util\";\nconst $pow = (obj, expr, options) => {\n  const args = computeValue(obj, expr, null, options);\n  assert(\n    isArray(args) && args.length === 2 && args.every(isNumber),\n    \"$pow expression must resolve to array(2) of numbers\"\n  );\n  assert(\n    !(args[0] === 0 && args[1] < 0),\n    \"$pow cannot raise 0 to a negative exponent\"\n  );\n  return Math.pow(args[0], args[1]);\n};\nexport {\n  $pow\n};\n","import { computeValue } from \"../../../core\";\nimport { assert, isNil, isNumber } from \"../../../util\";\nimport { truncate } from \"./_internal\";\nconst $round = (obj, expr, options) => {\n  const args = computeValue(obj, expr, null, options);\n  const num = args[0];\n  const place = args[1];\n  if (isNil(num) || isNaN(num) || Math.abs(num) === Infinity) return num;\n  assert(isNumber(num), \"$round expression must resolve to a number.\");\n  return truncate(num, place, true);\n};\nexport {\n  $round\n};\n","import { computeValue } from \"../../../core\";\nimport { assert, isNil, isNumber } from \"../../../util\";\nconst $sqrt = (obj, expr, options) => {\n  const n = computeValue(obj, expr, null, options);\n  if (isNil(n)) return null;\n  assert(\n    isNumber(n) && n > 0 || isNaN(n),\n    \"$sqrt expression must resolve to non-negative number.\"\n  );\n  return Math.sqrt(n);\n};\nexport {\n  $sqrt\n};\n","import { computeValue } from \"../../../core\";\nimport { assert, isDate, isNumber } from \"../../../util\";\nconst $subtract = (obj, expr, options) => {\n  const [a, b] = computeValue(obj, expr, null, options);\n  if (isNumber(a) && isNumber(b) || isDate(a) && isDate(b)) return +a - +b;\n  if (isDate(a) && isNumber(b)) return new Date(+a - b);\n  assert(false, \"$subtract: must resolve to number/date.\");\n};\nexport {\n  $subtract\n};\n","import { computeValue } from \"../../../core\";\nimport { assert, isNil, isNumber } from \"../../../util\";\nimport { truncate } from \"./_internal\";\nconst $trunc = (obj, expr, options) => {\n  const arr = computeValue(obj, expr, null, options);\n  const num = arr[0];\n  const places = arr[1];\n  if (isNil(num) || isNaN(num) || Math.abs(num) === Infinity) return num;\n  assert(isNumber(num), \"$trunc expression must resolve to a number.\");\n  assert(\n    isNil(places) || isNumber(places) && places > -20 && places < 100,\n    \"$trunc expression has invalid place\"\n  );\n  return truncate(num, places, false);\n};\nexport {\n  $trunc\n};\n","import { computeValue } from \"../../../core\";\nimport { assert, isArray, isNil } from \"../../../util\";\nconst $arrayElemAt = (obj, expr, options) => {\n  const args = computeValue(obj, expr, null, options);\n  assert(\n    isArray(args) && args.length === 2,\n    \"$arrayElemAt expression must resolve to array(2)\"\n  );\n  if (args.some(isNil)) return null;\n  const index = args[1];\n  const arr = args[0];\n  if (index < 0 && Math.abs(index) <= arr.length) {\n    return arr[(index + arr.length) % arr.length];\n  } else if (index >= 0 && index < arr.length) {\n    return arr[index];\n  }\n  return void 0;\n};\nexport {\n  $arrayElemAt\n};\n","import { computeValue } from \"../../../core\";\nimport { assert, has, isArray, isObject } from \"../../../util\";\nconst $arrayToObject = (obj, expr, options) => {\n  const arr = computeValue(obj, expr, null, options);\n  assert(isArray(arr), \"$arrayToObject: expression must resolve to an array\");\n  return arr.reduce((newObj, val) => {\n    while (isArray(val) && val.length === 1) val = val[0];\n    if (isArray(val) && val.length == 2) {\n      newObj[val[0]] = val[1];\n    } else {\n      const valObj = val;\n      assert(\n        isObject(valObj) && has(valObj, \"k\") && has(valObj, \"v\"),\n        \"$arrayToObject expression is invalid.\"\n      );\n      newObj[valObj.k] = valObj.v;\n    }\n    return newObj;\n  }, {});\n};\nexport {\n  $arrayToObject\n};\n","import { computeValue } from \"../../../core\";\nimport { assert, isArray, isNil } from \"../../../util\";\nconst $concatArrays = (obj, expr, options) => {\n  const nArray = computeValue(obj, expr, null, options);\n  assert(isArray(nArray), \"$concatArrays: input must resolve to an array\");\n  let size = 0;\n  for (const arr of nArray) {\n    if (isNil(arr)) return null;\n    size += arr.length;\n  }\n  const result = new Array(size);\n  let i = 0;\n  for (const arr of nArray) for (const item of arr) result[i++] = item;\n  return result;\n};\nexport {\n  $concatArrays\n};\n","import {\n  ComputeOptions,\n  computeValue\n} from \"../../../core\";\nimport { assert, isArray, isNil, truthy } from \"../../../util\";\nconst $filter = (obj, expr, options) => {\n  const input = computeValue(obj, expr.input, null, options);\n  if (isNil(input)) return null;\n  assert(isArray(input), \"$filter 'input' expression must resolve to an array\");\n  const copts = ComputeOptions.init(options, obj);\n  const k = expr.as || \"this\";\n  const local = {\n    variables: { [k]: null }\n  };\n  return input.filter((o) => {\n    local.variables[k] = o;\n    const b = computeValue(\n      obj,\n      expr.cond,\n      null,\n      copts.update(copts.root, local)\n    );\n    return truthy(b, options.useStrictMode);\n  });\n};\nexport {\n  $filter\n};\n","import { computeValue } from \"../../../core\";\nimport { assert, flatten, isArray, isNil } from \"../../../util\";\nimport { $first as __first } from \"../../accumulator/first\";\nconst $first = (obj, expr, options) => {\n  if (isArray(obj)) return __first(obj, expr, options);\n  const arr = computeValue(obj, expr, null, options);\n  if (isNil(arr)) return null;\n  assert(\n    isArray(arr) && arr.length > 0,\n    \"$first must resolve to a non-empty array.\"\n  );\n  return flatten(arr)[0];\n};\nexport {\n  $first\n};\n","import { computeValue } from \"../../../core\";\nimport { assert, isArray, isNil } from \"../../../util\";\nimport { $firstN as __firstN } from \"../../accumulator/firstN\";\nconst $firstN = (obj, expr, options) => {\n  if (isArray(obj)) return __firstN(obj, expr, options);\n  const { input, n } = computeValue(obj, expr, null, options);\n  if (isNil(input)) return null;\n  assert(isArray(input), \"Must resolve to an array/null or missing\");\n  return __firstN(input, { n, input: \"$$this\" }, options);\n};\nexport {\n  $firstN\n};\n","import { computeValue } from \"../../../core\";\nimport { assert, isArray, isEqual } from \"../../../util\";\nconst $in = (obj, expr, options) => {\n  const [item, arr] = computeValue(obj, expr, null, options);\n  assert(isArray(arr), \"$in second argument must be an array\");\n  return arr.some((v) => isEqual(v, item));\n};\nexport {\n  $in\n};\n","export * from \"./arrayElemAt\";\nexport * from \"./arrayToObject\";\nexport * from \"./concatArrays\";\nexport * from \"./filter\";\nexport * from \"./first\";\nexport * from \"./firstN\";\nexport * from \"./in\";\nexport * from \"./indexOfArray\";\nexport * from \"./isArray\";\nexport * from \"./last\";\nexport * from \"./lastN\";\nexport * from \"./map\";\nexport * from \"./maxN\";\nexport * from \"./minN\";\nexport * from \"./nin\";\nexport * from \"./range\";\nexport * from \"./reduce\";\nexport * from \"./reverseArray\";\nexport * from \"./size\";\nexport * from \"./slice\";\nexport * from \"./sortArray\";\nexport * from \"./zip\";\n","import { computeValue } from \"../../../core\";\nimport { assert, isArray, isEqual, isNil } from \"../../../util\";\nconst $indexOfArray = (obj, expr, options) => {\n  const args = computeValue(obj, expr, null, options);\n  if (isNil(args)) return null;\n  let arr = args[0];\n  const searchValue = args[1];\n  if (isNil(arr)) return null;\n  assert(isArray(arr), \"$indexOfArray expression must resolve to an array.\");\n  const start = args[2] || 0;\n  let end = args[3];\n  if (isNil(end)) end = arr.length;\n  if (start > end) return -1;\n  assert(start >= 0 && end >= 0, \"$indexOfArray expression is invalid\");\n  if (start > 0 || end < arr.length) {\n    arr = arr.slice(start, end);\n  }\n  let index = -1;\n  arr.some((v, i) => {\n    const b = isEqual(v, searchValue);\n    if (b) index = i;\n    return b;\n  });\n  return index + start;\n};\nexport {\n  $indexOfArray\n};\n","import { computeValue } from \"../../../core\";\nimport { isArray } from \"../../../util\";\nconst $isArray = (obj, expr, options) => isArray(computeValue(obj, expr[0], null, options));\nexport {\n  $isArray\n};\n","import { computeValue } from \"../../../core\";\nimport { assert, flatten, isArray, isNil } from \"../../../util\";\nimport { $last as __last } from \"../../accumulator/last\";\nconst $last = (obj, expr, options) => {\n  if (isArray(obj)) return __last(obj, expr, options);\n  const arr = computeValue(obj, expr, null, options);\n  if (isNil(arr)) return null;\n  assert(\n    isArray(arr) && arr.length > 0,\n    \"$last must resolve to a non-empty array.\"\n  );\n  return flatten(arr)[arr.length - 1];\n};\nexport {\n  $last\n};\n","import { computeValue } from \"../../../core\";\nimport { assert, isArray, isNil } from \"../../../util\";\nimport { $lastN as __lastN } from \"../../accumulator/lastN\";\nconst $lastN = (obj, expr, options) => {\n  if (isArray(obj)) return __lastN(obj, expr, options);\n  const { input, n } = computeValue(obj, expr, null, options);\n  if (isNil(input)) return null;\n  assert(isArray(input), \"Must resolve to an array/null or missing\");\n  return __lastN(input, { n, input: \"$$this\" }, options);\n};\nexport {\n  $lastN\n};\n","import {\n  ComputeOptions,\n  computeValue\n} from \"../../../core\";\nimport { assert, isArray, isNil } from \"../../../util\";\nconst $map = (obj, expr, options) => {\n  const input = computeValue(obj, expr.input, null, options);\n  if (isNil(input)) return null;\n  assert(isArray(input), `$map 'input' expression must resolve to an array`);\n  const copts = ComputeOptions.init(options);\n  const k = expr.as || \"this\";\n  return input.map((o) => {\n    return computeValue(\n      obj,\n      expr.in,\n      null,\n      copts.update(copts.root, {\n        variables: { [k]: o }\n      })\n    );\n  });\n};\nexport {\n  $map\n};\n","import { computeValue } from \"../../../core\";\nimport { assert, isArray, isNil } from \"../../../util\";\nimport { $maxN as __maxN } from \"../../accumulator/maxN\";\nconst $maxN = (obj, expr, options) => {\n  if (isArray(obj)) return __maxN(obj, expr, options);\n  const { input, n } = computeValue(obj, expr, null, options);\n  if (isNil(input)) return null;\n  assert(isArray(input), \"Must resolve to an array/null or missing\");\n  return __maxN(input, { n, input: \"$$this\" }, options);\n};\nexport {\n  $maxN\n};\n","import { computeValue } from \"../../../core\";\nimport { assert, isArray, isNil } from \"../../../util\";\nimport { $minN as __minN } from \"../../accumulator/minN\";\nconst $minN = (obj, expr, options) => {\n  if (isArray(obj)) return __minN(obj, expr, options);\n  const { input, n } = computeValue(obj, expr, null, options);\n  if (isNil(input)) return null;\n  assert(isArray(input), \"Must resolve to an array/null or missing\");\n  return __minN(input, { n, input: \"$$this\" }, options);\n};\nexport {\n  $minN\n};\n","import { $nin as __nin, createExpressionOperator } from \"../../_predicates\";\nconst $nin = createExpressionOperator(__nin);\nexport {\n  $nin\n};\n","import { computeValue } from \"../../../core\";\nconst $range = (obj, expr, options) => {\n  const arr = computeValue(obj, expr, null, options);\n  const start = arr[0];\n  const end = arr[1];\n  const step = arr[2] || 1;\n  const result = new Array();\n  let counter = start;\n  while (counter < end && step > 0 || counter > end && step < 0) {\n    result.push(counter);\n    counter += step;\n  }\n  return result;\n};\nexport {\n  $range\n};\n","import {\n  ComputeOptions,\n  computeValue\n} from \"../../../core\";\nimport { assert, isArray, isNil } from \"../../../util\";\nconst $reduce = (obj, expr, options) => {\n  const copts = ComputeOptions.init(options);\n  const input = computeValue(obj, expr.input, null, copts);\n  const initialValue = computeValue(obj, expr.initialValue, null, copts);\n  const inExpr = expr[\"in\"];\n  if (isNil(input)) return null;\n  assert(isArray(input), \"$reduce 'input' expression must resolve to an array\");\n  return input.reduce((acc, n) => {\n    return computeValue(\n      n,\n      inExpr,\n      null,\n      copts.update(copts.root, {\n        variables: { value: acc }\n      })\n    );\n  }, initialValue);\n};\nexport {\n  $reduce\n};\n","import { computeValue } from \"../../../core\";\nimport { assert, isArray, isNil } from \"../../../util\";\nconst $reverseArray = (obj, expr, options) => {\n  const arr = computeValue(obj, expr, null, options);\n  if (isNil(arr)) return null;\n  assert(isArray(arr), \"$reverseArray expression must resolve to an array\");\n  const result = arr.slice(0);\n  result.reverse();\n  return result;\n};\nexport {\n  $reverseArray\n};\n","import { computeValue } from \"../../../core\";\nimport { isArray } from \"../../../util\";\nconst $size = (obj, expr, options) => {\n  const value = computeValue(obj, expr, null, options);\n  return isArray(value) ? value.length : void 0;\n};\nexport {\n  $size\n};\n","import { computeValue } from \"../../../core\";\nimport { assert, isNil } from \"../../../util\";\nconst $slice = (obj, expr, options) => {\n  const args = computeValue(obj, expr, null, options);\n  const arr = args[0];\n  let skip = args[1];\n  let limit = args[2];\n  if (isNil(limit)) {\n    if (skip < 0) {\n      skip = Math.max(0, arr.length + skip);\n    } else {\n      limit = skip;\n      skip = 0;\n    }\n  } else {\n    if (skip < 0) {\n      skip = Math.max(0, arr.length + skip);\n    }\n    assert(\n      limit > 0,\n      `Invalid argument for $slice operator. Limit must be a positive number`\n    );\n    limit += skip;\n  }\n  return arr.slice(skip, limit);\n};\nexport {\n  $slice\n};\n","import { computeValue } from \"../../../core\";\nimport { Lazy } from \"../../../lazy\";\nimport { assert, compare, isArray, isNil, isObject } from \"../../../util\";\nimport { $sort } from \"../../pipeline/sort\";\nconst $sortArray = (obj, expr, options) => {\n  const { input, sortBy } = computeValue(obj, expr, null, options);\n  if (isNil(input)) return null;\n  assert(isArray(input), \"$sortArray expression must resolve to an array\");\n  if (isObject(sortBy)) {\n    return $sort(Lazy(input), sortBy, options).value();\n  }\n  const result = [...input];\n  result.sort(compare);\n  if (sortBy === -1) result.reverse();\n  return result;\n};\nexport {\n  $sortArray\n};\n","import { computeValue } from \"../../../core\";\nimport { assert, isArray, isBoolean, isNil } from \"../../../util\";\nconst $zip = (obj, expr, options) => {\n  const inputs = computeValue(obj, expr.inputs, null, options);\n  const useLongestLength = expr.useLongestLength || false;\n  if (isNil(inputs)) return null;\n  assert(isArray(inputs), \"'inputs' expression must resolve to an array\");\n  assert(isBoolean(useLongestLength), \"'useLongestLength' must be a boolean\");\n  if (isArray(expr.defaults)) {\n    assert(\n      useLongestLength,\n      \"'useLongestLength' must be set to true to use 'defaults'\"\n    );\n  }\n  let zipCount = 0;\n  for (const arr of inputs) {\n    if (isNil(arr)) return null;\n    assert(\n      isArray(arr),\n      \"'inputs' expression values must resolve to an array or null\"\n    );\n    zipCount = useLongestLength ? Math.max(zipCount, arr.length) : Math.min(zipCount || arr.length, arr.length);\n  }\n  const result = [];\n  const defaults = expr.defaults || [];\n  for (let i = 0; i < zipCount; i++) {\n    const temp = inputs.map((val, index) => {\n      return isNil(val[i]) ? defaults[index] || null : val[i];\n    });\n    result.push(temp);\n  }\n  return result;\n};\nexport {\n  $zip\n};\n","import { computeValue } from \"../../../core\";\nimport { assert, isArray, isNil, isNumber } from \"../../../util\";\nconst bitwise = (op, compute) => (obj, expr, options) => {\n  assert(isArray(expr), `${op}: expression must be an array.`);\n  const nums = computeValue(obj, expr, null, options);\n  if (nums.some(isNil)) return null;\n  assert(\n    nums.every(isNumber),\n    `${op}: expression must evalue to array of numbers.`\n  );\n  return compute(nums);\n};\nexport {\n  bitwise\n};\n","import { bitwise } from \"./_internal\";\nconst $bitAnd = bitwise(\n  \"$bitAnd\",\n  (nums) => nums.reduce((a, b) => a & b, -1)\n);\nexport {\n  $bitAnd\n};\n","import { computeValue } from \"../../../core\";\nimport { isNil, isNumber, MingoError } from \"../../../util\";\nconst $bitNot = (obj, expr, options) => {\n  const n = computeValue(obj, expr, null, options);\n  if (isNil(n)) return null;\n  if (isNumber(n)) return ~n;\n  throw new MingoError(\"$bitNot: expression must evaluate to a number.\");\n};\nexport {\n  $bitNot\n};\n","import { bitwise } from \"./_internal\";\nconst $bitOr = bitwise(\n  \"$bitOr\",\n  (nums) => nums.reduce((a, b) => a | b, 0)\n);\nexport {\n  $bitOr\n};\n","import { bitwise } from \"./_internal\";\nconst $bitXor = bitwise(\n  \"$bitXor\",\n  (nums) => nums.reduce((a, b) => a ^ b, 0)\n);\nexport {\n  $bitXor\n};\n","export * from \"./bitAnd\";\nexport * from \"./bitNot\";\nexport * from \"./bitOr\";\nexport * from \"./bitXor\";\n","import { computeValue } from \"../../../core\";\nimport { truthy } from \"../../../util\";\nconst $and = (obj, expr, options) => {\n  const value = computeValue(obj, expr, null, options);\n  return truthy(value, options.useStrictMode) && value.every((v) => truthy(v, options.useStrictMode));\n};\nexport {\n  $and\n};\n","export * from \"./and\";\nexport * from \"./not\";\nexport * from \"./or\";\n","import { computeValue } from \"../../../core\";\nimport { assert, ensureArray } from \"../../../util\";\nconst $not = (obj, expr, options) => {\n  const booleanExpr = ensureArray(expr);\n  if (booleanExpr.length == 0) return false;\n  assert(booleanExpr.length == 1, \"Expression $not takes exactly 1 argument\");\n  return !computeValue(obj, booleanExpr[0], null, options);\n};\nexport {\n  $not\n};\n","import { computeValue } from \"../../../core\";\nimport { truthy } from \"../../../util\";\nconst $or = (obj, expr, options) => {\n  const value = computeValue(obj, expr, null, options);\n  const strict = options.useStrictMode;\n  return truthy(value, strict) && value.some((v) => truthy(v, strict));\n};\nexport {\n  $or\n};\n","import { computeValue } from \"../../../core\";\nimport { assert, compare, isArray } from \"../../../util\";\nconst $cmp = (obj, expr, options) => {\n  const args = computeValue(obj, expr, null, options);\n  assert(\n    isArray(args) && args.length == 2,\n    \"$cmp: expression must resolve to array of size 2.\"\n  );\n  return compare(args[0], args[1]);\n};\nexport {\n  $cmp\n};\n","import { $eq as __eq, createExpressionOperator } from \"../../_predicates\";\nconst $eq = createExpressionOperator(__eq);\nexport {\n  $eq\n};\n","import { $gt as __gt, createExpressionOperator } from \"../../_predicates\";\nconst $gt = createExpressionOperator(__gt);\nexport {\n  $gt\n};\n","import { $gte as __gte, createExpressionOperator } from \"../../_predicates\";\nconst $gte = createExpressionOperator(__gte);\nexport {\n  $gte\n};\n","export * from \"./cmp\";\nexport * from \"./eq\";\nexport * from \"./gt\";\nexport * from \"./gte\";\nexport * from \"./lt\";\nexport * from \"./lte\";\nexport * from \"./ne\";\n","import { $lt as __lt, createExpressionOperator } from \"../../_predicates\";\nconst $lt = createExpressionOperator(__lt);\nexport {\n  $lt\n};\n","import { $lte as __lte, createExpressionOperator } from \"../../_predicates\";\nconst $lte = createExpressionOperator(__lte);\nexport {\n  $lte\n};\n","import { $ne as __ne, createExpressionOperator } from \"../../_predicates\";\nconst $ne = createExpressionOperator(__ne);\nexport {\n  $ne\n};\n","import { computeValue } from \"../../../core\";\nimport { assert, isArray, isObject, truthy } from \"../../../util\";\nconst $cond = (obj, expr, options) => {\n  let ifExpr;\n  let thenExpr;\n  let elseExpr;\n  const errorMsg = \"$cond: invalid arguments\";\n  if (isArray(expr)) {\n    assert(expr.length === 3, errorMsg);\n    ifExpr = expr[0];\n    thenExpr = expr[1];\n    elseExpr = expr[2];\n  } else {\n    assert(isObject(expr), errorMsg);\n    ifExpr = expr.if;\n    thenExpr = expr.then;\n    elseExpr = expr.else;\n  }\n  const condition = truthy(\n    computeValue(obj, ifExpr, null, options),\n    options.useStrictMode\n  );\n  return computeValue(obj, condition ? thenExpr : elseExpr, null, options);\n};\nexport {\n  $cond\n};\n","import { computeValue } from \"../../../core\";\nimport { isNil } from \"../../../util\";\nconst $ifNull = (obj, expr, options) => {\n  const args = computeValue(obj, expr, null, options);\n  return args.find((arg) => !isNil(arg)) ?? args[args.length - 1];\n};\nexport {\n  $ifNull\n};\n","export * from \"./cond\";\nexport * from \"./ifNull\";\nexport * from \"./switch\";\n","import { computeValue } from \"../../../core\";\nimport { truthy } from \"../../../util\";\nconst $switch = (obj, expr, options) => {\n  let thenExpr = null;\n  expr.branches.some((b) => {\n    const condition = truthy(\n      computeValue(obj, b.case, null, options),\n      options.useStrictMode\n    );\n    if (condition) thenExpr = b.then;\n    return condition;\n  });\n  return computeValue(\n    obj,\n    thenExpr !== null ? thenExpr : expr.default,\n    null,\n    options\n  );\n};\nexport {\n  $switch\n};\n","import { computeValue } from \"../../../core\";\nimport { assert } from \"../../../util\";\nconst $function = (obj, expr, options) => {\n  assert(\n    options.scriptEnabled,\n    \"$function operator requires 'scriptEnabled' option to be true\"\n  );\n  const fn = computeValue(obj, expr, null, options);\n  return fn.body.apply(null, fn.args);\n};\nexport {\n  $function\n};\n","export * from \"./function\";\n","import { computeValue } from \"../../../core\";\nimport { isDate, isNil, isNumber, MingoError } from \"../../../util\";\nconst LEAP_YEAR_REF_POINT = -1e9;\nconst DAYS_PER_WEEK = 7;\nconst isLeapYear = (y) => (y & 3) == 0 && (y % 100 != 0 || y % 400 == 0);\nconst DAYS_IN_YEAR = [\n  365,\n  366\n  /*leap*/\n];\nconst daysInYear = (year) => DAYS_IN_YEAR[+isLeapYear(year)];\nconst DAYS_IN_MONTH = [31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31];\nconst daysInMonth = (d) => DAYS_IN_MONTH[d.getUTCMonth()] + Number(\n  d.getUTCMonth() === 1 && isLeapYear(d.getUTCFullYear())\n);\nconst YEAR_DAYS_OFFSET = [\n  [0, 31, 59, 90, 120, 151, 181, 212, 243, 273, 304, 334],\n  [0, 31, 60, 91, 121, 152, 182, 213, 244, 274, 305, 335]\n  /*leap*/\n];\nconst dayOfYear = (d) => YEAR_DAYS_OFFSET[+isLeapYear(d.getUTCFullYear())][d.getUTCMonth()] + d.getUTCDate();\nconst isoWeekday = (date, startOfWeek = \"sun\") => {\n  const dow = date.getUTCDay() || 7;\n  return (dow - ISO_WEEKDAY_MAP[startOfWeek] + DAYS_PER_WEEK) % DAYS_PER_WEEK;\n};\nconst p = (y) => (y + Math.floor(y / 4) - Math.floor(y / 100) + Math.floor(y / 400)) % 7;\nconst weeks = (y) => 52 + Number(p(y) == 4 || p(y - 1) == 3);\nfunction isoWeek(d) {\n  const dow = d.getUTCDay() || 7;\n  const w = Math.floor((10 + dayOfYear(d) - dow) / 7);\n  if (w < 1) return weeks(d.getUTCFullYear() - 1);\n  if (w > weeks(d.getUTCFullYear())) return 1;\n  return w;\n}\nfunction isoWeekYear(d) {\n  return d.getUTCFullYear() - Number(d.getUTCMonth() === 0 && d.getUTCDate() == 1 && d.getUTCDay() < 1);\n}\nconst MINUTES_PER_HOUR = 60;\nconst MILLIS_PER_DAY = 1e3 * 60 * 60 * 24;\nconst TIMEUNIT_IN_MILLIS = {\n  week: MILLIS_PER_DAY * DAYS_PER_WEEK,\n  day: MILLIS_PER_DAY,\n  hour: 1e3 * 60 * 60,\n  minute: 1e3 * 60,\n  second: 1e3,\n  millisecond: 1\n};\nconst DAYS_OF_WEEK = [\n  \"monday\",\n  \"mon\",\n  \"tuesday\",\n  \"tue\",\n  \"wednesday\",\n  \"wed\",\n  \"thursday\",\n  \"thu\",\n  \"friday\",\n  \"fri\",\n  \"saturday\",\n  \"sat\",\n  \"sunday\",\n  \"sun\"\n];\nconst DAYS_OF_WEEK_SET = new Set(DAYS_OF_WEEK);\nconst ISO_WEEKDAY_MAP = Object.freeze({\n  mon: 1,\n  tue: 2,\n  wed: 3,\n  thu: 4,\n  fri: 5,\n  sat: 6,\n  sun: 7\n});\nconst DATE_FORMAT = \"%Y-%m-%dT%H:%M:%S.%LZ\";\nconst DATE_PART_INTERVAL = [\n  [\"year\", 0, 9999],\n  [\"month\", 1, 12],\n  [\"day\", 1, 31],\n  [\"hour\", 0, 23],\n  [\"minute\", 0, 59],\n  [\"second\", 0, 59],\n  [\"millisecond\", 0, 999]\n];\nconst DATE_SYM_TABLE = Object.freeze({\n  \"%Y\": { name: \"year\", padding: 4, re: /([0-9]{4})/ },\n  \"%G\": { name: \"year\", padding: 4, re: /([0-9]{4})/ },\n  \"%m\": { name: \"month\", padding: 2, re: /(0[1-9]|1[012])/ },\n  \"%d\": { name: \"day\", padding: 2, re: /(0[1-9]|[12][0-9]|3[01])/ },\n  \"%H\": { name: \"hour\", padding: 2, re: /([01][0-9]|2[0-3])/ },\n  \"%M\": { name: \"minute\", padding: 2, re: /([0-5][0-9])/ },\n  \"%S\": { name: \"second\", padding: 2, re: /([0-5][0-9]|60)/ },\n  \"%L\": { name: \"millisecond\", padding: 3, re: /([0-9]{3})/ },\n  \"%u\": { name: \"weekday\", padding: 1, re: /([1-7])/ },\n  \"%U\": { name: \"week\", padding: 2, re: /([1-4][0-9]?|5[0-3]?)/ },\n  \"%V\": { name: \"isoWeek\", padding: 2, re: /([1-4][0-9]?|5[0-3]?)/ },\n  \"%z\": {\n    name: \"timezone\",\n    padding: 2,\n    re: /(([+-][01][0-9]|2[0-3]):?([0-5][0-9])?)/\n  },\n  \"%Z\": { name: \"minuteOffset\", padding: 3, re: /([+-][0-9]{3})/ }\n  // \"%%\": \"%\",\n});\nconst TIMEZONE_RE = /^[a-zA-Z_]+\\/[a-zA-Z_]+$/;\nfunction parseTimezone(tzstr) {\n  if (isNil(tzstr)) return 0;\n  if (TIMEZONE_RE.test(tzstr)) {\n    const date = /* @__PURE__ */ new Date();\n    const utcDate = new Date(date.toLocaleString(\"en-US\", { timeZone: \"UTC\" }));\n    const tzDate = new Date(date.toLocaleString(\"en-US\", { timeZone: tzstr }));\n    return (tzDate.getTime() - utcDate.getTime()) / 6e4;\n  }\n  const m = DATE_SYM_TABLE[\"%z\"].re.exec(tzstr);\n  if (!m) {\n    throw new MingoError(`Timezone '${tzstr}' is invalid or not supported`);\n  }\n  const hr = parseInt(m[2]) || 0;\n  const min = parseInt(m[3]) || 0;\n  return (Math.abs(hr * MINUTES_PER_HOUR) + min) * (hr < 0 ? -1 : 1);\n}\nfunction formatTimezone(minuteOffset) {\n  return (minuteOffset < 0 ? \"-\" : \"+\") + padDigits(Math.abs(Math.floor(minuteOffset / MINUTES_PER_HOUR)), 2) + padDigits(Math.abs(minuteOffset) % MINUTES_PER_HOUR, 2);\n}\nfunction adjustDate(d, minuteOffset) {\n  d.setUTCMinutes(d.getUTCMinutes() + minuteOffset);\n}\nfunction computeDate(obj, expr, options) {\n  if (isDate(obj)) return obj;\n  const d = computeValue(obj, expr, null, options);\n  if (isDate(d)) return new Date(d);\n  if (isNumber(d)) return new Date(d * 1e3);\n  if (d.date) {\n    const date = isDate(d.date) ? new Date(d.date) : new Date(d.date * 1e3);\n    if (d.timezone) {\n      adjustDate(date, parseTimezone(d.timezone));\n    }\n    return date;\n  }\n  throw Error(`cannot convert ${JSON.stringify(expr)} to date`);\n}\nfunction padDigits(n, digits) {\n  return new Array(Math.max(digits - String(n).length + 1, 0)).join(\"0\") + n.toString();\n}\nconst leapYearsSinceReferencePoint = (year) => {\n  const yearsSinceReferencePoint = year - LEAP_YEAR_REF_POINT;\n  return Math.trunc(yearsSinceReferencePoint / 4) - Math.trunc(yearsSinceReferencePoint / 100) + Math.trunc(yearsSinceReferencePoint / 400);\n};\nfunction daysBetweenYears(startYear, endYear) {\n  return Math.trunc(\n    leapYearsSinceReferencePoint(endYear - 1) - leapYearsSinceReferencePoint(startYear - 1) + (endYear - startYear) * DAYS_IN_YEAR[0]\n  );\n}\nconst dateDiffYear = (start, end) => end.getUTCFullYear() - start.getUTCFullYear();\nconst dateDiffMonth = (start, end) => end.getUTCMonth() - start.getUTCMonth() + dateDiffYear(start, end) * 12;\nconst dateDiffQuarter = (start, end) => {\n  const a = Math.trunc(start.getUTCMonth() / 3);\n  const b = Math.trunc(end.getUTCMonth() / 3);\n  return b - a + dateDiffYear(start, end) * 4;\n};\nconst dateDiffDay = (start, end) => dayOfYear(end) - dayOfYear(start) + daysBetweenYears(start.getUTCFullYear(), end.getUTCFullYear());\nconst dateDiffWeek = (start, end, startOfWeek) => {\n  const wk = (startOfWeek || \"sun\").substring(0, 3);\n  return Math.trunc(\n    (dateDiffDay(start, end) + isoWeekday(start, wk) - isoWeekday(end, wk)) / DAYS_PER_WEEK\n  );\n};\nconst dateDiffHour = (start, end) => end.getUTCHours() - start.getUTCHours() + dateDiffDay(start, end) * 24;\nconst addMonth = (d, amount) => {\n  const m = d.getUTCMonth() + amount;\n  const yearOffset = Math.floor(m / 12);\n  if (m < 0) {\n    const month = m % 12 + 12;\n    d.setUTCFullYear(d.getUTCFullYear() + yearOffset, month, d.getUTCDate());\n  } else {\n    d.setUTCFullYear(d.getUTCFullYear() + yearOffset, m % 12, d.getUTCDate());\n  }\n};\nconst dateAdd = (date, unit, amount, _timezone) => {\n  const d = new Date(date);\n  switch (unit) {\n    case \"year\":\n      d.setUTCFullYear(d.getUTCFullYear() + amount);\n      break;\n    case \"quarter\":\n      addMonth(d, 3 * amount);\n      break;\n    case \"month\":\n      addMonth(d, amount);\n      break;\n    default:\n      d.setTime(d.getTime() + TIMEUNIT_IN_MILLIS[unit] * amount);\n  }\n  return d;\n};\nexport {\n  DATE_FORMAT,\n  DATE_PART_INTERVAL,\n  DATE_SYM_TABLE,\n  DAYS_OF_WEEK,\n  DAYS_OF_WEEK_SET,\n  DAYS_PER_WEEK,\n  LEAP_YEAR_REF_POINT,\n  MILLIS_PER_DAY,\n  MINUTES_PER_HOUR,\n  TIMEUNIT_IN_MILLIS,\n  adjustDate,\n  computeDate,\n  dateAdd,\n  dateDiffDay,\n  dateDiffHour,\n  dateDiffMonth,\n  dateDiffQuarter,\n  dateDiffWeek,\n  dateDiffYear,\n  dayOfYear,\n  daysBetweenYears,\n  daysInMonth,\n  daysInYear,\n  formatTimezone,\n  isLeapYear,\n  isoWeek,\n  isoWeekYear,\n  isoWeekday,\n  padDigits,\n  parseTimezone\n};\n","import { computeValue } from \"../../../core\";\nimport { dateAdd } from \"./_internal\";\nconst $dateAdd = (obj, expr, options) => {\n  const args = computeValue(obj, expr, null, options);\n  return dateAdd(args.startDate, args.unit, args.amount, args.timezone);\n};\nexport {\n  $dateAdd\n};\n","import { computeValue } from \"../../../core\";\nimport {\n  adjustDate,\n  dateDiffDay,\n  dateDiffHour,\n  dateDiffMonth,\n  dateDiffQuarter,\n  dateDiffWeek,\n  dateDiffYear,\n  parseTimezone,\n  TIMEUNIT_IN_MILLIS\n} from \"./_internal\";\nconst $dateDiff = (obj, expr, options) => {\n  const { startDate, endDate, unit, timezone, startOfWeek } = computeValue(\n    obj,\n    expr,\n    null,\n    options\n  );\n  const d1 = new Date(startDate);\n  const d2 = new Date(endDate);\n  const minuteOffset = parseTimezone(timezone);\n  adjustDate(d1, minuteOffset);\n  adjustDate(d2, minuteOffset);\n  switch (unit) {\n    case \"year\":\n      return dateDiffYear(d1, d2);\n    case \"quarter\":\n      return dateDiffQuarter(d1, d2);\n    case \"month\":\n      return dateDiffMonth(d1, d2);\n    case \"week\":\n      return dateDiffWeek(d1, d2, startOfWeek);\n    case \"day\":\n      return dateDiffDay(d1, d2);\n    case \"hour\":\n      return dateDiffHour(d1, d2);\n    case \"minute\":\n      d1.setUTCSeconds(0);\n      d1.setUTCMilliseconds(0);\n      d2.setUTCSeconds(0);\n      d2.setUTCMilliseconds(0);\n      return Math.round(\n        (d2.getTime() - d1.getTime()) / TIMEUNIT_IN_MILLIS[unit]\n      );\n    default:\n      return Math.round(\n        (d2.getTime() - d1.getTime()) / TIMEUNIT_IN_MILLIS[unit]\n      );\n  }\n};\nexport {\n  $dateDiff\n};\n","import { computeValue } from \"../../../core\";\nimport {\n  DATE_PART_INTERVAL,\n  isLeapYear,\n  MINUTES_PER_HOUR,\n  parseTimezone\n} from \"./_internal\";\nconst DAYS_IN_MONTH = [31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31];\nconst getDaysInMonth = (date) => {\n  return date.month == 2 && isLeapYear(date.year) ? 29 : DAYS_IN_MONTH[date.month - 1];\n};\nconst $dateFromParts = (obj, expr, options) => {\n  const args = computeValue(obj, expr, null, options);\n  const minuteOffset = parseTimezone(args.timezone);\n  for (let i = DATE_PART_INTERVAL.length - 1, remainder = 0; i >= 0; i--) {\n    const datePartInterval = DATE_PART_INTERVAL[i];\n    const k = datePartInterval[0];\n    const min = datePartInterval[1];\n    const max = datePartInterval[2];\n    let part = (args[k] || 0) + remainder;\n    remainder = 0;\n    const limit = max + 1;\n    if (k == \"hour\") part += Math.floor(minuteOffset / MINUTES_PER_HOUR) * -1;\n    if (k == \"minute\") part += minuteOffset % MINUTES_PER_HOUR * -1;\n    if (part < min) {\n      const delta = min - part;\n      remainder = -1 * Math.ceil(delta / limit);\n      part = limit - delta % limit;\n    } else if (part > max) {\n      part += min;\n      remainder = Math.trunc(part / limit);\n      part %= limit;\n    }\n    args[k] = part;\n  }\n  args.day = Math.min(args.day, getDaysInMonth(args));\n  return new Date(\n    Date.UTC(\n      args.year,\n      args.month - 1,\n      args.day,\n      args.hour,\n      args.minute,\n      args.second,\n      args.millisecond\n    )\n  );\n};\nexport {\n  $dateFromParts\n};\n","import { computeValue } from \"../../../core\";\nimport { assert, isNil, isObject } from \"../../../util\";\nimport {\n  adjustDate,\n  DATE_FORMAT,\n  DATE_SYM_TABLE,\n  MINUTES_PER_HOUR,\n  parseTimezone\n} from \"./_internal\";\nconst buildMap = (letters, sign) => {\n  const h = {};\n  letters.split(\"\").forEach((v, i) => h[v] = sign * (i + 1));\n  return h;\n};\nconst TZ_LETTER_OFFSETS = {\n  ...buildMap(\"ABCDEFGHIKLM\", 1),\n  ...buildMap(\"NOPQRSTUVWXY\", -1),\n  Z: 0\n};\nconst regexStrip = (s) => s.replace(/^\\//, \"\").replace(/\\/$/, \"\");\nconst REGEX_SPECIAL_CHARS = [\"^\", \".\", \"-\", \"*\", \"?\", \"$\"];\nconst regexQuote = (s) => {\n  REGEX_SPECIAL_CHARS.forEach((c) => {\n    s = s.replace(c, `\\\\${c}`);\n  });\n  return s;\n};\nconst $dateFromString = (obj, expr, options) => {\n  const args = computeValue(obj, expr, null, options);\n  args.format = args.format || DATE_FORMAT;\n  args.onNull = args.onNull || null;\n  let dateString = args.dateString;\n  if (isNil(dateString)) return args.onNull;\n  const separators = args.format.split(/%[YGmdHMSLuVzZ]/);\n  separators.reverse();\n  const matches = args.format.match(\n    /(%%|%Y|%G|%m|%d|%H|%M|%S|%L|%u|%V|%z|%Z)/g\n  );\n  const dateParts = {};\n  let expectedPattern = \"\";\n  for (let i = 0, len = matches.length; i < len; i++) {\n    const formatSpecifier = matches[i];\n    const props = DATE_SYM_TABLE[formatSpecifier];\n    if (isObject(props)) {\n      const m2 = props.re.exec(dateString);\n      const delimiter = separators.pop() || \"\";\n      if (m2 !== null) {\n        dateParts[props.name] = /^\\d+$/.exec(m2[0]) ? parseInt(m2[0]) : m2[0];\n        dateString = dateString.substr(0, m2.index) + dateString.substr(m2.index + m2[0].length);\n        expectedPattern += regexQuote(delimiter) + regexStrip(props.re.toString());\n      } else {\n        dateParts[props.name] = null;\n      }\n    }\n  }\n  if (isNil(dateParts.year) || isNil(dateParts.month) || isNil(dateParts.day) || !new RegExp(\"^\" + expectedPattern + \"[A-Z]?$\").exec(args.dateString)) {\n    return args.onError;\n  }\n  const m = args.dateString.match(/([A-Z])$/);\n  assert(\n    // only one of in-date timeone or timezone argument but not both.\n    !(m && args.timezone),\n    `$dateFromString: you cannot pass in a date/time string with time zone information ('${m && m[0]}') together with a timezone argument`\n  );\n  const minuteOffset = m ? TZ_LETTER_OFFSETS[m[0]] * MINUTES_PER_HOUR : parseTimezone(args.timezone);\n  const d = new Date(\n    Date.UTC(dateParts.year, dateParts.month - 1, dateParts.day, 0, 0, 0)\n  );\n  if (!isNil(dateParts.hour)) d.setUTCHours(dateParts.hour);\n  if (!isNil(dateParts.minute)) d.setUTCMinutes(dateParts.minute);\n  if (!isNil(dateParts.second)) d.setUTCSeconds(dateParts.second);\n  if (!isNil(dateParts.millisecond))\n    d.setUTCMilliseconds(dateParts.millisecond);\n  adjustDate(d, -minuteOffset);\n  return d;\n};\nexport {\n  $dateFromString\n};\n","import { computeValue } from \"../../../core\";\nimport { $dateAdd } from \"./dateAdd\";\nconst $dateSubtract = (obj, expr, options) => {\n  const amount = computeValue(obj, expr?.amount, null, options);\n  return $dateAdd(obj, { ...expr, amount: -1 * amount }, options);\n};\nexport {\n  $dateSubtract\n};\n","import { computeValue } from \"../../../core\";\nimport { adjustDate, isoWeek, isoWeekYear, parseTimezone } from \"./_internal\";\nconst $dateToParts = (obj, expr, options) => {\n  const args = computeValue(obj, expr, null, options);\n  const d = new Date(args.date);\n  const tz = parseTimezone(args.timezone);\n  adjustDate(d, tz);\n  const timePart = {\n    hour: d.getUTCHours(),\n    minute: d.getUTCMinutes(),\n    second: d.getUTCSeconds(),\n    millisecond: d.getUTCMilliseconds()\n  };\n  if (args.iso8601 == true) {\n    return Object.assign(timePart, {\n      isoWeekYear: isoWeekYear(d),\n      isoWeek: isoWeek(d),\n      isoDayOfWeek: d.getUTCDay() || 7\n    });\n  }\n  return Object.assign(timePart, {\n    year: d.getUTCFullYear(),\n    month: d.getUTCMonth() + 1,\n    day: d.getUTCDate()\n  });\n};\nexport {\n  $dateToParts\n};\n","import { computeValue } from \"../../../core\";\nimport { assert, isNil, isObject } from \"../../../util\";\nimport {\n  adjustDate,\n  computeDate,\n  DATE_FORMAT,\n  DATE_SYM_TABLE,\n  formatTimezone,\n  padDigits,\n  parseTimezone\n} from \"./_internal\";\nimport { $dayOfMonth } from \"./dayOfMonth\";\nimport { $hour } from \"./hour\";\nimport { $isoDayOfWeek } from \"./isoDayOfWeek\";\nimport { $isoWeek } from \"./isoWeek\";\nimport { $millisecond } from \"./millisecond\";\nimport { $minute } from \"./minute\";\nimport { $month } from \"./month\";\nimport { $second } from \"./second\";\nimport { $week } from \"./week\";\nimport { $year } from \"./year\";\nconst DATE_FUNCTIONS = {\n  \"%Y\": $year,\n  \"%G\": $year,\n  \"%m\": $month,\n  \"%d\": $dayOfMonth,\n  \"%H\": $hour,\n  \"%M\": $minute,\n  \"%S\": $second,\n  \"%L\": $millisecond,\n  \"%u\": $isoDayOfWeek,\n  \"%U\": $week,\n  \"%V\": $isoWeek\n};\nconst $dateToString = (obj, expr, options) => {\n  const args = computeValue(obj, expr, null, options);\n  if (isNil(args.onNull)) args.onNull = null;\n  if (isNil(args.date)) return args.onNull;\n  const date = computeDate(obj, args.date, options);\n  let format = args.format || DATE_FORMAT;\n  const minuteOffset = parseTimezone(args.timezone);\n  const matches = format.match(/(%%|%Y|%G|%m|%d|%H|%M|%S|%L|%u|%U|%V|%z|%Z)/g);\n  adjustDate(date, minuteOffset);\n  for (let i = 0, len = matches.length; i < len; i++) {\n    const formatSpecifier = matches[i];\n    const props = DATE_SYM_TABLE[formatSpecifier];\n    const operatorFn = DATE_FUNCTIONS[formatSpecifier];\n    let value;\n    if (isObject(props)) {\n      if (props.name === \"timezone\") {\n        value = formatTimezone(minuteOffset);\n      } else if (props.name === \"minuteOffset\") {\n        value = minuteOffset.toString();\n      } else {\n        assert(\n          !!operatorFn,\n          `unsupported date format specifier '${formatSpecifier}'`\n        );\n        value = padDigits(operatorFn(obj, date, options), props.padding);\n      }\n    }\n    format = format.replace(formatSpecifier, value);\n  }\n  return format;\n};\nexport {\n  $dateToString\n};\n","import { computeValue } from \"../../../core\";\nimport { TIME_UNITS } from \"../../../types\";\nimport { assert, isDate, isNil } from \"../../../util\";\nimport {\n  adjustDate,\n  dateAdd,\n  dateDiffDay,\n  dateDiffMonth,\n  dateDiffQuarter,\n  dateDiffWeek,\n  dateDiffYear,\n  DAYS_OF_WEEK_SET,\n  DAYS_PER_WEEK,\n  isoWeekday,\n  parseTimezone,\n  TIMEUNIT_IN_MILLIS\n} from \"./_internal\";\nconst REF_DATE_MILLIS = 9466848e5;\nconst distanceToBinLowerBound = (value, binSize) => {\n  let remainder = value % binSize;\n  if (remainder < 0) {\n    remainder += binSize;\n  }\n  return remainder;\n};\nconst DATE_DIFF_FN = {\n  day: dateDiffDay,\n  month: dateDiffMonth,\n  quarter: dateDiffQuarter,\n  year: dateDiffYear\n};\nconst $dateTrunc = (obj, expr, options) => {\n  const {\n    date,\n    unit,\n    binSize: optBinSize,\n    timezone,\n    startOfWeek: optStartOfWeek\n  } = computeValue(obj, expr, null, options);\n  if (isNil(date) || isNil(unit)) return null;\n  const startOfWeek = (optStartOfWeek ?? \"sun\").toLowerCase().substring(0, 3);\n  assert(\n    isDate(date),\n    \"$dateTrunc: 'date' must resolve to a valid Date object.\"\n  );\n  assert(TIME_UNITS.includes(unit), \"$dateTrunc: unit is invalid.\");\n  assert(\n    unit != \"week\" || DAYS_OF_WEEK_SET.has(startOfWeek),\n    `$dateTrunc: startOfWeek '${startOfWeek}' is not a valid.`\n  );\n  assert(\n    isNil(optBinSize) || optBinSize > 0,\n    \"$dateTrunc requires 'binSize' to be greater than 0, but got value 0.\"\n  );\n  const binSize = optBinSize ?? 1;\n  switch (unit) {\n    case \"millisecond\":\n    case \"second\":\n    case \"minute\":\n    case \"hour\": {\n      const binSizeMillis = binSize * TIMEUNIT_IN_MILLIS[unit];\n      const shiftedDate = date.getTime() - REF_DATE_MILLIS;\n      return new Date(\n        date.getTime() - distanceToBinLowerBound(shiftedDate, binSizeMillis)\n      );\n    }\n    default: {\n      assert(binSize <= 1e11, \"dateTrunc unsupported binSize value\");\n      const d = new Date(date);\n      const refPointDate = new Date(REF_DATE_MILLIS);\n      let distanceFromRefPoint = 0;\n      if (unit == \"week\") {\n        const refPointDayOfWeek = isoWeekday(refPointDate, startOfWeek);\n        const daysToAdjustBy = (DAYS_PER_WEEK - refPointDayOfWeek) % DAYS_PER_WEEK;\n        refPointDate.setTime(\n          refPointDate.getTime() + daysToAdjustBy * TIMEUNIT_IN_MILLIS.day\n        );\n        distanceFromRefPoint = dateDiffWeek(refPointDate, d, startOfWeek);\n      } else {\n        distanceFromRefPoint = DATE_DIFF_FN[unit](refPointDate, d);\n      }\n      const binLowerBoundFromRefPoint = distanceFromRefPoint - distanceToBinLowerBound(distanceFromRefPoint, binSize);\n      const newDate = dateAdd(\n        refPointDate,\n        unit,\n        binLowerBoundFromRefPoint,\n        timezone\n      );\n      const minuteOffset = parseTimezone(timezone);\n      adjustDate(newDate, -minuteOffset);\n      return newDate;\n    }\n  }\n};\nexport {\n  $dateTrunc\n};\n","import { computeDate } from \"./_internal\";\nconst $dayOfMonth = (obj, expr, options) => {\n  return computeDate(obj, expr, options).getUTCDate();\n};\nexport {\n  $dayOfMonth\n};\n","import { computeDate } from \"./_internal\";\nconst $dayOfWeek = (obj, expr, options) => {\n  return computeDate(obj, expr, options).getUTCDay() + 1;\n};\nexport {\n  $dayOfWeek\n};\n","import { computeDate, dayOfYear } from \"./_internal\";\nconst $dayOfYear = (obj, expr, options) => {\n  return dayOfYear(computeDate(obj, expr, options));\n};\nexport {\n  $dayOfYear\n};\n","import { computeDate } from \"./_internal\";\nconst $hour = (obj, expr, options) => {\n  return computeDate(obj, expr, options).getUTCHours();\n};\nexport {\n  $hour\n};\n","export * from \"./dateAdd\";\nexport * from \"./dateDiff\";\nexport * from \"./dateFromParts\";\nexport * from \"./dateFromString\";\nexport * from \"./dateSubtract\";\nexport * from \"./dateToParts\";\nexport * from \"./dateToString\";\nexport * from \"./dateTrunc\";\nexport * from \"./dayOfMonth\";\nexport * from \"./dayOfWeek\";\nexport * from \"./dayOfYear\";\nexport * from \"./hour\";\nexport * from \"./isoDayOfWeek\";\nexport * from \"./isoWeek\";\nexport * from \"./isoWeekYear\";\nexport * from \"./millisecond\";\nexport * from \"./minute\";\nexport * from \"./month\";\nexport * from \"./second\";\nexport * from \"./week\";\nexport * from \"./year\";\n","import { computeDate } from \"./_internal\";\nconst $isoDayOfWeek = (obj, expr, options) => {\n  return computeDate(obj, expr, options).getUTCDay() || 7;\n};\nexport {\n  $isoDayOfWeek\n};\n","import { computeDate, isoWeek } from \"./_internal\";\nconst $isoWeek = (obj, expr, options) => {\n  return isoWeek(computeDate(obj, expr, options));\n};\nexport {\n  $isoWeek\n};\n","import { computeDate, isoWeekYear } from \"./_internal\";\nconst $isoWeekYear = (obj, expr, options) => isoWeekYear(computeDate(obj, expr, options));\nexport {\n  $isoWeekYear\n};\n","import { computeDate } from \"./_internal\";\nconst $millisecond = (obj, expr, options) => {\n  return computeDate(obj, expr, options).getUTCMilliseconds();\n};\nexport {\n  $millisecond\n};\n","import { computeDate } from \"./_internal\";\nconst $minute = (obj, expr, options) => {\n  return computeDate(obj, expr, options).getUTCMinutes();\n};\nexport {\n  $minute\n};\n","import { computeDate } from \"./_internal\";\nconst $month = (obj, expr, options) => {\n  return computeDate(obj, expr, options).getUTCMonth() + 1;\n};\nexport {\n  $month\n};\n","import { computeDate } from \"./_internal\";\nconst $second = (obj, expr, options) => {\n  return computeDate(obj, expr, options).getUTCSeconds();\n};\nexport {\n  $second\n};\n","import { computeDate, isoWeek } from \"./_internal\";\nconst $week = (obj, expr, options) => {\n  const d = computeDate(obj, expr, options);\n  const result = isoWeek(d);\n  if (d.getUTCDay() > 0 && d.getUTCDate() == 1 && d.getUTCMonth() == 0)\n    return 0;\n  if (d.getUTCDay() == 0) return result + 1;\n  return result;\n};\nexport {\n  $week\n};\n","import { computeDate } from \"./_internal\";\nconst $year = (obj, expr, options) => {\n  return computeDate(obj, expr, options).getUTCFullYear();\n};\nexport {\n  $year\n};\n","export * from \"./arithmetic\";\nexport * from \"./array\";\nexport * from \"./bitwise\";\nexport * from \"./boolean\";\nexport * from \"./comparison\";\nexport * from \"./conditional\";\nexport * from \"./custom\";\nexport * from \"./date\";\nexport * from \"./literal\";\nexport * from \"./median\";\nexport * from \"./misc\";\nexport * from \"./object\";\nexport * from \"./percentile\";\nexport * from \"./set\";\nexport * from \"./string\";\nexport * from \"./trignometry\";\nexport * from \"./type\";\nexport * from \"./variable\";\n","const $literal = (_obj, expr, _options) => expr;\nexport {\n  $literal\n};\n","import { computeValue } from \"../../core\";\nimport { $median as __median } from \"../accumulator/median\";\nconst $median = (obj, expr, options) => {\n  const input = computeValue(obj, expr.input, null, options);\n  return __median(input, { input: \"$$CURRENT\" }, options);\n};\nexport {\n  $median\n};\n","import { computeValue } from \"../../../core\";\nimport { assert, isNil, isObject, isString } from \"../../../util\";\nconst $getField = (obj, expr, options) => {\n  const args = computeValue(obj, expr, null, options);\n  const [field, input] = isObject(args) ? [args.field, args.input || obj] : [args, obj];\n  if (isNil(input)) return null;\n  assert(\n    isObject(input),\n    \"$getField expression 'input' must evaluate to an object\"\n  );\n  assert(\n    isString(field),\n    \"$getField expression 'field' must evaluate to a string\"\n  );\n  return input[field];\n};\nexport {\n  $getField\n};\n","export * from \"./getField\";\nexport * from \"./rand\";\nexport * from \"./sampleRate\";\n","const $rand = (_obj, _expr, _options) => Math.random();\nexport {\n  $rand\n};\n","import { computeValue } from \"../../../core\";\nconst $sampleRate = (obj, expr, options) => Math.random() <= computeValue(obj, expr, null, options);\nexport {\n  $sampleRate\n};\n","export * from \"./mergeObjects\";\nexport * from \"./objectToArray\";\nexport * from \"./setField\";\nexport * from \"./unsetField\";\n","import { computeValue } from \"../../../core\";\nimport { isNil } from \"../../../util\";\nconst $mergeObjects = (obj, expr, options) => {\n  const docs = computeValue(obj, expr, null, options) ?? [];\n  const acc = {};\n  for (const o of docs) {\n    if (isNil(o)) continue;\n    for (const k of Object.keys(o)) {\n      if (o[k] !== void 0) acc[k] = o[k];\n    }\n  }\n  return acc;\n};\nexport {\n  $mergeObjects\n};\n","import { computeValue } from \"../../../core\";\nimport { assert, isNil, isObject, typeOf } from \"../../../util\";\nconst $objectToArray = (obj, expr, options) => {\n  const val = computeValue(obj, expr, null, options);\n  if (isNil(val)) return null;\n  assert(\n    isObject(val),\n    `$objectToArray requires a document input, found: ${typeOf(val)}`\n  );\n  const entries = Object.entries(val);\n  const result = new Array(entries.length);\n  let i = 0;\n  for (const [k, v] of entries) {\n    result[i++] = { k, v };\n  }\n  return result;\n};\nexport {\n  $objectToArray\n};\n","import { computeValue } from \"../../../core\";\nimport { assert, isNil, isObject, isString } from \"../../../util\";\nconst $setField = (obj, expr, options) => {\n  const { input, field, value } = computeValue(\n    obj,\n    expr,\n    null,\n    options\n  );\n  if (isNil(input)) return null;\n  assert(\n    isObject(input),\n    \"$setField expression 'input' must evaluate to an object\"\n  );\n  assert(\n    isString(field),\n    \"$setField expression 'field' must evaluate to a string\"\n  );\n  const newObj = { ...input };\n  if (expr.value == \"$$REMOVE\") {\n    delete newObj[field];\n  } else {\n    newObj[field] = value;\n  }\n  return newObj;\n};\nexport {\n  $setField\n};\n","import { $setField } from \"./setField\";\nconst $unsetField = (obj, expr, options) => {\n  return $setField(\n    obj,\n    {\n      ...expr,\n      value: \"$$REMOVE\"\n    },\n    options\n  );\n};\nexport {\n  $unsetField\n};\n","import { computeValue } from \"../../core\";\nimport { $percentile as __percentile } from \"../accumulator/percentile\";\nconst $percentile = (obj, expr, options) => {\n  const input = computeValue(obj, expr.input, null, options);\n  return __percentile(input, { ...expr, input: \"$$CURRENT\" }, options);\n};\nexport {\n  $percentile\n};\n","import { computeValue } from \"../../../core\";\nimport { truthy } from \"../../../util\";\nconst $allElementsTrue = (obj, expr, options) => {\n  const args = computeValue(obj, expr, null, options)[0];\n  return args.every((v) => truthy(v, options.useStrictMode));\n};\nexport {\n  $allElementsTrue\n};\n","import { computeValue } from \"../../../core\";\nimport { truthy } from \"../../../util\";\nconst $anyElementTrue = (obj, expr, options) => {\n  const args = computeValue(obj, expr, null, options)[0];\n  return args.some((v) => truthy(v, options.useStrictMode));\n};\nexport {\n  $anyElementTrue\n};\n","export * from \"./allElementsTrue\";\nexport * from \"./anyElementTrue\";\nexport * from \"./setDifference\";\nexport * from \"./setEquals\";\nexport * from \"./setIntersection\";\nexport * from \"./setIsSubset\";\nexport * from \"./setUnion\";\n","import { computeValue } from \"../../../core\";\nimport { assert, isArray, isNil, ValueMap } from \"../../../util\";\nconst $setDifference = (obj, expr, options) => {\n  const args = computeValue(obj, expr, null, options);\n  if (isNil(args)) return null;\n  assert(isArray(args), \"$setDifference must be an arrays.\");\n  if (args.some(isNil)) return null;\n  assert(args.length == 2, `$setDifference takes exactly 2 arguments.`);\n  assert(args.every(isArray), \"$setDifference operands must be arrays.\");\n  const m = ValueMap.init(options.hashFunction);\n  args[0].forEach((v) => m.set(v, true));\n  args[1].forEach((v) => m.delete(v));\n  return Array.from(m.keys());\n};\nexport {\n  $setDifference\n};\n","import { computeValue } from \"../../../core\";\nimport { assert, isArray, ValueMap } from \"../../../util\";\nconst $setEquals = (obj, expr, options) => {\n  const args = computeValue(obj, expr, null, options);\n  assert(\n    isArray(args) && args.every(isArray),\n    \"$setEquals operands must be arrays.\"\n  );\n  const map = ValueMap.init();\n  args[0].every((v, i) => map.set(v, i));\n  for (let i = 1; i < args.length; i++) {\n    const arr = args[i];\n    const set = /* @__PURE__ */ new Set();\n    for (let j = 0; j < arr.length; j++) {\n      const n = map.get(arr[j]) ?? -1;\n      if (n === -1) return false;\n      set.add(n);\n    }\n    if (set.size !== map.size) return false;\n  }\n  return true;\n};\nexport {\n  $setEquals\n};\n","import { computeValue } from \"../../../core\";\nimport { assert, intersection, isArray, isNil } from \"../../../util\";\nconst $setIntersection = (obj, expr, options) => {\n  const args = computeValue(obj, expr, null, options);\n  if (isNil(args)) return null;\n  assert(\n    isArray(args) && args.every(isArray),\n    \"$setIntersection operands must be arrays.\"\n  );\n  return intersection(args, options?.hashFunction);\n};\nexport {\n  $setIntersection\n};\n","import { computeValue } from \"../../../core\";\nimport { assert, isArray, ValueMap } from \"../../../util\";\nconst $setIsSubset = (obj, expr, options) => {\n  const args = computeValue(obj, expr, null, options);\n  assert(\n    isArray(args) && args.every(isArray),\n    \"$setIsSubset operands must be arrays.\"\n  );\n  const first = args[0];\n  const second = args[1];\n  const map = ValueMap.init();\n  const set = /* @__PURE__ */ new Set();\n  first.every((v, i) => map.set(v, i));\n  for (const v of second) {\n    set.add(map.get(v) ?? -1);\n    if (set.size > map.size) return true;\n  }\n  set.delete(-1);\n  return set.size == map.size;\n};\nexport {\n  $setIsSubset\n};\n","import { computeValue } from \"../../../core\";\nimport { assert, flatten, isArray, isNil, unique } from \"../../../util\";\nconst $setUnion = (obj, expr, options) => {\n  const args = computeValue(obj, expr, null, options);\n  if (isNil(args)) return null;\n  assert(isArray(args), \"$setUnion operands must be arrays.\");\n  if (args.some(isNil)) return null;\n  return unique(flatten(args), options?.hashFunction);\n};\nexport {\n  $setUnion\n};\n","import { computeValue } from \"../../../core\";\nimport { assert, isNil, isString } from \"../../../util\";\nconst WHITESPACE_CHARS = [\n  0,\n  // '\\0' Null character\n  32,\n  // ' ', Space\n  9,\n  // '\\t' Horizontal tab\n  10,\n  // '\\n' Line feed/new line\n  11,\n  // '\\v' Vertical tab\n  12,\n  // '\\f' Form feed\n  13,\n  // '\\r' Carriage return\n  160,\n  // Non-breaking space\n  5760,\n  // Ogham space mark\n  8192,\n  // En quad\n  8193,\n  // Em quad\n  8194,\n  // En space\n  8195,\n  // Em space\n  8196,\n  // Three-per-em space\n  8197,\n  // Four-per-em space\n  8198,\n  // Six-per-em space\n  8199,\n  // Figure space\n  8200,\n  // Punctuation space\n  8201,\n  // Thin space\n  8202\n  // Hair space\n];\nfunction trimString(obj, expr, options, trimOpts) {\n  const val = computeValue(obj, expr, null, options);\n  const s = val.input;\n  if (isNil(s)) return null;\n  const codepoints = isNil(val.chars) ? WHITESPACE_CHARS : val.chars.split(\"\").map((c) => c.codePointAt(0));\n  let i = 0;\n  let j = s.length - 1;\n  while (trimOpts.left && i <= j && codepoints.indexOf(s[i].codePointAt(0)) !== -1)\n    i++;\n  while (trimOpts.right && i <= j && codepoints.indexOf(s[j].codePointAt(0)) !== -1)\n    j--;\n  return s.substring(i, j + 1);\n}\nfunction regexSearch(obj, expr, options, reOpts) {\n  const val = computeValue(obj, expr, null, options);\n  if (!isString(val.input)) return [];\n  const regexOptions = val.options;\n  if (regexOptions) {\n    assert(\n      regexOptions.indexOf(\"x\") === -1,\n      \"extended capability option 'x' not supported\"\n    );\n    assert(regexOptions.indexOf(\"g\") === -1, \"global option 'g' not supported\");\n  }\n  let input = val.input;\n  const re = new RegExp(val.regex, regexOptions);\n  let m;\n  const matches = new Array();\n  let offset = 0;\n  while (m = re.exec(input)) {\n    const result = {\n      match: m[0],\n      idx: m.index + offset,\n      captures: []\n    };\n    for (let i = 1; i < m.length; i++) result.captures.push(m[i] || null);\n    matches.push(result);\n    if (!reOpts.global) break;\n    offset = m.index + m[0].length;\n    input = input.substring(offset);\n  }\n  return matches;\n}\nexport {\n  regexSearch,\n  trimString\n};\n","import { computeValue } from \"../../../core\";\nimport { assert, isNil, isString } from \"../../../util\";\nconst $concat = (obj, expr, options) => {\n  const args = computeValue(obj, expr, null, options);\n  assert(\n    args.every((v) => isString(v) || isNil(v)),\n    \"$concat only supports strings.\"\n  );\n  if (args.some(isNil)) return null;\n  return args.join(\"\");\n};\nexport {\n  $concat\n};\n","export * from \"./concat\";\nexport * from \"./indexOfBytes\";\nexport * from \"./ltrim\";\nexport * from \"./regexFind\";\nexport * from \"./regexFindAll\";\nexport * from \"./regexMatch\";\nexport * from \"./replaceAll\";\nexport * from \"./replaceOne\";\nexport * from \"./rtrim\";\nexport * from \"./split\";\nexport * from \"./strcasecmp\";\nexport * from \"./strLenBytes\";\nexport * from \"./strLenCP\";\nexport * from \"./substr\";\nexport * from \"./substrBytes\";\nexport * from \"./substrCP\";\nexport * from \"./toLower\";\nexport * from \"./toUpper\";\nexport * from \"./trim\";\n","import { computeValue } from \"../../../core\";\nimport { assert, isNil, isNumber, isString } from \"../../../util\";\nconst $indexOfBytes = (obj, expr, options) => {\n  const arr = computeValue(obj, expr, null, options);\n  const errorMsg = \"$indexOfBytes expression resolves to invalid an argument\";\n  if (isNil(arr[0])) return null;\n  assert(isString(arr[0]) && isString(arr[1]), errorMsg);\n  const str = arr[0];\n  const searchStr = arr[1];\n  let start = arr[2];\n  let end = arr[3];\n  let valid = isNil(start) || isNumber(start) && start >= 0 && Math.round(start) === start;\n  valid = valid && (isNil(end) || isNumber(end) && end >= 0 && Math.round(end) === end);\n  assert(valid, errorMsg);\n  start = start || 0;\n  end = end || str.length;\n  if (start > end) return -1;\n  const index = str.substring(start, end).indexOf(searchStr);\n  return index > -1 ? index + start : index;\n};\nexport {\n  $indexOfBytes\n};\n","import { trimString } from \"./_internal\";\nconst $ltrim = (obj, expr, options) => {\n  return trimString(obj, expr, options, { left: true, right: false });\n};\nexport {\n  $ltrim\n};\n","import { regexSearch } from \"./_internal\";\nconst $regexFind = (obj, expr, options) => {\n  const result = regexSearch(obj, expr, options, { global: false });\n  return result && result.length > 0 ? result[0] : null;\n};\nexport {\n  $regexFind\n};\n","import { regexSearch } from \"./_internal\";\nconst $regexFindAll = (obj, expr, options) => {\n  return regexSearch(obj, expr, options, { global: true });\n};\nexport {\n  $regexFindAll\n};\n","import { regexSearch } from \"./_internal\";\nconst $regexMatch = (obj, expr, options) => {\n  return regexSearch(obj, expr, options, { global: false }).length != 0;\n};\nexport {\n  $regexMatch\n};\n","import { computeValue } from \"../../../core\";\nimport { assert, isNil, isString } from \"../../../util\";\nconst $replaceAll = (obj, expr, options) => {\n  const args = computeValue(obj, expr, null, options);\n  const arr = [args.input, args.find, args.replacement];\n  if (arr.some(isNil)) return null;\n  assert(\n    arr.every(isString),\n    \"$replaceAll expression fields must evaluate to string\"\n  );\n  return args.input.replace(new RegExp(args.find, \"g\"), args.replacement);\n};\nexport {\n  $replaceAll\n};\n","import { computeValue } from \"../../../core\";\nimport { assert, isNil, isString } from \"../../../util\";\nconst $replaceOne = (obj, expr, options) => {\n  const args = computeValue(obj, expr, null, options);\n  const arr = [args.input, args.find, args.replacement];\n  if (arr.some(isNil)) return null;\n  assert(\n    arr.every(isString),\n    \"$replaceOne expression fields must evaluate to string\"\n  );\n  return args.input.replace(args.find, args.replacement);\n};\nexport {\n  $replaceOne\n};\n","import { trimString } from \"./_internal\";\nconst $rtrim = (obj, expr, options) => {\n  return trimString(obj, expr, options, { left: false, right: true });\n};\nexport {\n  $rtrim\n};\n","import { computeValue } from \"../../../core\";\nimport { assert, isNil, isString } from \"../../../util\";\nconst $split = (obj, expr, options) => {\n  const args = computeValue(obj, expr, null, options);\n  if (isNil(args[0])) return null;\n  assert(\n    args.every(isString),\n    \"$split expression must result to array(2) of strings\"\n  );\n  return args[0].split(args[1]);\n};\nexport {\n  $split\n};\n","import { computeValue } from \"../../../core\";\nconst $strLenBytes = (obj, expr, options) => {\n  return ~-encodeURI(computeValue(obj, expr, null, options)).split(\n    /%..|./\n  ).length;\n};\nexport {\n  $strLenBytes\n};\n","import { computeValue } from \"../../../core\";\nconst $strLenCP = (obj, expr, options) => {\n  return computeValue(obj, expr, null, options).length;\n};\nexport {\n  $strLenCP\n};\n","import { computeValue } from \"../../../core\";\nimport { assert, isEqual, isNil, isString } from \"../../../util\";\nconst $strcasecmp = (obj, expr, options) => {\n  const args = computeValue(obj, expr, null, options);\n  let a = args[0];\n  let b = args[1];\n  if (isEqual(a, b) || args.every(isNil)) return 0;\n  assert(\n    args.every(isString),\n    \"$strcasecmp must resolve to array(2) of strings\"\n  );\n  a = a.toUpperCase();\n  b = b.toUpperCase();\n  return a > b && 1 || a < b && -1 || 0;\n};\nexport {\n  $strcasecmp\n};\n","import { computeValue } from \"../../../core\";\nimport { isString } from \"../../../util\";\nconst $substr = (obj, expr, options) => {\n  const [s, start, count] = computeValue(obj, expr, null, options);\n  if (start < 0 || !isString(s)) return \"\";\n  if (count < 0) return s.substring(start);\n  return s.substring(start, start + count);\n};\nexport {\n  $substr\n};\n","import { computeValue } from \"../../../core\";\nimport { assert, isNumber, isString } from \"../../../util\";\nconst UTF8_MASK = [192, 224, 240];\nfunction toUtf8(n) {\n  if (n < 128) return [n];\n  let count = n < 2048 && 1 || n < 65536 && 2 || 3;\n  const offset = UTF8_MASK[count - 1];\n  const utf8 = [(n >> 6 * count) + offset];\n  while (count > 0) utf8.push(128 | n >> 6 * --count & 63);\n  return utf8;\n}\nfunction utf8Encode(s) {\n  const buf = [];\n  for (let i = 0, len = s.length; i < len; i++) {\n    buf.push(toUtf8(s.codePointAt(i)));\n  }\n  return buf;\n}\nconst $substrBytes = (obj, expr, options) => {\n  const args = computeValue(obj, expr, null, options);\n  const s = args[0];\n  const index = args[1];\n  const count = args[2];\n  assert(\n    isString(s) && isNumber(index) && index >= 0 && isNumber(count) && count >= 0,\n    \"$substrBytes: invalid arguments\"\n  );\n  const buf = utf8Encode(s);\n  const validIndex = [];\n  let acc = 0;\n  for (let i = 0; i < buf.length; i++) {\n    validIndex.push(acc);\n    acc += buf[i].length;\n  }\n  const begin = validIndex.indexOf(index);\n  const end = validIndex.indexOf(index + count);\n  assert(\n    begin > -1 && end > -1,\n    \"$substrBytes: invalid range, start or end index is a UTF-8 continuation byte.\"\n  );\n  return s.substring(begin, end);\n};\nexport {\n  $substrBytes\n};\n","import { $substr } from \"./substr\";\nconst $substrCP = (obj, expr, options) => {\n  return $substr(obj, expr, options);\n};\nexport {\n  $substrCP\n};\n","import { computeValue } from \"../../../core\";\nimport { isEmpty } from \"../../../util\";\nconst $toLower = (obj, expr, options) => {\n  const value = computeValue(obj, expr, null, options);\n  return isEmpty(value) ? \"\" : value.toLowerCase();\n};\nexport {\n  $toLower\n};\n","import { computeValue } from \"../../../core\";\nimport { isEmpty } from \"../../../util\";\nconst $toUpper = (obj, expr, options) => {\n  const value = computeValue(obj, expr, null, options);\n  return isEmpty(value) ? \"\" : value.toUpperCase();\n};\nexport {\n  $toUpper\n};\n","import { trimString } from \"./_internal\";\nconst $trim = (obj, expr, options) => {\n  return trimString(obj, expr, options, { left: true, right: true });\n};\nexport {\n  $trim\n};\n","import { computeValue } from \"../../../core\";\nimport { MingoError } from \"../../../util\";\nconst FIXED_POINTS = {\n  undefined: null,\n  null: null,\n  NaN: NaN,\n  Infinity: new Error(),\n  \"-Infinity\": new Error()\n};\nfunction createTrignometryOperator(f, fixedPoints = FIXED_POINTS) {\n  const fp = Object.assign({}, FIXED_POINTS, fixedPoints);\n  const keySet = new Set(Object.keys(fp));\n  return (obj, expr, options) => {\n    const n = computeValue(obj, expr, null, options);\n    if (keySet.has(`${n}`)) {\n      const res = fp[`${n}`];\n      if (res instanceof Error) {\n        throw new MingoError(\n          `cannot apply $${f.name} to -inf, value must in (-inf,inf)`\n        );\n      }\n      return res;\n    }\n    return f(n);\n  };\n}\nexport {\n  createTrignometryOperator\n};\n","import { createTrignometryOperator } from \"./_internal\";\nconst $acos = createTrignometryOperator(Math.acos, {\n  Infinity: Infinity,\n  0: new Error()\n});\nexport {\n  $acos\n};\n","import { createTrignometryOperator } from \"./_internal\";\nconst $acosh = createTrignometryOperator(Math.acosh, {\n  Infinity: Infinity,\n  0: new Error()\n});\nexport {\n  $acosh\n};\n","import { createTrignometryOperator } from \"./_internal\";\nconst $asin = createTrignometryOperator(Math.asin);\nexport {\n  $asin\n};\n","import { createTrignometryOperator } from \"./_internal\";\nconst $asinh = createTrignometryOperator(Math.asinh, {\n  Infinity: Infinity,\n  \"-Infinity\": -Infinity\n});\nexport {\n  $asinh\n};\n","import { createTrignometryOperator } from \"./_internal\";\nconst $atan = createTrignometryOperator(Math.atan);\nexport {\n  $atan\n};\n","import { computeValue } from \"../../../core\";\nimport { isNil } from \"../../../util\";\nconst $atan2 = (obj, expr, options) => {\n  const [y, x] = computeValue(obj, expr, null, options);\n  if (isNaN(y) || isNil(y)) return y;\n  if (isNaN(x) || isNil(x)) return x;\n  return Math.atan2(y, x);\n};\nexport {\n  $atan2\n};\n","import { createTrignometryOperator } from \"./_internal\";\nconst $atanh = createTrignometryOperator(Math.atanh, {\n  1: Infinity,\n  \"-1\": -Infinity\n});\nexport {\n  $atanh\n};\n","import { createTrignometryOperator } from \"./_internal\";\nconst $cos = createTrignometryOperator(Math.cos);\nexport {\n  $cos\n};\n","import { createTrignometryOperator } from \"./_internal\";\nconst $cosh = createTrignometryOperator(Math.cosh, {\n  \"-Infinity\": Infinity,\n  Infinity: Infinity\n});\nexport {\n  $cosh\n};\n","import { createTrignometryOperator } from \"./_internal\";\nconst RADIANS_FACTOR = Math.PI / 180;\nconst $degreesToRadians = createTrignometryOperator(\n  (n) => n * RADIANS_FACTOR,\n  {\n    Infinity: Infinity,\n    \"-Infinity\": Infinity\n  }\n);\nexport {\n  $degreesToRadians\n};\n","export * from \"./acos\";\nexport * from \"./acosh\";\nexport * from \"./asin\";\nexport * from \"./asinh\";\nexport * from \"./atan\";\nexport * from \"./atan2\";\nexport * from \"./atanh\";\nexport * from \"./cos\";\nexport * from \"./cosh\";\nexport * from \"./degreesToRadians\";\nexport * from \"./radiansToDegrees\";\nexport * from \"./sin\";\nexport * from \"./sinh\";\nexport * from \"./tan\";\n","import { createTrignometryOperator } from \"./_internal\";\nconst DEGREES_FACTOR = 180 / Math.PI;\nconst $radiansToDegrees = createTrignometryOperator(\n  (n) => n * DEGREES_FACTOR,\n  {\n    Infinity: Infinity,\n    \"-Infinity\": -Infinity\n  }\n);\nexport {\n  $radiansToDegrees\n};\n","import { createTrignometryOperator } from \"./_internal\";\nconst $sin = createTrignometryOperator(Math.sin);\nexport {\n  $sin\n};\n","import { createTrignometryOperator } from \"./_internal\";\nconst $sinh = createTrignometryOperator(Math.sinh, {\n  \"-Infinity\": -Infinity,\n  Infinity: Infinity\n});\nexport {\n  $sinh\n};\n","import { createTrignometryOperator } from \"./_internal\";\nconst $tan = createTrignometryOperator(Math.tan);\nexport {\n  $tan\n};\n","import { computeValue } from \"../../../core\";\nimport { isDate, isNil, isNumber, isString } from \"../../../util\";\nconst MAX_INT = 2147483647;\nconst MIN_INT = -2147483648;\nconst MAX_LONG = Number.MAX_SAFE_INTEGER;\nconst MIN_LONG = Number.MIN_SAFE_INTEGER;\nclass TypeConvertError extends Error {\n  constructor(message) {\n    super(message);\n  }\n}\nfunction toInteger(obj, expr, options, min, max) {\n  const val = computeValue(obj, expr, null, options);\n  if (val === true) return 1;\n  if (val === false) return 0;\n  if (isNil(val)) return null;\n  if (isDate(val)) return val.getTime();\n  const n = Number(val);\n  if (isNumber(n) && n >= min && n <= max) {\n    if (!isString(val) || n.toString().indexOf(\".\") === -1) {\n      return Math.trunc(n);\n    }\n  }\n  throw new TypeConvertError(\n    `cannot convert '${val}' to ${max == MAX_INT ? \"int\" : \"long\"}`\n  );\n}\nexport {\n  MAX_INT,\n  MAX_LONG,\n  MIN_INT,\n  MIN_LONG,\n  TypeConvertError,\n  toInteger\n};\n","import { computeValue } from \"../../../core\";\nimport { isNil } from \"../../../util\";\nimport { TypeConvertError } from \"./_internal\";\nimport { $toBool } from \"./toBool\";\nimport { $toDate } from \"./toDate\";\nimport { $toDouble } from \"./toDouble\";\nimport { $toInt } from \"./toInt\";\nimport { $toLong } from \"./toLong\";\nimport { $toString } from \"./toString\";\nconst $convert = (obj, expr, options) => {\n  const args = computeValue(obj, expr, null, options);\n  args.onNull = args.onNull === void 0 ? null : args.onNull;\n  if (isNil(args.input)) return args.onNull;\n  try {\n    switch (args.to) {\n      case 2:\n      case \"string\":\n        return $toString(obj, args.input, options);\n      case 8:\n      case \"boolean\":\n      case \"bool\":\n        return $toBool(obj, args.input, options);\n      case 9:\n      case \"date\":\n        return $toDate(obj, args.input, options);\n      case 1:\n      case 19:\n      case \"double\":\n      case \"decimal\":\n      case \"number\":\n        return $toDouble(obj, args.input, options);\n      case 16:\n      case \"int\":\n        return $toInt(obj, args.input, options);\n      case 18:\n      case \"long\":\n        return $toLong(obj, args.input, options);\n    }\n  } catch {\n  }\n  if (args.onError !== void 0) return args.onError;\n  throw new TypeConvertError(`could not convert to type ${args.to}.`);\n};\nexport {\n  $convert\n};\n","export * from \"./convert\";\nexport * from \"./isNumber\";\nexport * from \"./toBool\";\nexport * from \"./toDate\";\nexport * from \"./toDecimal\";\nexport * from \"./toDouble\";\nexport * from \"./toInt\";\nexport * from \"./toLong\";\nexport * from \"./toString\";\nexport * from \"./type\";\n","import { computeValue } from \"../../../core\";\nimport { isNumber } from \"../../../util\";\nconst $isNumber = (obj, expr, options) => {\n  const n = computeValue(obj, expr, null, options);\n  return isNumber(n);\n};\nexport {\n  $isNumber\n};\n","import { computeValue } from \"../../../core\";\nimport { isNil, isString } from \"../../../util\";\nconst $toBool = (obj, expr, options) => {\n  const val = computeValue(obj, expr, null, options);\n  if (isNil(val)) return null;\n  if (isString(val)) return true;\n  return Boolean(val);\n};\nexport {\n  $toBool\n};\n","import { computeValue } from \"../../../core\";\nimport { isDate, isNil } from \"../../../util\";\nimport { TypeConvertError } from \"./_internal\";\nconst $toDate = (obj, expr, options) => {\n  const val = computeValue(obj, expr, null, options);\n  if (isDate(val)) return val;\n  if (isNil(val)) return null;\n  const d = new Date(val);\n  const n = d.getTime();\n  if (!isNaN(n)) return d;\n  throw new TypeConvertError(`cannot convert '${val}' to date`);\n};\nexport {\n  $toDate\n};\n","import { $toDouble } from \"./toDouble\";\nconst $toDecimal = $toDouble;\nexport {\n  $toDecimal\n};\n","import { computeValue } from \"../../../core\";\nimport { isDate, isNil, isNumber } from \"../../../util\";\nimport { TypeConvertError } from \"./_internal\";\nconst $toDouble = (obj, expr, options) => {\n  const val = computeValue(obj, expr, null, options);\n  if (isNil(val)) return null;\n  if (isDate(val)) return val.getTime();\n  if (val === true) return 1;\n  if (val === false) return 0;\n  const n = Number(val);\n  if (isNumber(n)) return n;\n  throw new TypeConvertError(`cannot convert '${val}' to double/decimal`);\n};\nexport {\n  $toDouble\n};\n","import { MAX_INT, MIN_INT, toInteger } from \"./_internal\";\nconst $toInt = (obj, expr, options) => toInteger(obj, expr, options, MIN_INT, MAX_INT);\nexport {\n  $toInt\n};\n","import { MAX_LONG, MIN_LONG, toInteger } from \"./_internal\";\nconst $toLong = (obj, expr, options) => toInteger(obj, expr, options, MIN_LONG, MAX_LONG);\nexport {\n  $toLong\n};\n","import { computeValue } from \"../../../core\";\nimport { isDate, isNil } from \"../../../util\";\nimport { $dateToString } from \"../date/dateToString\";\nconst $toString = (obj, expr, options) => {\n  const val = computeValue(obj, expr, null, options);\n  if (isNil(val)) return null;\n  if (isDate(val)) {\n    return $dateToString(\n      obj,\n      {\n        date: expr,\n        format: \"%Y-%m-%dT%H:%M:%S.%LZ\"\n      },\n      options\n    );\n  }\n  return val.toString();\n};\nexport {\n  $toString\n};\n","import { computeValue } from \"../../../core\";\nimport { isNumber, isRegExp, typeOf } from \"../../../util\";\nimport { MAX_INT, MIN_INT } from \"./_internal\";\nconst $type = (obj, expr, options) => {\n  const v = computeValue(obj, expr, null, options);\n  if (options.useStrictMode) {\n    if (v === void 0) return \"missing\";\n    if (v === true || v === false) return \"bool\";\n    if (isNumber(v)) {\n      if (v % 1 != 0) return \"double\";\n      return v >= MIN_INT && v <= MAX_INT ? \"int\" : \"long\";\n    }\n    if (isRegExp(v)) return \"regex\";\n  }\n  return typeOf(v);\n};\nexport {\n  $type\n};\n","export * from \"./let\";\n","import {\n  ComputeOptions,\n  computeValue\n} from \"../../../core\";\nconst $let = (obj, expr, options) => {\n  const variables = {};\n  for (const [key, val] of Object.entries(expr.vars)) {\n    variables[key] = computeValue(obj, val, null, options);\n  }\n  return computeValue(\n    obj,\n    expr.in,\n    null,\n    ComputeOptions.init(options, obj, { variables })\n  );\n};\nexport {\n  $let\n};\n","const isUnbounded = (window) => {\n  const boundary = window?.documents || window?.range;\n  return !boundary || boundary[0] === \"unbounded\" && boundary[1] === \"unbounded\";\n};\nexport {\n  isUnbounded\n};\n","import { computeValue } from \"../../core\";\nimport { removeValue, setValue } from \"../../util\";\nconst $addFields = (collection, expr, options) => {\n  const newFields = Object.keys(expr);\n  if (newFields.length === 0) return collection;\n  return collection.map((obj) => {\n    const newObj = { ...obj };\n    for (const field of newFields) {\n      const newValue = computeValue(obj, expr[field], null, options);\n      if (newValue !== void 0) {\n        setValue(newObj, field, newValue);\n      } else {\n        removeValue(newObj, field);\n      }\n    }\n    return newObj;\n  });\n};\nexport {\n  $addFields\n};\n","import { computeValue } from \"../../core\";\nimport { Lazy } from \"../../lazy\";\nimport { assert, compare, findInsertIndex, isNil, typeOf } from \"../../util\";\nconst $bucket = (collection, expr, options) => {\n  const bounds = [...expr.boundaries];\n  const defaultKey = expr.default;\n  const lower = bounds[0];\n  const upper = bounds[bounds.length - 1];\n  const outputExpr = expr.output || { count: { $sum: 1 } };\n  assert(bounds.length > 1, \"$bucket must specify at least two boundaries.\");\n  const isValid = bounds.every(\n    (v, i) => i === 0 || typeOf(v) === typeOf(bounds[i - 1]) && compare(v, bounds[i - 1]) > 0\n  );\n  assert(\n    isValid,\n    `$bucket: bounds must be of same type and in ascending order`\n  );\n  if (!isNil(defaultKey) && typeOf(defaultKey) === typeOf(lower)) {\n    assert(\n      compare(defaultKey, upper) >= 0 || compare(defaultKey, lower) < 0,\n      \"$bucket 'default' expression must be out of boundaries range\"\n    );\n  }\n  const createBuckets = () => {\n    const buckets = /* @__PURE__ */ new Map();\n    for (let i = 0; i < bounds.length - 1; i++) {\n      buckets.set(bounds[i], []);\n    }\n    if (!isNil(defaultKey)) buckets.set(defaultKey, []);\n    collection.each((obj) => {\n      const key = computeValue(obj, expr.groupBy, null, options);\n      if (isNil(key) || compare(key, lower) < 0 || compare(key, upper) >= 0) {\n        assert(\n          !isNil(defaultKey),\n          \"$bucket require a default for out of range values\"\n        );\n        buckets.get(defaultKey).push(obj);\n      } else {\n        assert(\n          compare(key, lower) >= 0 && compare(key, upper) < 0,\n          \"$bucket 'groupBy' expression must resolve to a value in range of boundaries\"\n        );\n        const index = findInsertIndex(bounds, key);\n        const boundKey = bounds[Math.max(0, index - 1)];\n        buckets.get(boundKey).push(obj);\n      }\n    });\n    bounds.pop();\n    if (!isNil(defaultKey)) bounds.push(defaultKey);\n    assert(\n      buckets.size === bounds.length,\n      \"bounds and groups must be of equal size.\"\n    );\n    return Lazy(bounds).map((key) => {\n      return {\n        ...computeValue(\n          buckets.get(key),\n          outputExpr,\n          null,\n          options\n        ),\n        _id: key\n      };\n    });\n  };\n  let iterator;\n  return Lazy(() => {\n    if (!iterator) iterator = createBuckets();\n    return iterator.next();\n  });\n};\nexport {\n  $bucket\n};\n","import { computeValue } from \"../../core\";\nimport { Lazy } from \"../../lazy\";\nimport {\n  assert,\n  compare,\n  findInsertIndex,\n  isArray,\n  isEqual,\n  isNil,\n  isNumber\n} from \"../../util\";\nconst $bucketAuto = (collection, expr, options) => {\n  const {\n    buckets: bucketCount,\n    groupBy: groupByExpr,\n    output: optOutputExpr,\n    // Available only if the all groupBy values are numeric and none of them are NaN.\n    granularity\n  } = expr;\n  const outputExpr = optOutputExpr ?? { count: { $sum: 1 } };\n  assert(\n    bucketCount > 0,\n    `$bucketAuto: 'buckets' field must be greater than 0, but found: ${bucketCount}`\n  );\n  if (granularity) {\n    assert(\n      /^(POWERSOF2|1-2-5|E(6|12|24|48|96|192)|R(5|10|20|40|80))$/.test(\n        granularity\n      ),\n      `$bucketAuto: invalid granularity '${granularity}'.`\n    );\n  }\n  const keyMap = /* @__PURE__ */ new Map();\n  const setKey = !granularity ? (o, k) => keyMap.set(o, k) : (_, _2) => {\n  };\n  const sorted = collection.map((o) => {\n    const k = computeValue(o, groupByExpr, null, options) ?? null;\n    assert(\n      !granularity || isNumber(k),\n      \"$bucketAuto: groupBy values must be numeric when granularity is specified.\"\n    );\n    setKey(o, k ?? null);\n    return [k ?? null, o];\n  }).value();\n  sorted.sort((x, y) => {\n    if (isNil(x[0])) return -1;\n    if (isNil(y[0])) return 1;\n    return compare(x[0], y[0]);\n  });\n  let getNext;\n  if (!granularity) {\n    getNext = granularityDefault(sorted, bucketCount, keyMap);\n  } else if (granularity == \"POWERSOF2\") {\n    getNext = granularityPowerOfTwo(\n      sorted,\n      bucketCount\n    );\n  } else {\n    getNext = granularityPreferredSeries(\n      sorted,\n      bucketCount,\n      granularity\n    );\n  }\n  let terminate = false;\n  return Lazy(() => {\n    if (terminate) return { done: true };\n    const { min, max, bucket, done } = getNext();\n    terminate = done;\n    const outFields = computeValue(\n      bucket,\n      outputExpr,\n      null,\n      options\n    );\n    for (const [k, v] of Object.entries(outFields)) {\n      if (isArray(v)) outFields[k] = v.filter((v2) => v2 !== void 0);\n    }\n    return {\n      done: false,\n      value: {\n        ...outFields,\n        _id: { min, max }\n      }\n    };\n  });\n};\nfunction granularityDefault(sorted, bucketCount, keyMap) {\n  const size = sorted.length;\n  const approxBucketSize = Math.max(1, Math.round(sorted.length / bucketCount));\n  let index = 0;\n  let nBuckets = 0;\n  return () => {\n    const isLastBucket = ++nBuckets == bucketCount;\n    const bucket = new Array();\n    while (index < size && (isLastBucket || bucket.length < approxBucketSize || index > 0 && isEqual(sorted[index - 1][0], sorted[index][0]))) {\n      bucket.push(sorted[index++][1]);\n    }\n    const min = keyMap.get(bucket[0]);\n    let max;\n    if (index < size) {\n      max = sorted[index][0];\n    } else {\n      max = keyMap.get(bucket[bucket.length - 1]);\n    }\n    assert(\n      isNil(max) || isNil(min) || min <= max,\n      `error: $bucketAuto boundary must be in order.`\n    );\n    return {\n      min,\n      max,\n      bucket,\n      done: index >= size\n    };\n  };\n}\nfunction granularityPowerOfTwo(sorted, bucketCount) {\n  const size = sorted.length;\n  const approxBucketSize = Math.max(1, Math.round(sorted.length / bucketCount));\n  const roundUp2 = (n) => n === 0 ? 0 : 2 ** (Math.floor(Math.log2(n)) + 1);\n  let index = 0;\n  let min = 0;\n  let max = 0;\n  return () => {\n    const bucket = new Array();\n    const boundValue = roundUp2(max);\n    min = index > 0 ? max : 0;\n    while (bucket.length < approxBucketSize && index < size && (max === 0 || sorted[index][0] < boundValue)) {\n      bucket.push(sorted[index++][1]);\n    }\n    max = max == 0 ? roundUp2(sorted[index - 1][0]) : boundValue;\n    while (index < size && sorted[index][0] < max) {\n      bucket.push(sorted[index++][1]);\n    }\n    return {\n      min,\n      max,\n      bucket,\n      done: index >= size\n    };\n  };\n}\nconst PREFERRED_NUMBERS = Object.freeze({\n  // \"Least rounded\" Renard number series, taken from Wikipedia page on preferred\n  // numbers: https://en.wikipedia.org/wiki/Preferred_number#Renard_numbers\n  R5: [10, 16, 25, 40, 63],\n  R10: [100, 125, 160, 200, 250, 315, 400, 500, 630, 800],\n  R20: [\n    100,\n    112,\n    125,\n    140,\n    160,\n    180,\n    200,\n    224,\n    250,\n    280,\n    315,\n    355,\n    400,\n    450,\n    500,\n    560,\n    630,\n    710,\n    800,\n    900\n  ],\n  R40: [\n    100,\n    106,\n    112,\n    118,\n    125,\n    132,\n    140,\n    150,\n    160,\n    170,\n    180,\n    190,\n    200,\n    212,\n    224,\n    236,\n    250,\n    265,\n    280,\n    300,\n    315,\n    355,\n    375,\n    400,\n    425,\n    450,\n    475,\n    500,\n    530,\n    560,\n    600,\n    630,\n    670,\n    710,\n    750,\n    800,\n    850,\n    900,\n    950\n  ],\n  R80: [\n    103,\n    109,\n    115,\n    122,\n    128,\n    136,\n    145,\n    155,\n    165,\n    175,\n    185,\n    195,\n    206,\n    218,\n    230,\n    243,\n    258,\n    272,\n    290,\n    307,\n    325,\n    345,\n    365,\n    387,\n    412,\n    437,\n    462,\n    487,\n    515,\n    545,\n    575,\n    615,\n    650,\n    690,\n    730,\n    775,\n    825,\n    875,\n    925,\n    975\n  ],\n  // https://en.wikipedia.org/wiki/Preferred_number#1-2-5_series\n  \"1-2-5\": [10, 20, 50],\n  // E series, taken from Wikipedia page on preferred numbers:\n  // https://en.wikipedia.org/wiki/Preferred_number#E_series\n  E6: [10, 15, 22, 33, 47, 68],\n  E12: [10, 12, 15, 18, 22, 27, 33, 39, 47, 56, 68, 82],\n  E24: [\n    10,\n    11,\n    12,\n    13,\n    15,\n    16,\n    18,\n    20,\n    22,\n    24,\n    27,\n    30,\n    33,\n    36,\n    39,\n    43,\n    47,\n    51,\n    56,\n    62,\n    68,\n    75,\n    82,\n    91\n  ],\n  E48: [\n    100,\n    105,\n    110,\n    115,\n    121,\n    127,\n    133,\n    140,\n    147,\n    154,\n    162,\n    169,\n    178,\n    187,\n    196,\n    205,\n    215,\n    226,\n    237,\n    249,\n    261,\n    274,\n    287,\n    301,\n    316,\n    332,\n    348,\n    365,\n    383,\n    402,\n    422,\n    442,\n    464,\n    487,\n    511,\n    536,\n    562,\n    590,\n    619,\n    649,\n    681,\n    715,\n    750,\n    787,\n    825,\n    866,\n    909,\n    953\n  ],\n  E96: [\n    100,\n    102,\n    105,\n    107,\n    110,\n    113,\n    115,\n    118,\n    121,\n    124,\n    127,\n    130,\n    133,\n    137,\n    140,\n    143,\n    147,\n    150,\n    154,\n    158,\n    162,\n    165,\n    169,\n    174,\n    178,\n    182,\n    187,\n    191,\n    196,\n    200,\n    205,\n    210,\n    215,\n    221,\n    226,\n    232,\n    237,\n    243,\n    249,\n    255,\n    261,\n    267,\n    274,\n    280,\n    287,\n    294,\n    301,\n    309,\n    316,\n    324,\n    332,\n    340,\n    348,\n    357,\n    365,\n    374,\n    383,\n    392,\n    402,\n    412,\n    422,\n    432,\n    442,\n    453,\n    464,\n    475,\n    487,\n    499,\n    511,\n    523,\n    536,\n    549,\n    562,\n    576,\n    590,\n    604,\n    619,\n    634,\n    649,\n    665,\n    681,\n    698,\n    715,\n    732,\n    750,\n    768,\n    787,\n    806,\n    825,\n    845,\n    866,\n    887,\n    909,\n    931,\n    953,\n    976\n  ],\n  E192: [\n    100,\n    101,\n    102,\n    104,\n    105,\n    106,\n    107,\n    109,\n    110,\n    111,\n    113,\n    114,\n    115,\n    117,\n    118,\n    120,\n    121,\n    123,\n    124,\n    126,\n    127,\n    129,\n    130,\n    132,\n    133,\n    135,\n    137,\n    138,\n    140,\n    142,\n    143,\n    145,\n    147,\n    149,\n    150,\n    152,\n    154,\n    156,\n    158,\n    160,\n    162,\n    164,\n    165,\n    167,\n    169,\n    172,\n    174,\n    176,\n    178,\n    180,\n    182,\n    184,\n    187,\n    189,\n    191,\n    193,\n    196,\n    198,\n    200,\n    203,\n    205,\n    208,\n    210,\n    213,\n    215,\n    218,\n    221,\n    223,\n    226,\n    229,\n    232,\n    234,\n    237,\n    240,\n    243,\n    246,\n    249,\n    252,\n    255,\n    258,\n    261,\n    264,\n    267,\n    271,\n    274,\n    277,\n    280,\n    284,\n    287,\n    291,\n    294,\n    298,\n    301,\n    305,\n    309,\n    312,\n    316,\n    320,\n    324,\n    328,\n    332,\n    336,\n    340,\n    344,\n    348,\n    352,\n    357,\n    361,\n    365,\n    370,\n    374,\n    379,\n    383,\n    388,\n    392,\n    397,\n    402,\n    407,\n    412,\n    417,\n    422,\n    427,\n    432,\n    437,\n    442,\n    448,\n    453,\n    459,\n    464,\n    470,\n    475,\n    481,\n    487,\n    493,\n    499,\n    505,\n    511,\n    517,\n    523,\n    530,\n    536,\n    542,\n    549,\n    556,\n    562,\n    569,\n    576,\n    583,\n    590,\n    597,\n    604,\n    612,\n    619,\n    626,\n    634,\n    642,\n    649,\n    657,\n    665,\n    673,\n    681,\n    690,\n    698,\n    706,\n    715,\n    723,\n    732,\n    741,\n    750,\n    759,\n    768,\n    777,\n    787,\n    796,\n    806,\n    816,\n    825,\n    835,\n    845,\n    856,\n    866,\n    876,\n    887,\n    898,\n    909,\n    920,\n    931,\n    942,\n    953,\n    965,\n    976,\n    988\n  ]\n});\nconst roundUp = (n, granularity) => {\n  if (n == 0) return 0;\n  const series = PREFERRED_NUMBERS[granularity];\n  const first = series[0];\n  const last = series[series.length - 1];\n  let multiplier = 1;\n  while (n >= last * multiplier) {\n    multiplier *= 10;\n  }\n  let previousMin = 0;\n  while (n < first * multiplier) {\n    previousMin = first * multiplier;\n    multiplier /= 10;\n    if (n >= last * multiplier) {\n      return previousMin;\n    }\n  }\n  assert(\n    n >= first * multiplier && n < last * multiplier,\n    \"$bucketAuto: number out of range of series.\"\n  );\n  const i = findInsertIndex(series, n, (a, b) => {\n    b *= multiplier;\n    if (a < b) return -1;\n    if (a > b) return 1;\n    return 0;\n  });\n  const seriesNumber = series[i] * multiplier;\n  return n == seriesNumber ? series[i + 1] * multiplier : seriesNumber;\n};\nfunction granularityPreferredSeries(sorted, bucketCount, granularity) {\n  const size = sorted.length;\n  const approxBucketSize = Math.max(1, Math.round(sorted.length / bucketCount));\n  let index = 0;\n  let nBuckets = 0;\n  let min = 0;\n  let max = 0;\n  return () => {\n    const isLastBucket = ++nBuckets == bucketCount;\n    const bucket = new Array();\n    min = index > 0 ? max : 0;\n    while (index < size && (isLastBucket || bucket.length < approxBucketSize)) {\n      bucket.push(sorted[index++][1]);\n    }\n    max = roundUp(sorted[index - 1][0], granularity);\n    const nItems = bucket.length;\n    while (index < size && (isLastBucket || sorted[index][0] < max)) {\n      bucket.push(sorted[index++][1]);\n    }\n    if (nItems != bucket.length) {\n      max = roundUp(sorted[index - 1][0], granularity);\n    }\n    assert(min < max, `$bucketAuto: ${min} < ${max}.`);\n    return {\n      min,\n      max,\n      bucket,\n      done: index >= size\n    };\n  };\n}\nexport {\n  $bucketAuto\n};\n","import { Lazy } from \"../../lazy\";\nimport { assert, isEmpty, isString } from \"../../util\";\nconst $count = (collection, expr, _options) => {\n  assert(\n    isString(expr) && !isEmpty(expr) && expr.indexOf(\".\") === -1 && expr.trim()[0] !== \"$\",\n    \"Invalid expression value for $count\"\n  );\n  return Lazy([\n    {\n      [expr]: collection.size()\n    }\n  ]);\n};\nexport {\n  $count\n};\n","import { ComputeOptions } from \"../../core\";\nimport { concat, Lazy } from \"../../lazy\";\nimport { TIME_UNITS } from \"../../types\";\nimport {\n  assert,\n  isArray,\n  isDate,\n  isNil,\n  isNumber,\n  isObject,\n  isString,\n  resolve,\n  ValueMap\n} from \"../../util\";\nimport { $dateAdd } from \"../expression/date/dateAdd\";\nimport { $sort } from \"./sort\";\nconst EMPTY_OBJECT = Object.freeze({});\nconst $densify = (collection, expr, options) => {\n  const { step, bounds, unit } = expr.range;\n  if (unit) {\n    assert(TIME_UNITS.includes(unit), \"\");\n    assert(\n      Number.isInteger(step) && step > 0,\n      \"The step parameter in a range statement must be a whole number when densifying a date range.\"\n    );\n  } else {\n    assert(\n      isNumber(step) && step > 0,\n      \"The step parameter in a range statement must be a strictly positive numeric value.\"\n    );\n  }\n  if (isArray(bounds)) {\n    assert(\n      !!bounds && bounds.length === 2,\n      \"A bounding array in a range statement must have exactly two elements.\"\n    );\n    assert(\n      (bounds.every(isNumber) || bounds.every(isDate)) && bounds[0] < bounds[1],\n      \"A bounding array must be an ascending array of either two dates or two numbers.\"\n    );\n    assert(\n      unit && !bounds.some(isNumber),\n      \"Numeric bounds may not have unit parameter.\"\n    );\n  }\n  if (expr.partitionByFields) {\n    assert(\n      isArray(expr.partitionByFields),\n      \"$densify: `partitionByFields` must be an array of strings\"\n    );\n  }\n  collection = $sort(collection, { [expr.field]: 1 }, options);\n  const nilOptions = ComputeOptions.init(options, null);\n  const computeNextValue = (value) => {\n    return isNumber(value) ? value + step : $dateAdd(\n      EMPTY_OBJECT,\n      { startDate: value, unit, amount: step },\n      nilOptions\n    );\n  };\n  const isValidUnit = !!unit && TIME_UNITS.includes(unit);\n  const getFieldValue = (o) => {\n    const v = resolve(o, expr.field);\n    if (isNil(v)) return v;\n    if (isNumber(v)) {\n      assert(\n        !isValidUnit,\n        \"$densify: Encountered non-date value in collection when step has a date unit.\"\n      );\n    } else if (isDate(v)) {\n      assert(\n        isValidUnit,\n        \"$densify: Encountered date value in collection when step does not have a date unit.\"\n      );\n    } else {\n      assert(false, \"$densify: Densify field type must be numeric or a date\");\n    }\n    return v;\n  };\n  const peekItem = new Array();\n  const nilFieldsIterator = Lazy(() => {\n    const item = collection.next();\n    const fieldValue = getFieldValue(item.value);\n    if (isNil(fieldValue)) return item;\n    peekItem.push(item);\n    return { done: true };\n  });\n  const nextDensifyValueMap = ValueMap.init(\n    options.hashFunction\n  );\n  const [lower, upper] = isArray(bounds) ? bounds : [bounds, bounds];\n  let maxFieldValue = void 0;\n  const updateMaxFieldValue = (value) => {\n    maxFieldValue = maxFieldValue === void 0 || maxFieldValue < value ? value : maxFieldValue;\n  };\n  const rootKey = [];\n  const densifyIterator = Lazy(() => {\n    const item = peekItem.length > 0 ? peekItem.pop() : collection.next();\n    if (item.done) return item;\n    let partitionKey = rootKey;\n    if (isArray(expr.partitionByFields)) {\n      partitionKey = expr.partitionByFields.map(\n        (k) => resolve(item.value, k)\n      );\n      assert(\n        partitionKey.every(isString),\n        \"$densify: Partition fields must evaluate to string values.\"\n      );\n    }\n    assert(isObject(item.value), \"$densify: collection must contain documents\");\n    const itemValue = getFieldValue(item.value);\n    if (!nextDensifyValueMap.has(partitionKey)) {\n      if (lower == \"full\") {\n        if (!nextDensifyValueMap.has(rootKey)) {\n          nextDensifyValueMap.set(rootKey, itemValue);\n        }\n        nextDensifyValueMap.set(partitionKey, nextDensifyValueMap.get(rootKey));\n      } else if (lower == \"partition\") {\n        nextDensifyValueMap.set(partitionKey, itemValue);\n      } else {\n        nextDensifyValueMap.set(partitionKey, lower);\n      }\n    }\n    const densifyValue = nextDensifyValueMap.get(partitionKey);\n    if (\n      // current item field value is lower than current densify value.\n      itemValue <= densifyValue || // range value equals or exceeds upper bound\n      upper != \"full\" && upper != \"partition\" && densifyValue >= upper\n    ) {\n      if (densifyValue <= itemValue) {\n        nextDensifyValueMap.set(partitionKey, computeNextValue(densifyValue));\n      }\n      updateMaxFieldValue(itemValue);\n      return item;\n    }\n    nextDensifyValueMap.set(partitionKey, computeNextValue(densifyValue));\n    updateMaxFieldValue(densifyValue);\n    const denseObj = { [expr.field]: densifyValue };\n    if (partitionKey) {\n      partitionKey.forEach((v, i) => {\n        denseObj[expr.partitionByFields[i]] = v;\n      });\n    }\n    peekItem.push(item);\n    return { done: false, value: denseObj };\n  });\n  if (lower !== \"full\") return concat(nilFieldsIterator, densifyIterator);\n  let paritionIndex = -1;\n  let partitionKeysSet = void 0;\n  const fullBoundsIterator = Lazy(() => {\n    if (paritionIndex === -1) {\n      const fullDensifyValue = nextDensifyValueMap.get(rootKey);\n      nextDensifyValueMap.delete(rootKey);\n      partitionKeysSet = Array.from(nextDensifyValueMap.keys());\n      if (partitionKeysSet.length === 0) {\n        partitionKeysSet.push(rootKey);\n        nextDensifyValueMap.set(rootKey, fullDensifyValue);\n      }\n      paritionIndex++;\n    }\n    do {\n      const partitionKey = partitionKeysSet[paritionIndex];\n      const partitionMaxValue = nextDensifyValueMap.get(partitionKey);\n      if (partitionMaxValue < maxFieldValue) {\n        nextDensifyValueMap.set(\n          partitionKey,\n          computeNextValue(partitionMaxValue)\n        );\n        const denseObj = { [expr.field]: partitionMaxValue };\n        partitionKey.forEach((v, i) => {\n          denseObj[expr.partitionByFields[i]] = v;\n        });\n        return { done: false, value: denseObj };\n      }\n      paritionIndex++;\n    } while (paritionIndex < partitionKeysSet.length);\n    return { done: true };\n  });\n  return concat(nilFieldsIterator, densifyIterator, fullBoundsIterator);\n};\nexport {\n  $densify\n};\n","import { Aggregator } from \"../../aggregator\";\nimport { ProcessingMode } from \"../../core\";\nconst $facet = (collection, expr, options) => {\n  return collection.transform((array) => {\n    const o = {};\n    for (const [k, pipeline] of Object.entries(expr)) {\n      o[k] = new Aggregator(pipeline, {\n        ...options,\n        processingMode: ProcessingMode.CLONE_INPUT\n      }).run(array);\n    }\n    return [o];\n  });\n};\nexport {\n  $facet\n};\n","import { initOptions } from \"../../core\";\nimport { assert, has, isObject } from \"../../util\";\nimport { $ifNull } from \"../expression/conditional/ifNull\";\nimport { $linearFill } from \"../window/linearFill\";\nimport { $locf } from \"../window/locf\";\nimport { $addFields } from \"./addFields\";\nimport { $setWindowFields } from \"./setWindowFields\";\nconst FILL_METHODS = {\n  locf: \"$locf\",\n  linear: \"$linearFill\"\n};\nconst $fill = (collection, expr, options) => {\n  assert(!expr.sortBy || isObject(expr.sortBy), \"sortBy must be an object.\");\n  assert(\n    !!expr.sortBy || Object.values(expr.output).every((m) => has(m, \"value\")),\n    \"sortBy required if any output field specifies a 'method'.\"\n  );\n  assert(\n    !(expr.partitionBy && expr.partitionByFields),\n    \"specify either partitionBy or partitionByFields.\"\n  );\n  assert(\n    !expr.partitionByFields || expr?.partitionByFields?.every((s) => s[0] !== \"$\"),\n    \"fields in partitionByFields cannot begin with '$'.\"\n  );\n  options = initOptions(options);\n  options.context.addExpressionOps({ $ifNull });\n  options.context.addWindowOps({ $locf, $linearFill });\n  const partitionExpr = expr.partitionBy || expr?.partitionByFields?.map((s) => \"$\" + s);\n  const valueExpr = {};\n  const methodExpr = {};\n  for (const [k, m] of Object.entries(expr.output)) {\n    if (has(m, \"value\")) {\n      valueExpr[k] = { $ifNull: [`$$CURRENT.${k}`, m[\"value\"]] };\n    } else {\n      const fillOp = FILL_METHODS[m[\"method\"]];\n      assert(!!fillOp, `invalid fill method '${m[\"method\"]}'.`);\n      methodExpr[k] = { [fillOp]: \"$\" + k };\n    }\n  }\n  if (Object.keys(methodExpr).length > 0) {\n    collection = $setWindowFields(\n      collection,\n      {\n        sortBy: expr.sortBy || {},\n        partitionBy: partitionExpr,\n        output: methodExpr\n      },\n      options\n    );\n  }\n  if (Object.keys(valueExpr).length > 0) {\n    collection = $addFields(collection, valueExpr, options);\n  }\n  return collection;\n};\nexport {\n  $fill\n};\n","import { computeValue } from \"../../core\";\nimport { Lazy } from \"../../lazy\";\nimport { flatten, isNil, isString, setValue, ValueMap } from \"../../util\";\nimport { $lookup } from \"./lookup\";\nconst $graphLookup = (collection, expr, options) => {\n  const fromColl = isString(expr.from) ? options?.collectionResolver(expr.from) : expr.from;\n  const {\n    connectFromField,\n    connectToField,\n    as: asField,\n    maxDepth,\n    depthField,\n    restrictSearchWithMatch: matchExpr\n  } = expr;\n  const pipelineExpr = matchExpr ? { pipeline: [{ $match: matchExpr }] } : {};\n  return collection.map((obj) => {\n    const matchObj = {};\n    setValue(\n      matchObj,\n      connectFromField,\n      computeValue(obj, expr.startWith, null, options)\n    );\n    let matches = [matchObj];\n    let i = -1;\n    const map = ValueMap.init(options.hashFunction);\n    do {\n      i++;\n      matches = flatten(\n        $lookup(\n          Lazy(matches),\n          {\n            from: fromColl,\n            localField: connectFromField,\n            foreignField: connectToField,\n            as: asField,\n            ...pipelineExpr\n          },\n          options\n        ).map((o) => o[asField]).value()\n      );\n      const oldSize = map.size;\n      matches.forEach((k) => map.set(k, map.get(k) ?? i));\n      if (oldSize == map.size) break;\n    } while (isNil(maxDepth) || i < maxDepth);\n    const result = new Array(map.size);\n    let n = 0;\n    map.forEach((v, k) => {\n      result[n++] = Object.assign(depthField ? { [depthField]: v } : {}, k);\n    });\n    return { ...obj, [asField]: result };\n  });\n};\nexport {\n  $graphLookup\n};\n","import {\n  ComputeOptions,\n  computeValue\n} from \"../../core\";\nimport { assert, groupBy, has } from \"../../util\";\nconst ID_KEY = \"_id\";\nconst $group = (collection, expr, options) => {\n  assert(has(expr, ID_KEY), \"$group specification must include an '_id'\");\n  const idExpr = expr[ID_KEY];\n  const copts = ComputeOptions.init(options);\n  const newFields = Object.keys(expr).filter((k) => k != ID_KEY);\n  return collection.transform((coll) => {\n    const partitions = groupBy(\n      coll,\n      (obj) => computeValue(obj, idExpr, null, options),\n      options.hashFunction\n    );\n    let i = -1;\n    const partitionKeys = Array.from(partitions.keys());\n    return () => {\n      if (++i === partitions.size) return { done: true };\n      const groupId = partitionKeys[i];\n      const obj = {};\n      if (groupId !== void 0) {\n        obj[ID_KEY] = groupId;\n      }\n      for (const key of newFields) {\n        obj[key] = computeValue(\n          partitions.get(groupId),\n          expr[key],\n          null,\n          copts.update(null, { groupId })\n        );\n      }\n      return { value: obj, done: false };\n    };\n  });\n};\nexport {\n  $group\n};\n","export * from \"./addFields\";\nexport * from \"./bucket\";\nexport * from \"./bucketAuto\";\nexport * from \"./count\";\nexport * from \"./densify\";\nexport * from \"./facet\";\nexport * from \"./fill\";\nexport * from \"./graphLookup\";\nexport * from \"./group\";\nexport * from \"./limit\";\nexport * from \"./lookup\";\nexport * from \"./match\";\nexport * from \"./merge\";\nexport * from \"./out\";\nexport * from \"./project\";\nexport * from \"./redact\";\nexport * from \"./replaceRoot\";\nexport * from \"./replaceWith\";\nexport * from \"./sample\";\nexport * from \"./set\";\nexport * from \"./setWindowFields\";\nexport * from \"./skip\";\nexport * from \"./sort\";\nexport * from \"./sortByCount\";\nexport * from \"./unionWith\";\nexport * from \"./unset\";\nexport * from \"./unwind\";\n","const $limit = (collection, expr, _options) => collection.take(expr);\nexport {\n  $limit\n};\n","import { Aggregator } from \"../../aggregator\";\nimport { computeValue } from \"../../core\";\nimport {\n  ensureArray,\n  flatten,\n  isArray,\n  isString,\n  resolve,\n  ValueMap\n} from \"../../util\";\nconst $lookup = (collection, expr, options) => {\n  const joinColl = isString(expr.from) ? options?.collectionResolver(expr.from) : expr.from;\n  const { let: letExpr, pipeline, foreignField, localField } = expr;\n  const subQueryPipeline = pipeline || [];\n  let lookupEq = (_) => [true, []];\n  if (foreignField && localField) {\n    const map = ValueMap.init(options.hashFunction);\n    for (const doc of joinColl) {\n      ensureArray(resolve(doc, foreignField) ?? null).forEach((v) => {\n        const xs = map.get(v);\n        const arr = xs ?? [];\n        arr.push(doc);\n        if (arr !== xs) map.set(v, arr);\n      });\n    }\n    lookupEq = (o) => {\n      const local = resolve(o, localField) ?? null;\n      if (isArray(local)) {\n        if (subQueryPipeline.length) {\n          return [local.some((v) => map.has(v)), null];\n        }\n        const result2 = Array.from(\n          new Set(flatten(local.map((v) => map.get(v), options.hashFunction)))\n        );\n        return [result2.length > 0, result2];\n      }\n      const result = map.get(local) ?? null;\n      return [result !== null, result ?? []];\n    };\n    if (subQueryPipeline.length === 0) {\n      return collection.map((obj) => {\n        return {\n          ...obj,\n          [expr.as]: lookupEq(obj).pop()\n        };\n      });\n    }\n  }\n  const agg = new Aggregator(subQueryPipeline, options);\n  const opts = { ...options };\n  return collection.map((obj) => {\n    const vars = computeValue(obj, letExpr, null, options);\n    opts.variables = { ...options.variables, ...vars };\n    const [ok, res] = lookupEq(obj);\n    return {\n      ...obj,\n      [expr.as]: ok ? agg.run(joinColl, opts) : res\n    };\n  });\n};\nexport {\n  $lookup\n};\n","import { Query } from \"../../query\";\nconst $match = (collection, expr, options) => {\n  const q = new Query(expr, options);\n  return collection.filter((o) => q.test(o));\n};\nexport {\n  $match\n};\n","import { Aggregator } from \"../../aggregator\";\nimport {\n  ComputeOptions,\n  computeValue\n} from \"../../core\";\nimport {\n  assert,\n  hashCode,\n  isArray,\n  isString,\n  MingoError,\n  resolve,\n  ValueMap\n} from \"../../util\";\nimport { $mergeObjects } from \"../expression\";\nconst $merge = (collection, expr, options) => {\n  const output = isString(expr.into) ? options?.collectionResolver(expr.into) : expr.into;\n  assert(isArray(output), `$merge: option 'into' must resolve to an array`);\n  const onField = expr.on || options.idKey;\n  const getHash = isString(onField) ? (o) => hashCode(resolve(o, onField), options.hashFunction) : (o) => hashCode(onField.map((s) => resolve(o, s), options.hashFunction));\n  const map = ValueMap.init();\n  for (let i = 0; i < output.length; i++) {\n    const obj = output[i];\n    const k = getHash(obj);\n    assert(\n      !map.has(k),\n      \"$merge: 'into' collection must have unique entries for the 'on' field.\"\n    );\n    map.set(k, [obj, i]);\n  }\n  const copts = ComputeOptions.init(options);\n  return collection.map((o) => {\n    const k = getHash(o);\n    if (map.has(k)) {\n      const [target, i] = map.get(k);\n      const variables = computeValue(\n        target,\n        expr.let || { new: \"$$ROOT\" },\n        null,\n        // 'root' is the item from the iteration.\n        copts.update(o)\n      );\n      if (isArray(expr.whenMatched)) {\n        const aggregator = new Aggregator(expr.whenMatched, {\n          ...options,\n          variables\n        });\n        output[i] = aggregator.run([target])[0];\n      } else {\n        switch (expr.whenMatched) {\n          case \"replace\":\n            output[i] = o;\n            break;\n          case \"fail\":\n            throw new MingoError(\n              \"$merge: failed due to matching as specified by 'whenMatched' option.\"\n            );\n          case \"keepExisting\":\n            break;\n          case \"merge\":\n          default:\n            output[i] = $mergeObjects(\n              target,\n              [target, o],\n              // 'root' is the item from the iteration.\n              copts.update(o, { variables })\n            );\n            break;\n        }\n      }\n    } else {\n      switch (expr.whenNotMatched) {\n        case \"discard\":\n          break;\n        case \"fail\":\n          throw new MingoError(\n            \"$merge: failed due to matching as specified by 'whenMatched' option.\"\n          );\n        case \"insert\":\n        default:\n          output.push(o);\n          break;\n      }\n    }\n    return o;\n  });\n};\nexport {\n  $merge\n};\n","import { assert, cloneDeep, isArray, isString } from \"../../util\";\nconst $out = (collection, expr, options) => {\n  const outputColl = isString(expr) ? options?.collectionResolver(expr) : expr;\n  assert(isArray(outputColl), `expression must resolve to an array`);\n  return collection.map((o) => {\n    outputColl.push(cloneDeep(o));\n    return o;\n  });\n};\nexport {\n  $out\n};\n","import {\n  ComputeOptions,\n  computeValue,\n  getOperator\n} from \"../../core\";\nimport {\n  assert,\n  ensureArray,\n  filterMissing,\n  has,\n  isArray,\n  isBoolean,\n  isEmpty,\n  isNumber,\n  isObject,\n  isOperator,\n  isString,\n  merge,\n  removeValue,\n  resolve,\n  resolveGraph,\n  setValue\n} from \"../../util\";\nconst $project = (collection, expr, options) => {\n  if (isEmpty(expr)) return collection;\n  validateExpression(expr, options);\n  return collection.map(createHandler(expr, ComputeOptions.init(options)));\n};\nfunction createHandler(expr, options, isRoot = true) {\n  const idKey = options.idKey;\n  const expressionKeys = Object.keys(expr);\n  const excludedKeys = new Array();\n  const includedKeys = new Array();\n  const handlers = {};\n  for (const key of expressionKeys) {\n    const subExpr = expr[key];\n    if (isNumber(subExpr) || isBoolean(subExpr)) {\n      if (subExpr) {\n        includedKeys.push(key);\n      } else {\n        excludedKeys.push(key);\n      }\n    } else if (isArray(subExpr)) {\n      handlers[key] = (o) => subExpr.map((v) => computeValue(o, v, null, options.update(o)) ?? null);\n    } else if (isObject(subExpr)) {\n      const subExprKeys = Object.keys(subExpr);\n      const operator = subExprKeys.length == 1 ? subExprKeys[0] : \"\";\n      const projectFn = getOperator(\n        \"projection\",\n        operator,\n        options\n      );\n      if (projectFn) {\n        const foundSlice = operator === \"$slice\";\n        if (foundSlice && !ensureArray(subExpr[operator]).every(isNumber)) {\n          handlers[key] = (o) => computeValue(o, subExpr, key, options.update(o));\n        } else {\n          handlers[key] = (o) => projectFn(o, subExpr[operator], key, options.update(o));\n        }\n      } else if (isOperator(operator)) {\n        handlers[key] = (o) => computeValue(o, subExpr[operator], operator, options);\n      } else {\n        validateExpression(subExpr, options);\n        handlers[key] = (o) => {\n          if (!has(o, key)) return computeValue(o, subExpr, null, options);\n          if (isRoot) options.update(o);\n          const target = resolve(o, key);\n          const fn = createHandler(subExpr, options, false);\n          if (isArray(target)) return target.map(fn);\n          if (isObject(target)) return fn(target);\n          return fn(o);\n        };\n      }\n    } else {\n      handlers[key] = isString(subExpr) && subExpr[0] === \"$\" ? (o) => computeValue(o, subExpr, key, options) : (_) => subExpr;\n    }\n  }\n  const handlerKeys = Object.keys(handlers);\n  const idKeyExcluded = excludedKeys.includes(idKey);\n  const idKeyOnlyExcluded = isRoot && idKeyExcluded && excludedKeys.length === 1 && !includedKeys.length && !handlerKeys.length;\n  if (idKeyOnlyExcluded) {\n    return (o) => {\n      const newObj = { ...o };\n      delete newObj[idKey];\n      return newObj;\n    };\n  }\n  const idKeyImplicit = isRoot && !idKeyExcluded && !includedKeys.includes(idKey);\n  const opts = {\n    preserveMissing: true\n  };\n  return (o) => {\n    const newObj = {};\n    if (excludedKeys.length && !includedKeys.length) {\n      merge(newObj, o);\n      for (const k of excludedKeys) {\n        removeValue(newObj, k, { descendArray: true });\n      }\n    }\n    for (const k of includedKeys) {\n      const pathObj = resolveGraph(o, k, opts) ?? {};\n      merge(newObj, pathObj);\n    }\n    if (includedKeys.length) filterMissing(newObj);\n    for (const k of handlerKeys) {\n      const value = handlers[k](o);\n      if (value === void 0) {\n        removeValue(newObj, k, { descendArray: true });\n      } else {\n        setValue(newObj, k, value);\n      }\n    }\n    if (idKeyImplicit && has(o, idKey)) {\n      newObj[idKey] = resolve(o, idKey);\n    }\n    return newObj;\n  };\n}\nfunction validateExpression(expr, options) {\n  let exclusions = false;\n  let inclusions = false;\n  for (const [k, v] of Object.entries(expr)) {\n    assert(!k.startsWith(\"$\"), \"Field names may not start with '$'.\");\n    assert(\n      !k.endsWith(\".$\"),\n      \"Positional projection operator '$' is not supported.\"\n    );\n    if (k === options?.idKey) continue;\n    if (v === 0 || v === false) {\n      exclusions = true;\n    } else if (v === 1 || v === true) {\n      inclusions = true;\n    }\n    assert(\n      !(exclusions && inclusions),\n      \"Projection cannot have a mix of inclusion and exclusion.\"\n    );\n  }\n}\nexport {\n  $project\n};\n","import { ComputeOptions, redact } from \"../../core\";\nconst $redact = (collection, expr, options) => {\n  const copts = ComputeOptions.init(options);\n  return collection.map(\n    (obj) => redact(obj, expr, copts.update(obj))\n  );\n};\nexport {\n  $redact\n};\n","import { computeValue } from \"../../core\";\nimport { assert, isObject } from \"../../util\";\nconst $replaceRoot = (collection, expr, options) => {\n  return collection.map((obj) => {\n    obj = computeValue(obj, expr.newRoot, null, options);\n    assert(isObject(obj), \"$replaceRoot expression must return an object\");\n    return obj;\n  });\n};\nexport {\n  $replaceRoot\n};\n","import { computeValue } from \"../../core\";\nimport { assert, isObject } from \"../../util\";\nconst $replaceWith = (collection, expr, options) => {\n  return collection.map((obj) => {\n    obj = computeValue(obj, expr, null, options);\n    assert(isObject(obj), \"$replaceWith expression must return an object\");\n    return obj;\n  });\n};\nexport {\n  $replaceWith\n};\n","const $sample = (collection, expr, _options) => {\n  return collection.transform((xs) => {\n    const len = xs.length;\n    let i = -1;\n    return () => {\n      if (++i === expr.size) return { done: true };\n      const n = Math.floor(Math.random() * len);\n      return { value: xs[n], done: false };\n    };\n  });\n};\nexport {\n  $sample\n};\n","import { $addFields } from \"./addFields\";\nconst $set = $addFields;\nexport {\n  $set\n};\n","import {\n  getOperator,\n  initOptions\n} from \"../../core\";\nimport { concat, Lazy } from \"../../lazy\";\nimport { assert, isNumber, isOperator, isString } from \"../../util\";\nimport { $function } from \"../expression/custom/function\";\nimport { $dateAdd } from \"../expression/date/dateAdd\";\nimport { isUnbounded } from \"./_internal\";\nimport { $addFields } from \"./addFields\";\nimport { $group } from \"./group\";\nimport { $sort } from \"./sort\";\nconst SORT_REQUIRED_OPS = /* @__PURE__ */ new Set([\n  \"$denseRank\",\n  \"$documentNumber\",\n  \"$first\",\n  \"$last\",\n  \"$linearFill\",\n  \"$rank\",\n  \"$shift\"\n]);\nconst WINDOW_UNBOUNDED_OPS = /* @__PURE__ */ new Set([\n  \"$denseRank\",\n  \"$expMovingAvg\",\n  \"$linearFill\",\n  \"$locf\",\n  \"$rank\",\n  \"$shift\"\n]);\nconst $setWindowFields = (collection, expr, options) => {\n  options = initOptions(options);\n  options.context.addExpressionOps({ $function });\n  for (const outputExpr of Object.values(expr.output)) {\n    const keys = Object.keys(outputExpr);\n    const op = keys.find(isOperator);\n    assert(\n      !!getOperator(\"window\", op, options) || !!getOperator(\"accumulator\", op, options),\n      `'${op}' is not a valid window operator`\n    );\n    assert(\n      keys.length > 0 && keys.length <= 2 && (keys.length == 1 || keys.includes(\"window\")),\n      \"'output' option should have a single window operator.\"\n    );\n    if (outputExpr?.window) {\n      const { documents, range } = outputExpr.window;\n      assert(\n        !!documents && !range || !documents && !!range || !documents && !range,\n        \"'window' option supports only one of 'documents' or 'range'.\"\n      );\n    }\n  }\n  if (expr.sortBy) {\n    collection = $sort(collection, expr.sortBy, options);\n  }\n  collection = $group(\n    collection,\n    {\n      _id: expr.partitionBy,\n      items: { $push: \"$$CURRENT\" }\n    },\n    options\n  );\n  return collection.transform((partitions) => {\n    const iterators = [];\n    const outputConfig = [];\n    for (const [field, outputExpr] of Object.entries(expr.output)) {\n      const op = Object.keys(outputExpr).find(isOperator);\n      const config = {\n        operatorName: op,\n        func: {\n          left: getOperator(\"accumulator\", op, options),\n          right: getOperator(\"window\", op, options)\n        },\n        args: outputExpr[op],\n        field,\n        window: outputExpr.window\n      };\n      assert(\n        !!expr.sortBy || !(SORT_REQUIRED_OPS.has(op) || !config.window),\n        `${SORT_REQUIRED_OPS.has(op) ? `'${op}'` : \"bounded window operation\"} requires a sortBy.`\n      );\n      assert(\n        !config.window || !WINDOW_UNBOUNDED_OPS.has(op),\n        `${op} does not accept a 'window' field.`\n      );\n      outputConfig.push(config);\n    }\n    partitions.forEach((group) => {\n      const items = group.items;\n      let iterator = Lazy(items);\n      const windowResultMap = {};\n      for (const config of outputConfig) {\n        const { func, args, field, window } = config;\n        const makeResultFunc = (getItemsFn) => {\n          let index = -1;\n          return (obj) => {\n            ++index;\n            if (func.left) {\n              return func.left(getItemsFn(obj, index), args, options);\n            } else if (func.right) {\n              return func.right(\n                obj,\n                getItemsFn(obj, index),\n                {\n                  parentExpr: expr,\n                  inputExpr: args,\n                  documentNumber: index + 1,\n                  field\n                },\n                // must use raw options only since it operates over a collection.\n                options\n              );\n            }\n          };\n        };\n        if (window) {\n          const { documents, range, unit } = window;\n          const boundary = documents || range;\n          if (!isUnbounded(window)) {\n            const [begin, end] = boundary;\n            const toBeginIndex = (currentIndex) => {\n              if (begin == \"current\") return currentIndex;\n              if (begin == \"unbounded\") return 0;\n              return Math.max(begin + currentIndex, 0);\n            };\n            const toEndIndex = (currentIndex) => {\n              if (end == \"current\") return currentIndex + 1;\n              if (end == \"unbounded\") return items.length;\n              return end + currentIndex + 1;\n            };\n            const getItems = (current, index) => {\n              if (!!documents || boundary.every(isString)) {\n                return items.slice(toBeginIndex(index), toEndIndex(index));\n              }\n              const sortKey = Object.keys(expr.sortBy)[0];\n              let lower;\n              let upper;\n              if (unit) {\n                const getTime = (amount) => {\n                  return $dateAdd(\n                    current,\n                    {\n                      startDate: new Date(current[sortKey]),\n                      unit,\n                      amount\n                    },\n                    options\n                  ).getTime();\n                };\n                lower = isNumber(begin) ? getTime(begin) : -Infinity;\n                upper = isNumber(end) ? getTime(end) : Infinity;\n              } else {\n                const currentValue = current[sortKey];\n                lower = isNumber(begin) ? currentValue + begin : -Infinity;\n                upper = isNumber(end) ? currentValue + end : Infinity;\n              }\n              let array = items;\n              if (begin == \"current\") array = items.slice(index);\n              if (end == \"current\") array = items.slice(0, index + 1);\n              return array.filter((o) => {\n                const n = +o[sortKey];\n                return n >= lower && n <= upper;\n              });\n            };\n            windowResultMap[field] = makeResultFunc(getItems);\n          }\n        }\n        if (!windowResultMap[field]) {\n          windowResultMap[field] = makeResultFunc((_) => items);\n        }\n        iterator = $addFields(\n          iterator,\n          {\n            [field]: {\n              $function: {\n                body: (obj) => windowResultMap[field](obj),\n                args: [\"$$CURRENT\"]\n              }\n            }\n          },\n          options\n        );\n      }\n      iterators.push(iterator);\n    });\n    return concat(...iterators);\n  });\n};\nexport {\n  $setWindowFields\n};\n","const $skip = (collection, expr, _options) => {\n  return collection.drop(expr);\n};\nexport {\n  $skip\n};\n","import {\n  assert,\n  compare,\n  groupBy,\n  isEmpty,\n  isObject,\n  isString,\n  resolve\n} from \"../../util\";\nconst $sort = (collection, sortKeys, options) => {\n  if (isEmpty(sortKeys) || !isObject(sortKeys)) return collection;\n  let cmp = compare;\n  const collationSpec = options.collation;\n  if (isObject(collationSpec) && isString(collationSpec.locale)) {\n    cmp = collationComparator(collationSpec);\n  }\n  return collection.transform((coll) => {\n    const modifiers = Object.keys(sortKeys);\n    for (const key of modifiers.reverse()) {\n      const groups = groupBy(\n        coll,\n        (obj) => resolve(obj, key),\n        options.hashFunction\n      );\n      const sortedKeys = Array.from(groups.keys()).sort(cmp);\n      if (sortKeys[key] === -1) sortedKeys.reverse();\n      let i = 0;\n      for (const k of sortedKeys) for (const v of groups.get(k)) coll[i++] = v;\n      assert(i == coll.length, \"bug: counter must match collection size.\");\n    }\n    return coll;\n  });\n};\nconst COLLATION_STRENGTH = {\n  // Only strings that differ in base letters compare as unequal. Examples: a ≠ b, a = á, a = A.\n  1: \"base\",\n  //  Only strings that differ in base letters or accents and other diacritic marks compare as unequal.\n  // Examples: a ≠ b, a ≠ á, a = A.\n  2: \"accent\",\n  // Strings that differ in base letters, accents and other diacritic marks, or case compare as unequal.\n  // Other differences may also be taken into consideration. Examples: a ≠ b, a ≠ á, a ≠ A\n  3: \"variant\"\n  // case - Only strings that differ in base letters or case compare as unequal. Examples: a ≠ b, a = á, a ≠ A.\n};\nfunction collationComparator(spec) {\n  const localeOpt = {\n    sensitivity: COLLATION_STRENGTH[spec.strength || 3],\n    caseFirst: spec.caseFirst === \"off\" ? \"false\" : spec.caseFirst || \"false\",\n    numeric: spec.numericOrdering || false,\n    ignorePunctuation: spec.alternate === \"shifted\"\n  };\n  if ((spec.caseLevel || false) === true) {\n    if (localeOpt.sensitivity === \"base\") localeOpt.sensitivity = \"case\";\n    if (localeOpt.sensitivity === \"accent\") localeOpt.sensitivity = \"variant\";\n  }\n  const collator = new Intl.Collator(spec.locale, localeOpt);\n  return (a, b) => {\n    if (!isString(a) || !isString(b)) return compare(a, b);\n    const i = collator.compare(a, b);\n    if (i < 0) return -1;\n    if (i > 0) return 1;\n    return 0;\n  };\n}\nexport {\n  $sort\n};\n","import { $group } from \"./group\";\nimport { $sort } from \"./sort\";\nconst $sortByCount = (collection, expr, options) => {\n  return $sort(\n    $group(collection, { _id: expr, count: { $sum: 1 } }, options),\n    { count: -1 },\n    options\n  );\n};\nexport {\n  $sortByCount\n};\n","import { Aggregator } from \"../../aggregator\";\nimport { concat, Lazy } from \"../../lazy\";\nimport { isString } from \"../../util\";\nconst $unionWith = (collection, expr, options) => {\n  const array = isString(expr.coll) ? options.collectionResolver(expr.coll) : expr.coll;\n  const iterators = [collection];\n  iterators.push(\n    expr.pipeline ? new Aggregator(expr.pipeline, options).stream(array) : Lazy(array)\n  );\n  return concat(...iterators);\n};\nexport {\n  $unionWith\n};\n","import { ensureArray } from \"../../util\";\nimport { $project } from \"./project\";\nconst $unset = (collection, expr, options) => {\n  expr = ensureArray(expr);\n  const doc = {};\n  for (const k of expr) doc[k] = 0;\n  return $project(collection, doc, options);\n};\nexport {\n  $unset\n};\n","import { Iterator, Lazy } from \"../../lazy\";\nimport {\n  isArray,\n  isEmpty,\n  isString,\n  removeValue,\n  resolve,\n  resolveGraph,\n  setValue\n} from \"../../util\";\nconst $unwind = (collection, expr, _options) => {\n  if (isString(expr)) expr = { path: expr };\n  const path = expr.path;\n  const field = path.substring(1);\n  const includeArrayIndex = expr?.includeArrayIndex || false;\n  const preserveNullAndEmptyArrays = expr.preserveNullAndEmptyArrays || false;\n  const format = (o, i) => {\n    if (includeArrayIndex !== false) o[includeArrayIndex] = i;\n    return o;\n  };\n  let value;\n  return Lazy(() => {\n    for (; ; ) {\n      if (value instanceof Iterator) {\n        const tmp = value.next();\n        if (!tmp.done) return tmp;\n      }\n      const wrapper = collection.next();\n      if (wrapper.done) return wrapper;\n      const obj = wrapper.value;\n      value = resolve(obj, field);\n      if (isArray(value)) {\n        if (value.length === 0 && preserveNullAndEmptyArrays === true) {\n          value = null;\n          removeValue(obj, field);\n          return { value: format(obj, null), done: false };\n        } else {\n          value = Lazy(value).map((item, i) => {\n            const newObj = resolveGraph(obj, field, {\n              preserveKeys: true\n            });\n            setValue(newObj, field, item);\n            return format(newObj, i);\n          });\n        }\n      } else if (!isEmpty(value) || preserveNullAndEmptyArrays === true) {\n        return { value: format(obj, null), done: false };\n      }\n    }\n  });\n};\nexport {\n  $unwind\n};\n","import { $all as __all, createQueryOperator } from \"../../_predicates\";\nconst $all = createQueryOperator(__all);\nexport {\n  $all\n};\n","import {\n  $elemMatch as __elemMatch,\n  createQueryOperator\n} from \"../../_predicates\";\nconst $elemMatch = createQueryOperator(__elemMatch);\nexport {\n  $elemMatch\n};\n","export * from \"./all\";\nexport * from \"./elemMatch\";\nexport * from \"./size\";\n","import { $size as __size, createQueryOperator } from \"../../_predicates\";\nconst $size = createQueryOperator(__size);\nexport {\n  $size\n};\n","import { isArray } from \"../../../util\";\nimport { createQueryOperator } from \"../../_predicates\";\nconst createBitwiseOperator = (predicate) => {\n  return createQueryOperator(\n    (value, mask, _options) => {\n      let b = 0;\n      if (isArray(mask)) {\n        for (const n of mask) b = b | 1 << n;\n      } else {\n        b = mask;\n      }\n      return predicate(value & b, b);\n    }\n  );\n};\nexport {\n  createBitwiseOperator\n};\n","import { createBitwiseOperator } from \"./_internal\";\nconst $bitsAllClear = createBitwiseOperator((result, _) => result == 0);\nexport {\n  $bitsAllClear\n};\n","import { createBitwiseOperator } from \"./_internal\";\nconst $bitsAllSet = createBitwiseOperator(\n  (result, mask) => result == mask\n);\nexport {\n  $bitsAllSet\n};\n","import { createBitwiseOperator } from \"./_internal\";\nconst $bitsAnyClear = createBitwiseOperator(\n  (result, mask) => result < mask\n);\nexport {\n  $bitsAnyClear\n};\n","import { createBitwiseOperator } from \"./_internal\";\nconst $bitsAnySet = createBitwiseOperator((result, _) => result > 0);\nexport {\n  $bitsAnySet\n};\n","import { $bitsAllClear } from \"./bitsAllClear\";\nimport { $bitsAllSet } from \"./bitsAllSet\";\nimport { $bitsAnyClear } from \"./bitsAnyClear\";\nimport { $bitsAnySet } from \"./bitsAnySet\";\nexport {\n  $bitsAllClear,\n  $bitsAllSet,\n  $bitsAnyClear,\n  $bitsAnySet\n};\n","import { $eq as __eq, createQueryOperator } from \"../../_predicates\";\nconst $eq = createQueryOperator(__eq);\nexport {\n  $eq\n};\n","import { $gt as __gt, createQueryOperator } from \"../../_predicates\";\nconst $gt = createQueryOperator(__gt);\nexport {\n  $gt\n};\n","import { $gte as __gte, createQueryOperator } from \"../../_predicates\";\nconst $gte = createQueryOperator(__gte);\nexport {\n  $gte\n};\n","import { $in as __in, createQueryOperator } from \"../../_predicates\";\nconst $in = createQueryOperator(__in);\nexport {\n  $in\n};\n","import { $eq } from \"./eq\";\nimport { $gt } from \"./gt\";\nimport { $gte } from \"./gte\";\nimport { $in } from \"./in\";\nimport { $lt } from \"./lt\";\nimport { $lte } from \"./lte\";\nimport { $ne } from \"./ne\";\nimport { $nin } from \"./nin\";\nexport {\n  $eq,\n  $gt,\n  $gte,\n  $in,\n  $lt,\n  $lte,\n  $ne,\n  $nin\n};\n","import { $lt as __lt, createQueryOperator } from \"../../_predicates\";\nconst $lt = createQueryOperator(__lt);\nexport {\n  $lt\n};\n","import { $lte as __lte, createQueryOperator } from \"../../_predicates\";\nconst $lte = createQueryOperator(__lte);\nexport {\n  $lte\n};\n","import { $ne as __ne, createQueryOperator } from \"../../_predicates\";\nconst $ne = createQueryOperator(__ne);\nexport {\n  $ne\n};\n","import { $nin as __nin, createQueryOperator } from \"../../_predicates\";\nconst $nin = createQueryOperator(__nin);\nexport {\n  $nin\n};\n","import { isArray, resolve, resolveGraph } from \"../../../util\";\nconst $exists = (selector, value, _options) => {\n  const nested = selector.includes(\".\");\n  const b = !!value;\n  if (!nested || selector.match(/\\.\\d+$/)) {\n    return (o) => resolve(o, selector) !== void 0 === b;\n  }\n  return (o) => {\n    const path = resolveGraph(o, selector, { preserveIndex: true });\n    const val = resolve(path, selector.substring(0, selector.lastIndexOf(\".\")));\n    return isArray(val) ? val.some((v) => v !== void 0) === b : val !== void 0 === b;\n  };\n};\nexport {\n  $exists\n};\n","export * from \"./exists\";\nexport * from \"./type\";\n","import { $type as __type, createQueryOperator } from \"../../_predicates\";\nconst $type = createQueryOperator(__type);\nexport {\n  $type\n};\n","import { computeValue } from \"../../../core\";\nfunction $expr(_, rhs, options) {\n  return (obj) => computeValue(obj, rhs, null, options);\n}\nexport {\n  $expr\n};\n","export * from \"./expr\";\nexport * from \"./jsonSchema\";\nexport * from \"./mod\";\nexport * from \"./regex\";\nexport * from \"./where\";\n","import { MingoError } from \"../../../util\";\nfunction $jsonSchema(_, schema, options) {\n  if (!options?.jsonSchemaValidator) {\n    throw new MingoError(\n      \"Missing option 'jsonSchemaValidator'. Configure to use '$jsonSchema' operator.\"\n    );\n  }\n  const validate = options?.jsonSchemaValidator(schema);\n  return (obj) => validate(obj);\n}\nexport {\n  $jsonSchema\n};\n","import { $mod as __mod, createQueryOperator } from \"../../_predicates\";\nconst $mod = createQueryOperator(__mod);\nexport {\n  $mod\n};\n","import { $regex as __regex, createQueryOperator } from \"../../_predicates\";\nconst $regex = createQueryOperator(__regex);\nexport {\n  $regex\n};\n","import { assert, isFunction, truthy } from \"../../../util\";\nfunction $where(_, rhs, options) {\n  assert(\n    options.scriptEnabled,\n    \"$where operator requires 'scriptEnabled' option to be true\"\n  );\n  const f = rhs;\n  assert(isFunction(f), \"$where only accepts a Function object\");\n  return (obj) => truthy(f.call(obj), options?.useStrictMode);\n}\nexport {\n  $where\n};\n","export * from \"./array\";\nexport * from \"./bitwise\";\nexport * from \"./comparison\";\nexport * from \"./element\";\nexport * from \"./evaluation\";\nexport * from \"./logical\";\n","import { Query } from \"../../../query\";\nimport { assert, isArray } from \"../../../util\";\nconst $and = (_, rhs, options) => {\n  assert(\n    isArray(rhs),\n    \"Invalid expression: $and expects value to be an Array.\"\n  );\n  const queries = rhs.map((expr) => new Query(expr, options));\n  return (obj) => queries.every((q) => q.test(obj));\n};\nexport {\n  $and\n};\n","export * from \"./and\";\nexport * from \"./nor\";\nexport * from \"./not\";\nexport * from \"./or\";\n","import { assert, isArray } from \"../../../util\";\nimport { $or } from \"./or\";\nconst $nor = (_, rhs, options) => {\n  assert(\n    isArray(rhs),\n    \"Invalid expression. $nor expects value to be an array.\"\n  );\n  const f = $or(\"$or\", rhs, options);\n  return (obj) => !f(obj);\n};\nexport {\n  $nor\n};\n","import { Query } from \"../../../query\";\nimport { normalize } from \"../../../util\";\nconst $not = (selector, rhs, options) => {\n  const criteria = {};\n  criteria[selector] = normalize(rhs);\n  const query = new Query(criteria, options);\n  return (obj) => !query.test(obj);\n};\nexport {\n  $not\n};\n","import { Query } from \"../../../query\";\nimport { assert, isArray } from \"../../../util\";\nconst $or = (_, rhs, options) => {\n  assert(isArray(rhs), \"Invalid expression. $or expects value to be an Array\");\n  const queries = rhs.map((expr) => new Query(expr, options));\n  return (obj) => queries.some((q) => q.test(obj));\n};\nexport {\n  $or\n};\n","import { Context, initOptions } from \"../../core\";\nimport * as booleanOperators from \"../../operators/expression/boolean\";\nimport * as comparisonOperators from \"../../operators/expression/comparison\";\nimport * as queryOperators from \"../../operators/query\";\nimport { Query } from \"../../query\";\nimport {\n  assert,\n  cloneDeep,\n  isArray,\n  isDate,\n  isObject,\n  isRegExp,\n  resolve,\n  walk\n} from \"../../util\";\nconst UPDATE_OPTIONS = {\n  cloneMode: \"copy\",\n  queryOptions: initOptions({\n    context: Context.init().addQueryOps(queryOperators).addExpressionOps(booleanOperators).addExpressionOps(comparisonOperators)\n  })\n};\nconst clone = (mode, val) => {\n  switch (mode) {\n    case \"deep\":\n      return cloneDeep(val);\n    case \"copy\": {\n      if (isDate(val)) return new Date(val);\n      if (isArray(val)) return [...val];\n      if (isObject(val)) return { ...val };\n      if (isRegExp(val)) return new RegExp(val);\n      return val;\n    }\n    default:\n      return val;\n  }\n};\nconst FILTER_IDENT_RE = /^[a-z]+[a-zA-Z0-9]*$/;\nfunction tokenizePath(selector) {\n  if (!selector.includes(\".$\")) {\n    return [{ parent: selector, selector }, []];\n  }\n  const begin = selector.indexOf(\".$\");\n  const end = selector.indexOf(\"]\");\n  const parent = selector.substring(0, begin);\n  const child = selector.substring(begin + 3, end);\n  assert(\n    child === \"\" || FILTER_IDENT_RE.test(child),\n    \"The filter <identifier> must begin with a lowercase letter and contain only alphanumeric characters.\"\n  );\n  const rest = selector.substring(end + 2);\n  const [next, elems] = rest ? tokenizePath(rest) : [];\n  return [\n    { selector, parent, child: child || \"$\", next },\n    [child, ...elems || []].filter(Boolean)\n  ];\n}\nconst applyUpdate = (o, n, q, f, opts) => {\n  const { parent, child: c, next } = n;\n  if (!c) {\n    let b = false;\n    const g = (u, k) => b = Boolean(f(u, k)) || b;\n    walk(o, parent, g, opts);\n    return b;\n  }\n  const t = resolve(o, parent);\n  if (!isArray(t)) return false;\n  return t.map((e, i) => {\n    if (q[c] && !q[c].test({ [c]: e })) return false;\n    return next ? applyUpdate(e, next, q, f, opts) : f(t, i);\n  }).some(Boolean);\n};\nfunction walkExpression(expr, arrayFilter, options, callback) {\n  const res = [];\n  for (const [selector, val] of Object.entries(expr)) {\n    const [node, vars] = tokenizePath(selector);\n    if (!vars.length) {\n      if (callback(val, node, {})) res.push(node.parent);\n    } else {\n      const conditions = {};\n      arrayFilter.forEach((o) => {\n        Object.keys(o).forEach((k) => {\n          vars.forEach((w) => {\n            if (k === w || k.startsWith(w + \".\")) {\n              conditions[w] = conditions[w] || {};\n              Object.assign(conditions[w], { [k]: o[k] });\n            }\n          });\n        });\n      });\n      const queries = {};\n      for (const [k, condition] of Object.entries(conditions)) {\n        queries[k] = new Query(condition, options.queryOptions);\n      }\n      if (callback(val, node, queries)) res.push(node.parent);\n    }\n  }\n  return res;\n}\nexport {\n  UPDATE_OPTIONS,\n  applyUpdate,\n  clone,\n  tokenizePath,\n  walkExpression\n};\n","import { has, intersection, isObject, unique } from \"../../util\";\nimport {\n  applyUpdate,\n  clone,\n  UPDATE_OPTIONS,\n  walkExpression\n} from \"./_internal\";\nconst $addToSet = (obj, expr, arrayFilters = [], options = UPDATE_OPTIONS) => {\n  return walkExpression(expr, arrayFilters, options, (val, node, queries) => {\n    const args = { $each: [val] };\n    if (isObject(val) && has(val, \"$each\")) {\n      Object.assign(args, val);\n    }\n    return applyUpdate(\n      obj,\n      node,\n      queries,\n      (o, k) => {\n        const prev = o[k] ||= [];\n        const common = intersection([prev, args.$each]);\n        if (common.length === args.$each.length) return false;\n        o[k] = clone(options.cloneMode, unique(prev.concat(args.$each)));\n        return true;\n      },\n      { buildGraph: true }\n    );\n  });\n};\nexport {\n  $addToSet\n};\n","import { assert, isNumber } from \"../../util\";\nimport {\n  applyUpdate,\n  UPDATE_OPTIONS,\n  walkExpression\n} from \"./_internal\";\nconst BIT_OPS = /* @__PURE__ */ new Set([\"and\", \"or\", \"xor\"]);\nconst $bit = (obj, expr, arrayFilters = [], options = UPDATE_OPTIONS) => {\n  return walkExpression(expr, arrayFilters, options, (val, node, queries) => {\n    const op = Object.keys(val);\n    assert(\n      op.length === 1 && BIT_OPS.has(op[0]),\n      `Invalid bit operator '${op[0]}'. Must be one of 'and', 'or', or 'xor'.`\n    );\n    return applyUpdate(\n      obj,\n      node,\n      queries,\n      (o, k) => {\n        let n = o[k];\n        const v = val[op[0]];\n        if (n !== void 0 && !(isNumber(n) && isNumber(v))) return false;\n        n = n || 0;\n        switch (op[0]) {\n          case \"and\":\n            o[k] = n & v;\n            break;\n          case \"or\":\n            o[k] = n | v;\n            break;\n          case \"xor\":\n            o[k] = n ^ v;\n            break;\n        }\n        return o[k] !== n;\n      },\n      { buildGraph: true }\n    );\n  });\n};\nexport {\n  $bit\n};\n","import {\n  applyUpdate,\n  UPDATE_OPTIONS,\n  walkExpression\n} from \"./_internal\";\nconst $currentDate = (obj, expr, arrayFilters = [], options = UPDATE_OPTIONS) => {\n  const now = Date.now();\n  return walkExpression(expr, arrayFilters, options, (_, node, queries) => {\n    return applyUpdate(\n      obj,\n      node,\n      queries,\n      (o, k) => {\n        o[k] = now;\n        return true;\n      },\n      { buildGraph: true }\n    );\n  });\n};\nexport {\n  $currentDate\n};\n","import { assert, isNumber, resolve } from \"../../util\";\nimport { applyUpdate, UPDATE_OPTIONS, walkExpression } from \"./_internal\";\nconst $inc = (obj, expr, arrayFilters = [], options = UPDATE_OPTIONS) => {\n  return walkExpression(expr, arrayFilters, options, (val, node, queries) => {\n    if (!node.child) {\n      const n = resolve(obj, node.parent);\n      assert(\n        n === void 0 || isNumber(n),\n        `cannot apply $inc to a value of non-numeric type`\n      );\n    }\n    return applyUpdate(\n      obj,\n      node,\n      queries,\n      (o, k) => {\n        o[k] = (o[k] ||= 0) + val;\n        return true;\n      },\n      { buildGraph: true }\n    );\n  });\n};\nexport {\n  $inc\n};\n","export * from \"./addToSet\";\nexport * from \"./bit\";\nexport * from \"./currentDate\";\nexport * from \"./inc\";\nexport * from \"./max\";\nexport * from \"./min\";\nexport * from \"./mul\";\nexport * from \"./pop\";\nexport * from \"./pull\";\nexport * from \"./pullAll\";\nexport * from \"./push\";\nexport * from \"./rename\";\nexport * from \"./set\";\nexport * from \"./unset\";\n","import { compare } from \"../../util\";\nimport {\n  applyUpdate,\n  UPDATE_OPTIONS,\n  walkExpression\n} from \"./_internal\";\nconst $max = (obj, expr, arrayFilters = [], options = UPDATE_OPTIONS) => {\n  return walkExpression(expr, arrayFilters, options, (val, node, queries) => {\n    return applyUpdate(\n      obj,\n      node,\n      queries,\n      (o, k) => {\n        if (o[k] !== void 0 && compare(o[k], val) > -1) return false;\n        o[k] = val;\n        return true;\n      },\n      { buildGraph: true }\n    );\n  });\n};\nexport {\n  $max\n};\n","import { compare } from \"../../util\";\nimport {\n  applyUpdate,\n  UPDATE_OPTIONS,\n  walkExpression\n} from \"./_internal\";\nconst $min = (obj, expr, arrayFilters = [], options = UPDATE_OPTIONS) => {\n  return walkExpression(expr, arrayFilters, options, (val, node, queries) => {\n    return applyUpdate(\n      obj,\n      node,\n      queries,\n      (o, k) => {\n        if (o[k] !== void 0 && compare(o[k], val) < 1) return false;\n        o[k] = val;\n        return true;\n      },\n      { buildGraph: true }\n    );\n  });\n};\nexport {\n  $min\n};\n","import {\n  applyUpdate,\n  UPDATE_OPTIONS,\n  walkExpression\n} from \"./_internal\";\nconst $mul = (obj, expr, arrayFilters = [], options = UPDATE_OPTIONS) => {\n  return walkExpression(expr, arrayFilters, options, (val, node, queries) => {\n    return applyUpdate(\n      obj,\n      node,\n      queries,\n      (o, k) => {\n        const prev = o[k];\n        o[k] = o[k] === void 0 ? 0 : o[k] * val;\n        return o[k] !== prev;\n      },\n      { buildGraph: true }\n    );\n  });\n};\nexport {\n  $mul\n};\n","import { assert, isArray } from \"../../util\";\nimport {\n  applyUpdate,\n  UPDATE_OPTIONS,\n  walkExpression\n} from \"./_internal\";\nconst $pop = (obj, expr, arrayFilters = [], options = UPDATE_OPTIONS) => {\n  return walkExpression(expr, arrayFilters, options, (val, node, queries) => {\n    return applyUpdate(obj, node, queries, (o, k) => {\n      const arr = o[k];\n      assert(\n        isArray(arr),\n        `path '${node.selector}' contains an element of non-array type.`\n      );\n      if (!arr.length) return false;\n      if (val === -1) {\n        arr.splice(0, 1);\n      } else {\n        arr.pop();\n      }\n      return true;\n    });\n  });\n};\nexport {\n  $pop\n};\n","import { Query } from \"../../query\";\nimport { isObject, isOperator } from \"../../util\";\nimport {\n  applyUpdate,\n  UPDATE_OPTIONS,\n  walkExpression\n} from \"./_internal\";\nconst $pull = (obj, expr, arrayFilters = [], options = UPDATE_OPTIONS) => {\n  return walkExpression(expr, arrayFilters, options, (val, node, queries) => {\n    const wrap = !isObject(val) || Object.keys(val).some(isOperator);\n    const query = new Query(\n      wrap ? { k: val } : val,\n      options.queryOptions\n    );\n    const pred = wrap ? (v) => query.test({ k: v }) : (v) => query.test(v);\n    return applyUpdate(obj, node, queries, (o, k) => {\n      const prev = o[k];\n      const curr = new Array();\n      const found = prev.map((v) => {\n        const b = pred(v);\n        if (!b) curr.push(v);\n        return b;\n      }).some(Boolean);\n      if (!found) return false;\n      o[k] = curr;\n      return true;\n    });\n  });\n};\nexport {\n  $pull\n};\n","import { UPDATE_OPTIONS } from \"./_internal\";\nimport { $pull } from \"./pull\";\nconst $pullAll = (obj, expr, arrayFilters = [], options = UPDATE_OPTIONS) => {\n  const pullExpr = {};\n  Object.entries(expr).forEach(([k, v]) => {\n    pullExpr[k] = { $in: v };\n  });\n  return $pull(obj, pullExpr, arrayFilters, options);\n};\nexport {\n  $pullAll\n};\n","import { compare, has, isEqual, isNumber, isObject, resolve } from \"../../util\";\nimport {\n  applyUpdate,\n  clone,\n  UPDATE_OPTIONS,\n  walkExpression\n} from \"./_internal\";\nconst OPERATOR_MODIFIERS = Object.freeze([\n  \"$each\",\n  \"$slice\",\n  \"$sort\",\n  \"$position\"\n]);\nconst $push = (obj, expr, arrayFilters = [], options = UPDATE_OPTIONS) => {\n  return walkExpression(expr, arrayFilters, options, (val, node, queries) => {\n    const args = {\n      $each: [val]\n    };\n    if (isObject(val) && OPERATOR_MODIFIERS.some((m) => has(val, m))) {\n      Object.assign(args, val);\n    }\n    return applyUpdate(\n      obj,\n      node,\n      queries,\n      (o, k) => {\n        const arr = o[k] ||= [];\n        const prev = arr.slice(0, args.$slice || arr.length);\n        const oldsize = arr.length;\n        const pos = isNumber(args.$position) ? args.$position : arr.length;\n        arr.splice(pos, 0, ...clone(options.cloneMode, args.$each));\n        if (args.$sort) {\n          const sortKey = isObject(args.$sort) ? Object.keys(args.$sort || {}).pop() : \"\";\n          const order = !sortKey ? args.$sort : args.$sort[sortKey];\n          const f = !sortKey ? (a) => a : (a) => resolve(a, sortKey);\n          arr.sort((a, b) => order * compare(f(a), f(b)));\n        }\n        if (isNumber(args.$slice)) {\n          if (args.$slice < 0) arr.splice(0, arr.length + args.$slice);\n          else arr.splice(args.$slice);\n        }\n        return oldsize != arr.length || !isEqual(prev, arr);\n      },\n      { descendArray: true, buildGraph: true }\n    );\n  });\n};\nexport {\n  $push\n};\n","import { has } from \"../../util\";\nimport {\n  applyUpdate,\n  UPDATE_OPTIONS,\n  walkExpression\n} from \"./_internal\";\nimport { $set } from \"./set\";\nconst $rename = (obj, expr, arrayFilters = [], options = UPDATE_OPTIONS) => {\n  const res = [];\n  const changed = walkExpression(expr, arrayFilters, options, (val, node, queries) => {\n    return applyUpdate(obj, node, queries, (o, k) => {\n      if (!has(o, k)) return false;\n      res.push(...$set(obj, { [val]: o[k] }, arrayFilters, options));\n      delete o[k];\n      return true;\n    });\n  });\n  return Array.from(new Set(changed.concat(res)));\n};\nexport {\n  $rename\n};\n","import { isEqual } from \"../../util\";\nimport {\n  applyUpdate,\n  clone,\n  UPDATE_OPTIONS,\n  walkExpression\n} from \"./_internal\";\nconst $set = (obj, expr, arrayFilters = [], options = UPDATE_OPTIONS) => {\n  return walkExpression(expr, arrayFilters, options, (val, node, queries) => {\n    return applyUpdate(\n      obj,\n      node,\n      queries,\n      (o, k) => {\n        if (isEqual(o[k], val)) return false;\n        o[k] = clone(options.cloneMode, val);\n        return true;\n      },\n      { buildGraph: true }\n    );\n  });\n};\nexport {\n  $set\n};\n","import { has, isArray } from \"../../util\";\nimport { applyUpdate, UPDATE_OPTIONS, walkExpression } from \"./_internal\";\nconst $unset = (obj, expr, arrayFilters = [], options = UPDATE_OPTIONS) => {\n  return walkExpression(expr, arrayFilters, options, (_, node, queries) => {\n    return applyUpdate(obj, node, queries, (o, k) => {\n      if (!has(o, k)) return false;\n      if (isArray(o)) {\n        o[k] = null;\n      } else {\n        delete o[k];\n      }\n      return true;\n    });\n  });\n};\nexport {\n  $unset\n};\n","import { groupBy, isEqual, MingoError } from \"../../util\";\nimport { $push } from \"../accumulator\";\nimport { MILLIS_PER_DAY } from \"../expression/date/_internal\";\nimport { isUnbounded } from \"../pipeline/_internal\";\nconst MILLIS_PER_UNIT = {\n  week: MILLIS_PER_DAY * 7,\n  day: MILLIS_PER_DAY,\n  hour: MILLIS_PER_DAY / 24,\n  minute: 6e4,\n  second: 1e3,\n  millisecond: 1\n};\nconst memo = /* @__PURE__ */ new WeakMap();\nfunction withMemo(collection, expr, cacheFn, fn) {\n  if (!isUnbounded(expr.parentExpr.output[expr.field].window)) {\n    return fn(cacheFn());\n  }\n  if (!memo.has(collection)) {\n    memo.set(collection, { [expr.field]: cacheFn() });\n  }\n  const data = memo.get(collection);\n  if (data[expr.field] === void 0) {\n    data[expr.field] = cacheFn();\n  }\n  let failed = false;\n  try {\n    return fn(data[expr.field]);\n  } catch {\n    failed = true;\n  } finally {\n    if (failed || expr.documentNumber === collection.length) {\n      delete data[expr.field];\n      if (Object.keys(data).length === 0) memo.delete(collection);\n    }\n  }\n}\nfunction rank(_, collection, expr, options, dense) {\n  return withMemo(\n    collection,\n    expr,\n    () => {\n      const sortKey = \"$\" + Object.keys(expr.parentExpr.sortBy)[0];\n      const values = $push(collection, sortKey, options);\n      const groups = groupBy(\n        values,\n        (_2, n) => values[n],\n        options.hashFunction\n      );\n      return { values, groups };\n    },\n    (input) => {\n      const { values, groups: partitions } = input;\n      if (partitions.size == collection.length) {\n        return expr.documentNumber;\n      }\n      const current = values[expr.documentNumber - 1];\n      let i = 0;\n      let offset = 0;\n      for (const key of partitions.keys()) {\n        if (isEqual(current, key)) {\n          return dense ? i + 1 : offset + 1;\n        }\n        i++;\n        offset += partitions.get(key).length;\n      }\n      throw new MingoError(\n        \"rank: invalid return value. please submit a bug report.\"\n      );\n    }\n  );\n}\nexport {\n  MILLIS_PER_UNIT,\n  rank,\n  withMemo\n};\n","import { isNumber } from \"../../util\";\nimport { $push } from \"../accumulator\";\nimport { withMemo } from \"./_internal\";\nconst interpolate = (x1, y1, x2, y2, x) => y1 + (x - x1) * ((y2 - y1) / (x2 - x1));\nconst $linearFill = (_, collection, expr, options) => {\n  return withMemo(\n    collection,\n    expr,\n    () => {\n      const sortKey = \"$\" + Object.keys(expr.parentExpr.sortBy)[0];\n      const points = $push(\n        collection,\n        [sortKey, expr.inputExpr],\n        options\n      ).filter(([x, _2]) => isNumber(+x));\n      if (points.length !== collection.length) return null;\n      let lindex = -1;\n      let rindex = 0;\n      while (rindex < points.length) {\n        while (lindex + 1 < points.length && isNumber(points[lindex + 1][1])) {\n          lindex++;\n          rindex = lindex;\n        }\n        while (rindex + 1 < points.length && !isNumber(points[rindex + 1][1])) {\n          rindex++;\n        }\n        if (rindex + 1 >= points.length) break;\n        rindex++;\n        while (lindex + 1 < rindex) {\n          points[lindex + 1][1] = interpolate(\n            points[lindex][0],\n            points[lindex][1],\n            points[rindex][0],\n            points[rindex][1],\n            points[lindex + 1][0]\n          );\n          lindex++;\n        }\n        lindex = rindex;\n      }\n      return points.map(([_2, y]) => y);\n    },\n    (values) => values[expr.documentNumber - 1]\n  );\n};\nexport {\n  $linearFill\n};\n","import { isNil } from \"../../util\";\nimport { $push } from \"../accumulator/push\";\nimport { withMemo } from \"./_internal\";\nconst $locf = (_, collection, expr, options) => {\n  return withMemo(\n    collection,\n    expr,\n    () => {\n      const values = $push(collection, expr.inputExpr, options);\n      for (let i = 1; i < values.length; i++) {\n        if (isNil(values[i])) values[i] = values[i - 1];\n      }\n      return values;\n    },\n    (series) => series[expr.documentNumber - 1]\n  );\n};\nexport {\n  $locf\n};\n","import { getOperator, initOptions } from \"./core\";\nimport { Cursor } from \"./cursor\";\nimport { assert, cloneDeep, isObject, isOperator, normalize } from \"./util\";\nconst TOP_LEVEL_OPS = new Set(\n  Array.from([\"$and\", \"$or\", \"$nor\", \"$expr\", \"$jsonSchema\"])\n);\nclass Query {\n  #compiled;\n  #options;\n  #condition;\n  constructor(condition, options) {\n    this.#condition = cloneDeep(condition);\n    this.#options = initOptions(options);\n    this.#compiled = [];\n    this.compile();\n  }\n  compile() {\n    assert(\n      isObject(this.#condition),\n      `query criteria must be an object: ${JSON.stringify(this.#condition)}`\n    );\n    const whereOperator = {};\n    for (const [field, expr] of Object.entries(this.#condition)) {\n      if (\"$where\" === field) {\n        assert(\n          this.#options.scriptEnabled,\n          \"$where operator requires 'scriptEnabled' option to be true.\"\n        );\n        Object.assign(whereOperator, { field, expr });\n      } else if (TOP_LEVEL_OPS.has(field)) {\n        this.processOperator(field, field, expr);\n      } else {\n        assert(!isOperator(field), `unknown top level operator: ${field}`);\n        for (const [operator, val] of Object.entries(\n          normalize(expr)\n        )) {\n          this.processOperator(field, operator, val);\n        }\n      }\n      if (whereOperator.field) {\n        this.processOperator(\n          whereOperator.field,\n          whereOperator.field,\n          whereOperator.expr\n        );\n      }\n    }\n  }\n  processOperator(field, operator, value) {\n    const call = getOperator(\"query\", operator, this.#options);\n    assert(!!call, `unknown query operator ${operator}`);\n    this.#compiled.push(call(field, value, this.#options));\n  }\n  /**\n   * Checks if the object passes the query criteria. Returns true if so, false otherwise.\n   *\n   * @param obj The object to test\n   * @returns {boolean}\n   */\n  test(obj) {\n    return this.#compiled.every((p) => p(obj));\n  }\n  /**\n   * Returns a cursor to select matching documents from the input source.\n   *\n   * @param source A source providing a sequence of documents\n   * @param projection An optional projection criteria\n   * @returns {Cursor} A Cursor for iterating over the results\n   */\n  find(collection, projection) {\n    return new Cursor(\n      collection,\n      (o) => this.test(o),\n      projection || {},\n      this.#options\n    );\n  }\n  /**\n   * Remove matched documents from the collection returning the remainder\n   *\n   * @param collection An array of documents\n   * @returns {Array} A new array with matching elements removed\n   */\n  remove(collection) {\n    return collection.reduce((acc, obj) => {\n      if (!this.test(obj)) acc.push(obj);\n      return acc;\n    }, []);\n  }\n}\nexport {\n  Query\n};\n","const TIME_UNITS = [\n  \"year\",\n  \"quarter\",\n  \"month\",\n  \"week\",\n  \"day\",\n  \"hour\",\n  \"minute\",\n  \"second\",\n  \"millisecond\"\n];\nexport {\n  TIME_UNITS\n};\n","import * as UPDATE_OPERATORS from \"./operators/update\";\nimport { UPDATE_OPTIONS } from \"./operators/update/_internal\";\nimport { Query } from \"./query\";\nimport { assert, has } from \"./util\";\nfunction createUpdater(defaultOptions) {\n  defaultOptions = defaultOptions ?? UPDATE_OPTIONS;\n  return (obj, expr, arrayFilters = [], condition = {}, options = defaultOptions) => {\n    const entry = Object.entries(expr);\n    assert(\n      entry.length === 1,\n      \"Update expression must contain only one operator.\"\n    );\n    const [op, args] = entry[0];\n    assert(\n      has(UPDATE_OPERATORS, op),\n      `Update operator '${op}' is not supported.`\n    );\n    const mutate = UPDATE_OPERATORS[op];\n    if (Object.keys(condition).length) {\n      const q = new Query(condition, options.queryOptions);\n      if (!q.test(obj)) return [];\n    }\n    return mutate(obj, args, arrayFilters, options);\n  };\n}\nconst update = createUpdater();\nconst updateObject = update;\nexport {\n  createUpdater,\n  update,\n  updateObject\n};\n","class MingoError extends Error {\n}\nconst MISSING = Symbol(\"missing\");\nconst CYCLE_FOUND_ERROR = Object.freeze(\n  new Error(\"mingo: cycle detected while processing object/array\")\n);\nconst DEFAULT_HASH_FUNCTION = (value) => {\n  const s = stringify(value);\n  let hash = 0;\n  let i = s.length;\n  while (i) hash = (hash << 5) - hash ^ s.charCodeAt(--i);\n  return hash >>> 0;\n};\nconst isPrimitive = (v) => typeof v !== \"object\" && typeof v !== \"function\" || v === null;\nconst isScalar = (v) => isPrimitive(v) || isDate(v) || isRegExp(v);\nconst SORT_ORDER = {\n  undefined: 1,\n  null: 2,\n  number: 3,\n  string: 4,\n  symbol: 5,\n  object: 6,\n  array: 7,\n  arraybuffer: 8,\n  boolean: 9,\n  date: 10,\n  regexp: 11,\n  function: 12\n};\nconst compare = (a, b) => {\n  if (a === MISSING) a = void 0;\n  if (b === MISSING) b = void 0;\n  const [u, v] = [a, b].map((n) => SORT_ORDER[typeOf(n)] || 0);\n  if (u !== v) return u - v;\n  if (isEqual(a, b)) return 0;\n  if (a < b) return -1;\n  if (a > b) return 1;\n  return 0;\n};\nclass ValueMap extends Map {\n  // The hash function\n  #hashFn = DEFAULT_HASH_FUNCTION;\n  // maps the hashcode to key set\n  #keyMap = /* @__PURE__ */ new Map();\n  // returns a tuple of [<masterKey>, <hash>]. Expects an object key.\n  #unpack = (key) => {\n    const hash = this.#hashFn(key);\n    return [(this.#keyMap.get(hash) || []).find((k) => isEqual(k, key)), hash];\n  };\n  constructor() {\n    super();\n  }\n  /**\n   * Returns a new {@link ValueMap} object.\n   * @param fn An optional custom hash function\n   */\n  static init(fn) {\n    const m = new ValueMap();\n    if (fn) m.#hashFn = fn;\n    return m;\n  }\n  clear() {\n    super.clear();\n    this.#keyMap.clear();\n  }\n  /**\n   * @returns true if an element in the Map existed and has been removed, or false if the element does not exist.\n   */\n  delete(key) {\n    if (isPrimitive(key)) return super.delete(key);\n    const [masterKey, hash] = this.#unpack(key);\n    if (!super.delete(masterKey)) return false;\n    this.#keyMap.set(\n      hash,\n      this.#keyMap.get(hash).filter((k) => !isEqual(k, masterKey))\n    );\n    return true;\n  }\n  /**\n   * Returns a specified element from the Map object. If the value that is associated to the provided key is an object, then you will get a reference to that object and any change made to that object will effectively modify it inside the Map.\n   * @returns Returns the element associated with the specified key. If no element is associated with the specified key, undefined is returned.\n   */\n  get(key) {\n    if (isPrimitive(key)) return super.get(key);\n    const [masterKey, _] = this.#unpack(key);\n    return super.get(masterKey);\n  }\n  /**\n   * @returns boolean indicating whether an element with the specified key exists or not.\n   */\n  has(key) {\n    if (isPrimitive(key)) return super.has(key);\n    const [masterKey, _] = this.#unpack(key);\n    return super.has(masterKey);\n  }\n  /**\n   * Adds a new element with a specified key and value to the Map. If an element with the same key already exists, the element will be updated.\n   */\n  set(key, value) {\n    if (isPrimitive(key)) return super.set(key, value);\n    const [masterKey, hash] = this.#unpack(key);\n    if (super.has(masterKey)) {\n      super.set(masterKey, value);\n    } else {\n      super.set(key, value);\n      const keys = this.#keyMap.get(hash) || [];\n      keys.push(key);\n      this.#keyMap.set(hash, keys);\n    }\n    return this;\n  }\n  /**\n   * @returns the number of elements in the Map.\n   */\n  get size() {\n    return super.size;\n  }\n}\nfunction assert(condition, message) {\n  if (!condition) throw new MingoError(message);\n}\nconst STRING_REP = Object.keys(SORT_ORDER).reduce(\n  (memo, k) => {\n    memo[\"[object \" + k[0].toUpperCase() + k.substring(1) + \"]\"] = k;\n    return memo;\n  },\n  {}\n);\nfunction typeOf(v) {\n  const s = Object.prototype.toString.call(v);\n  return s === \"[object Object]\" ? v?.constructor?.name?.toLowerCase() || \"object\" : STRING_REP[s] || s.substring(8, s.length - 1).toLowerCase();\n}\nconst isBoolean = (v) => typeof v === \"boolean\";\nconst isString = (v) => typeof v === \"string\";\nconst isSymbol = (v) => typeof v === \"symbol\";\nconst isNumber = (v) => !isNaN(v) && typeof v === \"number\";\nconst isNotNaN = (v) => !(isNaN(v) && typeof v === \"number\");\nconst isArray = Array.isArray;\nfunction isObject(v) {\n  if (!v) return false;\n  const p = Object.getPrototypeOf(v);\n  return (p === Object.prototype || p === null) && typeOf(v) === \"object\";\n}\nconst isObjectLike = (v) => !isPrimitive(v);\nconst isDate = (v) => v instanceof Date;\nconst isRegExp = (v) => v instanceof RegExp;\nconst isFunction = (v) => typeof v === \"function\";\nconst isNil = (v) => v === null || v === void 0;\nconst truthy = (arg, strict = true) => !!arg || strict && arg === \"\";\nconst isEmpty = (x) => isNil(x) || isString(x) && !x || isArray(x) && x.length === 0 || isObject(x) && Object.keys(x).length === 0;\nconst ensureArray = (x) => isArray(x) ? x : [x];\nconst has = (obj, prop) => !!obj && Object.prototype.hasOwnProperty.call(obj, prop);\nconst isTypedArray = (v) => typeof ArrayBuffer !== \"undefined\" && ArrayBuffer.isView(v);\nconst cloneDeep = (v, refs) => {\n  if (isNil(v) || isBoolean(v) || isNumber(v) || isString(v)) return v;\n  if (isDate(v)) return new Date(v);\n  if (isRegExp(v)) return new RegExp(v);\n  if (isTypedArray(v)) {\n    const ctor = v.constructor;\n    return new ctor(v);\n  }\n  if (!(refs instanceof Set)) refs = /* @__PURE__ */ new Set();\n  if (refs.has(v)) throw CYCLE_FOUND_ERROR;\n  refs.add(v);\n  try {\n    if (isArray(v)) {\n      const arr = new Array(v.length);\n      for (let i = 0; i < v.length; i++) arr[i] = cloneDeep(v[i], refs);\n      return arr;\n    }\n    if (isObject(v)) {\n      const obj = {};\n      for (const k of Object.keys(v)) obj[k] = cloneDeep(v[k], refs);\n      return obj;\n    }\n  } finally {\n    refs.delete(v);\n  }\n  return v;\n};\nconst isMissing = (v) => v === MISSING;\nfunction merge(target, input) {\n  if (isMissing(target) || isNil(target)) return input;\n  if (isMissing(input) || isNil(input)) return target;\n  if (isPrimitive(target) || isPrimitive(input)) return input;\n  if (isArray(target) && isArray(input)) {\n    assert(\n      target.length === input.length,\n      \"arrays must be of equal length to merge.\"\n    );\n  }\n  for (const k of Object.keys(input)) {\n    target[k] = merge(target[k], input[k]);\n  }\n  return target;\n}\nfunction intersection(input, hashFunction = DEFAULT_HASH_FUNCTION) {\n  const vmaps = [ValueMap.init(hashFunction), ValueMap.init(hashFunction)];\n  if (input.length === 0) return [];\n  if (input.some((arr) => arr.length === 0)) return [];\n  if (input.length === 1) return [...input];\n  input[input.length - 1].forEach((v) => vmaps[0].set(v, true));\n  for (let i = input.length - 2; i > -1; i--) {\n    input[i].forEach((v) => {\n      if (vmaps[0].has(v)) vmaps[1].set(v, true);\n    });\n    if (vmaps[1].size === 0) return [];\n    vmaps.reverse();\n    vmaps[1].clear();\n  }\n  return Array.from(vmaps[0].keys());\n}\nfunction flatten(xs, depth = 1) {\n  const arr = new Array();\n  function flatten2(ys, n) {\n    for (let i = 0, len = ys.length; i < len; i++) {\n      if (isArray(ys[i]) && (n > 0 || n < 0)) {\n        flatten2(ys[i], Math.max(-1, n - 1));\n      } else {\n        arr.push(ys[i]);\n      }\n    }\n  }\n  flatten2(xs, depth);\n  return arr;\n}\nfunction getMembersOf(o) {\n  const props = {};\n  while (o) {\n    for (const k of Object.getOwnPropertyNames(o))\n      if (!(k in props)) props[k] = o[k];\n    o = Object.getPrototypeOf(o);\n  }\n  return props;\n}\nfunction hasCustomString(o) {\n  while (o) {\n    if (Object.getOwnPropertyNames(o).includes(\"toString\"))\n      return o[\"toString\"] !== Object.prototype.toString;\n    o = Object.getPrototypeOf(o);\n  }\n  return false;\n}\nfunction isEqual(a, b) {\n  if (a === b || Object.is(a, b)) return true;\n  if (a === null || b === null) return false;\n  if (typeof a !== typeof b) return false;\n  if (typeof a !== \"object\") return false;\n  if (a.constructor !== b.constructor) return false;\n  if (a instanceof Date) return +a === +b;\n  if (a instanceof RegExp) return a.toString() === b.toString();\n  const ctor = a.constructor;\n  if (ctor === Array || ctor === Object) {\n    const aKeys = Object.keys(a).sort();\n    const bKeys = Object.keys(b).sort();\n    if (aKeys.length !== bKeys.length) return false;\n    for (let i = 0, k = aKeys[i]; i < aKeys.length; k = aKeys[++i]) {\n      if (k !== bKeys[i] || !isEqual(a[k], b[k])) return false;\n    }\n    return true;\n  }\n  return hasCustomString(a) && a.toString() === b.toString();\n}\nfunction unique(input, hashFunction = DEFAULT_HASH_FUNCTION) {\n  const m = ValueMap.init(hashFunction);\n  input.forEach((v) => m.set(v, true));\n  return Array.from(m.keys());\n}\nconst stringify = (v, refs) => {\n  if (v === null) return \"null\";\n  if (v === void 0) return \"undefined\";\n  if (isString(v) || isNumber(v) || isBoolean(v)) return JSON.stringify(v);\n  if (isDate(v)) return v.toISOString();\n  if (isRegExp(v) || isSymbol(v) || isFunction(v))\n    return v.toString();\n  if (!(refs instanceof Set)) refs = /* @__PURE__ */ new Set();\n  if (refs.has(v)) throw CYCLE_FOUND_ERROR;\n  try {\n    refs.add(v);\n    if (isArray(v)) return \"[\" + v.map((s2) => stringify(s2, refs)).join(\",\") + \"]\";\n    if (isObject(v)) {\n      const keys = Object.keys(v).sort();\n      return \"{\" + keys.map((k) => `${k}:${stringify(v[k], refs)}`).join() + \"}\";\n    }\n    const s = hasCustomString(v) ? v.toString() : stringify(getMembersOf(v), refs);\n    return typeOf(v) + \"(\" + s + \")\";\n  } finally {\n    refs.delete(v);\n  }\n};\nfunction hashCode(value, hashFunction) {\n  if (isNil(value)) return null;\n  hashFunction = hashFunction || DEFAULT_HASH_FUNCTION;\n  return hashFunction(value);\n}\nfunction groupBy(collection, keyFn, hashFunction = DEFAULT_HASH_FUNCTION) {\n  if (collection.length < 1) return /* @__PURE__ */ new Map();\n  const lookup = /* @__PURE__ */ new Map();\n  const result = /* @__PURE__ */ new Map();\n  for (let i = 0; i < collection.length; i++) {\n    const obj = collection[i];\n    const key = keyFn(obj, i);\n    const hash = hashCode(key, hashFunction);\n    if (hash === null) {\n      if (result.has(null)) {\n        result.get(null).push(obj);\n      } else {\n        result.set(null, [obj]);\n      }\n    } else {\n      const existingKey = lookup.has(hash) ? lookup.get(hash).find((k) => isEqual(k, key)) : null;\n      if (isNil(existingKey)) {\n        result.set(key, [obj]);\n        if (lookup.has(hash)) {\n          lookup.get(hash).push(key);\n        } else {\n          lookup.set(hash, [key]);\n        }\n      } else {\n        result.get(existingKey).push(obj);\n      }\n    }\n  }\n  return result;\n}\nconst MAX_ARRAY_PUSH = 5e4;\nfunction into(target, ...rest) {\n  if (isArray(target)) {\n    for (const arr of rest) {\n      let i = Math.ceil(arr.length / MAX_ARRAY_PUSH);\n      let begin = 0;\n      while (i-- > 0) {\n        Array.prototype.push.apply(\n          target,\n          arr.slice(begin, begin + MAX_ARRAY_PUSH)\n        );\n        begin += MAX_ARRAY_PUSH;\n      }\n    }\n    return target;\n  } else {\n    return rest.filter(isObjectLike).reduce((acc, item) => {\n      Object.assign(acc, item);\n      return acc;\n    }, target);\n  }\n}\nfunction getValue(obj, key) {\n  return isObjectLike(obj) ? obj[key] : void 0;\n}\nfunction unwrap(arr, depth) {\n  if (depth < 1) return arr;\n  while (depth-- && arr.length === 1) arr = arr[0];\n  return arr;\n}\nfunction resolve(obj, selector, options) {\n  let depth = 0;\n  function resolve2(o, path) {\n    let value = o;\n    for (let i = 0; i < path.length; i++) {\n      const field = path[i];\n      const isText = /^\\d+$/.exec(field) === null;\n      if (isText && isArray(value)) {\n        if (i === 0 && depth > 0) break;\n        depth += 1;\n        const subpath = path.slice(i);\n        value = value.reduce((acc, item) => {\n          const v = resolve2(item, subpath);\n          if (v !== void 0) acc.push(v);\n          return acc;\n        }, []);\n        break;\n      } else {\n        value = getValue(value, field);\n      }\n      if (value === void 0) break;\n    }\n    return value;\n  }\n  const res = isScalar(obj) ? obj : resolve2(obj, selector.split(\".\"));\n  return isArray(res) && options?.unwrapArray ? unwrap(res, depth) : res;\n}\nfunction resolveGraph(obj, selector, options) {\n  const sep = selector.indexOf(\".\");\n  const key = sep == -1 ? selector : selector.substring(0, sep);\n  const next = selector.substring(sep + 1);\n  const hasNext = sep != -1;\n  if (isArray(obj)) {\n    const isIndex = /^\\d+$/.test(key);\n    const arr = isIndex && options?.preserveIndex ? [...obj] : [];\n    if (isIndex) {\n      const index = parseInt(key);\n      let value2 = getValue(obj, index);\n      if (hasNext) {\n        value2 = resolveGraph(value2, next, options);\n      }\n      if (options?.preserveIndex) {\n        arr[index] = value2;\n      } else {\n        arr.push(value2);\n      }\n    } else {\n      for (const item of obj) {\n        const value2 = resolveGraph(item, selector, options);\n        if (options?.preserveMissing) {\n          arr.push(value2 == void 0 ? MISSING : value2);\n        } else if (value2 != void 0 || options?.preserveIndex) {\n          arr.push(value2);\n        }\n      }\n    }\n    return arr;\n  }\n  const res = options?.preserveKeys ? { ...obj } : {};\n  let value = getValue(obj, key);\n  if (hasNext) {\n    value = resolveGraph(value, next, options);\n  }\n  if (value === void 0) return void 0;\n  res[key] = value;\n  return res;\n}\nfunction filterMissing(obj) {\n  if (isArray(obj)) {\n    for (let i = obj.length - 1; i >= 0; i--) {\n      if (obj[i] === MISSING) {\n        obj.splice(i, 1);\n      } else {\n        filterMissing(obj[i]);\n      }\n    }\n  } else if (isObject(obj)) {\n    for (const k in obj) {\n      if (has(obj, k)) {\n        filterMissing(obj[k]);\n      }\n    }\n  }\n}\nconst NUMBER_RE = /^\\d+$/;\nfunction walk(obj, selector, fn, options) {\n  const names = selector.split(\".\");\n  const key = names[0];\n  const next = names.slice(1).join(\".\");\n  if (names.length === 1) {\n    if (isObject(obj) || isArray(obj) && NUMBER_RE.test(key)) {\n      fn(obj, key);\n    }\n  } else {\n    if (options?.buildGraph && isNil(obj[key])) {\n      obj[key] = {};\n    }\n    const item = obj[key];\n    if (!item) return;\n    const isNextArrayIndex = !!(names.length > 1 && NUMBER_RE.test(names[1]));\n    if (isArray(item) && options?.descendArray && !isNextArrayIndex) {\n      item.forEach((e) => walk(e, next, fn, options));\n    } else {\n      walk(item, next, fn, options);\n    }\n  }\n}\nfunction setValue(obj, selector, value) {\n  walk(\n    obj,\n    selector,\n    (item, key) => {\n      item[key] = isFunction(value) ? value(item[key]) : value;\n    },\n    { buildGraph: true }\n  );\n}\nfunction removeValue(obj, selector, options) {\n  walk(\n    obj,\n    selector,\n    (item, key) => {\n      if (isArray(item)) {\n        if (/^\\d+$/.test(key)) {\n          item.splice(parseInt(key), 1);\n        } else if (options && options.descendArray) {\n          for (const elem of item) {\n            if (isObject(elem)) {\n              delete elem[key];\n            }\n          }\n        }\n      } else if (isObject(item)) {\n        delete item[key];\n      }\n    },\n    options\n  );\n}\nconst OPERATOR_NAME_PATTERN = /^\\$[a-zA-Z0-9_]+$/;\nfunction isOperator(name) {\n  return OPERATOR_NAME_PATTERN.test(name);\n}\nfunction normalize(expr) {\n  if (isScalar(expr)) {\n    return isRegExp(expr) ? { $regex: expr } : { $eq: expr };\n  }\n  if (isObjectLike(expr)) {\n    if (!Object.keys(expr).some(isOperator)) return { $eq: expr };\n    if (has(expr, \"$regex\")) {\n      const newExpr = { ...expr };\n      newExpr[\"$regex\"] = new RegExp(\n        expr[\"$regex\"],\n        expr[\"$options\"]\n      );\n      delete newExpr[\"$options\"];\n      return newExpr;\n    }\n  }\n  return expr;\n}\nfunction findInsertIndex(sorted, item, comparator = compare) {\n  let lo = 0;\n  let hi = sorted.length - 1;\n  while (lo <= hi) {\n    const mid = Math.round(lo + (hi - lo) / 2);\n    if (comparator(item, sorted[mid]) < 0) {\n      hi = mid - 1;\n    } else if (comparator(item, sorted[mid]) > 0) {\n      lo = mid + 1;\n    } else {\n      return mid;\n    }\n  }\n  return lo;\n}\nexport {\n  MingoError,\n  ValueMap,\n  assert,\n  cloneDeep,\n  compare,\n  ensureArray,\n  filterMissing,\n  findInsertIndex,\n  flatten,\n  groupBy,\n  has,\n  hashCode,\n  intersection,\n  into,\n  isArray,\n  isBoolean,\n  isDate,\n  isEmpty,\n  isEqual,\n  isFunction,\n  isNil,\n  isNotNaN,\n  isNumber,\n  isObject,\n  isObjectLike,\n  isOperator,\n  isRegExp,\n  isString,\n  isSymbol,\n  merge,\n  normalize,\n  removeValue,\n  resolve,\n  resolveGraph,\n  setValue,\n  stringify,\n  truthy,\n  typeOf,\n  unique,\n  walk\n};\n","/**\n * this is a set which automatically forgets\n * a given entry when a new entry is set and the ttl\n * of the old one is over\n */\nexport class ObliviousSet {\n    ttl;\n    map = new Map();\n    /**\n     * Creating calls to setTimeout() is expensive,\n     * so we only do that if there is not timeout already open.\n     */\n    _to = false;\n    constructor(ttl) {\n        this.ttl = ttl;\n    }\n    has(value) {\n        return this.map.has(value);\n    }\n    add(value) {\n        this.map.set(value, now());\n        /**\n         * When a new value is added,\n         * start the cleanup at the next tick\n         * to not block the cpu for more important stuff\n         * that might happen.\n         */\n        if (!this._to) {\n            this._to = true;\n            setTimeout(() => {\n                this._to = false;\n                removeTooOldValues(this);\n            }, 0);\n        }\n    }\n    clear() {\n        this.map.clear();\n    }\n}\n/**\n * Removes all entries from the set\n * where the TTL has expired\n */\nexport function removeTooOldValues(obliviousSet) {\n    const olderThen = now() - obliviousSet.ttl;\n    const iterator = obliviousSet.map[Symbol.iterator]();\n    /**\n     * Because we can assume the new values are added at the bottom,\n     * we start from the top and stop as soon as we reach a non-too-old value.\n     */\n    while (true) {\n        const next = iterator.next().value;\n        if (!next) {\n            return; // no more elements\n        }\n        const value = next[0];\n        const time = next[1];\n        if (time < olderThen) {\n            obliviousSet.map.delete(value);\n        }\n        else {\n            // We reached a value that is not old enough\n            return;\n        }\n    }\n}\nexport function now() {\n    return Date.now();\n}\n//# sourceMappingURL=index.js.map","/**\n * a buffer-cache which holds the last X changeEvents of the collection\n */\n\nimport { filter } from 'rxjs/operators';\nimport { appendToArray, requestIdlePromiseNoQueue } from \"./plugins/utils/index.js\";\n\n/**\n * This buffer rembemers previous change events\n * so that queries can use them on .exec()\n * to calculate the new result set via event-reduce instead\n * of running the query against the storage.\n */\nexport var ChangeEventBuffer = /*#__PURE__*/function () {\n  /**\n   * These properties are private to ensure they cannot\n   * be read without first processing the lazy tasks.\n   */\n\n  /**\n   * array with changeEvents\n   * starts with oldest known event, ends with newest\n  */\n\n  function ChangeEventBuffer(collection) {\n    this.subs = [];\n    this.counter = 0;\n    this.eventCounterMap = new WeakMap();\n    this.buffer = [];\n    this.limit = 100;\n    this.tasks = new Set();\n    this.collection = collection;\n    this.subs.push(this.collection.eventBulks$.pipe(filter(bulk => !bulk.isLocal)).subscribe(eventBulk => {\n      this.tasks.add(() => this._handleChangeEvents(eventBulk.events));\n      if (this.tasks.size <= 1) {\n        requestIdlePromiseNoQueue().then(() => {\n          this.processTasks();\n        });\n      }\n    }));\n  }\n  var _proto = ChangeEventBuffer.prototype;\n  _proto.processTasks = function processTasks() {\n    if (this.tasks.size === 0) {\n      return;\n    }\n    var tasks = Array.from(this.tasks);\n    tasks.forEach(task => task());\n    this.tasks.clear();\n  };\n  _proto._handleChangeEvents = function _handleChangeEvents(events) {\n    var counterBefore = this.counter;\n    this.counter = this.counter + events.length;\n    if (events.length > this.limit) {\n      this.buffer = events.slice(events.length * -1);\n    } else {\n      appendToArray(this.buffer, events);\n      this.buffer = this.buffer.slice(this.limit * -1);\n    }\n    var counterBase = counterBefore + 1;\n    var eventCounterMap = this.eventCounterMap;\n    for (var index = 0; index < events.length; index++) {\n      var event = events[index];\n      eventCounterMap.set(event, counterBase + index);\n    }\n  };\n  _proto.getCounter = function getCounter() {\n    this.processTasks();\n    return this.counter;\n  };\n  _proto.getBuffer = function getBuffer() {\n    this.processTasks();\n    return this.buffer;\n  }\n\n  /**\n   * gets the array-index for the given pointer\n   * @return arrayIndex which can be used to iterate from there. If null, pointer is out of lower bound\n   */;\n  _proto.getArrayIndexByPointer = function getArrayIndexByPointer(pointer) {\n    this.processTasks();\n    var oldestEvent = this.buffer[0];\n    var oldestCounter = this.eventCounterMap.get(oldestEvent);\n    if (pointer < oldestCounter) return null; // out of bounds\n\n    var rest = pointer - oldestCounter;\n    return rest;\n  }\n\n  /**\n   * get all changeEvents which came in later than the pointer-event\n   * @return array with change-events. If null, pointer out of bounds\n   */;\n  _proto.getFrom = function getFrom(pointer) {\n    this.processTasks();\n    var ret = [];\n    var currentIndex = this.getArrayIndexByPointer(pointer);\n    if (currentIndex === null)\n      // out of bounds\n      return null;\n    while (true) {\n      var nextEvent = this.buffer[currentIndex];\n      currentIndex++;\n      if (!nextEvent) {\n        return ret;\n      } else {\n        ret.push(nextEvent);\n      }\n    }\n  };\n  _proto.runFrom = function runFrom(pointer, fn) {\n    this.processTasks();\n    var ret = this.getFrom(pointer);\n    if (ret === null) {\n      throw new Error('out of bounds');\n    } else {\n      ret.forEach(cE => fn(cE));\n    }\n  }\n\n  /**\n   * no matter how many operations are done on one document,\n   * only the last operation has to be checked to calculate the new state\n   * this function reduces the events to the last ChangeEvent of each doc.\n   * This functionality is currently disabled. It is questionable if\n   * pre-merging the events would really be faster or actually slower.\n   */;\n  _proto.reduceByLastOfDoc = function reduceByLastOfDoc(changeEvents) {\n    this.processTasks();\n    return changeEvents.slice(0);\n  };\n  _proto.close = function close() {\n    this.tasks.clear();\n    this.subs.forEach(sub => sub.unsubscribe());\n  };\n  return ChangeEventBuffer;\n}();\nexport function createChangeEventBuffer(collection) {\n  return new ChangeEventBuffer(collection);\n}\n//# sourceMappingURL=change-event-buffer.js.map","import _createClass from \"@babel/runtime/helpers/createClass\";\nimport { getFromMapOrThrow, getHeightOfRevision, overwriteGetterForCaching, requestIdlePromiseNoQueue } from \"./plugins/utils/index.js\";\nimport { overwritable } from \"./overwritable.js\";\n\n/**\n * Because we have to create many cache items,\n * we use an array instead of an object with properties\n * for better performance and less memory usage.\n * @link https://stackoverflow.com/questions/17295056/array-vs-object-efficiency-in-javascript\n */\n\n/**\n * @link https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/FinalizationRegistry\n */\n\n/**\n * The DocumentCache stores RxDocument objects\n * by their primary key and revision.\n * This is useful on client side applications where\n * it is not known how much memory can be used, so\n * we de-duplicate RxDocument states to save memory.\n * To not fill up the memory with old document states, the DocumentCache\n * only contains weak references to the RxDocuments themself.\n * @link https://caniuse.com/?search=weakref\n */\nexport var DocumentCache = /*#__PURE__*/function () {\n  /**\n   * Process stuff lazy to not block the CPU\n   * on critical paths.\n   */\n\n  /**\n   * Some JavaScript runtimes like QuickJS,\n   * so not have a FinalizationRegistry or WeakRef.\n   * Therefore we need a workaround which might waste a lot of memory,\n   * but at least works.\n   */\n\n  function DocumentCache(primaryPath, changes$,\n  /**\n   * A method that can create a RxDocument by the given document data.\n   */\n  documentCreator) {\n    this.cacheItemByDocId = new Map();\n    this.tasks = new Set();\n    this.registry = typeof FinalizationRegistry === 'function' ? new FinalizationRegistry(docMeta => {\n      var docId = docMeta.docId;\n      var cacheItem = this.cacheItemByDocId.get(docId);\n      if (cacheItem) {\n        cacheItem[0].delete(docMeta.revisionHeight);\n        if (cacheItem[0].size === 0) {\n          /**\n           * No state of the document is cached anymore,\n           * so we can clean up.\n           */\n          this.cacheItemByDocId.delete(docId);\n        }\n      }\n    }) : undefined;\n    this.primaryPath = primaryPath;\n    this.changes$ = changes$;\n    this.documentCreator = documentCreator;\n    changes$.subscribe(events => {\n      this.tasks.add(() => {\n        var cacheItemByDocId = this.cacheItemByDocId;\n        for (var index = 0; index < events.length; index++) {\n          var event = events[index];\n          var cacheItem = cacheItemByDocId.get(event.documentId);\n          if (cacheItem) {\n            var documentData = event.documentData;\n            if (!documentData) {\n              documentData = event.previousDocumentData;\n            }\n            cacheItem[1] = documentData;\n          }\n        }\n      });\n      if (this.tasks.size <= 1) {\n        requestIdlePromiseNoQueue().then(() => {\n          this.processTasks();\n        });\n      }\n    });\n  }\n  var _proto = DocumentCache.prototype;\n  _proto.processTasks = function processTasks() {\n    if (this.tasks.size === 0) {\n      return;\n    }\n    var tasks = Array.from(this.tasks);\n    tasks.forEach(task => task());\n    this.tasks.clear();\n  }\n\n  /**\n   * Get the RxDocument from the cache\n   * and create a new one if not exits before.\n   * @overwrites itself with the actual function\n   * because this is @performance relevant.\n   * It is called on each document row for each write and read.\n   */;\n  /**\n   * Throws if not exists\n   */\n  _proto.getLatestDocumentData = function getLatestDocumentData(docId) {\n    this.processTasks();\n    var cacheItem = getFromMapOrThrow(this.cacheItemByDocId, docId);\n    return cacheItem[1];\n  };\n  _proto.getLatestDocumentDataIfExists = function getLatestDocumentDataIfExists(docId) {\n    this.processTasks();\n    var cacheItem = this.cacheItemByDocId.get(docId);\n    if (cacheItem) {\n      return cacheItem[1];\n    }\n  };\n  return _createClass(DocumentCache, [{\n    key: \"getCachedRxDocuments\",\n    get: function () {\n      var fn = getCachedRxDocumentMonad(this);\n      return overwriteGetterForCaching(this, 'getCachedRxDocuments', fn);\n    }\n  }, {\n    key: \"getCachedRxDocument\",\n    get: function () {\n      var fn = getCachedRxDocumentMonad(this);\n      return overwriteGetterForCaching(this, 'getCachedRxDocument', doc => fn([doc])[0]);\n    }\n  }]);\n}();\n\n/**\n * This function is called very very often.\n * This is likely the most important function for RxDB overall performance\n * @hotPath This is one of the most important methods for performance.\n * It is used in many places to transform the raw document data into RxDocuments.\n */\nfunction getCachedRxDocumentMonad(docCache) {\n  var primaryPath = docCache.primaryPath;\n  var cacheItemByDocId = docCache.cacheItemByDocId;\n  var registry = docCache.registry;\n  var deepFreezeWhenDevMode = overwritable.deepFreezeWhenDevMode;\n  var documentCreator = docCache.documentCreator;\n  var fn = docsData => {\n    var ret = new Array(docsData.length);\n    var registryTasks = [];\n    for (var index = 0; index < docsData.length; index++) {\n      var docData = docsData[index];\n      var docId = docData[primaryPath];\n      var revisionHeight = getHeightOfRevision(docData._rev);\n      var byRev = void 0;\n      var cachedRxDocumentWeakRef = void 0;\n      var cacheItem = cacheItemByDocId.get(docId);\n      if (!cacheItem) {\n        byRev = new Map();\n        cacheItem = [byRev, docData];\n        cacheItemByDocId.set(docId, cacheItem);\n      } else {\n        byRev = cacheItem[0];\n        cachedRxDocumentWeakRef = byRev.get(revisionHeight);\n      }\n      var cachedRxDocument = cachedRxDocumentWeakRef ? cachedRxDocumentWeakRef.deref() : undefined;\n      if (!cachedRxDocument) {\n        docData = deepFreezeWhenDevMode(docData);\n        cachedRxDocument = documentCreator(docData);\n        byRev.set(revisionHeight, createWeakRefWithFallback(cachedRxDocument));\n        if (registry) {\n          registryTasks.push(cachedRxDocument);\n        }\n      }\n      ret[index] = cachedRxDocument;\n    }\n    if (registryTasks.length > 0 && registry) {\n      /**\n       * Calling registry.register() has shown to have\n       * really bad performance. So we add the cached documents\n       * lazily.\n       */\n      docCache.tasks.add(() => {\n        for (var _index = 0; _index < registryTasks.length; _index++) {\n          var doc = registryTasks[_index];\n          registry.register(doc, {\n            docId: doc.primary,\n            revisionHeight: getHeightOfRevision(doc.revision)\n          });\n        }\n      });\n      if (docCache.tasks.size <= 1) {\n        requestIdlePromiseNoQueue().then(() => {\n          docCache.processTasks();\n        });\n      }\n    }\n    return ret;\n  };\n  return fn;\n}\nexport function mapDocumentsDataToCacheDocs(docCache, docsData) {\n  var getCachedRxDocuments = docCache.getCachedRxDocuments;\n  return getCachedRxDocuments(docsData);\n}\n\n/**\n * Fallback for JavaScript runtimes that do not support WeakRef.\n * The fallback will keep the items in cache forever,\n * but at least works.\n */\nvar HAS_WEAK_REF = typeof WeakRef === 'function';\nvar createWeakRefWithFallback = HAS_WEAK_REF ? createWeakRef : createWeakRefFallback;\nfunction createWeakRef(obj) {\n  return new WeakRef(obj);\n}\nfunction createWeakRefFallback(obj) {\n  return {\n    deref() {\n      return obj;\n    }\n  };\n}\n//# sourceMappingURL=doc-cache.js.map","import { calculateActionName, runAction } from 'event-reduce-js';\nimport { rxChangeEventToEventReduceChangeEvent } from \"./rx-change-event.js\";\nimport { clone, ensureNotFalsy, getFromMapOrCreate } from \"./plugins/utils/index.js\";\nimport { getQueryMatcher, getSortComparator, normalizeMangoQuery } from \"./rx-query-helper.js\";\nexport function getSortFieldsOfQuery(primaryKey, query) {\n  if (!query.sort || query.sort.length === 0) {\n    return [primaryKey];\n  } else {\n    return query.sort.map(part => Object.keys(part)[0]);\n  }\n}\nexport var RXQUERY_QUERY_PARAMS_CACHE = new WeakMap();\nexport function getQueryParams(rxQuery) {\n  return getFromMapOrCreate(RXQUERY_QUERY_PARAMS_CACHE, rxQuery, () => {\n    var collection = rxQuery.collection;\n    var normalizedMangoQuery = normalizeMangoQuery(collection.storageInstance.schema, clone(rxQuery.mangoQuery));\n    var primaryKey = collection.schema.primaryPath;\n\n    /**\n     * Create a custom sort comparator\n     * that uses the hooks to ensure\n     * we send for example compressed documents to be sorted by compressed queries.\n     */\n    var sortComparator = getSortComparator(collection.schema.jsonSchema, normalizedMangoQuery);\n    var useSortComparator = (docA, docB) => {\n      var sortComparatorData = {\n        docA,\n        docB,\n        rxQuery\n      };\n      return sortComparator(sortComparatorData.docA, sortComparatorData.docB);\n    };\n\n    /**\n     * Create a custom query matcher\n     * that uses the hooks to ensure\n     * we send for example compressed documents to match compressed queries.\n     */\n    var queryMatcher = getQueryMatcher(collection.schema.jsonSchema, normalizedMangoQuery);\n    var useQueryMatcher = doc => {\n      var queryMatcherData = {\n        doc,\n        rxQuery\n      };\n      return queryMatcher(queryMatcherData.doc);\n    };\n    var ret = {\n      primaryKey: rxQuery.collection.schema.primaryPath,\n      skip: normalizedMangoQuery.skip,\n      limit: normalizedMangoQuery.limit,\n      sortFields: getSortFieldsOfQuery(primaryKey, normalizedMangoQuery),\n      sortComparator: useSortComparator,\n      queryMatcher: useQueryMatcher\n    };\n    return ret;\n  });\n}\nexport function calculateNewResults(rxQuery, rxChangeEvents) {\n  if (!rxQuery.collection.database.eventReduce) {\n    return {\n      runFullQueryAgain: true\n    };\n  }\n  var queryParams = getQueryParams(rxQuery);\n  var previousResults = ensureNotFalsy(rxQuery._result).docsData.slice(0);\n  var previousResultsMap = ensureNotFalsy(rxQuery._result).docsDataMap;\n  var changed = false;\n  var eventReduceEvents = [];\n  for (var index = 0; index < rxChangeEvents.length; index++) {\n    var cE = rxChangeEvents[index];\n    var eventReduceEvent = rxChangeEventToEventReduceChangeEvent(cE);\n    if (eventReduceEvent) {\n      eventReduceEvents.push(eventReduceEvent);\n    }\n  }\n  var foundNonOptimizeable = eventReduceEvents.find(eventReduceEvent => {\n    var stateResolveFunctionInput = {\n      queryParams,\n      changeEvent: eventReduceEvent,\n      previousResults,\n      keyDocumentMap: previousResultsMap\n    };\n    var actionName = calculateActionName(stateResolveFunctionInput);\n    if (actionName === 'runFullQueryAgain') {\n      return true;\n    } else if (actionName !== 'doNothing') {\n      changed = true;\n      runAction(actionName, queryParams, eventReduceEvent, previousResults, previousResultsMap);\n      return false;\n    }\n  });\n  if (foundNonOptimizeable) {\n    return {\n      runFullQueryAgain: true\n    };\n  } else {\n    return {\n      runFullQueryAgain: false,\n      changed,\n      newResults: previousResults\n    };\n  }\n}\n//# sourceMappingURL=event-reduce.js.map","/**\n * hook-functions that can be extended by the plugin\n */\nexport var HOOKS = {\n  /**\n   * Runs before a plugin is added.\n   * Use this to block the usage of non-compatible plugins.\n   */\n  preAddRxPlugin: [],\n  /**\n   * functions that run before the database is created\n   */\n  preCreateRxDatabase: [],\n  /**\n   * runs after the database is created and prepared\n   * but before the instance is returned to the user\n   * @async\n   */\n  createRxDatabase: [],\n  preCreateRxCollection: [],\n  createRxCollection: [],\n  createRxState: [],\n  /**\n  * runs at the end of the close-process of a collection\n  * @async\n  */\n  postCloseRxCollection: [],\n  /**\n   * Runs after a collection is removed.\n   * @async\n   */\n  postRemoveRxCollection: [],\n  /**\n    * functions that get the json-schema as input\n    * to do additionally checks/manipulation\n    */\n  preCreateRxSchema: [],\n  /**\n   * functions that run after the RxSchema is created\n   * gets RxSchema as attribute\n   */\n  createRxSchema: [],\n  prePrepareRxQuery: [],\n  preCreateRxQuery: [],\n  /**\n   * Runs before a query is send to the\n   * prepareQuery function of the storage engine.\n   */\n  prePrepareQuery: [],\n  createRxDocument: [],\n  /**\n   * runs after a RxDocument is created,\n   * cannot be async\n   */\n  postCreateRxDocument: [],\n  /**\n   * Runs before a RxStorageInstance is created\n   * gets the params of createStorageInstance()\n   * as attribute so you can manipulate them.\n   * Notice that you have to clone stuff before mutating the inputs.\n   */\n  preCreateRxStorageInstance: [],\n  preStorageWrite: [],\n  /**\n   * runs on the document-data before the document is migrated\n   * {\n   *   doc: Object, // original doc-data\n   *   migrated: // migrated doc-data after run through migration-strategies\n   * }\n   */\n  preMigrateDocument: [],\n  /**\n   * runs after the migration of a document has been done\n   */\n  postMigrateDocument: [],\n  /**\n   * runs at the beginning of the close-process of a database\n   */\n  preCloseRxDatabase: [],\n  /**\n   * runs after a database has been removed\n   * @async\n   */\n  postRemoveRxDatabase: [],\n  postCleanup: [],\n  /**\n   * runs before the replication writes the rows to master\n   * but before the rows have been modified\n   * @async\n   */\n  preReplicationMasterWrite: [],\n  /**\n   * runs after the replication has been sent to the server\n   * but before the new documents have been handled\n   * @async\n   */\n  preReplicationMasterWriteDocumentsHandle: []\n};\nexport function runPluginHooks(hookKey, obj) {\n  if (HOOKS[hookKey].length > 0) {\n    HOOKS[hookKey].forEach(fun => fun(obj));\n  }\n}\n\n/**\n * We do intentionally not run the hooks in parallel\n * because that makes stuff unpredictable and we use runAsyncPluginHooks()\n * only in places that are not that relevant for performance.\n */\nexport async function runAsyncPluginHooks(hookKey, obj) {\n  for (var fn of HOOKS[hookKey]) {\n    await fn(obj);\n  }\n}\n\n/**\n * used in tests to remove hooks\n */\nexport function _clearHook(type, fun) {\n  HOOKS[type] = HOOKS[type].filter(h => h !== fun);\n}\n//# sourceMappingURL=hooks.js.map","import { isBulkWriteConflictError, rxStorageWriteErrorToRxError } from \"./rx-error.js\";\nimport { clone, ensureNotFalsy, getFromMapOrCreate, getFromMapOrThrow, getHeightOfRevision, stripMetaDataFromDocument } from \"./plugins/utils/index.js\";\nimport { getWrittenDocumentsFromBulkWriteResponse } from \"./rx-storage-helper.js\";\n/**\n * The incremental write queue\n * batches up all incremental writes to a collection\n * so that performance can be improved by:\n * - Running only one write even when there are multiple modifications to the same document.\n * - Run all writes ins a single bulkWrite() call even when there are writes to many documents.\n */\nexport var IncrementalWriteQueue = /*#__PURE__*/function () {\n  function IncrementalWriteQueue(storageInstance, primaryPath,\n  // can be used to run hooks etc.\n  preWrite, postWrite) {\n    this.queueByDocId = new Map();\n    this.isRunning = false;\n    this.storageInstance = storageInstance;\n    this.primaryPath = primaryPath;\n    this.preWrite = preWrite;\n    this.postWrite = postWrite;\n  }\n  var _proto = IncrementalWriteQueue.prototype;\n  _proto.addWrite = function addWrite(lastKnownDocumentState, modifier) {\n    var docId = lastKnownDocumentState[this.primaryPath];\n    var ar = getFromMapOrCreate(this.queueByDocId, docId, () => []);\n    var ret = new Promise((resolve, reject) => {\n      var item = {\n        lastKnownDocumentState,\n        modifier,\n        resolve,\n        reject\n      };\n      ensureNotFalsy(ar).push(item);\n      this.triggerRun();\n    });\n    return ret;\n  };\n  _proto.triggerRun = async function triggerRun() {\n    if (this.isRunning === true || this.queueByDocId.size === 0) {\n      // already running\n      return;\n    }\n    this.isRunning = true;\n    var writeRows = [];\n\n    /**\n     * 'take over' so that while the async functions runs,\n     * new incremental updates could be added from the outside.\n     */\n    var itemsById = this.queueByDocId;\n    this.queueByDocId = new Map();\n    await Promise.all(Array.from(itemsById.entries()).map(async ([_docId, items]) => {\n      var oldData = findNewestOfDocumentStates(items.map(i => i.lastKnownDocumentState));\n      var newData = oldData;\n      for (var item of items) {\n        try {\n          newData = await item.modifier(\n          /**\n           * We have to clone() each time because the modifier\n           * might throw while it already changed some properties\n           * of the document.\n           */\n          clone(newData));\n        } catch (err) {\n          item.reject(err);\n          item.reject = () => {};\n          item.resolve = () => {};\n        }\n      }\n      try {\n        await this.preWrite(newData, oldData);\n      } catch (err) {\n        /**\n         * If the before-hooks fail,\n         * we reject all of the writes because it is\n         * not possible to determine which one is to blame.\n         */\n        items.forEach(item => item.reject(err));\n        return;\n      }\n      writeRows.push({\n        previous: oldData,\n        document: newData\n      });\n    }));\n    var writeResult = writeRows.length > 0 ? await this.storageInstance.bulkWrite(writeRows, 'incremental-write') : {\n      error: []\n    };\n\n    // process success\n    await Promise.all(getWrittenDocumentsFromBulkWriteResponse(this.primaryPath, writeRows, writeResult).map(result => {\n      var docId = result[this.primaryPath];\n      this.postWrite(result);\n      var items = getFromMapOrThrow(itemsById, docId);\n      items.forEach(item => item.resolve(result));\n    }));\n\n    // process errors\n    writeResult.error.forEach(error => {\n      var docId = error.documentId;\n      var items = getFromMapOrThrow(itemsById, docId);\n      var isConflict = isBulkWriteConflictError(error);\n      if (isConflict) {\n        // had conflict -> retry afterwards\n        var ar = getFromMapOrCreate(this.queueByDocId, docId, () => []);\n        /**\n         * Add the items back to this.queueByDocId\n         * by maintaining the original order.\n         */\n        items.reverse().forEach(item => {\n          item.lastKnownDocumentState = ensureNotFalsy(isConflict.documentInDb);\n          ensureNotFalsy(ar).unshift(item);\n        });\n      } else {\n        // other error -> must be thrown\n        var rxError = rxStorageWriteErrorToRxError(error);\n        items.forEach(item => item.reject(rxError));\n      }\n    });\n    this.isRunning = false;\n\n    /**\n     * Always trigger another run\n     * because in between there might be new items\n     * been added to the queue.\n     */\n    return this.triggerRun();\n  };\n  return IncrementalWriteQueue;\n}();\nexport function modifierFromPublicToInternal(publicModifier) {\n  var ret = async docData => {\n    var withoutMeta = stripMetaDataFromDocument(docData);\n    withoutMeta._deleted = docData._deleted;\n    var modified = await publicModifier(withoutMeta);\n    var reattachedMeta = Object.assign({}, modified, {\n      _meta: docData._meta,\n      _attachments: docData._attachments,\n      _rev: docData._rev,\n      _deleted: typeof modified._deleted !== 'undefined' ? modified._deleted : docData._deleted\n    });\n    if (typeof reattachedMeta._deleted === 'undefined') {\n      reattachedMeta._deleted = false;\n    }\n    return reattachedMeta;\n  };\n  return ret;\n}\nexport function findNewestOfDocumentStates(docs) {\n  var newest = docs[0];\n  var newestRevisionHeight = getHeightOfRevision(newest._rev);\n  docs.forEach(doc => {\n    var height = getHeightOfRevision(doc._rev);\n    if (height > newestRevisionHeight) {\n      newest = doc;\n      newestRevisionHeight = height;\n    }\n  });\n  return newest;\n}\n//# sourceMappingURL=incremental-write.js.map","/**\n * functions that can or should be overwritten by plugins\n * IMPORTANT: Do not import any big stuff from RxDB here!\n * An 'overwritable' can be used inside WebWorkers for RxStorage only,\n * and we do not want to have the full RxDB lib bundled in them.\n */\n\nexport var overwritable = {\n  /**\n   * if this method is overwritten with one\n   * that returns true, we do additional checks\n   * which help the developer but have bad performance\n   */\n  isDevMode() {\n    return false;\n  },\n  /**\n   * Deep freezes and object when in dev-mode.\n   * Deep-Freezing has the same performance as deep-cloning, so we only do that in dev-mode.\n   * Also, we can ensure the readonly state via typescript\n   * @link https://developer.mozilla.org/de/docs/Web/JavaScript/Reference/Global_Objects/Object/freeze\n   */\n  deepFreezeWhenDevMode(obj) {\n    return obj;\n  },\n  /**\n   * overwritten to map error-codes to text-messages\n   */\n  tunnelErrorMessage(message) {\n    return \"\\n        RxDB Error-Code: \" + message + \".\\n        Hint: Error messages are not included in RxDB core to reduce build size.\\n        To show the full error messages and to ensure that you do not make any mistakes when using RxDB,\\n        use the dev-mode plugin when you are in development mode: https://rxdb.info/dev-mode.html?console=error\\n        \";\n  }\n};\n//# sourceMappingURL=overwritable.js.map","/**\n * this handles how plugins are added to rxdb\n * basically it changes the internal prototypes\n * by passing them to the plugins-functions\n */\nimport { RxSchema } from \"./rx-schema.js\";\nimport { basePrototype as RxDocumentPrototype } from \"./rx-document.js\";\nimport { RxQueryBase } from \"./rx-query.js\";\nimport { RxCollectionBase } from \"./rx-collection.js\";\nimport { RxDatabaseBase } from \"./rx-database.js\";\nimport { overwritable } from \"./overwritable.js\";\nimport { HOOKS, runPluginHooks } from \"./hooks.js\";\nimport { newRxError, newRxTypeError } from \"./rx-error.js\";\n\n/**\n * prototypes that can be manipulated with a plugin\n */\nvar PROTOTYPES = {\n  RxSchema: RxSchema.prototype,\n  RxDocument: RxDocumentPrototype,\n  RxQuery: RxQueryBase.prototype,\n  RxCollection: RxCollectionBase.prototype,\n  RxDatabase: RxDatabaseBase.prototype\n};\nvar ADDED_PLUGINS = new Set();\nvar ADDED_PLUGIN_NAMES = new Set();\n\n/**\n * Add a plugin to the RxDB library.\n * Plugins are added globally and cannot be removed.\n */\nexport function addRxPlugin(plugin) {\n  runPluginHooks('preAddRxPlugin', {\n    plugin,\n    plugins: ADDED_PLUGINS\n  });\n\n  // do nothing if added before\n  if (ADDED_PLUGINS.has(plugin)) {\n    return;\n  } else {\n    // ensure no other plugin with the same name was already added\n    if (ADDED_PLUGIN_NAMES.has(plugin.name)) {\n      throw newRxError('PL3', {\n        name: plugin.name,\n        plugin\n      });\n    }\n    ADDED_PLUGINS.add(plugin);\n    ADDED_PLUGIN_NAMES.add(plugin.name);\n  }\n\n  /**\n   * To identify broken configurations,\n   * we only allow RxDB plugins to be passed into addRxPlugin().\n   */\n  if (!plugin.rxdb) {\n    throw newRxTypeError('PL1', {\n      plugin\n    });\n  }\n  if (plugin.init) {\n    plugin.init();\n  }\n\n  // prototype-overwrites\n  if (plugin.prototypes) {\n    Object.entries(plugin.prototypes).forEach(([name, fun]) => {\n      return fun(PROTOTYPES[name]);\n    });\n  }\n  // overwritable-overwrites\n  if (plugin.overwritable) {\n    Object.assign(overwritable, plugin.overwritable);\n  }\n  // extend-hooks\n  if (plugin.hooks) {\n    Object.entries(plugin.hooks).forEach(([name, hooksObj]) => {\n      if (hooksObj.after) {\n        HOOKS[name].push(hooksObj.after);\n      }\n      if (hooksObj.before) {\n        HOOKS[name].unshift(hooksObj.before);\n      }\n    });\n  }\n}\n//# sourceMappingURL=plugin.js.map","import { newRxError } from \"../../rx-error.js\";\nimport { ensureNotFalsy } from \"../utils/index.js\";\nexport function ensureSchemaSupportsAttachments(doc) {\n  var schemaJson = doc.collection.schema.jsonSchema;\n  if (!schemaJson.attachments) {\n    throw newRxError('AT1', {\n      link: 'https://pubkey.github.io/rxdb/rx-attachment.html'\n    });\n  }\n}\nexport function assignMethodsToAttachment(attachment) {\n  Object.entries(attachment.doc.collection.attachments).forEach(([funName, fun]) => {\n    Object.defineProperty(attachment, funName, {\n      get: () => fun.bind(attachment)\n    });\n  });\n}\n\n/**\n * Fill up the missing attachment.data of the newDocument\n * so that the new document can be send to somewhere else\n * which could then receive all required attachments data\n * that it did not have before.\n */\nexport async function fillWriteDataForAttachmentsChange(primaryPath, storageInstance, newDocument, originalDocument) {\n  if (!newDocument._attachments || originalDocument && !originalDocument._attachments) {\n    throw new Error('_attachments missing');\n  }\n  var docId = newDocument[primaryPath];\n  var originalAttachmentsIds = new Set(originalDocument && originalDocument._attachments ? Object.keys(originalDocument._attachments) : []);\n  await Promise.all(Object.entries(newDocument._attachments).map(async ([key, value]) => {\n    if ((!originalAttachmentsIds.has(key) || originalDocument && ensureNotFalsy(originalDocument._attachments)[key].digest !== value.digest) && !value.data) {\n      var attachmentDataString = await storageInstance.getAttachmentData(docId, key, value.digest);\n      value.data = attachmentDataString;\n    }\n  }));\n  return newDocument;\n}\n//# sourceMappingURL=attachments-utils.js.map","import { getLocal, getLocal$, insertLocal, upsertLocal } from \"./local-documents.js\";\nimport { closeStateByParent, createLocalDocStateByParent, removeLocalDocumentsStorageInstance } from \"./local-documents-helper.js\";\nexport * from \"./local-documents-helper.js\";\nexport * from \"./local-documents.js\";\nexport * from \"./rx-local-document.js\";\nexport var RxDBLocalDocumentsPlugin = {\n  name: 'local-documents',\n  rxdb: true,\n  prototypes: {\n    RxCollection: proto => {\n      proto.insertLocal = insertLocal;\n      proto.upsertLocal = upsertLocal;\n      proto.getLocal = getLocal;\n      proto.getLocal$ = getLocal$;\n    },\n    RxDatabase: proto => {\n      proto.insertLocal = insertLocal;\n      proto.upsertLocal = upsertLocal;\n      proto.getLocal = getLocal;\n      proto.getLocal$ = getLocal$;\n    }\n  },\n  hooks: {\n    createRxDatabase: {\n      before: args => {\n        if (args.creator.localDocuments) {\n          /**\n           * We do not have to await\n           * the creation to speed up initial page load.\n           */\n          /* await */\n          createLocalDocStateByParent(args.database);\n        }\n      }\n    },\n    createRxCollection: {\n      before: args => {\n        if (args.creator.localDocuments) {\n          /**\n           * We do not have to await\n           * the creation to speed up initial page load.\n           */\n          /* await */\n          createLocalDocStateByParent(args.collection);\n        }\n      }\n    },\n    preCloseRxDatabase: {\n      after: db => {\n        return closeStateByParent(db);\n      }\n    },\n    postCloseRxCollection: {\n      after: collection => closeStateByParent(collection)\n    },\n    postRemoveRxDatabase: {\n      after: args => {\n        return removeLocalDocumentsStorageInstance(args.storage, args.databaseName, '');\n      }\n    },\n    postRemoveRxCollection: {\n      after: args => {\n        return removeLocalDocumentsStorageInstance(args.storage, args.databaseName, args.collectionName);\n      }\n    }\n  },\n  overwritable: {}\n};\n//# sourceMappingURL=index.js.map","import { filter, map } from 'rxjs';\nimport { DocumentCache } from \"../../doc-cache.js\";\nimport { IncrementalWriteQueue } from \"../../incremental-write.js\";\nimport { newRxError } from \"../../rx-error.js\";\nimport { fillWithDefaultSettings } from \"../../rx-schema-helper.js\";\nimport { getWrappedStorageInstance } from \"../../rx-storage-helper.js\";\nimport { randomToken } from \"../../plugins/utils/index.js\";\nimport { createRxLocalDocument } from \"./rx-local-document.js\";\nimport { overwritable } from \"../../overwritable.js\";\nexport var LOCAL_DOC_STATE_BY_PARENT = new WeakMap();\nexport var LOCAL_DOC_STATE_BY_PARENT_RESOLVED = new WeakMap();\nexport function createLocalDocStateByParent(parent) {\n  var database = parent.database ? parent.database : parent;\n  var collectionName = parent.database ? parent.name : '';\n  var statePromise = (async () => {\n    var storageInstance = await createLocalDocumentStorageInstance(database.token, database.storage, database.name, collectionName, database.instanceCreationOptions, database.multiInstance);\n    storageInstance = getWrappedStorageInstance(database, storageInstance, RX_LOCAL_DOCUMENT_SCHEMA);\n    var docCache = new DocumentCache('id', database.eventBulks$.pipe(filter(changeEventBulk => {\n      var ret = false;\n      if (\n      // parent is database\n      collectionName === '' && !changeEventBulk.collectionName ||\n      // parent is collection\n\n      collectionName !== '' && changeEventBulk.collectionName === collectionName) {\n        ret = true;\n      }\n      return ret && changeEventBulk.isLocal;\n    }), map(b => b.events)), docData => createRxLocalDocument(docData, parent));\n    var incrementalWriteQueue = new IncrementalWriteQueue(storageInstance, 'id', () => {}, () => {});\n\n    /**\n     * Emit the changestream into the collections change stream\n     */\n    var databaseStorageToken = await database.storageToken;\n    var subLocalDocs = storageInstance.changeStream().subscribe(eventBulk => {\n      var events = new Array(eventBulk.events.length);\n      var rawEvents = eventBulk.events;\n      var collectionName = parent.database ? parent.name : undefined;\n      for (var index = 0; index < rawEvents.length; index++) {\n        var event = rawEvents[index];\n        events[index] = {\n          documentId: event.documentId,\n          collectionName,\n          isLocal: true,\n          operation: event.operation,\n          documentData: overwritable.deepFreezeWhenDevMode(event.documentData),\n          previousDocumentData: overwritable.deepFreezeWhenDevMode(event.previousDocumentData)\n        };\n      }\n      var changeEventBulk = {\n        id: eventBulk.id,\n        isLocal: true,\n        internal: false,\n        collectionName: parent.database ? parent.name : undefined,\n        storageToken: databaseStorageToken,\n        events,\n        databaseToken: database.token,\n        checkpoint: eventBulk.checkpoint,\n        context: eventBulk.context\n      };\n      database.$emit(changeEventBulk);\n    });\n    parent._subs.push(subLocalDocs);\n    var state = {\n      database,\n      parent,\n      storageInstance,\n      docCache,\n      incrementalWriteQueue\n    };\n    LOCAL_DOC_STATE_BY_PARENT_RESOLVED.set(parent, state);\n    return state;\n  })();\n  LOCAL_DOC_STATE_BY_PARENT.set(parent, statePromise);\n}\nexport function getLocalDocStateByParent(parent) {\n  var statePromise = LOCAL_DOC_STATE_BY_PARENT.get(parent);\n  if (!statePromise) {\n    var database = parent.database ? parent.database : parent;\n    var collectionName = parent.database ? parent.name : '';\n    throw newRxError('LD8', {\n      database: database.name,\n      collection: collectionName\n    });\n  }\n  return statePromise;\n}\nexport function createLocalDocumentStorageInstance(databaseInstanceToken, storage, databaseName, collectionName, instanceCreationOptions, multiInstance) {\n  return storage.createStorageInstance({\n    databaseInstanceToken,\n    databaseName: databaseName,\n    /**\n     * Use a different collection name for the local documents instance\n     * so that the local docs can be kept while deleting the normal instance\n     * after migration.\n     */\n    collectionName: getCollectionLocalInstanceName(collectionName),\n    schema: RX_LOCAL_DOCUMENT_SCHEMA,\n    options: instanceCreationOptions,\n    multiInstance,\n    devMode: overwritable.isDevMode()\n  });\n}\nexport function closeStateByParent(parent) {\n  var statePromise = LOCAL_DOC_STATE_BY_PARENT.get(parent);\n  if (statePromise) {\n    LOCAL_DOC_STATE_BY_PARENT.delete(parent);\n    return statePromise.then(state => state.storageInstance.close());\n  }\n}\nexport async function removeLocalDocumentsStorageInstance(storage, databaseName, collectionName) {\n  var databaseInstanceToken = randomToken(10);\n  var storageInstance = await createLocalDocumentStorageInstance(databaseInstanceToken, storage, databaseName, collectionName, {}, false);\n  await storageInstance.remove();\n}\nexport function getCollectionLocalInstanceName(collectionName) {\n  return 'plugin-local-documents-' + collectionName;\n}\nexport var RX_LOCAL_DOCUMENT_SCHEMA = fillWithDefaultSettings({\n  title: 'RxLocalDocument',\n  version: 0,\n  primaryKey: 'id',\n  type: 'object',\n  properties: {\n    id: {\n      type: 'string',\n      maxLength: 128\n    },\n    data: {\n      type: 'object',\n      additionalProperties: true\n    }\n  },\n  required: ['id', 'data']\n});\n//# sourceMappingURL=local-documents-helper.js.map","import { getDefaultRevision, getDefaultRxDocumentMeta } from \"../../plugins/utils/index.js\";\nimport { filter, map, startWith, mergeMap } from 'rxjs';\nimport { getLocalDocStateByParent } from \"./local-documents-helper.js\";\nimport { getSingleDocument, writeSingle } from \"../../rx-storage-helper.js\";\n\n/**\n * save the local-document-data\n * throws if already exists\n */\nexport async function insertLocal(id, data) {\n  var state = await getLocalDocStateByParent(this);\n\n  // create new one\n  var docData = {\n    id: id,\n    data,\n    _deleted: false,\n    _meta: getDefaultRxDocumentMeta(),\n    _rev: getDefaultRevision(),\n    _attachments: {}\n  };\n  return writeSingle(state.storageInstance, {\n    document: docData\n  }, 'local-document-insert').then(newDocData => state.docCache.getCachedRxDocument(newDocData));\n}\n\n/**\n * save the local-document-data\n * overwrites existing if exists\n */\nexport function upsertLocal(id, data) {\n  return this.getLocal(id).then(existing => {\n    if (!existing) {\n      // create new one\n      var docPromise = this.insertLocal(id, data);\n      return docPromise;\n    } else {\n      // update existing\n      return existing.incrementalModify(() => {\n        return data;\n      });\n    }\n  });\n}\nexport async function getLocal(id) {\n  var state = await getLocalDocStateByParent(this);\n  var docCache = state.docCache;\n\n  // check in doc-cache\n  var found = docCache.getLatestDocumentDataIfExists(id);\n  if (found) {\n    return Promise.resolve(docCache.getCachedRxDocument(found));\n  }\n\n  // if not found, check in storage instance\n  return getSingleDocument(state.storageInstance, id).then(docData => {\n    if (!docData) {\n      return null;\n    }\n    return state.docCache.getCachedRxDocument(docData);\n  });\n}\nexport function getLocal$(id) {\n  return this.$.pipe(startWith(null), mergeMap(async cE => {\n    if (cE) {\n      return {\n        changeEvent: cE\n      };\n    } else {\n      var doc = await this.getLocal(id);\n      return {\n        doc: doc\n      };\n    }\n  }), mergeMap(async changeEventOrDoc => {\n    if (changeEventOrDoc.changeEvent) {\n      var cE = changeEventOrDoc.changeEvent;\n      if (!cE.isLocal || cE.documentId !== id) {\n        return {\n          use: false\n        };\n      } else {\n        var doc = await this.getLocal(id);\n        return {\n          use: true,\n          doc: doc\n        };\n      }\n    } else {\n      return {\n        use: true,\n        doc: changeEventOrDoc.doc\n      };\n    }\n  }), filter(filterFlagged => filterFlagged.use), map(filterFlagged => {\n    return filterFlagged.doc;\n  }));\n}\n//# sourceMappingURL=local-documents.js.map","import _inheritsLoose from \"@babel/runtime/helpers/inheritsLoose\";\nimport { distinctUntilChanged, filter, map, shareReplay, startWith } from 'rxjs';\nimport { overwritable } from \"../../overwritable.js\";\nimport { getDocumentDataOfRxChangeEvent } from \"../../rx-change-event.js\";\nimport { basePrototype, createRxDocumentConstructor } from \"../../rx-document.js\";\nimport { newRxError, newRxTypeError } from \"../../rx-error.js\";\nimport { getWrittenDocumentsFromBulkWriteResponse, writeSingle } from \"../../rx-storage-helper.js\";\nimport { ensureNotFalsy, flatClone, getFromMapOrThrow, getProperty, RXJS_SHARE_REPLAY_DEFAULTS } from \"../../plugins/utils/index.js\";\nimport { getLocalDocStateByParent, LOCAL_DOC_STATE_BY_PARENT_RESOLVED } from \"./local-documents-helper.js\";\nimport { isRxDatabase } from \"../../rx-database.js\";\nvar RxDocumentParent = createRxDocumentConstructor();\nvar RxLocalDocumentClass = /*#__PURE__*/function (_RxDocumentParent) {\n  function RxLocalDocumentClass(id, jsonData, parent) {\n    var _this2;\n    _this2 = _RxDocumentParent.call(this, null, jsonData) || this;\n    _this2.id = id;\n    _this2.parent = parent;\n    return _this2;\n  }\n  _inheritsLoose(RxLocalDocumentClass, _RxDocumentParent);\n  return RxLocalDocumentClass;\n}(RxDocumentParent);\nvar RxLocalDocumentPrototype = {\n  get isLocal() {\n    return true;\n  },\n  //\n  // overwrites\n  //\n  get allAttachments$() {\n    // this is overwritten here because we cannot re-set getters on the prototype\n    throw newRxError('LD1', {\n      document: this\n    });\n  },\n  get primaryPath() {\n    return 'id';\n  },\n  get primary() {\n    return this.id;\n  },\n  get $() {\n    var _this = this;\n    var state = getFromMapOrThrow(LOCAL_DOC_STATE_BY_PARENT_RESOLVED, this.parent);\n    var id = this.primary;\n    return _this.parent.eventBulks$.pipe(filter(bulk => !!bulk.isLocal), map(bulk => bulk.events.find(ev => ev.documentId === id)), filter(event => !!event), map(changeEvent => getDocumentDataOfRxChangeEvent(ensureNotFalsy(changeEvent))), startWith(state.docCache.getLatestDocumentData(this.primary)), distinctUntilChanged((prev, curr) => prev._rev === curr._rev), map(docData => state.docCache.getCachedRxDocument(docData)), shareReplay(RXJS_SHARE_REPLAY_DEFAULTS));\n    ;\n  },\n  get $$() {\n    var _this = this;\n    var db = getRxDatabaseFromLocalDocument(_this);\n    var reactivity = db.getReactivityFactory();\n    return reactivity.fromObservable(_this.$, _this.getLatest()._data, db);\n  },\n  get deleted$$() {\n    var _this = this;\n    var db = getRxDatabaseFromLocalDocument(_this);\n    var reactivity = db.getReactivityFactory();\n    return reactivity.fromObservable(_this.deleted$, _this.getLatest().deleted, db);\n  },\n  getLatest() {\n    var state = getFromMapOrThrow(LOCAL_DOC_STATE_BY_PARENT_RESOLVED, this.parent);\n    var latestDocData = state.docCache.getLatestDocumentData(this.primary);\n    return state.docCache.getCachedRxDocument(latestDocData);\n  },\n  get(objPath) {\n    objPath = 'data.' + objPath;\n    if (!this._data) {\n      return undefined;\n    }\n    if (typeof objPath !== 'string') {\n      throw newRxTypeError('LD2', {\n        objPath\n      });\n    }\n    var valueObj = getProperty(this._data, objPath);\n    valueObj = overwritable.deepFreezeWhenDevMode(valueObj);\n    return valueObj;\n  },\n  get$(objPath) {\n    objPath = 'data.' + objPath;\n    if (overwritable.isDevMode()) {\n      if (objPath.includes('.item.')) {\n        throw newRxError('LD3', {\n          objPath\n        });\n      }\n      if (objPath === this.primaryPath) {\n        throw newRxError('LD4');\n      }\n    }\n    return this.$.pipe(map(localDocument => localDocument._data), map(data => getProperty(data, objPath)), distinctUntilChanged());\n  },\n  get$$(objPath) {\n    var db = getRxDatabaseFromLocalDocument(this);\n    var reactivity = db.getReactivityFactory();\n    return reactivity.fromObservable(this.get$(objPath), this.getLatest().get(objPath), db);\n  },\n  async incrementalModify(mutationFunction) {\n    var state = await getLocalDocStateByParent(this.parent);\n    return state.incrementalWriteQueue.addWrite(this._data, async docData => {\n      docData.data = await mutationFunction(docData.data, this);\n      return docData;\n    }).then(result => state.docCache.getCachedRxDocument(result));\n  },\n  incrementalPatch(patch) {\n    return this.incrementalModify(docData => {\n      Object.entries(patch).forEach(([k, v]) => {\n        docData[k] = v;\n      });\n      return docData;\n    });\n  },\n  async _saveData(newData) {\n    var state = await getLocalDocStateByParent(this.parent);\n    var oldData = this._data;\n    newData.id = this.id;\n    var writeRows = [{\n      previous: oldData,\n      document: newData\n    }];\n    return state.storageInstance.bulkWrite(writeRows, 'local-document-save-data').then(res => {\n      if (res.error[0]) {\n        throw res.error[0];\n      }\n      var success = getWrittenDocumentsFromBulkWriteResponse(this.collection.schema.primaryPath, writeRows, res)[0];\n      newData = flatClone(newData);\n      newData._rev = success._rev;\n    });\n  },\n  async remove() {\n    var state = await getLocalDocStateByParent(this.parent);\n    var writeData = flatClone(this._data);\n    writeData._deleted = true;\n    return writeSingle(state.storageInstance, {\n      previous: this._data,\n      document: writeData\n    }, 'local-document-remove').then(writeResult => state.docCache.getCachedRxDocument(writeResult));\n  }\n};\nvar INIT_DONE = false;\nvar _init = () => {\n  if (INIT_DONE) return;else INIT_DONE = true;\n\n  // add functions of RxDocument\n  var docBaseProto = basePrototype;\n  var props = Object.getOwnPropertyNames(docBaseProto);\n  props.forEach(key => {\n    var exists = Object.getOwnPropertyDescriptor(RxLocalDocumentPrototype, key);\n    if (exists) return;\n    var desc = Object.getOwnPropertyDescriptor(docBaseProto, key);\n    Object.defineProperty(RxLocalDocumentPrototype, key, desc);\n  });\n\n  /**\n   * Overwrite things that do not work on local documents\n   * with a throwing function.\n   */\n  var getThrowingFun = k => () => {\n    throw newRxError('LD6', {\n      functionName: k\n    });\n  };\n  ['populate', 'update', 'putAttachment', 'getAttachment', 'allAttachments'].forEach(k => RxLocalDocumentPrototype[k] = getThrowingFun(k));\n};\nexport function createRxLocalDocument(data, parent) {\n  _init();\n  var newDoc = new RxLocalDocumentClass(data.id, data, parent);\n  Object.setPrototypeOf(newDoc, RxLocalDocumentPrototype);\n  newDoc.prototype = RxLocalDocumentPrototype;\n  return newDoc;\n}\nexport function getRxDatabaseFromLocalDocument(doc) {\n  var parent = doc.parent;\n  if (isRxDatabase(parent)) {\n    return parent;\n  } else {\n    return parent.database;\n  }\n}\n//# sourceMappingURL=rx-local-document.js.map","import { shareReplay } from 'rxjs';\nimport { getFromMapOrCreate, PROMISE_RESOLVE_FALSE, RXJS_SHARE_REPLAY_DEFAULTS } from \"../../plugins/utils/index.js\";\nimport { RxMigrationState } from \"./rx-migration-state.js\";\nimport { getMigrationStateByDatabase, mustMigrate, onDatabaseClose } from \"./migration-helpers.js\";\nimport { addRxPlugin } from \"../../plugin.js\";\nimport { RxDBLocalDocumentsPlugin } from \"../local-documents/index.js\";\nexport var DATA_MIGRATOR_BY_COLLECTION = new WeakMap();\nexport var RxDBMigrationPlugin = {\n  name: 'migration-schema',\n  rxdb: true,\n  init() {\n    addRxPlugin(RxDBLocalDocumentsPlugin);\n  },\n  hooks: {\n    preCloseRxDatabase: {\n      after: onDatabaseClose\n    }\n  },\n  prototypes: {\n    RxDatabase: proto => {\n      proto.migrationStates = function () {\n        return getMigrationStateByDatabase(this).pipe(shareReplay(RXJS_SHARE_REPLAY_DEFAULTS));\n      };\n    },\n    RxCollection: proto => {\n      proto.getMigrationState = function () {\n        return getFromMapOrCreate(DATA_MIGRATOR_BY_COLLECTION, this, () => new RxMigrationState(this.asRxCollection, this.migrationStrategies));\n      };\n      proto.migrationNeeded = function () {\n        if (this.schema.version === 0) {\n          return PROMISE_RESOLVE_FALSE;\n        }\n        return mustMigrate(this.getMigrationState());\n      };\n    }\n  }\n};\nexport var RxDBMigrationSchemaPlugin = RxDBMigrationPlugin;\nexport * from \"./rx-migration-state.js\";\nexport * from \"./migration-helpers.js\";\nexport * from \"./migration-types.js\";\n//# sourceMappingURL=index.js.map","import { BehaviorSubject } from 'rxjs';\nimport { INTERNAL_CONTEXT_COLLECTION, getPrimaryKeyOfInternalDocument } from \"../../rx-database-internal-store.js\";\nimport { getPreviousVersions } from \"../../rx-schema.js\";\nimport { PROMISE_RESOLVE_FALSE, PROMISE_RESOLVE_NULL, clone, flatClone, getFromMapOrCreate, toPromise } from \"../utils/index.js\";\nexport async function getOldCollectionMeta(migrationState) {\n  var collectionDocKeys = getPreviousVersions(migrationState.collection.schema.jsonSchema).map(version => migrationState.collection.name + '-' + version);\n  var found = await migrationState.database.internalStore.findDocumentsById(collectionDocKeys.map(key => getPrimaryKeyOfInternalDocument(key, INTERNAL_CONTEXT_COLLECTION)), false);\n  if (found.length > 1) {\n    throw new Error('more than one old collection meta found');\n  }\n  return found[0];\n}\n\n/**\n * runs the doc-data through all following migrationStrategies\n * so it will match the newest schema.\n * @throws Error if final doc does not match final schema or migrationStrategy crashes\n * @return final object or null if migrationStrategy deleted it\n */\nexport function migrateDocumentData(collection, docSchemaVersion, docData) {\n  /**\n   * We cannot deep-clone Blob or Buffer\n   * so we just flat clone it here\n   * and attach it to the deep cloned document data.\n   */\n  var attachmentsBefore = flatClone(docData._attachments);\n  var mutateableDocData = clone(docData);\n  var meta = mutateableDocData._meta;\n  delete mutateableDocData._meta;\n  mutateableDocData._attachments = attachmentsBefore;\n  var nextVersion = docSchemaVersion + 1;\n\n  // run the document through migrationStrategies\n  var currentPromise = Promise.resolve(mutateableDocData);\n  var _loop = function () {\n    var version = nextVersion;\n    currentPromise = currentPromise.then(docOrNull => runStrategyIfNotNull(collection, version, docOrNull));\n    nextVersion++;\n  };\n  while (nextVersion <= collection.schema.version) {\n    _loop();\n  }\n  return currentPromise.then(doc => {\n    if (doc === null) {\n      return PROMISE_RESOLVE_NULL;\n    }\n    doc._meta = meta;\n    return doc;\n  });\n}\nexport function runStrategyIfNotNull(collection, version, docOrNull) {\n  if (docOrNull === null) {\n    return PROMISE_RESOLVE_NULL;\n  } else {\n    var ret = collection.migrationStrategies[version](docOrNull, collection);\n    var retPromise = toPromise(ret);\n    return retPromise;\n  }\n}\n\n/**\n * returns true if a migration is needed\n */\nexport async function mustMigrate(migrationState) {\n  if (migrationState.collection.schema.version === 0) {\n    return PROMISE_RESOLVE_FALSE;\n  }\n  var oldColDoc = await getOldCollectionMeta(migrationState);\n  return !!oldColDoc;\n}\nexport var MIGRATION_DEFAULT_BATCH_SIZE = 200;\nexport var DATA_MIGRATION_STATE_SUBJECT_BY_DATABASE = new WeakMap();\nexport function addMigrationStateToDatabase(migrationState) {\n  var allSubject = getMigrationStateByDatabase(migrationState.database);\n  var allList = allSubject.getValue().slice(0);\n  allList.push(migrationState);\n  allSubject.next(allList);\n}\nexport function getMigrationStateByDatabase(database) {\n  return getFromMapOrCreate(DATA_MIGRATION_STATE_SUBJECT_BY_DATABASE, database, () => new BehaviorSubject([]));\n}\n\n/**\n * Complete on database close\n * so people do not have to unsubscribe\n */\nexport function onDatabaseClose(database) {\n  var subject = DATA_MIGRATION_STATE_SUBJECT_BY_DATABASE.get(database);\n  if (subject) {\n    subject.complete();\n  }\n}\n//# sourceMappingURL=migration-helpers.js.map","import { Subject, filter, firstValueFrom, map, shareReplay } from 'rxjs';\nimport { isBulkWriteConflictError, newRxError } from \"../../rx-error.js\";\nimport { MIGRATION_DEFAULT_BATCH_SIZE, addMigrationStateToDatabase, getOldCollectionMeta, migrateDocumentData, mustMigrate } from \"./migration-helpers.js\";\nimport { PROMISE_RESOLVE_TRUE, RXJS_SHARE_REPLAY_DEFAULTS, clone, deepEqual, ensureNotFalsy, errorToPlainJson, getDefaultRevision, getDefaultRxDocumentMeta } from \"../utils/index.js\";\nimport { getSingleDocument, hasEncryption, observeSingle, writeSingle } from \"../../rx-storage-helper.js\";\nimport { BroadcastChannel, createLeaderElection } from 'broadcast-channel';\nimport { META_INSTANCE_SCHEMA_TITLE, awaitRxStorageReplicationFirstInSync, awaitRxStorageReplicationInSync, cancelRxStorageReplication, defaultConflictHandler, getRxReplicationMetaInstanceSchema, replicateRxStorageInstance, rxStorageInstanceToReplicationHandler } from \"../../replication-protocol/index.js\";\nimport { overwritable } from \"../../overwritable.js\";\nimport { INTERNAL_CONTEXT_MIGRATION_STATUS, addConnectedStorageToCollection, getPrimaryKeyOfInternalDocument } from \"../../rx-database-internal-store.js\";\nimport { normalizeMangoQuery, prepareQuery } from \"../../rx-query-helper.js\";\nexport var RxMigrationState = /*#__PURE__*/function () {\n  function RxMigrationState(collection, migrationStrategies, statusDocKey = [collection.name, 'v', collection.schema.version].join('-')) {\n    this.started = false;\n    this.updateStatusHandlers = [];\n    this.updateStatusQueue = PROMISE_RESOLVE_TRUE;\n    this.collection = collection;\n    this.migrationStrategies = migrationStrategies;\n    this.statusDocKey = statusDocKey;\n    this.database = collection.database;\n    this.oldCollectionMeta = getOldCollectionMeta(this);\n    this.mustMigrate = mustMigrate(this);\n    this.statusDocId = getPrimaryKeyOfInternalDocument(this.statusDocKey, INTERNAL_CONTEXT_MIGRATION_STATUS);\n    addMigrationStateToDatabase(this);\n    this.$ = observeSingle(this.database.internalStore, this.statusDocId).pipe(filter(d => !!d), map(d => ensureNotFalsy(d).data), shareReplay(RXJS_SHARE_REPLAY_DEFAULTS));\n  }\n  var _proto = RxMigrationState.prototype;\n  _proto.getStatus = function getStatus() {\n    return firstValueFrom(this.$);\n  }\n\n  /**\n   * Starts the migration.\n   * Returns void so that people to not get the idea to await\n   * this function.\n   * Instead use migratePromise() if you want to await\n   * the migration. This ensures it works even if the migration\n   * is run on a different browser tab.\n   */;\n  _proto.startMigration = async function startMigration(batchSize = MIGRATION_DEFAULT_BATCH_SIZE) {\n    var must = await this.mustMigrate;\n    if (!must) {\n      return;\n    }\n    if (this.started) {\n      throw newRxError('DM1');\n    }\n    this.started = true;\n    var broadcastChannel = undefined;\n    /**\n     * To ensure that multiple tabs do not migrate the same collection,\n     * we use a new broadcastChannel/leaderElector for each collection.\n     * This is required because collections can be added dynamically and\n     * not all tabs might know about this collection.\n     */\n    if (this.database.multiInstance) {\n      broadcastChannel = new BroadcastChannel(['rx-migration-state', this.database.name, this.collection.name, this.collection.schema.version].join('|'));\n      var leaderElector = createLeaderElection(broadcastChannel);\n      await leaderElector.awaitLeadership();\n    }\n\n    /**\n     * Instead of writing a custom migration protocol,\n     * we do a push-only replication from the old collection data to the new one.\n     * This also ensure that restarting the replication works without problems.\n     */\n    var oldCollectionMeta = await this.oldCollectionMeta;\n    var oldStorageInstance = await this.database.storage.createStorageInstance({\n      databaseName: this.database.name,\n      collectionName: this.collection.name,\n      databaseInstanceToken: this.database.token,\n      multiInstance: this.database.multiInstance,\n      options: {},\n      schema: oldCollectionMeta.data.schema,\n      password: this.database.password,\n      devMode: overwritable.isDevMode()\n    });\n    var connectedInstances = await this.getConnectedStorageInstances();\n\n    /**\n     * Initially write the migration status into a meta document.\n     */\n    var totalCount = await this.countAllDoucments([oldStorageInstance].concat(connectedInstances.map(r => r.oldStorage)));\n    await this.updateStatus(s => {\n      s.count.total = totalCount;\n      return s;\n    });\n    try {\n      /**\n       * First migrate the connected storages,\n       * afterwards migrate the normal collection.\n       */\n      await Promise.all(connectedInstances.map(async connectedInstance => {\n        await addConnectedStorageToCollection(this.collection, connectedInstance.newStorage.collectionName, connectedInstance.newStorage.schema);\n        await this.migrateStorage(connectedInstance.oldStorage, connectedInstance.newStorage, batchSize);\n        await connectedInstance.newStorage.close();\n      }));\n      await this.migrateStorage(oldStorageInstance,\n      /**\n       * Use the originalStorageInstance here\n       * so that the _meta.lwt time keeps the same\n       * and our replication checkpoints still point to the\n       * correct checkpoint.\n       */\n      this.collection.storageInstance.originalStorageInstance, batchSize);\n    } catch (err) {\n      await oldStorageInstance.close();\n      await this.updateStatus(s => {\n        s.status = 'ERROR';\n        s.error = errorToPlainJson(err);\n        return s;\n      });\n      return;\n    }\n\n    // remove old collection meta doc\n    await writeSingle(this.database.internalStore, {\n      previous: oldCollectionMeta,\n      document: Object.assign({}, oldCollectionMeta, {\n        _deleted: true\n      })\n    }, 'rx-migration-remove-collection-meta');\n    await this.updateStatus(s => {\n      s.status = 'DONE';\n      return s;\n    });\n    if (broadcastChannel) {\n      await broadcastChannel.close();\n    }\n  };\n  _proto.updateStatus = function updateStatus(handler) {\n    this.updateStatusHandlers.push(handler);\n    this.updateStatusQueue = this.updateStatusQueue.then(async () => {\n      if (this.updateStatusHandlers.length === 0) {\n        return;\n      }\n      // re-run until no conflict\n      var useHandlers = this.updateStatusHandlers;\n      this.updateStatusHandlers = [];\n      while (true) {\n        var previous = await getSingleDocument(this.database.internalStore, this.statusDocId);\n        var newDoc = clone(previous);\n        if (!previous) {\n          newDoc = {\n            id: this.statusDocId,\n            key: this.statusDocKey,\n            context: INTERNAL_CONTEXT_MIGRATION_STATUS,\n            data: {\n              collectionName: this.collection.name,\n              status: 'RUNNING',\n              count: {\n                total: 0,\n                handled: 0,\n                percent: 0\n              }\n            },\n            _deleted: false,\n            _meta: getDefaultRxDocumentMeta(),\n            _rev: getDefaultRevision(),\n            _attachments: {}\n          };\n        }\n        var status = ensureNotFalsy(newDoc).data;\n        for (var oneHandler of useHandlers) {\n          status = oneHandler(status);\n        }\n        status.count.percent = Math.round(status.count.handled / status.count.total * 100);\n        if (newDoc && previous && deepEqual(newDoc.data, previous.data)) {\n          break;\n        }\n        try {\n          await writeSingle(this.database.internalStore, {\n            previous,\n            document: ensureNotFalsy(newDoc)\n          }, INTERNAL_CONTEXT_MIGRATION_STATUS);\n\n          // write successful\n          break;\n        } catch (err) {\n          // ignore conflicts\n          if (!isBulkWriteConflictError(err)) {\n            throw err;\n          }\n        }\n      }\n    });\n    return this.updateStatusQueue;\n  };\n  _proto.migrateStorage = async function migrateStorage(oldStorage, newStorage, batchSize) {\n    var replicationMetaStorageInstance = await this.database.storage.createStorageInstance({\n      databaseName: this.database.name,\n      collectionName: 'rx-migration-state-meta-' + oldStorage.collectionName + '-' + oldStorage.schema.version,\n      databaseInstanceToken: this.database.token,\n      multiInstance: this.database.multiInstance,\n      options: {},\n      schema: getRxReplicationMetaInstanceSchema(oldStorage.schema, hasEncryption(oldStorage.schema)),\n      password: this.database.password,\n      devMode: overwritable.isDevMode()\n    });\n    var replicationHandlerBase = rxStorageInstanceToReplicationHandler(newStorage,\n    /**\n     * Ignore push-conflicts.\n     * If this happens we drop the 'old' document state.\n     */\n    defaultConflictHandler, this.database.token, true);\n    var replicationState = replicateRxStorageInstance({\n      keepMeta: true,\n      identifier: ['rx-migration-state', oldStorage.collectionName, oldStorage.schema.version, this.collection.schema.version].join('-'),\n      replicationHandler: {\n        masterChangesSince() {\n          return Promise.resolve({\n            checkpoint: null,\n            documents: []\n          });\n        },\n        masterWrite: async rows => {\n          rows = await Promise.all(rows.map(async row => {\n            var newDocData = row.newDocumentState;\n            if (newStorage.schema.title === META_INSTANCE_SCHEMA_TITLE) {\n              newDocData = row.newDocumentState.docData;\n              if (row.newDocumentState.isCheckpoint === '1') {\n                return {\n                  assumedMasterState: undefined,\n                  newDocumentState: row.newDocumentState\n                };\n              }\n            }\n            var migratedDocData = await migrateDocumentData(this.collection, oldStorage.schema.version, newDocData);\n            var newRow = {\n              // drop the assumed master state, we do not have to care about conflicts here.\n              assumedMasterState: undefined,\n              newDocumentState: newStorage.schema.title === META_INSTANCE_SCHEMA_TITLE ? Object.assign({}, row.newDocumentState, {\n                docData: migratedDocData\n              }) : migratedDocData\n            };\n            return newRow;\n          }));\n\n          // filter out the documents where the migration strategy returned null\n          rows = rows.filter(row => !!row.newDocumentState);\n          var result = await replicationHandlerBase.masterWrite(rows);\n          return result;\n        },\n        masterChangeStream$: new Subject().asObservable()\n      },\n      forkInstance: oldStorage,\n      metaInstance: replicationMetaStorageInstance,\n      pushBatchSize: batchSize,\n      pullBatchSize: 0,\n      conflictHandler: defaultConflictHandler,\n      hashFunction: this.database.hashFunction\n    });\n    var hasError = false;\n    replicationState.events.error.subscribe(err => hasError = err);\n\n    // update replication status on each change\n    replicationState.events.processed.up.subscribe(() => {\n      this.updateStatus(status => {\n        status.count.handled = status.count.handled + 1;\n        return status;\n      });\n    });\n    await awaitRxStorageReplicationFirstInSync(replicationState);\n    await awaitRxStorageReplicationInSync(replicationState);\n    await cancelRxStorageReplication(replicationState);\n    await this.updateStatusQueue;\n    if (hasError) {\n      await replicationMetaStorageInstance.close();\n      throw hasError;\n    }\n\n    // cleanup old storages\n    await Promise.all([oldStorage.remove(), replicationMetaStorageInstance.remove()]);\n  };\n  _proto.countAllDoucments = async function countAllDoucments(storageInstances) {\n    var ret = 0;\n    await Promise.all(storageInstances.map(async instance => {\n      var preparedQuery = prepareQuery(instance.schema, normalizeMangoQuery(instance.schema, {\n        selector: {}\n      }));\n      var countResult = await instance.count(preparedQuery);\n      ret += countResult.count;\n    }));\n    return ret;\n  };\n  _proto.getConnectedStorageInstances = async function getConnectedStorageInstances() {\n    var oldCollectionMeta = await this.oldCollectionMeta;\n    var ret = [];\n    await Promise.all(await Promise.all(oldCollectionMeta.data.connectedStorages.map(async connectedStorage => {\n      // atm we can only migrate replication states.\n      if (connectedStorage.schema.title !== META_INSTANCE_SCHEMA_TITLE) {\n        throw new Error('unknown migration handling for schema');\n      }\n      var newSchema = getRxReplicationMetaInstanceSchema(clone(this.collection.schema.jsonSchema), hasEncryption(connectedStorage.schema));\n      newSchema.version = this.collection.schema.version;\n      var [oldStorage, newStorage] = await Promise.all([this.database.storage.createStorageInstance({\n        databaseInstanceToken: this.database.token,\n        databaseName: this.database.name,\n        devMode: overwritable.isDevMode(),\n        multiInstance: this.database.multiInstance,\n        options: {},\n        schema: connectedStorage.schema,\n        password: this.database.password,\n        collectionName: connectedStorage.collectionName\n      }), this.database.storage.createStorageInstance({\n        databaseInstanceToken: this.database.token,\n        databaseName: this.database.name,\n        devMode: overwritable.isDevMode(),\n        multiInstance: this.database.multiInstance,\n        options: {},\n        schema: newSchema,\n        password: this.database.password,\n        collectionName: connectedStorage.collectionName\n      })]);\n      ret.push({\n        oldStorage,\n        newStorage\n      });\n    })));\n    return ret;\n  };\n  _proto.migratePromise = async function migratePromise(batchSize) {\n    this.startMigration(batchSize);\n    var must = await this.mustMigrate;\n    if (!must) {\n      return {\n        status: 'DONE',\n        collectionName: this.collection.name,\n        count: {\n          handled: 0,\n          percent: 0,\n          total: 0\n        }\n      };\n    }\n    var result = await Promise.race([firstValueFrom(this.$.pipe(filter(d => d.status === 'DONE'))), firstValueFrom(this.$.pipe(filter(d => d.status === 'ERROR')))]);\n    if (result.status === 'ERROR') {\n      throw newRxError('DM4', {\n        collection: this.collection.name,\n        error: result.error\n      });\n    } else {\n      return result;\n    }\n  };\n  return RxMigrationState;\n}();\n//# sourceMappingURL=rx-migration-state.js.map","import { createQueryBuilder, OTHER_MANGO_ATTRIBUTES, OTHER_MANGO_OPERATORS } from \"./mquery/nosql-query-builder.js\";\nimport { createRxQuery } from \"../../rx-query.js\";\nimport { clone } from \"../../plugins/utils/index.js\";\nimport { overwritable } from \"../../overwritable.js\";\nimport { newRxError } from \"../../rx-error.js\";\n\n// if the query-builder plugin is used, we have to save its last path\nvar RXQUERY_OTHER_FLAG = 'queryBuilderPath';\nexport function runBuildingStep(rxQuery, functionName, value) {\n  var queryBuilder = createQueryBuilder(clone(rxQuery.mangoQuery), rxQuery.other[RXQUERY_OTHER_FLAG]);\n  queryBuilder[functionName](value); // run\n\n  var queryBuilderJson = queryBuilder.toJSON();\n  return createRxQuery(rxQuery.op, queryBuilderJson.query, rxQuery.collection, {\n    ...rxQuery.other,\n    [RXQUERY_OTHER_FLAG]: queryBuilderJson.path\n  });\n}\nexport function applyBuildingStep(proto, functionName) {\n  proto[functionName] = function (value) {\n    if (overwritable.isDevMode() && this.op === 'findByIds') {\n      throw newRxError('QU17', {\n        collection: this.collection.name,\n        query: this.mangoQuery\n      });\n    }\n    return runBuildingStep(this, functionName, value);\n  };\n}\nexport * from \"./mquery/nosql-query-builder.js\";\nexport var RxDBQueryBuilderPlugin = {\n  name: 'query-builder',\n  rxdb: true,\n  prototypes: {\n    RxQuery(proto) {\n      ['where', 'equals', 'eq', 'or', 'nor', 'and', 'mod', 'exists', 'elemMatch', 'sort'].forEach(attribute => {\n        applyBuildingStep(proto, attribute);\n      });\n      OTHER_MANGO_ATTRIBUTES.forEach(attribute => {\n        applyBuildingStep(proto, attribute);\n      });\n      OTHER_MANGO_OPERATORS.forEach(operator => {\n        applyBuildingStep(proto, operator);\n      });\n    }\n  }\n};\n//# sourceMappingURL=index.js.map","/**\n * this is copied from\n * @link https://github.com/aheckmann/mquery/blob/master/lib/utils.js\n */\n\n/**\n * @link https://github.com/aheckmann/mquery/commit/792e69fd0a7281a0300be5cade5a6d7c1d468ad4\n */\nvar SPECIAL_PROPERTIES = ['__proto__', 'constructor', 'prototype'];\n\n/**\n * Merges 'from' into 'to' without overwriting existing properties.\n */\nexport function merge(to, from) {\n  Object.keys(from).forEach(key => {\n    if (SPECIAL_PROPERTIES.includes(key)) {\n      return;\n    }\n    if (typeof to[key] === 'undefined') {\n      to[key] = from[key];\n    } else {\n      if (isObject(from[key])) merge(to[key], from[key]);else to[key] = from[key];\n    }\n  });\n}\n\n/**\n * Determines if `arg` is an object.\n */\nexport function isObject(arg) {\n  return '[object Object]' === arg.toString();\n}\n//# sourceMappingURL=mquery-utils.js.map","import _readOnlyError from \"@babel/runtime/helpers/readOnlyError\";\n/**\n * this is based on\n * @link https://github.com/aheckmann/mquery/blob/master/lib/mquery.js\n */\nimport { isObject, merge as _merge } from \"./mquery-utils.js\";\nimport { newRxTypeError, newRxError } from \"../../../rx-error.js\";\nexport var NoSqlQueryBuilderClass = /*#__PURE__*/function () {\n  /**\n   * MQuery constructor used for building queries.\n   *\n   * ####Example:\n   *     var query = new MQuery({ name: 'mquery' });\n   *     query.where('age').gte(21).exec(callback);\n   *\n   */\n  function NoSqlQueryBuilderClass(mangoQuery, _path) {\n    this.options = {};\n    this._conditions = {};\n    this._fields = {};\n    this._path = _path;\n    if (mangoQuery) {\n      var queryBuilder = this;\n      if (mangoQuery.selector) {\n        queryBuilder.find(mangoQuery.selector);\n      }\n      if (mangoQuery.limit) {\n        queryBuilder.limit(mangoQuery.limit);\n      }\n      if (mangoQuery.skip) {\n        queryBuilder.skip(mangoQuery.skip);\n      }\n      if (mangoQuery.sort) {\n        mangoQuery.sort.forEach(s => queryBuilder.sort(s));\n      }\n    }\n  }\n\n  /**\n   * Specifies a `path` for use with chaining.\n   */\n  var _proto = NoSqlQueryBuilderClass.prototype;\n  _proto.where = function where(_path, _val) {\n    if (!arguments.length) return this;\n    var type = typeof arguments[0];\n    if ('string' === type) {\n      this._path = arguments[0];\n      if (2 === arguments.length) {\n        this._conditions[this._path] = arguments[1];\n      }\n      return this;\n    }\n    if ('object' === type && !Array.isArray(arguments[0])) {\n      return this.merge(arguments[0]);\n    }\n    throw newRxTypeError('MQ1', {\n      path: arguments[0]\n    });\n  }\n\n  /**\n   * Specifies the complementary comparison value for paths specified with `where()`\n   * ####Example\n   *     User.where('age').equals(49);\n   */;\n  _proto.equals = function equals(val) {\n    this._ensurePath('equals');\n    var path = this._path;\n    this._conditions[path] = val;\n    return this;\n  }\n\n  /**\n   * Specifies the complementary comparison value for paths specified with `where()`\n   * This is alias of `equals`\n   */;\n  _proto.eq = function eq(val) {\n    this._ensurePath('eq');\n    var path = this._path;\n    this._conditions[path] = val;\n    return this;\n  }\n\n  /**\n   * Specifies arguments for an `$or` condition.\n   * ####Example\n   *     query.or([{ color: 'red' }, { status: 'emergency' }])\n   */;\n  _proto.or = function or(array) {\n    var or = this._conditions.$or || (this._conditions.$or = []);\n    if (!Array.isArray(array)) array = [array];\n    or.push.apply(or, array);\n    return this;\n  }\n\n  /**\n   * Specifies arguments for a `$nor` condition.\n   * ####Example\n   *     query.nor([{ color: 'green' }, { status: 'ok' }])\n   */;\n  _proto.nor = function nor(array) {\n    var nor = this._conditions.$nor || (this._conditions.$nor = []);\n    if (!Array.isArray(array)) array = [array];\n    nor.push.apply(nor, array);\n    return this;\n  }\n\n  /**\n   * Specifies arguments for a `$and` condition.\n   * ####Example\n   *     query.and([{ color: 'green' }, { status: 'ok' }])\n   * @see $and http://docs.mongodb.org/manual/reference/operator/and/\n   */;\n  _proto.and = function and(array) {\n    var and = this._conditions.$and || (this._conditions.$and = []);\n    if (!Array.isArray(array)) array = [array];\n    and.push.apply(and, array);\n    return this;\n  }\n\n  /**\n   * Specifies a `$mod` condition\n   */;\n  _proto.mod = function mod(_path, _val) {\n    var val;\n    var path;\n    if (1 === arguments.length) {\n      this._ensurePath('mod');\n      val = arguments[0];\n      path = this._path;\n    } else if (2 === arguments.length && !Array.isArray(arguments[1])) {\n      this._ensurePath('mod');\n      val = arguments.slice();\n      path = this._path;\n    } else if (3 === arguments.length) {\n      val = arguments.slice(1);\n      path = arguments[0];\n    } else {\n      val = arguments[1];\n      path = arguments[0];\n    }\n    var conds = this._conditions[path] || (this._conditions[path] = {});\n    conds.$mod = val;\n    return this;\n  }\n\n  /**\n   * Specifies an `$exists` condition\n   * ####Example\n   *     // { name: { $exists: true }}\n   *     Thing.where('name').exists()\n   *     Thing.where('name').exists(true)\n   *     Thing.find().exists('name')\n   */;\n  _proto.exists = function exists(_path, _val) {\n    var path;\n    var val;\n    if (0 === arguments.length) {\n      this._ensurePath('exists');\n      path = this._path;\n      val = true;\n    } else if (1 === arguments.length) {\n      if ('boolean' === typeof arguments[0]) {\n        this._ensurePath('exists');\n        path = this._path;\n        val = arguments[0];\n      } else {\n        path = arguments[0];\n        val = true;\n      }\n    } else if (2 === arguments.length) {\n      path = arguments[0];\n      val = arguments[1];\n    }\n    var conds = this._conditions[path] || (this._conditions[path] = {});\n    conds.$exists = val;\n    return this;\n  }\n\n  /**\n   * Specifies an `$elemMatch` condition\n   * ####Example\n   *     query.elemMatch('comment', { author: 'autobot', votes: {$gte: 5}})\n   *     query.where('comment').elemMatch({ author: 'autobot', votes: {$gte: 5}})\n   *     query.elemMatch('comment', function (elem) {\n   *       elem.where('author').equals('autobot');\n   *       elem.where('votes').gte(5);\n   *     })\n   *     query.where('comment').elemMatch(function (elem) {\n   *       elem.where({ author: 'autobot' });\n   *       elem.where('votes').gte(5);\n   *     })\n   */;\n  _proto.elemMatch = function elemMatch(_path, _criteria) {\n    if (null === arguments[0]) throw newRxTypeError('MQ2');\n    var fn;\n    var path;\n    var criteria;\n    if ('function' === typeof arguments[0]) {\n      this._ensurePath('elemMatch');\n      path = this._path;\n      fn = arguments[0];\n    } else if (isObject(arguments[0])) {\n      this._ensurePath('elemMatch');\n      path = this._path;\n      criteria = arguments[0];\n    } else if ('function' === typeof arguments[1]) {\n      path = arguments[0];\n      fn = arguments[1];\n    } else if (arguments[1] && isObject(arguments[1])) {\n      path = arguments[0];\n      criteria = arguments[1];\n    } else throw newRxTypeError('MQ2');\n    if (fn) {\n      criteria = new NoSqlQueryBuilderClass();\n      fn(criteria);\n      criteria = criteria._conditions;\n    }\n    var conds = this._conditions[path] || (this._conditions[path] = {});\n    conds.$elemMatch = criteria;\n    return this;\n  }\n\n  /**\n   * Sets the sort order\n   * If an object is passed, values allowed are 'asc', 'desc', 'ascending', 'descending', 1, and -1.\n   * If a string is passed, it must be a space delimited list of path names.\n   * The sort order of each path is ascending unless the path name is prefixed with `-` which will be treated as descending.\n   * ####Example\n   *     query.sort({ field: 'asc', test: -1 });\n   *     query.sort('field -test');\n   *     query.sort([['field', 1], ['test', -1]]);\n   */;\n  _proto.sort = function sort(arg) {\n    if (!arg) return this;\n    var len;\n    var type = typeof arg;\n    // .sort([['field', 1], ['test', -1]])\n    if (Array.isArray(arg)) {\n      len = arg.length;\n      for (var i = 0; i < arg.length; ++i) {\n        _pushArr(this.options, arg[i][0], arg[i][1]);\n      }\n      return this;\n    }\n\n    // .sort('field -test')\n    if (1 === arguments.length && 'string' === type) {\n      arg = arg.split(/\\s+/);\n      len = arg.length;\n      for (var _i = 0; _i < len; ++_i) {\n        var field = arg[_i];\n        if (!field) continue;\n        var ascend = '-' === field[0] ? -1 : 1;\n        if (ascend === -1) field = field.substring(1);\n        push(this.options, field, ascend);\n      }\n      return this;\n    }\n\n    // .sort({ field: 1, test: -1 })\n    if (isObject(arg)) {\n      var keys = Object.keys(arg);\n      keys.forEach(field => push(this.options, field, arg[field]));\n      return this;\n    }\n    throw newRxTypeError('MQ3', {\n      args: arguments\n    });\n  }\n\n  /**\n   * Merges another MQuery or conditions object into this one.\n   *\n   * When a MQuery is passed, conditions, field selection and options are merged.\n   *\n   */;\n  _proto.merge = function merge(source) {\n    if (!source) {\n      return this;\n    }\n    if (!canMerge(source)) {\n      throw newRxTypeError('MQ4', {\n        source\n      });\n    }\n    if (source instanceof NoSqlQueryBuilderClass) {\n      // if source has a feature, apply it to ourselves\n\n      if (source._conditions) _merge(this._conditions, source._conditions);\n      if (source._fields) {\n        if (!this._fields) this._fields = {};\n        _merge(this._fields, source._fields);\n      }\n      if (source.options) {\n        if (!this.options) this.options = {};\n        _merge(this.options, source.options);\n      }\n      if (source._distinct) this._distinct = source._distinct;\n      return this;\n    }\n\n    // plain object\n    _merge(this._conditions, source);\n    return this;\n  }\n\n  /**\n   * Finds documents.\n   * ####Example\n   *     query.find()\n   *     query.find({ name: 'Burning Lights' })\n   */;\n  _proto.find = function find(criteria) {\n    if (canMerge(criteria)) {\n      this.merge(criteria);\n    }\n    return this;\n  }\n\n  /**\n   * Make sure _path is set.\n   *\n   * @param {String} method\n   */;\n  _proto._ensurePath = function _ensurePath(method) {\n    if (!this._path) {\n      throw newRxError('MQ5', {\n        method\n      });\n    }\n  };\n  _proto.toJSON = function toJSON() {\n    var query = {\n      selector: this._conditions\n    };\n    if (this.options.skip) {\n      query.skip = this.options.skip;\n    }\n    if (this.options.limit) {\n      query.limit = this.options.limit;\n    }\n    if (this.options.sort) {\n      query.sort = mQuerySortToRxDBSort(this.options.sort);\n    }\n    return {\n      query,\n      path: this._path\n    };\n  };\n  return NoSqlQueryBuilderClass;\n}();\nexport function mQuerySortToRxDBSort(sort) {\n  return Object.entries(sort).map(([k, v]) => {\n    var direction = v === 1 ? 'asc' : 'desc';\n    var part = {\n      [k]: direction\n    };\n    return part;\n  });\n}\n\n/**\n * Because some prototype-methods are generated,\n * we have to define the type of NoSqlQueryBuilder here\n */\n\n/**\n * limit, skip, maxScan, batchSize, comment\n *\n * Sets these associated options.\n *\n *     query.comment('feed query');\n */\nexport var OTHER_MANGO_ATTRIBUTES = ['limit', 'skip', 'maxScan', 'batchSize', 'comment'];\nOTHER_MANGO_ATTRIBUTES.forEach(function (method) {\n  NoSqlQueryBuilderClass.prototype[method] = function (v) {\n    this.options[method] = v;\n    return this;\n  };\n});\n\n/**\n * gt, gte, lt, lte, ne, in, nin, all, regex, size, maxDistance\n *\n *     Thing.where('type').nin(array)\n */\nexport var OTHER_MANGO_OPERATORS = ['gt', 'gte', 'lt', 'lte', 'ne', 'in', 'nin', 'all', 'regex', 'size'];\nOTHER_MANGO_OPERATORS.forEach(function ($conditional) {\n  NoSqlQueryBuilderClass.prototype[$conditional] = function () {\n    var path;\n    var val;\n    if (1 === arguments.length) {\n      this._ensurePath($conditional);\n      val = arguments[0];\n      path = this._path;\n    } else {\n      val = arguments[1];\n      path = arguments[0];\n    }\n    var conds = this._conditions[path] === null || typeof this._conditions[path] === 'object' ? this._conditions[path] : this._conditions[path] = {};\n    if ($conditional === 'regex') {\n      if (val instanceof RegExp) {\n        throw newRxError('QU16', {\n          field: path,\n          query: this._conditions\n        });\n      }\n      if (typeof val === 'string') {\n        conds['$' + $conditional] = val;\n      } else {\n        conds['$' + $conditional] = val.$regex;\n        if (val.$options) {\n          conds.$options = val.$options;\n        }\n      }\n    } else {\n      conds['$' + $conditional] = val;\n    }\n    return this;\n  };\n});\nfunction push(opts, field, value) {\n  if (Array.isArray(opts.sort)) {\n    throw newRxTypeError('MQ6', {\n      opts,\n      field,\n      value\n    });\n  }\n  if (value && value.$meta) {\n    var sort = opts.sort || (opts.sort = {});\n    sort[field] = {\n      $meta: value.$meta\n    };\n    return;\n  }\n  var val = String(value || 1).toLowerCase();\n  if (!/^(?:ascending|asc|descending|desc|1|-1)$/.test(val)) {\n    if (Array.isArray(value)) value = '[' + value + ']';\n    throw newRxTypeError('MQ7', {\n      field,\n      value\n    });\n  }\n  // store `sort` in a sane format\n  var s = opts.sort || (opts.sort = {});\n  var valueStr = value.toString().replace('asc', '1').replace('ascending', '1').replace('desc', '-1').replace('descending', '-1');\n  s[field] = parseInt(valueStr, 10);\n}\nfunction _pushArr(opts, field, value) {\n  opts.sort = opts.sort || [];\n  if (!Array.isArray(opts.sort)) {\n    throw newRxTypeError('MQ8', {\n      opts,\n      field,\n      value\n    });\n  }\n\n  /*    const valueStr = value.toString()\n          .replace('asc', '1')\n          .replace('ascending', '1')\n          .replace('desc', '-1')\n          .replace('descending', '-1');*/\n  opts.sort.push([field, value]);\n}\n\n/**\n * Determines if `conds` can be merged using `mquery().merge()`\n */\nexport function canMerge(conds) {\n  return conds instanceof NoSqlQueryBuilderClass || isObject(conds);\n}\nexport function createQueryBuilder(query, path) {\n  return new NoSqlQueryBuilderClass(query, path);\n}\n//# sourceMappingURL=nosql-query-builder.js.map","import { Dexie } from 'dexie';\nimport { flatClone, getFromMapOrCreate, getProperty, setProperty, toArray, uniqueArray } from \"../utils/index.js\";\nimport { getPrimaryFieldOfPrimaryKey, getSchemaByObjectPath } from \"../../rx-schema-helper.js\";\nexport var DEXIE_DOCS_TABLE_NAME = 'docs';\nexport var DEXIE_CHANGES_TABLE_NAME = 'changes';\nexport var DEXIE_ATTACHMENTS_TABLE_NAME = 'attachments';\nexport var RX_STORAGE_NAME_DEXIE = 'dexie';\nvar DEXIE_STATE_DB_BY_NAME = new Map();\nvar REF_COUNT_PER_DEXIE_DB = new Map();\nexport function getDexieDbWithTables(databaseName, collectionName, settings, schema) {\n  var dexieDbName = 'rxdb-dexie-' + databaseName + '--' + schema.version + '--' + collectionName;\n  var state = getFromMapOrCreate(DEXIE_STATE_DB_BY_NAME, dexieDbName, () => {\n    var value = (async () => {\n      /**\n       * IndexedDB was not designed for dynamically adding tables on the fly,\n       * so we create one dexie database per RxDB storage instance.\n       * @link https://github.com/dexie/Dexie.js/issues/684#issuecomment-373224696\n       */\n      var useSettings = flatClone(settings);\n      useSettings.autoOpen = false;\n      var dexieDb = new Dexie(dexieDbName, useSettings);\n      if (settings.onCreate) {\n        await settings.onCreate(dexieDb, dexieDbName);\n      }\n      var dexieStoresSettings = {\n        [DEXIE_DOCS_TABLE_NAME]: getDexieStoreSchema(schema),\n        [DEXIE_CHANGES_TABLE_NAME]: '++sequence, id',\n        [DEXIE_ATTACHMENTS_TABLE_NAME]: 'id'\n      };\n      dexieDb.version(1).stores(dexieStoresSettings);\n      await dexieDb.open();\n      return {\n        dexieDb,\n        dexieTable: dexieDb[DEXIE_DOCS_TABLE_NAME],\n        dexieAttachmentsTable: dexieDb[DEXIE_ATTACHMENTS_TABLE_NAME],\n        booleanIndexes: getBooleanIndexes(schema)\n      };\n    })();\n    DEXIE_STATE_DB_BY_NAME.set(dexieDbName, state);\n    REF_COUNT_PER_DEXIE_DB.set(state, 0);\n    return value;\n  });\n  return state;\n}\nexport async function closeDexieDb(statePromise) {\n  var state = await statePromise;\n  var prevCount = REF_COUNT_PER_DEXIE_DB.get(statePromise);\n  var newCount = prevCount - 1;\n  if (newCount === 0) {\n    state.dexieDb.close();\n    REF_COUNT_PER_DEXIE_DB.delete(statePromise);\n  } else {\n    REF_COUNT_PER_DEXIE_DB.set(statePromise, newCount);\n  }\n}\n\n/**\n * It is not possible to set non-javascript-variable-syntax\n * keys as IndexedDB indexes. So we have to substitute the pipe-char\n * which comes from the key-compression plugin.\n */\nexport var DEXIE_PIPE_SUBSTITUTE = '__';\nexport function dexieReplaceIfStartsWithPipe(str) {\n  var split = str.split('.');\n  if (split.length > 1) {\n    return split.map(part => dexieReplaceIfStartsWithPipe(part)).join('.');\n  }\n  if (str.startsWith('|')) {\n    var withoutFirst = str.substring(1);\n    return DEXIE_PIPE_SUBSTITUTE + withoutFirst;\n  } else {\n    return str;\n  }\n}\nexport function dexieReplaceIfStartsWithPipeRevert(str) {\n  var split = str.split('.');\n  if (split.length > 1) {\n    return split.map(part => dexieReplaceIfStartsWithPipeRevert(part)).join('.');\n  }\n  if (str.startsWith(DEXIE_PIPE_SUBSTITUTE)) {\n    var withoutFirst = str.substring(DEXIE_PIPE_SUBSTITUTE.length);\n    return '|' + withoutFirst;\n  } else {\n    return str;\n  }\n}\n\n/**\n * IndexedDB does not support boolean indexing.\n * So we have to replace true/false with '1'/'0'\n * @param d \n */\nexport function fromStorageToDexie(booleanIndexes, inputDoc) {\n  if (!inputDoc) {\n    return inputDoc;\n  }\n  var d = flatClone(inputDoc);\n  d = fromStorageToDexieField(d);\n  booleanIndexes.forEach(idx => {\n    var val = getProperty(inputDoc, idx);\n    var newVal = val ? '1' : '0';\n    var useIndex = dexieReplaceIfStartsWithPipe(idx);\n    setProperty(d, useIndex, newVal);\n  });\n  return d;\n}\nexport function fromDexieToStorage(booleanIndexes, d) {\n  if (!d) {\n    return d;\n  }\n  d = flatClone(d);\n  d = fromDexieToStorageField(d);\n  booleanIndexes.forEach(idx => {\n    var val = getProperty(d, idx);\n    var newVal = val === '1' ? true : false;\n    setProperty(d, idx, newVal);\n  });\n  return d;\n}\n\n/**\n * @recursive\n */\nexport function fromStorageToDexieField(documentData) {\n  if (!documentData || typeof documentData === 'string' || typeof documentData === 'number' || typeof documentData === 'boolean') {\n    return documentData;\n  } else if (Array.isArray(documentData)) {\n    return documentData.map(row => fromStorageToDexieField(row));\n  } else if (typeof documentData === 'object') {\n    var ret = {};\n    Object.entries(documentData).forEach(([key, value]) => {\n      if (typeof value === 'object') {\n        value = fromStorageToDexieField(value);\n      }\n      ret[dexieReplaceIfStartsWithPipe(key)] = value;\n    });\n    return ret;\n  }\n}\nexport function fromDexieToStorageField(documentData) {\n  if (!documentData || typeof documentData === 'string' || typeof documentData === 'number' || typeof documentData === 'boolean') {\n    return documentData;\n  } else if (Array.isArray(documentData)) {\n    return documentData.map(row => fromDexieToStorageField(row));\n  } else if (typeof documentData === 'object') {\n    var ret = {};\n    Object.entries(documentData).forEach(([key, value]) => {\n      if (typeof value === 'object' || Array.isArray(documentData)) {\n        value = fromDexieToStorageField(value);\n      }\n      ret[dexieReplaceIfStartsWithPipeRevert(key)] = value;\n    });\n    return ret;\n  }\n}\n\n/**\n * Creates a string that can be used to create the dexie store.\n * @link https://dexie.org/docs/API-Reference#quick-reference\n */\nexport function getDexieStoreSchema(rxJsonSchema) {\n  var parts = [];\n\n  /**\n   * First part must be the primary key\n   * @link https://github.com/dexie/Dexie.js/issues/1307#issuecomment-846590912\n   */\n  var primaryKey = getPrimaryFieldOfPrimaryKey(rxJsonSchema.primaryKey);\n  parts.push([primaryKey]);\n  parts.push(['_deleted', primaryKey]);\n\n  // add other indexes\n  if (rxJsonSchema.indexes) {\n    rxJsonSchema.indexes.forEach(index => {\n      var arIndex = toArray(index);\n      parts.push(arIndex);\n    });\n  }\n\n  // we also need the _meta.lwt+primaryKey index for the getChangedDocumentsSince() method.\n  parts.push(['_meta.lwt', primaryKey]);\n\n  // and this one for the cleanup()\n  parts.push(['_meta.lwt']);\n\n  /**\n   * It is not possible to set non-javascript-variable-syntax\n   * keys as IndexedDB indexes. So we have to substitute the pipe-char\n   * which comes from the key-compression plugin.\n   */\n  parts = parts.map(part => {\n    return part.map(str => dexieReplaceIfStartsWithPipe(str));\n  });\n  var dexieSchemaRows = parts.map(part => {\n    if (part.length === 1) {\n      return part[0];\n    } else {\n      return '[' + part.join('+') + ']';\n    }\n  });\n  dexieSchemaRows = dexieSchemaRows.filter((elem, pos, arr) => arr.indexOf(elem) === pos); // unique;\n\n  var dexieSchema = dexieSchemaRows.join(', ');\n  return dexieSchema;\n}\n\n/**\n * Returns all documents in the database.\n * Non-deleted plus deleted ones.\n */\nexport async function getDocsInDb(internals, docIds) {\n  var state = await internals;\n  var docsInDb = await state.dexieTable.bulkGet(docIds);\n  return docsInDb.map(d => fromDexieToStorage(state.booleanIndexes, d));\n}\nexport function attachmentObjectId(documentId, attachmentId) {\n  return documentId + '||' + attachmentId;\n}\nexport function getBooleanIndexes(schema) {\n  var checkedFields = new Set();\n  var ret = [];\n  if (!schema.indexes) {\n    return ret;\n  }\n  schema.indexes.forEach(index => {\n    var fields = toArray(index);\n    fields.forEach(field => {\n      if (checkedFields.has(field)) {\n        return;\n      }\n      checkedFields.add(field);\n      var schemaObj = getSchemaByObjectPath(schema, field);\n      if (schemaObj.type === 'boolean') {\n        ret.push(field);\n      }\n    });\n  });\n  ret.push('_deleted');\n  return uniqueArray(ret);\n}\n//# sourceMappingURL=dexie-helper.js.map","import { INDEX_MAX, INDEX_MIN } from \"../../query-planner.js\";\nimport { getQueryMatcher, getSortComparator } from \"../../rx-query-helper.js\";\nimport { dexieReplaceIfStartsWithPipe, DEXIE_DOCS_TABLE_NAME, fromDexieToStorage } from \"./dexie-helper.js\";\nexport function mapKeyForKeyRange(k) {\n  if (k === INDEX_MIN) {\n    return -Infinity;\n  } else {\n    return k;\n  }\n}\nfunction rangeFieldToBooleanSubstitute(booleanIndexes, fieldName, value) {\n  if (booleanIndexes.includes(fieldName)) {\n    var newValue = value === INDEX_MAX || value === true ? '1' : '0';\n    return newValue;\n  } else {\n    return value;\n  }\n}\nexport function getKeyRangeByQueryPlan(booleanIndexes, queryPlan, IDBKeyRange) {\n  if (!IDBKeyRange) {\n    if (typeof window === 'undefined') {\n      throw new Error('IDBKeyRange missing');\n    } else {\n      IDBKeyRange = window.IDBKeyRange;\n    }\n  }\n  var startKeys = queryPlan.startKeys.map((v, i) => {\n    var fieldName = queryPlan.index[i];\n    return rangeFieldToBooleanSubstitute(booleanIndexes, fieldName, v);\n  }).map(mapKeyForKeyRange);\n  var endKeys = queryPlan.endKeys.map((v, i) => {\n    var fieldName = queryPlan.index[i];\n    return rangeFieldToBooleanSubstitute(booleanIndexes, fieldName, v);\n  }).map(mapKeyForKeyRange);\n  var keyRange = IDBKeyRange.bound(startKeys, endKeys, !queryPlan.inclusiveStart, !queryPlan.inclusiveEnd);\n  return keyRange;\n}\n\n/**\n * Runs mango queries over the Dexie.js database.\n */\nexport async function dexieQuery(instance, preparedQuery) {\n  var state = await instance.internals;\n  var query = preparedQuery.query;\n  var skip = query.skip ? query.skip : 0;\n  var limit = query.limit ? query.limit : Infinity;\n  var skipPlusLimit = skip + limit;\n  var queryPlan = preparedQuery.queryPlan;\n  var queryMatcher = false;\n  if (!queryPlan.selectorSatisfiedByIndex) {\n    queryMatcher = getQueryMatcher(instance.schema, preparedQuery.query);\n  }\n  var keyRange = getKeyRangeByQueryPlan(state.booleanIndexes, queryPlan, state.dexieDb._options.IDBKeyRange);\n  var queryPlanFields = queryPlan.index;\n  var rows = [];\n  await state.dexieDb.transaction('r', state.dexieTable, async dexieTx => {\n    /**\n     * Here we use the native IndexedDB transaction\n     * to get the cursor.\n     * Maybe we should not leave Dexie.js API and find\n     * a way to create the cursor with Dexie.js.\n     */\n    var tx = dexieTx.idbtrans;\n\n    // const nativeIndexedDB = state.dexieDb.backendDB();\n    // const trans = nativeIndexedDB.transaction([DEXIE_DOCS_TABLE_NAME], 'readonly');\n\n    var store = tx.objectStore(DEXIE_DOCS_TABLE_NAME);\n    var index;\n    var indexName;\n    indexName = '[' + queryPlanFields.map(field => dexieReplaceIfStartsWithPipe(field)).join('+') + ']';\n    index = store.index(indexName);\n    var cursorReq = index.openCursor(keyRange);\n    await new Promise(res => {\n      cursorReq.onsuccess = function (e) {\n        var cursor = e.target.result;\n        if (cursor) {\n          // We have a record in cursor.value\n          var docData = fromDexieToStorage(state.booleanIndexes, cursor.value);\n          if (!queryMatcher || queryMatcher(docData)) {\n            rows.push(docData);\n          }\n\n          /**\n           * If we do not have to manually sort\n           * and have enough documents,\n           * we can abort iterating over the cursor\n           * because we already have every relevant document.\n           */\n          if (queryPlan.sortSatisfiedByIndex && rows.length === skipPlusLimit) {\n            res();\n          } else {\n            cursor.continue();\n          }\n        } else {\n          // Iteration complete\n          res();\n        }\n      };\n    });\n  });\n  if (!queryPlan.sortSatisfiedByIndex) {\n    var sortComparator = getSortComparator(instance.schema, preparedQuery.query);\n    rows = rows.sort(sortComparator);\n  }\n\n  // apply skip and limit boundaries.\n  rows = rows.slice(skip, skipPlusLimit);\n\n  /**\n   * Comment this in for debugging to check all fields in the database.\n   */\n  // const docsInDb = await state.dexieTable.filter(queryMatcher).toArray();\n  // let documents = docsInDb\n  //     .map(docData => stripDexieKey(docData))\n  //     .sort(sortComparator);\n  // if (preparedQuery.skip) {\n  //     documents = documents.slice(preparedQuery.skip);\n  // }\n  // if (preparedQuery.limit && documents.length > preparedQuery.limit) {\n  //     documents = documents.slice(0, preparedQuery.limit);\n  // }\n\n  return {\n    documents: rows\n  };\n}\nexport async function dexieCount(instance, preparedQuery) {\n  var state = await instance.internals;\n  var queryPlan = preparedQuery.queryPlan;\n  var queryPlanFields = queryPlan.index;\n  var keyRange = getKeyRangeByQueryPlan(state.booleanIndexes, queryPlan, state.dexieDb._options.IDBKeyRange);\n  var count = -1;\n  await state.dexieDb.transaction('r', state.dexieTable, async dexieTx => {\n    var tx = dexieTx.idbtrans;\n    var store = tx.objectStore(DEXIE_DOCS_TABLE_NAME);\n    var index;\n    var indexName;\n    indexName = '[' + queryPlanFields.map(field => dexieReplaceIfStartsWithPipe(field)).join('+') + ']';\n    index = store.index(indexName);\n    var request = index.count(keyRange);\n    count = await new Promise((res, rej) => {\n      request.onsuccess = function () {\n        res(request.result);\n      };\n      request.onerror = err => rej(err);\n    });\n  });\n  return count;\n}\n//# sourceMappingURL=dexie-query.js.map","import { RX_STORAGE_NAME_DEXIE } from \"./dexie-helper.js\";\nimport { createDexieStorageInstance } from \"./rx-storage-instance-dexie.js\";\nimport { ensureRxStorageInstanceParamsAreCorrect } from \"../../rx-storage-helper.js\";\nimport { RXDB_VERSION } from \"../utils/utils-rxdb-version.js\";\nimport { newRxError } from \"../../rx-error.js\";\nexport var RxStorageDexie = /*#__PURE__*/function () {\n  function RxStorageDexie(settings) {\n    this.name = RX_STORAGE_NAME_DEXIE;\n    this.rxdbVersion = RXDB_VERSION;\n    this.settings = settings;\n  }\n  var _proto = RxStorageDexie.prototype;\n  _proto.createStorageInstance = function createStorageInstance(params) {\n    ensureRxStorageInstanceParamsAreCorrect(params);\n\n    /**\n     * Dexie does not support non-required indexes and must throw if that is used.\n     * @link https://github.com/pubkey/rxdb/pull/6643#issuecomment-2505310082\n     */\n    if (params.schema.indexes) {\n      var indexFields = params.schema.indexes.flat();\n      indexFields.filter(indexField => !indexField.includes('.')).forEach(indexField => {\n        if (!params.schema.required || !params.schema.required.includes(indexField)) {\n          throw newRxError('DXE1', {\n            field: indexField,\n            schema: params.schema\n          });\n        }\n      });\n    }\n    return createDexieStorageInstance(this, params, this.settings);\n  };\n  return RxStorageDexie;\n}();\nexport function getRxStorageDexie(settings = {}) {\n  var storage = new RxStorageDexie(settings);\n  return storage;\n}\n//# sourceMappingURL=rx-storage-dexie.js.map","import { Subject } from 'rxjs';\nimport { now, ensureNotFalsy, hasPremiumFlag } from \"../utils/index.js\";\nimport { attachmentObjectId, closeDexieDb, fromStorageToDexie, getDexieDbWithTables, getDocsInDb, RX_STORAGE_NAME_DEXIE } from \"./dexie-helper.js\";\nimport { dexieCount, dexieQuery } from \"./dexie-query.js\";\nimport { getPrimaryFieldOfPrimaryKey } from \"../../rx-schema-helper.js\";\nimport { categorizeBulkWriteRows, flatCloneDocWithMeta } from \"../../rx-storage-helper.js\";\nimport { addRxStorageMultiInstanceSupport } from \"../../rx-storage-multiinstance.js\";\nimport { newRxError } from \"../../rx-error.js\";\nvar instanceId = now();\nvar shownNonPremiumLog = false;\nexport var RxStorageInstanceDexie = /*#__PURE__*/function () {\n  function RxStorageInstanceDexie(storage, databaseName, collectionName, schema, internals, options, settings, devMode) {\n    this.changes$ = new Subject();\n    this.instanceId = instanceId++;\n    this.storage = storage;\n    this.databaseName = databaseName;\n    this.collectionName = collectionName;\n    this.schema = schema;\n    this.internals = internals;\n    this.options = options;\n    this.settings = settings;\n    this.devMode = devMode;\n    this.primaryPath = getPrimaryFieldOfPrimaryKey(this.schema.primaryKey);\n  }\n  var _proto = RxStorageInstanceDexie.prototype;\n  _proto.bulkWrite = async function bulkWrite(documentWrites, context) {\n    ensureNotClosed(this);\n    if (!shownNonPremiumLog && !(await hasPremiumFlag())) {\n      console.warn(['-------------- RxDB Open Core RxStorage -------------------------------', 'You are using the free Dexie.js based RxStorage implementation from RxDB https://rxdb.info/rx-storage-dexie.html?console=dexie ', 'While this is a great option, we want to let you know that there are faster storage solutions available in our premium plugins.', 'For professional users and production environments, we highly recommend considering these premium options to enhance performance and reliability.', ' https://rxdb.info/premium/?console=dexie ', 'If you already purchased premium access you can disable this log by calling the setPremiumFlag() function from rxdb-premium/plugins/shared.', '---------------------------------------------------------------------'].join('\\n'));\n      shownNonPremiumLog = true;\n    } else {\n      shownNonPremiumLog = true;\n    }\n\n    /**\n     * Check some assumptions to ensure RxDB\n     * does not call the storage with an invalid write.\n     */\n    documentWrites.forEach(row => {\n      // ensure revision is set\n      if (!row.document._rev || row.previous && !row.previous._rev) {\n        throw newRxError('SNH', {\n          args: {\n            row\n          }\n        });\n      }\n    });\n    var state = await this.internals;\n    var ret = {\n      error: []\n    };\n\n    /**\n     * Some storages might add any _meta fields\n     * internally. To ensure RxDB can work with that in the\n     * test suite, we add a random field here.\n     * To ensure \n     */\n    if (this.devMode) {\n      documentWrites = documentWrites.map(row => {\n        var doc = flatCloneDocWithMeta(row.document);\n        return {\n          previous: row.previous,\n          document: doc\n        };\n      });\n    }\n    var documentKeys = documentWrites.map(writeRow => writeRow.document[this.primaryPath]);\n    var categorized;\n    await state.dexieDb.transaction('rw', state.dexieTable, state.dexieAttachmentsTable, async () => {\n      var docsInDbMap = new Map();\n      var docsInDbWithInternals = await getDocsInDb(this.internals, documentKeys);\n      docsInDbWithInternals.forEach(docWithDexieInternals => {\n        var doc = docWithDexieInternals;\n        if (doc) {\n          docsInDbMap.set(doc[this.primaryPath], doc);\n        }\n        return doc;\n      });\n      categorized = categorizeBulkWriteRows(this, this.primaryPath, docsInDbMap, documentWrites, context);\n      ret.error = categorized.errors;\n\n      /**\n       * Batch up the database operations\n       * so we can later run them in bulk.\n       */\n      var bulkPutDocs = [];\n      categorized.bulkInsertDocs.forEach(row => {\n        bulkPutDocs.push(row.document);\n      });\n      categorized.bulkUpdateDocs.forEach(row => {\n        bulkPutDocs.push(row.document);\n      });\n      bulkPutDocs = bulkPutDocs.map(d => fromStorageToDexie(state.booleanIndexes, d));\n      if (bulkPutDocs.length > 0) {\n        await state.dexieTable.bulkPut(bulkPutDocs);\n      }\n\n      // handle attachments\n      var putAttachments = [];\n      categorized.attachmentsAdd.forEach(attachment => {\n        putAttachments.push({\n          id: attachmentObjectId(attachment.documentId, attachment.attachmentId),\n          data: attachment.attachmentData.data\n        });\n      });\n      categorized.attachmentsUpdate.forEach(attachment => {\n        putAttachments.push({\n          id: attachmentObjectId(attachment.documentId, attachment.attachmentId),\n          data: attachment.attachmentData.data\n        });\n      });\n      await state.dexieAttachmentsTable.bulkPut(putAttachments);\n      await state.dexieAttachmentsTable.bulkDelete(categorized.attachmentsRemove.map(attachment => attachmentObjectId(attachment.documentId, attachment.attachmentId)));\n    });\n    categorized = ensureNotFalsy(categorized);\n    if (categorized.eventBulk.events.length > 0) {\n      var lastState = ensureNotFalsy(categorized.newestRow).document;\n      categorized.eventBulk.checkpoint = {\n        id: lastState[this.primaryPath],\n        lwt: lastState._meta.lwt\n      };\n      this.changes$.next(categorized.eventBulk);\n    }\n    return ret;\n  };\n  _proto.findDocumentsById = async function findDocumentsById(ids, deleted) {\n    ensureNotClosed(this);\n    var state = await this.internals;\n    var ret = [];\n    await state.dexieDb.transaction('r', state.dexieTable, async () => {\n      var docsInDb = await getDocsInDb(this.internals, ids);\n      docsInDb.forEach(documentInDb => {\n        if (documentInDb && (!documentInDb._deleted || deleted)) {\n          ret.push(documentInDb);\n        }\n      });\n    });\n    return ret;\n  };\n  _proto.query = function query(preparedQuery) {\n    ensureNotClosed(this);\n    return dexieQuery(this, preparedQuery);\n  };\n  _proto.count = async function count(preparedQuery) {\n    if (preparedQuery.queryPlan.selectorSatisfiedByIndex) {\n      var result = await dexieCount(this, preparedQuery);\n      return {\n        count: result,\n        mode: 'fast'\n      };\n    } else {\n      var _result = await dexieQuery(this, preparedQuery);\n      return {\n        count: _result.documents.length,\n        mode: 'slow'\n      };\n    }\n  };\n  _proto.changeStream = function changeStream() {\n    ensureNotClosed(this);\n    return this.changes$.asObservable();\n  };\n  _proto.cleanup = async function cleanup(minimumDeletedTime) {\n    ensureNotClosed(this);\n    var state = await this.internals;\n    await state.dexieDb.transaction('rw', state.dexieTable, async () => {\n      var maxDeletionTime = now() - minimumDeletedTime;\n      var toRemove = await state.dexieTable.where('_meta.lwt').below(maxDeletionTime).toArray();\n      var removeIds = [];\n      toRemove.forEach(doc => {\n        if (doc._deleted === '1') {\n          removeIds.push(doc[this.primaryPath]);\n        }\n      });\n      await state.dexieTable.bulkDelete(removeIds);\n    });\n    return true;\n  };\n  _proto.getAttachmentData = async function getAttachmentData(documentId, attachmentId, _digest) {\n    ensureNotClosed(this);\n    var state = await this.internals;\n    var id = attachmentObjectId(documentId, attachmentId);\n    return await state.dexieDb.transaction('r', state.dexieAttachmentsTable, async () => {\n      var attachment = await state.dexieAttachmentsTable.get(id);\n      if (attachment) {\n        return attachment.data;\n      } else {\n        throw new Error('attachment missing documentId: ' + documentId + ' attachmentId: ' + attachmentId);\n      }\n    });\n  };\n  _proto.remove = async function remove() {\n    ensureNotClosed(this);\n    var state = await this.internals;\n    await state.dexieTable.clear();\n    return this.close();\n  };\n  _proto.close = function close() {\n    if (this.closed) {\n      return this.closed;\n    }\n    this.closed = (async () => {\n      this.changes$.complete();\n      await closeDexieDb(this.internals);\n    })();\n    return this.closed;\n  };\n  return RxStorageInstanceDexie;\n}();\nexport async function createDexieStorageInstance(storage, params, settings) {\n  var internals = getDexieDbWithTables(params.databaseName, params.collectionName, settings, params.schema);\n  var instance = new RxStorageInstanceDexie(storage, params.databaseName, params.collectionName, params.schema, internals, params.options, settings, params.devMode);\n  await addRxStorageMultiInstanceSupport(RX_STORAGE_NAME_DEXIE, params, instance);\n  return Promise.resolve(instance);\n}\nfunction ensureNotClosed(instance) {\n  if (instance.closed) {\n    throw new Error('RxStorageInstanceDexie is closed ' + instance.databaseName + '-' + instance.collectionName);\n  }\n}\n//# sourceMappingURL=rx-storage-instance-dexie.js.map","/**\n * this plugin allows delta-updates with mongo-like-syntax\n * It's using mingo internally\n * @link https://github.com/kofrasa/mingo\n */\nimport { runQueryUpdateFunction } from \"../../rx-query-helper.js\";\nimport { mingoUpdater } from \"./mingo-updater.js\";\nexport function incrementalUpdate(updateObj) {\n  return this.incrementalModify(docData => {\n    var newDocData = mingoUpdater(docData, updateObj);\n    return newDocData;\n  });\n}\nexport function update(updateObj) {\n  var oldDocData = this._data;\n  var newDocData = mingoUpdater(oldDocData, updateObj);\n  return this._saveData(newDocData, oldDocData);\n}\nexport async function RxQueryUpdate(updateObj) {\n  return runQueryUpdateFunction(this.asRxQuery, doc => doc.update(updateObj));\n}\nexport var RxDBUpdatePlugin = {\n  name: 'update',\n  rxdb: true,\n  prototypes: {\n    RxDocument: proto => {\n      proto.update = update;\n      proto.incrementalUpdate = incrementalUpdate;\n    },\n    RxQuery: proto => {\n      proto.update = RxQueryUpdate;\n    }\n  }\n};\n//# sourceMappingURL=index.js.map","/**\n * Custom build of the mingo updater for smaller build size\n */\n\nimport { createUpdater } from \"mingo/updater\";\nimport { clone } from \"../utils/index.js\";\nvar updater;\nexport function mingoUpdater(d, op) {\n  if (!updater) {\n    var updateObject = createUpdater({\n      cloneMode: \"none\"\n    });\n    updater = (d, op) => {\n      var cloned = clone(d);\n      updateObject(cloned, op);\n      return cloned;\n    };\n  }\n  return updater(d, op);\n}\n//# sourceMappingURL=mingo-updater.js.map","export function lastOfArray(ar) {\n  return ar[ar.length - 1];\n}\n\n/**\n * shuffle the given array\n */\nexport function shuffleArray(arr) {\n  return arr.slice(0).sort(() => Math.random() - 0.5);\n}\nexport function randomOfArray(arr) {\n  var randomElement = arr[Math.floor(Math.random() * arr.length)];\n  return randomElement;\n}\nexport function toArray(input) {\n  return Array.isArray(input) ? input.slice(0) : [input];\n}\n\n/**\n * Split array with items into smaller arrays with items\n * @link https://stackoverflow.com/a/7273794/3443137\n */\nexport function batchArray(array, batchSize) {\n  array = array.slice(0);\n  var ret = [];\n  while (array.length) {\n    var batch = array.splice(0, batchSize);\n    ret.push(batch);\n  }\n  return ret;\n}\n\n/**\n * @link https://stackoverflow.com/a/15996017\n */\nexport function removeOneFromArrayIfMatches(ar, condition) {\n  ar = ar.slice();\n  var i = ar.length;\n  var done = false;\n  while (i-- && !done) {\n    if (condition(ar[i])) {\n      done = true;\n      ar.splice(i, 1);\n    }\n  }\n  return ar;\n}\n\n/**\n * returns true if the supplied argument is either an Array<T> or a Readonly<Array<T>>\n */\nexport function isMaybeReadonlyArray(x) {\n  // While this looks strange, it's a workaround for an issue in TypeScript:\n  // https://github.com/microsoft/TypeScript/issues/17002\n  //\n  // The problem is that `Array.isArray` as a type guard returns `false` for a readonly array,\n  // but at runtime the object is an array and the runtime call to `Array.isArray` would return `true`.\n  // The type predicate here allows for both `Array<T>` and `Readonly<Array<T>>` to pass a type check while\n  // still performing runtime type inspection.\n  return Array.isArray(x);\n}\nexport function isOneItemOfArrayInOtherArray(ar1, ar2) {\n  for (var i = 0; i < ar1.length; i++) {\n    var el = ar1[i];\n    var has = ar2.includes(el);\n    if (has) {\n      return true;\n    }\n  }\n  return false;\n}\n\n/**\n * Use this in array.filter() to remove all empty slots\n * and have the correct typings afterwards.\n * @link https://stackoverflow.com/a/46700791/3443137\n */\nexport function arrayFilterNotEmpty(value) {\n  if (value === null || value === undefined) {\n    return false;\n  }\n  return true;\n}\nexport function countUntilNotMatching(ar, matchingFn) {\n  var count = 0;\n  var idx = -1;\n  for (var item of ar) {\n    idx = idx + 1;\n    var matching = matchingFn(item, idx);\n    if (matching) {\n      count = count + 1;\n    } else {\n      break;\n    }\n  }\n  return count;\n}\nexport async function asyncFilter(array, predicate) {\n  var filters = await Promise.all(array.map(predicate));\n  return array.filter((...[, index]) => filters[index]);\n}\n\n/**\n * @link https://stackoverflow.com/a/3762735\n */\nexport function sumNumberArray(array) {\n  var count = 0;\n  for (var i = array.length; i--;) {\n    count += array[i];\n  }\n  return count;\n}\nexport function maxOfNumbers(arr) {\n  return Math.max(...arr);\n}\n\n/**\n * Appends the given documents to the given array.\n * This will mutate the first given array.\n * Mostly used as faster alternative to Array.concat()\n * because .concat() is so slow.\n * @link https://www.measurethat.net/Benchmarks/Show/4223/0/array-concat-vs-spread-operator-vs-push#latest_results_block\n * \n * TODO it turns out that in mid 2024 v8 has optimized Array.concat()\n * so it might be faster to just use concat() again:\n * @link https://jsperf.app/qiqawa/10\n */\nexport function appendToArray(ar, add) {\n  /**\n   * Pre-increasing the array size has turned out\n   * to be way faster when big arrays must be handled.\n   * @link https://dev.to/uilicious/javascript-array-push-is-945x-faster-than-array-concat-1oki\n   */\n  var addSize = add.length;\n  if (addSize === 0) {\n    return;\n  }\n  var baseSize = ar.length;\n  ar.length = baseSize + add.length;\n  for (var i = 0; i < addSize; ++i) {\n    ar[baseSize + i] = add[i];\n  }\n}\n\n/**\n * @link https://gist.github.com/telekosmos/3b62a31a5c43f40849bb\n */\nexport function uniqueArray(arrArg) {\n  return arrArg.filter(function (elem, pos, arr) {\n    return arr.indexOf(elem) === pos;\n  });\n}\nexport function sortByObjectNumberProperty(property) {\n  return (a, b) => {\n    return b[property] - a[property];\n  };\n}\n//# sourceMappingURL=utils-array.js.map","import { flatClone } from \"./utils-object.js\";\n/**\n * We use 1 as minimum so that the value is never falsy.\n * This const is used in several places because querying\n * with a value lower then the minimum could give false results.\n */\nexport var RX_META_LWT_MINIMUM = 1;\nexport function getDefaultRxDocumentMeta() {\n  return {\n    /**\n     * Set this to 1 to not waste performance\n     * while calling new Date()..\n     * The storage wrappers will anyway update\n     * the lastWrite time while calling transformDocumentDataFromRxDBToRxStorage()\n     */\n    lwt: RX_META_LWT_MINIMUM\n  };\n}\n\n/**\n * Returns a revision that is not valid.\n * Use this to have correct typings\n * while the storage wrapper anyway will overwrite the revision.\n */\nexport function getDefaultRevision() {\n  /**\n   * Use a non-valid revision format,\n   * to ensure that the RxStorage will throw\n   * when the revision is not replaced downstream.\n   */\n  return '';\n}\nexport function stripMetaDataFromDocument(docData) {\n  return Object.assign({}, docData, {\n    _meta: undefined,\n    _deleted: undefined,\n    _rev: undefined\n  });\n}\n\n/**\n * Faster way to check the equality of document lists\n * compared to doing a deep-equal.\n * Here we only check the ids and revisions.\n */\nexport function areRxDocumentArraysEqual(primaryPath, ar1, ar2) {\n  if (ar1.length !== ar2.length) {\n    return false;\n  }\n  var i = 0;\n  var len = ar1.length;\n  while (i < len) {\n    var row1 = ar1[i];\n    var row2 = ar2[i];\n    i++;\n    if (row1._rev !== row2._rev || row1[primaryPath] !== row2[primaryPath]) {\n      return false;\n    }\n  }\n  return true;\n}\nexport function getSortDocumentsByLastWriteTimeComparator(primaryPath) {\n  return (a, b) => {\n    if (a._meta.lwt === b._meta.lwt) {\n      if (b[primaryPath] < a[primaryPath]) {\n        return 1;\n      } else {\n        return -1;\n      }\n    } else {\n      return a._meta.lwt - b._meta.lwt;\n    }\n  };\n}\nexport function sortDocumentsByLastWriteTime(primaryPath, docs) {\n  return docs.sort(getSortDocumentsByLastWriteTimeComparator(primaryPath));\n}\nexport function toWithDeleted(docData) {\n  docData = flatClone(docData);\n  docData._deleted = !!docData._deleted;\n  return Object.assign(docData, {\n    _attachments: undefined,\n    _meta: undefined,\n    _rev: undefined\n  });\n}\n//# sourceMappingURL=utils-document.js.map","import { ucfirst } from \"./utils-string.js\";\n\n/**\n * Returns an error that indicates that a plugin is missing\n * We do not throw a RxError because this should not be handled\n * programmatically but by using the correct import\n */\nexport function pluginMissing(pluginKey) {\n  var keyParts = pluginKey.split('-');\n  var pluginName = 'RxDB';\n  keyParts.forEach(part => {\n    pluginName += ucfirst(part);\n  });\n  pluginName += 'Plugin';\n  return new Error(\"You are using a function which must be overwritten by a plugin.\\n        You should either prevent the usage of this function or add the plugin via:\\n            import { \" + pluginName + \" } from 'rxdb/plugins/\" + pluginKey + \"';\\n            addRxPlugin(\" + pluginName + \");\\n        \");\n}\nexport function errorToPlainJson(err) {\n  var ret = {\n    name: err.name,\n    message: err.message,\n    rxdb: err.rxdb,\n    parameters: err.parameters,\n    extensions: err.extensions,\n    code: err.code,\n    url: err.url,\n    /**\n     * stack must be last to make it easier to read the json in a console.\n     * Also we ensure that each linebreak is spaced so that the chrome devtools\n     * shows urls to the source code that can be clicked to inspect\n     * the correct place in the code.\n     */\n    stack: !err.stack ? undefined : err.stack.replace(/\\n/g, ' \\n ')\n  };\n  return ret;\n}\n//# sourceMappingURL=utils-error.js.map","/**\n * Can be used by some plugins to have a \"global\" object that\n * can be imported and mutated at will.\n */\nexport var RXDB_UTILS_GLOBAL = {};\n//# sourceMappingURL=utils-global.js.map","export async function nativeSha256(input) {\n  var data = new TextEncoder().encode(input);\n  /**\n   * If your JavaScript runtime does not support crypto.subtle.digest,\n   * provide your own hash function when calling createRxDatabase().\n   */\n\n  var hashBuffer = await crypto.subtle.digest('SHA-256', data);\n  /**\n   * @link https://jameshfisher.com/2017/10/30/web-cryptography-api-hello-world/\n   */\n  var hash = Array.prototype.map.call(new Uint8Array(hashBuffer), x => ('00' + x.toString(16)).slice(-2)).join('');\n  return hash;\n}\nexport var defaultHashSha256 = nativeSha256;\nexport function hashStringToNumber(str) {\n  var nr = 0;\n  var len = str.length;\n  for (var i = 0; i < len; i++) {\n    nr = nr + str.charCodeAt(i);\n    nr |= 0; // Convert to 32bit integer, improves performance\n  }\n  return nr;\n}\n//# sourceMappingURL=utils-hash.js.map","export function getFromMapOrThrow(map, key) {\n  var val = map.get(key);\n  if (typeof val === 'undefined') {\n    throw new Error('missing value from map ' + key);\n  }\n  return val;\n}\nexport function getFromMapOrCreate(map, index, creator, ifWasThere) {\n  var value = map.get(index);\n  if (typeof value === 'undefined') {\n    value = creator();\n    map.set(index, value);\n  } else if (ifWasThere) {\n    ifWasThere(value);\n  }\n  return value;\n}\n//# sourceMappingURL=utils-map.js.map","/**\n * Copied from the fast-deep-equal package\n * because it does not support es modules and causes optimization bailouts.\n * TODO use the npm package again when this is merged:\n * @link https://github.com/epoberezkin/fast-deep-equal/pull/105\n */\nexport function deepEqual(a, b) {\n  if (a === b) return true;\n  if (a && b && typeof a == 'object' && typeof b == 'object') {\n    if (a.constructor !== b.constructor) return false;\n    var length;\n    var i;\n    if (Array.isArray(a)) {\n      length = a.length;\n      if (length !== b.length) return false;\n      for (i = length; i-- !== 0;) if (!deepEqual(a[i], b[i])) return false;\n      return true;\n    }\n    if (a.constructor === RegExp) return a.source === b.source && a.flags === b.flags;\n    if (a.valueOf !== Object.prototype.valueOf) return a.valueOf() === b.valueOf();\n    if (a.toString !== Object.prototype.toString) return a.toString() === b.toString();\n    var keys = Object.keys(a);\n    length = keys.length;\n    if (length !== Object.keys(b).length) return false;\n    for (i = length; i-- !== 0;) if (!Object.prototype.hasOwnProperty.call(b, keys[i])) return false;\n    for (i = length; i-- !== 0;) {\n      var key = keys[i];\n      if (!deepEqual(a[key], b[key])) return false;\n    }\n    return true;\n  }\n\n  // true if both NaN, false otherwise\n  return a !== a && b !== b;\n}\n//# sourceMappingURL=utils-object-deep-equal.js.map","/**\n * Copied from\n * @link https://github.com/sindresorhus/dot-prop/blob/main/index.js\n * because it is currently an esm only module.\n * TODO use the npm package again when RxDB is also fully esm.\n */\n\nvar isObject = value => {\n  var type = typeof value;\n  return value !== null && (type === 'object' || type === 'function');\n};\nvar disallowedKeys = new Set(['__proto__', 'prototype', 'constructor']);\nvar digits = new Set('0123456789');\nfunction getPathSegments(path) {\n  var parts = [];\n  var currentSegment = '';\n  var currentPart = 'start';\n  var isIgnoring = false;\n  for (var character of path) {\n    switch (character) {\n      case '\\\\':\n        {\n          if (currentPart === 'index') {\n            throw new Error('Invalid character in an index');\n          }\n          if (currentPart === 'indexEnd') {\n            throw new Error('Invalid character after an index');\n          }\n          if (isIgnoring) {\n            currentSegment += character;\n          }\n          currentPart = 'property';\n          isIgnoring = !isIgnoring;\n          break;\n        }\n      case '.':\n        {\n          if (currentPart === 'index') {\n            throw new Error('Invalid character in an index');\n          }\n          if (currentPart === 'indexEnd') {\n            currentPart = 'property';\n            break;\n          }\n          if (isIgnoring) {\n            isIgnoring = false;\n            currentSegment += character;\n            break;\n          }\n          if (disallowedKeys.has(currentSegment)) {\n            return [];\n          }\n          parts.push(currentSegment);\n          currentSegment = '';\n          currentPart = 'property';\n          break;\n        }\n      case '[':\n        {\n          if (currentPart === 'index') {\n            throw new Error('Invalid character in an index');\n          }\n          if (currentPart === 'indexEnd') {\n            currentPart = 'index';\n            break;\n          }\n          if (isIgnoring) {\n            isIgnoring = false;\n            currentSegment += character;\n            break;\n          }\n          if (currentPart === 'property') {\n            if (disallowedKeys.has(currentSegment)) {\n              return [];\n            }\n            parts.push(currentSegment);\n            currentSegment = '';\n          }\n          currentPart = 'index';\n          break;\n        }\n      case ']':\n        {\n          if (currentPart === 'index') {\n            parts.push(Number.parseInt(currentSegment, 10));\n            currentSegment = '';\n            currentPart = 'indexEnd';\n            break;\n          }\n          if (currentPart === 'indexEnd') {\n            throw new Error('Invalid character after an index');\n          }\n\n          // Falls through\n        }\n      default:\n        {\n          if (currentPart === 'index' && !digits.has(character)) {\n            throw new Error('Invalid character in an index');\n          }\n          if (currentPart === 'indexEnd') {\n            throw new Error('Invalid character after an index');\n          }\n          if (currentPart === 'start') {\n            currentPart = 'property';\n          }\n          if (isIgnoring) {\n            isIgnoring = false;\n            currentSegment += '\\\\';\n          }\n          currentSegment += character;\n        }\n    }\n  }\n  if (isIgnoring) {\n    currentSegment += '\\\\';\n  }\n  switch (currentPart) {\n    case 'property':\n      {\n        if (disallowedKeys.has(currentSegment)) {\n          return [];\n        }\n        parts.push(currentSegment);\n        break;\n      }\n    case 'index':\n      {\n        throw new Error('Index was not closed');\n      }\n    case 'start':\n      {\n        parts.push('');\n        break;\n      }\n    // No default\n  }\n  return parts;\n}\nfunction isStringIndex(object, key) {\n  if (typeof key !== 'number' && Array.isArray(object)) {\n    var index = Number.parseInt(key, 10);\n    return Number.isInteger(index) && object[index] === object[key];\n  }\n  return false;\n}\nfunction assertNotStringIndex(object, key) {\n  if (isStringIndex(object, key)) {\n    throw new Error('Cannot use string index');\n  }\n}\n\n/**\n * TODO we need some performance tests and improvements here.\n */\nexport function getProperty(object, path, value) {\n  if (Array.isArray(path)) {\n    path = path.join('.');\n  }\n\n  /**\n   * Performance shortcut.\n   * In most cases we just have a simple property name\n   * so we can directly return it.\n   */\n  if (!path.includes('.') && !path.includes('[')) {\n    return object[path];\n  }\n  if (!isObject(object) || typeof path !== 'string') {\n    return value === undefined ? object : value;\n  }\n  var pathArray = getPathSegments(path);\n  if (pathArray.length === 0) {\n    return value;\n  }\n  for (var index = 0; index < pathArray.length; index++) {\n    var key = pathArray[index];\n    if (isStringIndex(object, key)) {\n      object = index === pathArray.length - 1 ? undefined : null;\n    } else {\n      object = object[key];\n    }\n    if (object === undefined || object === null) {\n      // `object` is either `undefined` or `null` so we want to stop the loop, and\n      // if this is not the last bit of the path, and\n      // if it didn't return `undefined`\n      // it would return `null` if `object` is `null`\n      // but we want `get({foo: null}, 'foo.bar')` to equal `undefined`, or the supplied value, not `null`\n      if (index !== pathArray.length - 1) {\n        return value;\n      }\n      break;\n    }\n  }\n  return object === undefined ? value : object;\n}\nexport function setProperty(object, path, value) {\n  if (Array.isArray(path)) {\n    path = path.join('.');\n  }\n  if (!isObject(object) || typeof path !== 'string') {\n    return object;\n  }\n  var root = object;\n  var pathArray = getPathSegments(path);\n  for (var index = 0; index < pathArray.length; index++) {\n    var key = pathArray[index];\n    assertNotStringIndex(object, key);\n    if (index === pathArray.length - 1) {\n      object[key] = value;\n    } else if (!isObject(object[key])) {\n      object[key] = typeof pathArray[index + 1] === 'number' ? [] : {};\n    }\n    object = object[key];\n  }\n  return root;\n}\nexport function deleteProperty(object, path) {\n  if (!isObject(object) || typeof path !== 'string') {\n    return false;\n  }\n  var pathArray = getPathSegments(path);\n  for (var index = 0; index < pathArray.length; index++) {\n    var key = pathArray[index];\n    assertNotStringIndex(object, key);\n    if (index === pathArray.length - 1) {\n      delete object[key];\n      return true;\n    }\n    object = object[key];\n    if (!isObject(object)) {\n      return false;\n    }\n  }\n}\nexport function hasProperty(object, path) {\n  if (!isObject(object) || typeof path !== 'string') {\n    return false;\n  }\n  var pathArray = getPathSegments(path);\n  if (pathArray.length === 0) {\n    return false;\n  }\n  for (var key of pathArray) {\n    if (!isObject(object) || !(key in object) || isStringIndex(object, key)) {\n      return false;\n    }\n    object = object[key];\n  }\n  return true;\n}\n\n// TODO: Backslashes with no effect should not be escaped\nfunction escapePath(path) {\n  if (typeof path !== 'string') {\n    throw new TypeError('Expected a string');\n  }\n  return path.replace(/[\\\\.[]/g, '\\\\$&');\n}\n\n// The keys returned by Object.entries() for arrays are strings\nfunction entries(value) {\n  if (Array.isArray(value)) {\n    return value.map((v, index) => [index, v]);\n  }\n  return Object.entries(value);\n}\nfunction stringifyPath(pathSegments) {\n  var result = '';\n\n  // eslint-disable-next-line prefer-const\n  for (var [index, segment] of entries(pathSegments)) {\n    if (typeof segment === 'number') {\n      result += \"[\" + segment + \"]\";\n    } else {\n      segment = escapePath(segment);\n      result += index === 0 ? segment : \".\" + segment;\n    }\n  }\n  return result;\n}\nfunction* deepKeysIterator(object, currentPath = []) {\n  if (!isObject(object)) {\n    if (currentPath.length > 0) {\n      yield stringifyPath(currentPath);\n    }\n    return;\n  }\n  for (var [key, value] of entries(object)) {\n    yield* deepKeysIterator(value, [...currentPath, key]);\n  }\n}\nexport function deepKeys(object) {\n  return [...deepKeysIterator(object)];\n}\n//# sourceMappingURL=utils-object-dot-prop.js.map","export function deepFreeze(o) {\n  Object.freeze(o);\n  Object.getOwnPropertyNames(o).forEach(function (prop) {\n    if (Object.prototype.hasOwnProperty.call(o, prop) && o[prop] !== null && (typeof o[prop] === 'object' || typeof o[prop] === 'function') && !Object.isFrozen(o[prop])) {\n      deepFreeze(o[prop]);\n    }\n  });\n  return o;\n}\n\n/**\n * To get specific nested path values from objects,\n * RxDB normally uses the 'dot-prop' npm module.\n * But when performance is really relevant, this is not fast enough.\n * Instead we use a monad that can prepare some stuff up front\n * and we can reuse the generated function.\n */\n\nexport function objectPathMonad(objectPath) {\n  var split = objectPath.split('.');\n\n  // reuse this variable for better performance.\n  var splitLength = split.length;\n\n  /**\n   * Performance shortcut,\n   * if no nested path is used,\n   * directly return the field of the object.\n   */\n  if (splitLength === 1) {\n    return obj => obj[objectPath];\n  }\n  return obj => {\n    var currentVal = obj;\n    for (var i = 0; i < splitLength; ++i) {\n      var subPath = split[i];\n      currentVal = currentVal[subPath];\n      if (typeof currentVal === 'undefined') {\n        return currentVal;\n      }\n    }\n    return currentVal;\n  };\n}\nexport function getFromObjectOrThrow(obj, key) {\n  var val = obj[key];\n  if (!val) {\n    throw new Error('missing value from object ' + key);\n  }\n  return val;\n}\n\n/**\n * returns a flattened object\n * @link https://gist.github.com/penguinboy/762197\n */\nexport function flattenObject(ob) {\n  var toReturn = {};\n  for (var i in ob) {\n    if (!Object.prototype.hasOwnProperty.call(ob, i)) continue;\n    if (typeof ob[i] === 'object') {\n      var flatObject = flattenObject(ob[i]);\n      for (var x in flatObject) {\n        if (!Object.prototype.hasOwnProperty.call(flatObject, x)) continue;\n        toReturn[i + '.' + x] = flatObject[x];\n      }\n    } else {\n      toReturn[i] = ob[i];\n    }\n  }\n  return toReturn;\n}\n\n/**\n * does a flat copy on the objects,\n * is about 3 times faster then using deepClone\n * @link https://jsperf.com/object-rest-spread-vs-clone/2\n */\nexport function flatClone(obj) {\n  return Object.assign({}, obj);\n}\n\n/**\n * @link https://stackoverflow.com/a/11509718/3443137\n */\nexport function firstPropertyNameOfObject(obj) {\n  return Object.keys(obj)[0];\n}\nexport function firstPropertyValueOfObject(obj) {\n  var key = Object.keys(obj)[0];\n  return obj[key];\n}\n\n/**\n * deep-sort an object so its attributes are in lexical order.\n * Also sorts the arrays inside of the object if no-array-sort not set\n */\nexport function sortObject(obj, noArraySort = false) {\n  if (!obj) return obj; // do not sort null, false or undefined\n\n  // array\n  if (!noArraySort && Array.isArray(obj)) {\n    return obj.sort((a, b) => {\n      if (typeof a === 'string' && typeof b === 'string') return a.localeCompare(b);\n      if (typeof a === 'object') return 1;else return -1;\n    }).map(i => sortObject(i, noArraySort));\n  }\n\n  // object\n  // array is also of type object\n  if (typeof obj === 'object' && !Array.isArray(obj)) {\n    var out = {};\n    Object.keys(obj).sort((a, b) => a.localeCompare(b)).forEach(key => {\n      out[key] = sortObject(obj[key], noArraySort);\n    });\n    return out;\n  }\n\n  // everything else\n  return obj;\n}\n\n/**\n * Deep clone a plain json object.\n * Does not work with recursive stuff\n * or non-plain-json.\n * IMPORTANT: Performance of this is very important,\n * do not change it without running performance tests!\n *\n * @link https://github.com/zxdong262/deep-copy/blob/master/src/index.ts\n */\nfunction deepClone(src) {\n  if (!src) {\n    return src;\n  }\n  if (src === null || typeof src !== 'object') {\n    return src;\n  }\n  if (Array.isArray(src)) {\n    var ret = new Array(src.length);\n    var i = ret.length;\n    while (i--) {\n      ret[i] = deepClone(src[i]);\n    }\n    return ret;\n  }\n  var dest = {};\n  // eslint-disable-next-line guard-for-in\n  for (var key in src) {\n    dest[key] = deepClone(src[key]);\n  }\n  return dest;\n}\nexport var clone = deepClone;\n\n/**\n * overwrites the getter with the actual value\n * Mostly used for caching stuff on the first run\n */\nexport function overwriteGetterForCaching(obj, getterName, value) {\n  Object.defineProperty(obj, getterName, {\n    get: function () {\n      return value;\n    }\n  });\n  return value;\n}\nexport function hasDeepProperty(obj, property) {\n  if (obj.hasOwnProperty(property)) {\n    return true;\n  }\n  if (Array.isArray(obj)) {\n    var has = !!obj.find(item => hasDeepProperty(item, property));\n    return has;\n  }\n\n  // Recursively check for property in nested objects\n  for (var key in obj) {\n    if (typeof obj[key] === 'object' && obj[key] !== null) {\n      if (hasDeepProperty(obj[key], property)) {\n        return true;\n      }\n    }\n  }\n\n  // Return false if 'foobar' is not found at any level\n  return false;\n}\n\n/**\n * Deeply checks if an object contains any property\n * with the value of undefined\n * If yes, returns the path to it.\n */\nexport function findUndefinedPath(obj, parentPath = '') {\n  // If `obj` is not an object or is null, we can't go deeper, so return false\n  if (typeof obj !== \"object\" || obj === null) {\n    return false;\n  }\n  for (var key of Object.keys(obj)) {\n    var value = obj[key];\n    // Build the full path. For the root level, it's just the key;\n    // for nested levels, prepend the parent path followed by a dot.\n    var currentPath = parentPath ? parentPath + \".\" + key : key;\n\n    // If the value is undefined, return the path\n    if (typeof value === 'undefined') {\n      return currentPath;\n    }\n\n    // If the value is an object, recurse to check deeper\n    if (typeof value === \"object\" && value !== null) {\n      var result = findUndefinedPath(value, currentPath);\n      // If a path was found in the nested object, return it\n      if (result) {\n        return result;\n      }\n    }\n  }\n\n  // If no property with undefined was found\n  return false;\n}\n//# sourceMappingURL=utils-object.js.map","export function runXTimes(xTimes, fn) {\n  new Array(xTimes).fill(0).forEach((_v, idx) => fn(idx));\n}\nexport function ensureNotFalsy(obj, message) {\n  if (!obj) {\n    if (!message) {\n      message = '';\n    }\n    throw new Error('ensureNotFalsy() is falsy: ' + message);\n  }\n  return obj;\n}\nexport function ensureInteger(obj) {\n  if (!Number.isInteger(obj)) {\n    throw new Error('ensureInteger() is falsy');\n  }\n  return obj;\n}\n\n/**\n * Using shareReplay() without settings will not unsubscribe\n * if there are no more subscribers.\n * So we use these defaults.\n * @link https://cartant.medium.com/rxjs-whats-changed-with-sharereplay-65c098843e95\n */\nexport var RXJS_SHARE_REPLAY_DEFAULTS = {\n  bufferSize: 1,\n  refCount: true\n};\n\n/**\n * Dynamically add a name to a function\n * so that it can later be found in the stack.\n * @link https://stackoverflow.com/a/41854075/3443137\n */\nexport function nameFunction(name, body) {\n  // @ts-ignore\n  return {\n    [name](...args) {\n      return body.apply(this, args);\n    }\n  }[name];\n}\nexport function customFetchWithFixedHeaders(headers) {\n  function customFetch(url, options = {}) {\n    // Ensure options object exists and headers property is initialized\n    options.headers = {\n      ...headers,\n      // include default custom headers\n      ...(options.headers || {}) // merge any headers passed in the function call\n    };\n\n    // Call the original fetch with the modified options\n    return fetch(url, options);\n  }\n  return customFetch;\n}\n//# sourceMappingURL=utils-other.js.map","import { RXDB_UTILS_GLOBAL } from \"./utils-global.js\";\nimport { defaultHashSha256 } from \"./utils-hash.js\";\nimport { PROMISE_RESOLVE_FALSE } from \"./utils-promise.js\";\nexport var PREMIUM_FLAG_HASH = '6da4936d1425ff3a5c44c02342c6daf791d266be3ae8479b8ec59e261df41b93';\nexport var NON_PREMIUM_COLLECTION_LIMIT = 16;\nvar hasPremiumPromise = PROMISE_RESOLVE_FALSE;\nvar premiumChecked = false;\n\n/**\n * Here we check if the premium flag has been set.\n * This code exists in the open source version of RxDB.\n * Yes you are allowed to fork the repo and just overwrite this function.\n * However you might better spend this time developing your real project\n * and supporting the RxDB efforts by buying premium.\n */\nexport async function hasPremiumFlag() {\n  if (premiumChecked) {\n    return hasPremiumPromise;\n  }\n  premiumChecked = true;\n  hasPremiumPromise = (async () => {\n    if (RXDB_UTILS_GLOBAL.premium && typeof RXDB_UTILS_GLOBAL.premium === 'string' && (await defaultHashSha256(RXDB_UTILS_GLOBAL.premium)) === PREMIUM_FLAG_HASH) {\n      return true;\n    } else {\n      return false;\n    }\n  })();\n  return hasPremiumPromise;\n}\n//# sourceMappingURL=utils-premium.js.map","/**\n * returns a promise that resolves on the next tick\n */\nexport function nextTick() {\n  return new Promise(res => setTimeout(res, 0));\n}\nexport function promiseWait(ms = 0) {\n  return new Promise(res => setTimeout(res, ms));\n}\nexport function toPromise(maybePromise) {\n  if (maybePromise && typeof maybePromise.then === 'function') {\n    // is promise\n    return maybePromise;\n  } else {\n    return Promise.resolve(maybePromise);\n  }\n}\n\n/**\n * returns true if promise is given\n */\nexport function isPromise(value) {\n  if (typeof value !== 'undefined' && typeof value.then === 'function') {\n    return true;\n  }\n  return false;\n}\n\n/**\n * Reusing resolved promises has a better\n * performance than creating new ones each time.\n */\nexport var PROMISE_RESOLVE_TRUE = Promise.resolve(true);\nexport var PROMISE_RESOLVE_FALSE = Promise.resolve(false);\nexport var PROMISE_RESOLVE_NULL = Promise.resolve(null);\nexport var PROMISE_RESOLVE_VOID = Promise.resolve();\nexport function requestIdlePromiseNoQueue(\n/**\n * We always set a timeout!\n * RxDB might be used on the server side where the\n * server runs 24/4 on 99% CPU. So without a timeout\n * this would never resolve which could cause a memory leak.\n */\ntimeout = 10000) {\n  /**\n   * Do not use window.requestIdleCallback\n   * because some javascript runtimes like react-native,\n   * do not have a window object, but still have a global\n   * requestIdleCallback function.\n   * @link https://github.com/pubkey/rxdb/issues/4804\n  */\n  if (typeof requestIdleCallback === 'function') {\n    return new Promise(res => {\n      requestIdleCallback(() => res(), {\n        timeout\n      });\n    });\n  } else {\n    return promiseWait(0);\n  }\n}\n\n/**\n * If multiple operations wait for an requestIdlePromise\n * we do not want them to resolve all at the same time.\n * So we have to queue the calls.\n */\nvar idlePromiseQueue = PROMISE_RESOLVE_VOID;\nexport function requestIdlePromise(timeout = undefined) {\n  idlePromiseQueue = idlePromiseQueue.then(() => {\n    return requestIdlePromiseNoQueue(timeout);\n  });\n  return idlePromiseQueue;\n}\n\n/**\n * run the callback if requestIdleCallback available\n * do nothing if not\n * @link https://developer.mozilla.org/de/docs/Web/API/Window/requestIdleCallback\n */\nexport function requestIdleCallbackIfAvailable(fun) {\n  /**\n   * Do not use window.requestIdleCallback\n   * because some javascript runtimes like react-native,\n   * do not have a window object, but still have a global\n   * requestIdleCallback function.\n   * @link https://github.com/pubkey/rxdb/issues/4804\n  */\n  if (typeof requestIdleCallback === 'function') {\n    requestIdleCallback(() => {\n      fun();\n    });\n  }\n}\n\n/**\n * like Promise.all() but runs in series instead of parallel\n * @link https://github.com/egoist/promise.series/blob/master/index.js\n * @param tasks array with functions that return a promise\n */\nexport function promiseSeries(tasks, initial) {\n  return tasks.reduce((current, next) => current.then(next), Promise.resolve(initial));\n}\n//# sourceMappingURL=utils-promise.js.map","export var REGEX_ALL_DOTS = /\\./g;\nexport var REGEX_ALL_PIPES = /\\|/g;\n//# sourceMappingURL=utils-regex.js.map","/**\n * Parses the full revision.\n * Do NOT use this if you only need the revision height,\n * then use getHeightOfRevision() instead which is faster.\n */\nexport function parseRevision(revision) {\n  var split = revision.split('-');\n  if (split.length !== 2) {\n    throw new Error('malformatted revision: ' + revision);\n  }\n  return {\n    height: parseInt(split[0], 10),\n    hash: split[1]\n  };\n}\n\n/**\n * @hotPath Performance is very important here\n * because we need to parse the revision height very often.\n * Do not use `parseInt(revision.split('-')[0], 10)` because\n * only fetching the start-number chars is faster.\n */\nexport function getHeightOfRevision(revision) {\n  var useChars = '';\n  for (var index = 0; index < revision.length; index++) {\n    var char = revision[index];\n    if (char === '-') {\n      return parseInt(useChars, 10);\n    }\n    useChars += char;\n  }\n  throw new Error('malformatted revision: ' + revision);\n}\n\n/**\n * Creates the next write revision for a given document.\n */\nexport function createRevision(databaseInstanceToken, previousDocData) {\n  var newRevisionHeight = !previousDocData ? 1 : getHeightOfRevision(previousDocData._rev) + 1;\n  return newRevisionHeight + '-' + databaseInstanceToken;\n}\n//# sourceMappingURL=utils-revision.js.map","/**\n * This file is replaced in the 'npm run build:version' script.\n */\nexport var RXDB_VERSION = '16.11.0';\n//# sourceMappingURL=utils-rxdb-version.js.map","var COUCH_NAME_CHARS = 'abcdefghijklmnopqrstuvwxyz';\n\n/**\n * Get a random string which can be used for many things in RxDB.\n * The returned string is guaranteed to be a valid database name or collection name\n * and also to be a valid JavaScript variable name.\n * \n * @link http://stackoverflow.com/a/1349426/3443137\n */\nexport function randomToken(length = 10) {\n  var text = '';\n  for (var i = 0; i < length; i++) {\n    text += COUCH_NAME_CHARS.charAt(Math.floor(Math.random() * COUCH_NAME_CHARS.length));\n  }\n  return text;\n}\n\n/**\n * A random string that is never inside of any storage\n */\nexport var RANDOM_STRING = 'Fz7SZXPmYJujkzjY1rpXWvlWBqoGAfAX';\n\n/**\n * uppercase first char\n */\nexport function ucfirst(str) {\n  str += '';\n  var f = str.charAt(0).toUpperCase();\n  return f + str.substr(1);\n}\n\n/**\n * removes trailing and ending dots from the string\n */\nexport function trimDots(str) {\n  // start\n  while (str.charAt(0) === '.') {\n    str = str.substr(1);\n  }\n\n  // end\n  while (str.slice(-1) === '.') {\n    str = str.slice(0, -1);\n  }\n  return str;\n}\n\n/**\n * @link https://stackoverflow.com/a/44950500/3443137\n */\nexport function lastCharOfString(str) {\n  return str.charAt(str.length - 1);\n}\n\n/**\n * returns true if the given name is likely a folder path\n */\nexport function isFolderPath(name) {\n  // do not check, if foldername is given\n  if (name.includes('/') ||\n  // unix\n  name.includes('\\\\') // windows\n  ) {\n    return true;\n  } else {\n    return false;\n  }\n}\n\n/**\n * @link https://gist.github.com/andreburgaud/6f73fd2d690b629346b8\n * @link https://stackoverflow.com/a/76240378/3443137\n */\nexport function arrayBufferToString(arrayBuffer) {\n  return new TextDecoder().decode(arrayBuffer);\n}\nexport function stringToArrayBuffer(str) {\n  return new TextEncoder().encode(str);\n}\nexport function normalizeString(str) {\n  return str.trim().replace(/[\\n\\s]+/g, '');\n}\n//# sourceMappingURL=utils-string.js.map","/**\n * Returns the current unix time in milliseconds (with two decimals!)\n * Because the accuracy of getTime() in javascript is bad,\n * and we cannot rely on performance.now() on all platforms,\n * this method implements a way to never return the same value twice.\n * This ensures that when now() is called often, we do not loose the information\n * about which call came first and which came after.\n *\n * We had to move from having no decimals, to having two decimal\n * because it turned out that some storages are such fast that\n * calling this method too often would return 'the future'.\n */\nvar _lastNow = 0;\n/**\n * Returns the current time in milliseconds,\n * also ensures to not return the same value twice.\n */\nexport function now() {\n  var ret = Date.now();\n  ret = ret + 0.01;\n  if (ret <= _lastNow) {\n    ret = _lastNow + 0.01;\n  }\n\n  /**\n   * Strip the returned number to max two decimals.\n   * In theory we would not need this but\n   * in practice JavaScript has no such good number precision\n   * so rounding errors could add another decimal place.\n   */\n  var twoDecimals = parseFloat(ret.toFixed(2));\n  _lastNow = twoDecimals;\n  return twoDecimals;\n}\n//# sourceMappingURL=utils-time.js.map","/**\n * the query-cache makes sure that on every query-state, exactly one instance can exist\n * if you use the same mango-query more then once, it will reuse the first RxQuery\n */\n\nimport { getFromMapOrCreate, nextTick, now, requestIdlePromise } from \"./plugins/utils/index.js\";\nexport var QueryCache = /*#__PURE__*/function () {\n  function QueryCache() {\n    this._map = new Map();\n  }\n  var _proto = QueryCache.prototype;\n  /**\n   * check if an equal query is in the cache,\n   * if true, return the cached one,\n   * if false, save the given one and return it\n   */\n  _proto.getByQuery = function getByQuery(rxQuery) {\n    var stringRep = rxQuery.toString();\n    var ret = getFromMapOrCreate(this._map, stringRep, () => rxQuery);\n    return ret;\n  };\n  return QueryCache;\n}();\nexport function createQueryCache() {\n  return new QueryCache();\n}\nexport function uncacheRxQuery(queryCache, rxQuery) {\n  rxQuery.uncached = true;\n  var stringRep = rxQuery.toString();\n  queryCache._map.delete(stringRep);\n}\nexport function countRxQuerySubscribers(rxQuery) {\n  return rxQuery.refCount$.observers.length;\n}\nexport var DEFAULT_TRY_TO_KEEP_MAX = 100;\nexport var DEFAULT_UNEXECUTED_LIFETIME = 30 * 1000;\n\n/**\n * The default cache replacement policy\n * See docs-src/query-cache.md to learn how it should work.\n * Notice that this runs often and should block the cpu as less as possible\n * This is a monad which makes it easier to unit test\n */\nexport var defaultCacheReplacementPolicyMonad = (tryToKeepMax, unExecutedLifetime) => (_collection, queryCache) => {\n  if (queryCache._map.size < tryToKeepMax) {\n    return;\n  }\n  var minUnExecutedLifetime = now() - unExecutedLifetime;\n  var maybeUncache = [];\n  var queriesInCache = Array.from(queryCache._map.values());\n  for (var rxQuery of queriesInCache) {\n    // filter out queries with subscribers\n    if (countRxQuerySubscribers(rxQuery) > 0) {\n      continue;\n    }\n    // directly uncache queries that never executed and are older than unExecutedLifetime\n    if (rxQuery._lastEnsureEqual === 0 && rxQuery._creationTime < minUnExecutedLifetime) {\n      uncacheRxQuery(queryCache, rxQuery);\n      continue;\n    }\n    maybeUncache.push(rxQuery);\n  }\n  var mustUncache = maybeUncache.length - tryToKeepMax;\n  if (mustUncache <= 0) {\n    return;\n  }\n  var sortedByLastUsage = maybeUncache.sort((a, b) => a._lastEnsureEqual - b._lastEnsureEqual);\n  var toRemove = sortedByLastUsage.slice(0, mustUncache);\n  toRemove.forEach(rxQuery => uncacheRxQuery(queryCache, rxQuery));\n};\nexport var defaultCacheReplacementPolicy = defaultCacheReplacementPolicyMonad(DEFAULT_TRY_TO_KEEP_MAX, DEFAULT_UNEXECUTED_LIFETIME);\nexport var COLLECTIONS_WITH_RUNNING_CLEANUP = new WeakSet();\n\n/**\n * Triggers the cache replacement policy after waitTime has passed.\n * We do not run this directly because at exactly the time a query is created,\n * we need all CPU to minimize latency.\n * Also this should not be triggered multiple times when waitTime is still waiting.\n */\nexport function triggerCacheReplacement(rxCollection) {\n  if (COLLECTIONS_WITH_RUNNING_CLEANUP.has(rxCollection)) {\n    // already started\n    return;\n  }\n  COLLECTIONS_WITH_RUNNING_CLEANUP.add(rxCollection);\n\n  /**\n   * Do not run directly to not reduce result latency of a new query\n   */\n  nextTick() // wait at least one tick\n  .then(() => requestIdlePromise(200)) // and then wait for the CPU to be idle\n  .then(() => {\n    if (!rxCollection.closed) {\n      rxCollection.cacheReplacementPolicy(rxCollection, rxCollection._queryCache);\n    }\n    COLLECTIONS_WITH_RUNNING_CLEANUP.delete(rxCollection);\n  });\n}\n//# sourceMappingURL=query-cache.js.map","import { countUntilNotMatching } from \"./plugins/utils/index.js\";\nimport { newRxError } from \"./rx-error.js\";\nimport { getSchemaByObjectPath } from \"./rx-schema-helper.js\";\nexport var INDEX_MAX = String.fromCharCode(65535);\n\n/**\n * Do not use -Infinity here because it would be\n * transformed to null on JSON.stringify() which can break things\n * when the query plan is send to the storage as json.\n * @link https://stackoverflow.com/a/16644751\n * Notice that for IndexedDB IDBKeyRange we have\n * to transform the value back to -Infinity\n * before we can use it in IDBKeyRange.bound.\n */\nexport var INDEX_MIN = Number.MIN_SAFE_INTEGER;\n\n/**\n * Returns the query plan which contains\n * information about how to run the query\n * and which indexes to use.\n *\n * This is used in some storage like Memory, dexie.js and IndexedDB.\n */\nexport function getQueryPlan(schema, query) {\n  var selector = query.selector;\n  var indexes = schema.indexes ? schema.indexes.slice(0) : [];\n  if (query.index) {\n    indexes = [query.index];\n  }\n\n  /**\n   * Most storages do not support descending indexes\n   * so having a 'desc' in the sorting, means we always have to re-sort the results.\n   */\n  var hasDescSorting = !!query.sort.find(sortField => Object.values(sortField)[0] === 'desc');\n\n  /**\n   * Some fields can be part of the selector while not being relevant for sorting\n   * because their selector operators specify that in all cases all matching docs\n   * would have the same value.\n   * For example the boolean field _deleted.\n   * TODO similar thing could be done for enums.\n   */\n  var sortIrrelevevantFields = new Set();\n  Object.keys(selector).forEach(fieldName => {\n    var schemaPart = getSchemaByObjectPath(schema, fieldName);\n    if (schemaPart && schemaPart.type === 'boolean' && Object.prototype.hasOwnProperty.call(selector[fieldName], '$eq')) {\n      sortIrrelevevantFields.add(fieldName);\n    }\n  });\n  var optimalSortIndex = query.sort.map(sortField => Object.keys(sortField)[0]);\n  var optimalSortIndexCompareString = optimalSortIndex.filter(f => !sortIrrelevevantFields.has(f)).join(',');\n  var currentBestQuality = -1;\n  var currentBestQueryPlan;\n\n  /**\n   * Calculate one query plan for each index\n   * and then test which of the plans is best.\n   */\n  indexes.forEach(index => {\n    var inclusiveEnd = true;\n    var inclusiveStart = true;\n    var opts = index.map(indexField => {\n      var matcher = selector[indexField];\n      var operators = matcher ? Object.keys(matcher) : [];\n      var matcherOpts = {};\n      if (!matcher || !operators.length) {\n        var startKey = inclusiveStart ? INDEX_MIN : INDEX_MAX;\n        matcherOpts = {\n          startKey,\n          endKey: inclusiveEnd ? INDEX_MAX : INDEX_MIN,\n          inclusiveStart: true,\n          inclusiveEnd: true\n        };\n      } else {\n        operators.forEach(operator => {\n          if (LOGICAL_OPERATORS.has(operator)) {\n            var operatorValue = matcher[operator];\n            var partialOpts = getMatcherQueryOpts(operator, operatorValue);\n            matcherOpts = Object.assign(matcherOpts, partialOpts);\n          }\n        });\n      }\n\n      // fill missing attributes\n      if (typeof matcherOpts.startKey === 'undefined') {\n        matcherOpts.startKey = INDEX_MIN;\n      }\n      if (typeof matcherOpts.endKey === 'undefined') {\n        matcherOpts.endKey = INDEX_MAX;\n      }\n      if (typeof matcherOpts.inclusiveStart === 'undefined') {\n        matcherOpts.inclusiveStart = true;\n      }\n      if (typeof matcherOpts.inclusiveEnd === 'undefined') {\n        matcherOpts.inclusiveEnd = true;\n      }\n      if (inclusiveStart && !matcherOpts.inclusiveStart) {\n        inclusiveStart = false;\n      }\n      if (inclusiveEnd && !matcherOpts.inclusiveEnd) {\n        inclusiveEnd = false;\n      }\n      return matcherOpts;\n    });\n    var startKeys = opts.map(opt => opt.startKey);\n    var endKeys = opts.map(opt => opt.endKey);\n    var queryPlan = {\n      index,\n      startKeys,\n      endKeys,\n      inclusiveEnd,\n      inclusiveStart,\n      sortSatisfiedByIndex: !hasDescSorting && optimalSortIndexCompareString === index.filter(f => !sortIrrelevevantFields.has(f)).join(','),\n      selectorSatisfiedByIndex: isSelectorSatisfiedByIndex(index, query.selector, startKeys, endKeys)\n    };\n    var quality = rateQueryPlan(schema, query, queryPlan);\n    if (quality >= currentBestQuality || query.index) {\n      currentBestQuality = quality;\n      currentBestQueryPlan = queryPlan;\n    }\n  });\n\n  /**\n   * In all cases and index must be found\n   */\n  if (!currentBestQueryPlan) {\n    throw newRxError('SNH', {\n      query\n    });\n  }\n  return currentBestQueryPlan;\n}\nexport var LOGICAL_OPERATORS = new Set(['$eq', '$gt', '$gte', '$lt', '$lte']);\nexport var LOWER_BOUND_LOGICAL_OPERATORS = new Set(['$eq', '$gt', '$gte']);\nexport var UPPER_BOUND_LOGICAL_OPERATORS = new Set(['$eq', '$lt', '$lte']);\nexport function isSelectorSatisfiedByIndex(index, selector, startKeys, endKeys) {\n  /**\n   * Not satisfied if one or more operators are non-logical\n   * operators that can never be satisfied by an index.\n   */\n  var selectorEntries = Object.entries(selector);\n  var hasNonMatchingOperator = selectorEntries.find(([fieldName, operation]) => {\n    if (!index.includes(fieldName)) {\n      return true;\n    }\n    var hasNonLogicOperator = Object.entries(operation).find(([op, _value]) => !LOGICAL_OPERATORS.has(op));\n    return hasNonLogicOperator;\n  });\n  if (hasNonMatchingOperator) {\n    return false;\n  }\n\n  /**\n   * Not satisfied if contains $and or $or operations.\n   */\n  if (selector.$and || selector.$or) {\n    return false;\n  }\n\n  // ensure all lower bound in index\n  var satisfieldLowerBound = [];\n  var lowerOperatorFieldNames = new Set();\n  for (var [fieldName, operation] of Object.entries(selector)) {\n    if (!index.includes(fieldName)) {\n      return false;\n    }\n\n    // If more then one logic op on the same field, we have to selector-match.\n    var lowerLogicOps = Object.keys(operation).filter(key => LOWER_BOUND_LOGICAL_OPERATORS.has(key));\n    if (lowerLogicOps.length > 1) {\n      return false;\n    }\n    var hasLowerLogicOp = lowerLogicOps[0];\n    if (hasLowerLogicOp) {\n      lowerOperatorFieldNames.add(fieldName);\n    }\n    if (hasLowerLogicOp !== '$eq') {\n      if (satisfieldLowerBound.length > 0) {\n        return false;\n      } else {\n        satisfieldLowerBound.push(hasLowerLogicOp);\n      }\n    }\n  }\n\n  // ensure all upper bound in index\n  var satisfieldUpperBound = [];\n  var upperOperatorFieldNames = new Set();\n  for (var [_fieldName, _operation] of Object.entries(selector)) {\n    if (!index.includes(_fieldName)) {\n      return false;\n    }\n\n    // If more then one logic op on the same field, we have to selector-match.\n    var upperLogicOps = Object.keys(_operation).filter(key => UPPER_BOUND_LOGICAL_OPERATORS.has(key));\n    if (upperLogicOps.length > 1) {\n      return false;\n    }\n    var hasUperLogicOp = upperLogicOps[0];\n    if (hasUperLogicOp) {\n      upperOperatorFieldNames.add(_fieldName);\n    }\n    if (hasUperLogicOp !== '$eq') {\n      if (satisfieldUpperBound.length > 0) {\n        return false;\n      } else {\n        satisfieldUpperBound.push(hasUperLogicOp);\n      }\n    }\n  }\n\n  /**\n   * If the index contains a non-relevant field between\n   * the relevant fields, then the index is not satisfying.\n   */\n  var i = 0;\n  for (var _fieldName2 of index) {\n    for (var set of [lowerOperatorFieldNames, upperOperatorFieldNames]) {\n      if (!set.has(_fieldName2) && set.size > 0) {\n        return false;\n      }\n      set.delete(_fieldName2);\n    }\n    var startKey = startKeys[i];\n    var endKey = endKeys[i];\n    if (startKey !== endKey && lowerOperatorFieldNames.size > 0 && upperOperatorFieldNames.size > 0) {\n      return false;\n    }\n    i++;\n  }\n  return true;\n}\nexport function getMatcherQueryOpts(operator, operatorValue) {\n  switch (operator) {\n    case '$eq':\n      return {\n        startKey: operatorValue,\n        endKey: operatorValue,\n        inclusiveEnd: true,\n        inclusiveStart: true\n      };\n    case '$lte':\n      return {\n        endKey: operatorValue,\n        inclusiveEnd: true\n      };\n    case '$gte':\n      return {\n        startKey: operatorValue,\n        inclusiveStart: true\n      };\n    case '$lt':\n      return {\n        endKey: operatorValue,\n        inclusiveEnd: false\n      };\n    case '$gt':\n      return {\n        startKey: operatorValue,\n        inclusiveStart: false\n      };\n    default:\n      throw new Error('SNH');\n  }\n}\n\n/**\n * Returns a number that determines the quality of the query plan.\n * Higher number means better query plan.\n */\nexport function rateQueryPlan(schema, query, queryPlan) {\n  var quality = 0;\n  var addQuality = value => {\n    if (value > 0) {\n      quality = quality + value;\n    }\n  };\n  var pointsPerMatchingKey = 10;\n  var nonMinKeyCount = countUntilNotMatching(queryPlan.startKeys, keyValue => keyValue !== INDEX_MIN && keyValue !== INDEX_MAX);\n  addQuality(nonMinKeyCount * pointsPerMatchingKey);\n  var nonMaxKeyCount = countUntilNotMatching(queryPlan.startKeys, keyValue => keyValue !== INDEX_MAX && keyValue !== INDEX_MIN);\n  addQuality(nonMaxKeyCount * pointsPerMatchingKey);\n  var equalKeyCount = countUntilNotMatching(queryPlan.startKeys, (keyValue, idx) => {\n    if (keyValue === queryPlan.endKeys[idx]) {\n      return true;\n    } else {\n      return false;\n    }\n  });\n  addQuality(equalKeyCount * pointsPerMatchingKey * 1.5);\n  var pointsIfNoReSortMustBeDone = queryPlan.sortSatisfiedByIndex ? 5 : 0;\n  addQuality(pointsIfNoReSortMustBeDone);\n  return quality;\n}\n//# sourceMappingURL=query-planner.js.map","import { getComposedPrimaryKeyOfDocumentData } from \"../rx-schema-helper.js\";\nimport { getWrittenDocumentsFromBulkWriteResponse, stackCheckpoints } from \"../rx-storage-helper.js\";\nimport { createRevision, ensureNotFalsy, getDefaultRevision, getDefaultRxDocumentMeta, now } from \"../plugins/utils/index.js\";\nexport async function getLastCheckpointDoc(state, direction) {\n  var checkpointDocId = getComposedPrimaryKeyOfDocumentData(state.input.metaInstance.schema, {\n    isCheckpoint: '1',\n    itemId: direction\n  });\n  var checkpointResult = await state.input.metaInstance.findDocumentsById([checkpointDocId], false);\n  var checkpointDoc = checkpointResult[0];\n  state.lastCheckpointDoc[direction] = checkpointDoc;\n  if (checkpointDoc) {\n    return checkpointDoc.checkpointData;\n  } else {\n    return undefined;\n  }\n}\n\n/**\n * Sets the checkpoint,\n * automatically resolves conflicts that appear.\n */\nexport async function setCheckpoint(state, direction, checkpoint) {\n  state.checkpointQueue = state.checkpointQueue.then(async () => {\n    var previousCheckpointDoc = state.lastCheckpointDoc[direction];\n    if (checkpoint &&\n    /**\n     * If the replication is already canceled,\n     * we do not write a checkpoint\n     * because that could mean we write a checkpoint\n     * for data that has been fetched from the master\n     * but not been written to the child.\n     */\n    !state.events.canceled.getValue() && (\n    /**\n     * Only write checkpoint if it is different from before\n     * to have less writes to the storage.\n     */\n\n    !previousCheckpointDoc || JSON.stringify(previousCheckpointDoc.checkpointData) !== JSON.stringify(checkpoint))) {\n      var newDoc = {\n        id: '',\n        isCheckpoint: '1',\n        itemId: direction,\n        _deleted: false,\n        _attachments: {},\n        checkpointData: checkpoint,\n        _meta: getDefaultRxDocumentMeta(),\n        _rev: getDefaultRevision()\n      };\n      newDoc.id = getComposedPrimaryKeyOfDocumentData(state.input.metaInstance.schema, newDoc);\n      while (!state.events.canceled.getValue()) {\n        /**\n         * Instead of just storing the new checkpoint,\n         * we have to stack up the checkpoint with the previous one.\n         * This is required for plugins like the sharding RxStorage\n         * where the changeStream events only contain a Partial of the\n         * checkpoint.\n         */\n        if (previousCheckpointDoc) {\n          newDoc.checkpointData = stackCheckpoints([previousCheckpointDoc.checkpointData, newDoc.checkpointData]);\n        }\n        newDoc._meta.lwt = now();\n        newDoc._rev = createRevision(await state.checkpointKey, previousCheckpointDoc);\n        if (state.events.canceled.getValue()) {\n          return;\n        }\n        var writeRows = [{\n          previous: previousCheckpointDoc,\n          document: newDoc\n        }];\n        var result = await state.input.metaInstance.bulkWrite(writeRows, 'replication-set-checkpoint');\n        var successDoc = getWrittenDocumentsFromBulkWriteResponse(state.primaryPath, writeRows, result)[0];\n        if (successDoc) {\n          state.lastCheckpointDoc[direction] = successDoc;\n          return;\n        } else {\n          var error = result.error[0];\n          if (error.status !== 409) {\n            throw error;\n          } else {\n            previousCheckpointDoc = ensureNotFalsy(error.documentInDb);\n            newDoc._rev = createRevision(await state.checkpointKey, previousCheckpointDoc);\n          }\n        }\n      }\n    }\n  });\n  await state.checkpointQueue;\n}\nexport async function getCheckpointKey(input) {\n  var hash = await input.hashFunction([input.identifier, input.forkInstance.databaseName, input.forkInstance.collectionName].join('||'));\n  return 'rx_storage_replication_' + hash;\n}\n//# sourceMappingURL=checkpoint.js.map","import { getDefaultRevision, createRevision, now, flatClone } from \"../plugins/utils/index.js\";\n\n/**\n * Resolves a conflict error or determines that the given document states are equal.\n * Returns the resolved document that must be written to the fork.\n * Then the new document state can be pushed upstream.\n * If document is not in conflict, returns undefined.\n * If error is non-409, it throws an error.\n * Conflicts are only solved in the upstream, never in the downstream.\n */\nexport async function resolveConflictError(state, input, forkState) {\n  var conflictHandler = state.input.conflictHandler;\n  var isEqual = conflictHandler.isEqual(input.realMasterState, input.newDocumentState, 'replication-resolve-conflict');\n  if (isEqual) {\n    /**\n     * Documents are equal,\n     * so this is not a conflict -> do nothing.\n     */\n    return undefined;\n  } else {\n    var resolved = await conflictHandler.resolve(input, 'replication-resolve-conflict');\n    /**\n     * We have a resolved conflict,\n     * use the resolved document data.\n     */\n    var resolvedDoc = Object.assign({}, resolved, {\n      /**\n       * Because the resolved conflict is written to the fork,\n       * we have to keep/update the forks _meta data, not the masters.\n       */\n      _meta: flatClone(forkState._meta),\n      _rev: getDefaultRevision(),\n      _attachments: flatClone(forkState._attachments)\n    });\n    resolvedDoc._meta.lwt = now();\n    resolvedDoc._rev = createRevision(await state.checkpointKey, forkState);\n    return resolvedDoc;\n  }\n}\n//# sourceMappingURL=conflicts.js.map","import { deepEqual } from \"../plugins/utils/index.js\";\nimport { stripAttachmentsDataFromDocument } from \"../rx-storage-helper.js\";\nexport var defaultConflictHandler = {\n  isEqual(a, b) {\n    /**\n     * If the documents are deep equal,\n     * we have no conflict.\n     * On your custom conflict handler you might only\n     * check some properties, like the updatedAt time,\n     * for better performance, because deepEqual is expensive.\n     */\n    return deepEqual(stripAttachmentsDataFromDocument(a), stripAttachmentsDataFromDocument(b));\n  },\n  resolve(i) {\n    /**\n     * The default conflict handler will always\n     * drop the fork state and use the master state instead.\n     */\n    return i.realMasterState;\n  }\n};\n//# sourceMappingURL=default-conflict-handler.js.map","import { firstValueFrom, filter, mergeMap } from 'rxjs';\nimport { newRxError } from \"../rx-error.js\";\nimport { getWrittenDocumentsFromBulkWriteResponse, stackCheckpoints } from \"../rx-storage-helper.js\";\nimport { appendToArray, createRevision, ensureNotFalsy, flatClone, getDefaultRevision, getHeightOfRevision, now, PROMISE_RESOLVE_VOID } from \"../plugins/utils/index.js\";\nimport { getLastCheckpointDoc, setCheckpoint } from \"./checkpoint.js\";\nimport { stripAttachmentsDataFromMetaWriteRows, writeDocToDocState } from \"./helper.js\";\nimport { getAssumedMasterState, getMetaWriteRow } from \"./meta-instance.js\";\n\n/**\n * Writes all documents from the master to the fork.\n * The downstream has two operation modes\n * - Sync by iterating over the checkpoints via downstreamResyncOnce()\n * - Sync by listening to the changestream via downstreamProcessChanges()\n * We need this to be able to do initial syncs\n * and still can have fast event based sync when the client is not offline.\n */\nexport async function startReplicationDownstream(state) {\n  if (state.input.initialCheckpoint && state.input.initialCheckpoint.downstream) {\n    var checkpointDoc = await getLastCheckpointDoc(state, 'down');\n    if (!checkpointDoc) {\n      await setCheckpoint(state, 'down', state.input.initialCheckpoint.downstream);\n    }\n  }\n  var identifierHash = await state.input.hashFunction(state.input.identifier);\n  var replicationHandler = state.input.replicationHandler;\n\n  // used to detect which tasks etc can in it at which order.\n  var timer = 0;\n  var openTasks = [];\n  function addNewTask(task) {\n    state.stats.down.addNewTask = state.stats.down.addNewTask + 1;\n    var taskWithTime = {\n      time: timer++,\n      task\n    };\n    openTasks.push(taskWithTime);\n    state.streamQueue.down = state.streamQueue.down.then(() => {\n      var useTasks = [];\n      while (openTasks.length > 0) {\n        state.events.active.down.next(true);\n        var innerTaskWithTime = ensureNotFalsy(openTasks.shift());\n\n        /**\n         * If the task came in before the last time we started the pull\n         * from the master, then we can drop the task.\n         */\n        if (innerTaskWithTime.time < lastTimeMasterChangesRequested) {\n          continue;\n        }\n        if (innerTaskWithTime.task === 'RESYNC') {\n          if (useTasks.length === 0) {\n            useTasks.push(innerTaskWithTime.task);\n            break;\n          } else {\n            break;\n          }\n        }\n        useTasks.push(innerTaskWithTime.task);\n      }\n      if (useTasks.length === 0) {\n        return;\n      }\n      if (useTasks[0] === 'RESYNC') {\n        return downstreamResyncOnce();\n      } else {\n        return downstreamProcessChanges(useTasks);\n      }\n    }).then(() => {\n      state.events.active.down.next(false);\n      if (!state.firstSyncDone.down.getValue() && !state.events.canceled.getValue()) {\n        state.firstSyncDone.down.next(true);\n      }\n    });\n  }\n  addNewTask('RESYNC');\n\n  /**\n   * If a write on the master happens, we have to trigger the downstream.\n   * Only do this if not canceled yet, otherwise firstValueFrom errors\n   * when running on a completed observable.\n   */\n  if (!state.events.canceled.getValue()) {\n    var sub = replicationHandler.masterChangeStream$.pipe(mergeMap(async ev => {\n      /**\n       * While a push is running, we have to delay all incoming\n       * events from the server to not mix up the replication state.\n       */\n      await firstValueFrom(state.events.active.up.pipe(filter(s => !s)));\n      return ev;\n    })).subscribe(task => {\n      state.stats.down.masterChangeStreamEmit = state.stats.down.masterChangeStreamEmit + 1;\n      addNewTask(task);\n    });\n    // unsubscribe when replication is canceled\n    firstValueFrom(state.events.canceled.pipe(filter(canceled => !!canceled))).then(() => sub.unsubscribe());\n  }\n\n  /**\n   * For faster performance, we directly start each write\n   * and then await all writes at the end.\n   */\n  var lastTimeMasterChangesRequested = -1;\n  async function downstreamResyncOnce() {\n    state.stats.down.downstreamResyncOnce = state.stats.down.downstreamResyncOnce + 1;\n    if (state.events.canceled.getValue()) {\n      return;\n    }\n    state.checkpointQueue = state.checkpointQueue.then(() => getLastCheckpointDoc(state, 'down'));\n    var lastCheckpoint = await state.checkpointQueue;\n    var promises = [];\n    while (!state.events.canceled.getValue()) {\n      lastTimeMasterChangesRequested = timer++;\n      var downResult = await replicationHandler.masterChangesSince(lastCheckpoint, state.input.pullBatchSize);\n      if (downResult.documents.length === 0) {\n        break;\n      }\n      lastCheckpoint = stackCheckpoints([lastCheckpoint, downResult.checkpoint]);\n      promises.push(persistFromMaster(downResult.documents, lastCheckpoint));\n\n      /**\n       * By definition we stop pull when the pulled documents\n       * do not fill up the pullBatchSize because we\n       * can assume that the remote has no more documents.\n       */\n      if (downResult.documents.length < state.input.pullBatchSize) {\n        break;\n      }\n    }\n    await Promise.all(promises);\n  }\n  function downstreamProcessChanges(tasks) {\n    state.stats.down.downstreamProcessChanges = state.stats.down.downstreamProcessChanges + 1;\n    var docsOfAllTasks = [];\n    var lastCheckpoint = null;\n    tasks.forEach(task => {\n      if (task === 'RESYNC') {\n        throw new Error('SNH');\n      }\n      appendToArray(docsOfAllTasks, task.documents);\n      lastCheckpoint = stackCheckpoints([lastCheckpoint, task.checkpoint]);\n    });\n    return persistFromMaster(docsOfAllTasks, ensureNotFalsy(lastCheckpoint));\n  }\n\n  /**\n   * It can happen that the calls to masterChangesSince() or the changeStream()\n   * are way faster then how fast the documents can be persisted.\n   * Therefore we merge all incoming downResults into the nonPersistedFromMaster object\n   * and process them together if possible.\n   * This often bundles up single writes and improves performance\n   * by processing the documents in bulks.\n   */\n  var persistenceQueue = PROMISE_RESOLVE_VOID;\n  var nonPersistedFromMaster = {\n    docs: {}\n  };\n  function persistFromMaster(docs, checkpoint) {\n    var primaryPath = state.primaryPath;\n    state.stats.down.persistFromMaster = state.stats.down.persistFromMaster + 1;\n\n    /**\n     * Add the new docs to the non-persistent list\n     */\n    docs.forEach(docData => {\n      var docId = docData[primaryPath];\n      nonPersistedFromMaster.docs[docId] = docData;\n    });\n    nonPersistedFromMaster.checkpoint = checkpoint;\n\n    /**\n     * Run in the queue\n     * with all open documents from nonPersistedFromMaster.\n     */\n    persistenceQueue = persistenceQueue.then(() => {\n      var downDocsById = nonPersistedFromMaster.docs;\n      nonPersistedFromMaster.docs = {};\n      var useCheckpoint = nonPersistedFromMaster.checkpoint;\n      var docIds = Object.keys(downDocsById);\n      if (state.events.canceled.getValue() || docIds.length === 0) {\n        return PROMISE_RESOLVE_VOID;\n      }\n      var writeRowsToFork = [];\n      var writeRowsToForkById = {};\n      var writeRowsToMeta = {};\n      var useMetaWriteRows = [];\n      return Promise.all([state.input.forkInstance.findDocumentsById(docIds, true), getAssumedMasterState(state, docIds)]).then(([currentForkStateList, assumedMasterState]) => {\n        var currentForkState = new Map();\n        currentForkStateList.forEach(doc => currentForkState.set(doc[primaryPath], doc));\n        return Promise.all(docIds.map(async docId => {\n          var forkStateFullDoc = currentForkState.get(docId);\n          var forkStateDocData = forkStateFullDoc ? writeDocToDocState(forkStateFullDoc, state.hasAttachments, false) : undefined;\n          var masterState = downDocsById[docId];\n          var assumedMaster = assumedMasterState[docId];\n          if (assumedMaster && forkStateFullDoc && assumedMaster.metaDocument.isResolvedConflict === forkStateFullDoc._rev) {\n            /**\n             * The current fork state represents a resolved conflict\n             * that first must be send to the master in the upstream.\n             * All conflicts are resolved by the upstream.\n             */\n            // return PROMISE_RESOLVE_VOID;\n            await state.streamQueue.up;\n          }\n          var isAssumedMasterEqualToForkState = !assumedMaster || !forkStateDocData ? false : state.input.conflictHandler.isEqual(assumedMaster.docData, forkStateDocData, 'downstream-check-if-equal-0');\n          if (!isAssumedMasterEqualToForkState && assumedMaster && assumedMaster.docData._rev && forkStateFullDoc && forkStateFullDoc._meta[state.input.identifier] && getHeightOfRevision(forkStateFullDoc._rev) === forkStateFullDoc._meta[state.input.identifier]) {\n            isAssumedMasterEqualToForkState = true;\n          }\n          if (forkStateFullDoc && assumedMaster && isAssumedMasterEqualToForkState === false || forkStateFullDoc && !assumedMaster) {\n            /**\n             * We have a non-upstream-replicated\n             * local write to the fork.\n             * This means we ignore the downstream of this document\n             * because anyway the upstream will first resolve the conflict.\n             */\n            return PROMISE_RESOLVE_VOID;\n          }\n          var areStatesExactlyEqual = !forkStateDocData ? false : state.input.conflictHandler.isEqual(masterState, forkStateDocData, 'downstream-check-if-equal-1');\n          if (forkStateDocData && areStatesExactlyEqual) {\n            /**\n             * Document states are exactly equal.\n             * This can happen when the replication is shut down\n             * unexpected like when the user goes offline.\n             *\n             * Only when the assumedMaster is different from the forkState,\n             * we have to patch the document in the meta instance.\n             */\n            if (!assumedMaster || isAssumedMasterEqualToForkState === false) {\n              useMetaWriteRows.push(await getMetaWriteRow(state, forkStateDocData, assumedMaster ? assumedMaster.metaDocument : undefined));\n            }\n            return PROMISE_RESOLVE_VOID;\n          }\n\n          /**\n           * All other master states need to be written to the forkInstance\n           * and metaInstance.\n           */\n          var newForkState = Object.assign({}, masterState, forkStateFullDoc ? {\n            _meta: flatClone(forkStateFullDoc._meta),\n            _attachments: state.hasAttachments && masterState._attachments ? masterState._attachments : {},\n            _rev: getDefaultRevision()\n          } : {\n            _meta: {\n              lwt: now()\n            },\n            _rev: getDefaultRevision(),\n            _attachments: state.hasAttachments && masterState._attachments ? masterState._attachments : {}\n          });\n          /**\n           * If the remote works with revisions,\n           * we store the height of the next fork-state revision\n           * inside of the documents meta data.\n           * By doing so we can filter it out in the upstream\n           * and detect the document as being equal to master or not.\n           * This is used for example in the CouchDB replication plugin.\n           */\n          if (masterState._rev) {\n            var nextRevisionHeight = !forkStateFullDoc ? 1 : getHeightOfRevision(forkStateFullDoc._rev) + 1;\n            newForkState._meta[state.input.identifier] = nextRevisionHeight;\n            if (state.input.keepMeta) {\n              newForkState._rev = masterState._rev;\n            }\n          }\n          if (state.input.keepMeta && masterState._meta) {\n            newForkState._meta = masterState._meta;\n          }\n          var forkWriteRow = {\n            previous: forkStateFullDoc,\n            document: newForkState\n          };\n          forkWriteRow.document._rev = forkWriteRow.document._rev ? forkWriteRow.document._rev : createRevision(identifierHash, forkWriteRow.previous);\n          writeRowsToFork.push(forkWriteRow);\n          writeRowsToForkById[docId] = forkWriteRow;\n          writeRowsToMeta[docId] = await getMetaWriteRow(state, masterState, assumedMaster ? assumedMaster.metaDocument : undefined);\n        }));\n      }).then(async () => {\n        if (writeRowsToFork.length > 0) {\n          return state.input.forkInstance.bulkWrite(writeRowsToFork, await state.downstreamBulkWriteFlag).then(forkWriteResult => {\n            var success = getWrittenDocumentsFromBulkWriteResponse(state.primaryPath, writeRowsToFork, forkWriteResult);\n            success.forEach(doc => {\n              var docId = doc[primaryPath];\n              state.events.processed.down.next(writeRowsToForkById[docId]);\n              useMetaWriteRows.push(writeRowsToMeta[docId]);\n            });\n            var mustThrow;\n            forkWriteResult.error.forEach(error => {\n              /**\n               * We do not have to care about downstream conflict errors here\n               * because on conflict, it will be solved locally and result in another write.\n               */\n              if (error.status === 409) {\n                return;\n              }\n              // other non-conflict errors must be handled\n              var throwMe = newRxError('RC_PULL', {\n                writeError: error\n              });\n              state.events.error.next(throwMe);\n              mustThrow = throwMe;\n            });\n            if (mustThrow) {\n              throw mustThrow;\n            }\n          });\n        }\n      }).then(() => {\n        if (useMetaWriteRows.length > 0) {\n          return state.input.metaInstance.bulkWrite(stripAttachmentsDataFromMetaWriteRows(state, useMetaWriteRows), 'replication-down-write-meta').then(metaWriteResult => {\n            metaWriteResult.error.forEach(writeError => {\n              state.events.error.next(newRxError('RC_PULL', {\n                id: writeError.documentId,\n                writeError\n              }));\n            });\n          });\n        }\n      }).then(() => {\n        /**\n         * For better performance we do not await checkpoint writes,\n         * but to ensure order on parallel checkpoint writes,\n         * we have to use a queue.\n         */\n        setCheckpoint(state, 'down', useCheckpoint);\n      });\n    }).catch(unhandledError => state.events.error.next(unhandledError));\n    return persistenceQueue;\n  }\n}\n//# sourceMappingURL=downstream.js.map","import { clone, createRevision, flatClone, getDefaultRevision, now } from \"../plugins/utils/index.js\";\nimport { stripAttachmentsDataFromDocument } from \"../rx-storage-helper.js\";\nexport function docStateToWriteDoc(databaseInstanceToken, hasAttachments, keepMeta, docState, previous) {\n  var docData = Object.assign({}, docState, {\n    _attachments: hasAttachments && docState._attachments ? docState._attachments : {},\n    _meta: keepMeta ? docState._meta : Object.assign({}, previous ? previous._meta : {}, {\n      lwt: now()\n    }),\n    _rev: keepMeta ? docState._rev : getDefaultRevision()\n  });\n  if (!docData._rev) {\n    docData._rev = createRevision(databaseInstanceToken, previous);\n  }\n  return docData;\n}\nexport function writeDocToDocState(writeDoc, keepAttachments, keepMeta) {\n  var ret = flatClone(writeDoc);\n  if (!keepAttachments) {\n    delete ret._attachments;\n  }\n  if (!keepMeta) {\n    delete ret._meta;\n    delete ret._rev;\n  }\n  return ret;\n}\nexport function stripAttachmentsDataFromMetaWriteRows(state, rows) {\n  if (!state.hasAttachments) {\n    return rows;\n  }\n  return rows.map(row => {\n    var document = clone(row.document);\n    document.docData = stripAttachmentsDataFromDocument(document.docData);\n    return {\n      document,\n      previous: row.previous\n    };\n  });\n}\nexport function getUnderlyingPersistentStorage(instance) {\n  while (true) {\n    if (instance.underlyingPersistentStorage) {\n      instance = instance.underlyingPersistentStorage;\n    } else {\n      return instance;\n    }\n  }\n}\n//# sourceMappingURL=helper.js.map","/**\n * These files contain the replication protocol.\n * It can be used to replicated RxStorageInstances or RxCollections\n * or even to do a client(s)-server replication.\n */\n\nimport { BehaviorSubject, combineLatest, filter, firstValueFrom, mergeMap, Subject } from 'rxjs';\nimport { getPrimaryFieldOfPrimaryKey } from \"../rx-schema-helper.js\";\nimport { clone, ensureNotFalsy, flatClone, PROMISE_RESOLVE_VOID } from \"../plugins/utils/index.js\";\nimport { getCheckpointKey } from \"./checkpoint.js\";\nimport { startReplicationDownstream } from \"./downstream.js\";\nimport { docStateToWriteDoc, getUnderlyingPersistentStorage, writeDocToDocState } from \"./helper.js\";\nimport { startReplicationUpstream } from \"./upstream.js\";\nimport { fillWriteDataForAttachmentsChange } from \"../plugins/attachments/index.js\";\nimport { getChangedDocumentsSince } from \"../rx-storage-helper.js\";\nimport { newRxError } from \"../rx-error.js\";\nexport * from \"./checkpoint.js\";\nexport * from \"./downstream.js\";\nexport * from \"./upstream.js\";\nexport * from \"./meta-instance.js\";\nexport * from \"./conflicts.js\";\nexport * from \"./helper.js\";\nexport * from \"./default-conflict-handler.js\";\nexport function replicateRxStorageInstance(input) {\n  input = flatClone(input);\n  input.forkInstance = getUnderlyingPersistentStorage(input.forkInstance);\n  input.metaInstance = getUnderlyingPersistentStorage(input.metaInstance);\n  var checkpointKeyPromise = getCheckpointKey(input);\n  var state = {\n    primaryPath: getPrimaryFieldOfPrimaryKey(input.forkInstance.schema.primaryKey),\n    hasAttachments: !!input.forkInstance.schema.attachments,\n    input,\n    checkpointKey: checkpointKeyPromise,\n    downstreamBulkWriteFlag: checkpointKeyPromise.then(checkpointKey => 'replication-downstream-' + checkpointKey),\n    events: {\n      canceled: new BehaviorSubject(false),\n      paused: new BehaviorSubject(false),\n      active: {\n        down: new BehaviorSubject(true),\n        up: new BehaviorSubject(true)\n      },\n      processed: {\n        down: new Subject(),\n        up: new Subject()\n      },\n      resolvedConflicts: new Subject(),\n      error: new Subject()\n    },\n    stats: {\n      down: {\n        addNewTask: 0,\n        downstreamProcessChanges: 0,\n        downstreamResyncOnce: 0,\n        masterChangeStreamEmit: 0,\n        persistFromMaster: 0\n      },\n      up: {\n        forkChangeStreamEmit: 0,\n        persistToMaster: 0,\n        persistToMasterConflictWrites: 0,\n        persistToMasterHadConflicts: 0,\n        processTasks: 0,\n        upstreamInitialSync: 0\n      }\n    },\n    firstSyncDone: {\n      down: new BehaviorSubject(false),\n      up: new BehaviorSubject(false)\n    },\n    streamQueue: {\n      down: PROMISE_RESOLVE_VOID,\n      up: PROMISE_RESOLVE_VOID\n    },\n    checkpointQueue: PROMISE_RESOLVE_VOID,\n    lastCheckpointDoc: {}\n  };\n  startReplicationDownstream(state);\n  startReplicationUpstream(state);\n  return state;\n}\nexport function awaitRxStorageReplicationFirstInSync(state) {\n  return firstValueFrom(combineLatest([state.firstSyncDone.down.pipe(filter(v => !!v)), state.firstSyncDone.up.pipe(filter(v => !!v))])).then(() => {});\n}\nexport function awaitRxStorageReplicationInSync(replicationState) {\n  return Promise.all([replicationState.streamQueue.up, replicationState.streamQueue.down, replicationState.checkpointQueue]);\n}\nexport async function awaitRxStorageReplicationIdle(state) {\n  await awaitRxStorageReplicationFirstInSync(state);\n  while (true) {\n    var {\n      down,\n      up\n    } = state.streamQueue;\n    await Promise.all([up, down]);\n    /**\n     * If the Promises have not been reassigned\n     * after awaiting them, we know that the replication\n     * is in idle state at this point in time.\n     */\n    if (down === state.streamQueue.down && up === state.streamQueue.up) {\n      return;\n    }\n  }\n}\nexport function rxStorageInstanceToReplicationHandler(instance, conflictHandler, databaseInstanceToken,\n/**\n * If set to true,\n * the _meta.lwt from the pushed documents is kept.\n * (Used in the migration to ensure checkpoints are still valid)\n */\nkeepMeta = false) {\n  instance = getUnderlyingPersistentStorage(instance);\n  var hasAttachments = !!instance.schema.attachments;\n  var primaryPath = getPrimaryFieldOfPrimaryKey(instance.schema.primaryKey);\n  var replicationHandler = {\n    masterChangeStream$: instance.changeStream().pipe(mergeMap(async eventBulk => {\n      var ret = {\n        checkpoint: eventBulk.checkpoint,\n        documents: await Promise.all(eventBulk.events.map(async event => {\n          var docData = writeDocToDocState(event.documentData, hasAttachments, keepMeta);\n          if (hasAttachments) {\n            docData = await fillWriteDataForAttachmentsChange(primaryPath, instance, clone(docData),\n            /**\n             * Notice that the master never knows\n             * the client state of the document.\n             * Therefore we always send all attachments data.\n             */\n            undefined);\n          }\n          return docData;\n        }))\n      };\n      return ret;\n    })),\n    masterChangesSince(checkpoint, batchSize) {\n      return getChangedDocumentsSince(instance, batchSize, checkpoint).then(async result => {\n        return {\n          checkpoint: result.documents.length > 0 ? result.checkpoint : checkpoint,\n          documents: await Promise.all(result.documents.map(async plainDocumentData => {\n            var docData = writeDocToDocState(plainDocumentData, hasAttachments, keepMeta);\n            if (hasAttachments) {\n              docData = await fillWriteDataForAttachmentsChange(primaryPath, instance, clone(docData),\n              /**\n               * Notice the the master never knows\n               * the client state of the document.\n               * Therefore we always send all attachments data.\n               */\n              undefined);\n            }\n            return docData;\n          }))\n        };\n      });\n    },\n    async masterWrite(rows) {\n      var rowById = {};\n      rows.forEach(row => {\n        var docId = row.newDocumentState[primaryPath];\n        rowById[docId] = row;\n      });\n      var ids = Object.keys(rowById);\n      var masterDocsStateList = await instance.findDocumentsById(ids, true);\n      var masterDocsState = new Map();\n      masterDocsStateList.forEach(doc => masterDocsState.set(doc[primaryPath], doc));\n      var conflicts = [];\n      var writeRows = [];\n      await Promise.all(Object.entries(rowById).map(([id, row]) => {\n        var masterState = masterDocsState.get(id);\n        if (!masterState) {\n          writeRows.push({\n            document: docStateToWriteDoc(databaseInstanceToken, hasAttachments, keepMeta, row.newDocumentState)\n          });\n        } else if (masterState && !row.assumedMasterState) {\n          conflicts.push(writeDocToDocState(masterState, hasAttachments, keepMeta));\n        } else if (conflictHandler.isEqual(writeDocToDocState(masterState, hasAttachments, keepMeta), ensureNotFalsy(row.assumedMasterState), 'rxStorageInstanceToReplicationHandler-masterWrite') === true) {\n          writeRows.push({\n            previous: masterState,\n            document: docStateToWriteDoc(databaseInstanceToken, hasAttachments, keepMeta, row.newDocumentState, masterState)\n          });\n        } else {\n          conflicts.push(writeDocToDocState(masterState, hasAttachments, keepMeta));\n        }\n      }));\n      if (writeRows.length > 0) {\n        var result = await instance.bulkWrite(writeRows, 'replication-master-write');\n        result.error.forEach(err => {\n          if (err.status !== 409) {\n            throw newRxError('SNH', {\n              name: 'non conflict error',\n              error: err\n            });\n          } else {\n            conflicts.push(writeDocToDocState(ensureNotFalsy(err.documentInDb), hasAttachments, keepMeta));\n          }\n        });\n      }\n      return conflicts;\n    }\n  };\n  return replicationHandler;\n}\nexport async function cancelRxStorageReplication(replicationState) {\n  replicationState.events.canceled.next(true);\n  replicationState.events.active.up.complete();\n  replicationState.events.active.down.complete();\n  replicationState.events.processed.up.complete();\n  replicationState.events.processed.down.complete();\n  replicationState.events.resolvedConflicts.complete();\n  replicationState.events.canceled.complete();\n  await replicationState.checkpointQueue;\n}\n//# sourceMappingURL=index.js.map","import { fillWithDefaultSettings, getComposedPrimaryKeyOfDocumentData, getLengthOfPrimaryKey } from \"../rx-schema-helper.js\";\nimport { flatCloneDocWithMeta } from \"../rx-storage-helper.js\";\nimport { getDefaultRevision, createRevision, now } from \"../plugins/utils/index.js\";\nexport var META_INSTANCE_SCHEMA_TITLE = 'RxReplicationProtocolMetaData';\nexport function getRxReplicationMetaInstanceSchema(replicatedDocumentsSchema, encrypted) {\n  var parentPrimaryKeyLength = getLengthOfPrimaryKey(replicatedDocumentsSchema);\n  var baseSchema = {\n    title: META_INSTANCE_SCHEMA_TITLE,\n    primaryKey: {\n      key: 'id',\n      fields: ['itemId', 'isCheckpoint'],\n      separator: '|'\n    },\n    type: 'object',\n    version: replicatedDocumentsSchema.version,\n    additionalProperties: false,\n    properties: {\n      id: {\n        type: 'string',\n        minLength: 1,\n        // add +1 for the '|' and +1 for the 'isCheckpoint' flag\n        maxLength: parentPrimaryKeyLength + 2\n      },\n      isCheckpoint: {\n        type: 'string',\n        enum: ['0', '1'],\n        minLength: 1,\n        maxLength: 1\n      },\n      itemId: {\n        type: 'string',\n        /**\n         * ensure that all values of RxStorageReplicationDirection ('DOWN' has 4 chars) fit into it\n         * because checkpoints use the itemId field for that.\n         */\n        maxLength: parentPrimaryKeyLength > 4 ? parentPrimaryKeyLength : 4\n      },\n      checkpointData: {\n        type: 'object',\n        additionalProperties: true\n      },\n      docData: {\n        type: 'object',\n        properties: replicatedDocumentsSchema.properties\n      },\n      isResolvedConflict: {\n        type: 'string'\n      }\n    },\n    keyCompression: replicatedDocumentsSchema.keyCompression,\n    required: ['id', 'isCheckpoint', 'itemId']\n  };\n  if (encrypted) {\n    baseSchema.encrypted = ['docData'];\n  }\n  var metaInstanceSchema = fillWithDefaultSettings(baseSchema);\n  return metaInstanceSchema;\n}\n\n/**\n * Returns the document states of what the fork instance\n * assumes to be the latest state on the master instance.\n */\nexport function getAssumedMasterState(state, docIds) {\n  return state.input.metaInstance.findDocumentsById(docIds.map(docId => {\n    var useId = getComposedPrimaryKeyOfDocumentData(state.input.metaInstance.schema, {\n      itemId: docId,\n      isCheckpoint: '0'\n    });\n    return useId;\n  }), true).then(metaDocs => {\n    var ret = {};\n    Object.values(metaDocs).forEach(metaDoc => {\n      ret[metaDoc.itemId] = {\n        docData: metaDoc.docData,\n        metaDocument: metaDoc\n      };\n    });\n    return ret;\n  });\n}\nexport async function getMetaWriteRow(state, newMasterDocState, previous, isResolvedConflict) {\n  var docId = newMasterDocState[state.primaryPath];\n  var newMeta = previous ? flatCloneDocWithMeta(previous) : {\n    id: '',\n    isCheckpoint: '0',\n    itemId: docId,\n    docData: newMasterDocState,\n    _attachments: {},\n    _deleted: false,\n    _rev: getDefaultRevision(),\n    _meta: {\n      lwt: 0\n    }\n  };\n  newMeta.docData = newMasterDocState;\n\n  /**\n   * Sending isResolvedConflict with the value undefined\n   * will throw a schema validation error because it must be either\n   * not set or have a string.\n   */\n  if (isResolvedConflict) {\n    newMeta.isResolvedConflict = isResolvedConflict;\n  }\n  newMeta._meta.lwt = now();\n  newMeta.id = getComposedPrimaryKeyOfDocumentData(state.input.metaInstance.schema, newMeta);\n  newMeta._rev = createRevision(await state.checkpointKey, previous);\n  var ret = {\n    previous,\n    document: newMeta\n  };\n  return ret;\n}\n//# sourceMappingURL=meta-instance.js.map","import { firstValueFrom, filter } from 'rxjs';\nimport { getChangedDocumentsSince, getWrittenDocumentsFromBulkWriteResponse, stackCheckpoints } from \"../rx-storage-helper.js\";\nimport { appendToArray, batchArray, clone, ensureNotFalsy, getHeightOfRevision, PROMISE_RESOLVE_FALSE } from \"../plugins/utils/index.js\";\nimport { getLastCheckpointDoc, setCheckpoint } from \"./checkpoint.js\";\nimport { resolveConflictError } from \"./conflicts.js\";\nimport { stripAttachmentsDataFromMetaWriteRows, writeDocToDocState } from \"./helper.js\";\nimport { getAssumedMasterState, getMetaWriteRow } from \"./meta-instance.js\";\nimport { fillWriteDataForAttachmentsChange } from \"../plugins/attachments/index.js\";\nimport { newRxError } from \"../rx-error.js\";\n\n/**\n * Writes all document changes from the fork to the master.\n * The upstream runs on two modes:\n * - For initial replication, a checkpoint-iteration is used\n * - For ongoing local writes, we just subscribe to the changeStream of the fork.\n *   In contrast to the master, the fork can be assumed to never loose connection,\n *   so we do not have to prepare for missed out events.\n */\nexport async function startReplicationUpstream(state) {\n  if (state.input.initialCheckpoint && state.input.initialCheckpoint.upstream) {\n    var checkpointDoc = await getLastCheckpointDoc(state, 'up');\n    if (!checkpointDoc) {\n      await setCheckpoint(state, 'up', state.input.initialCheckpoint.upstream);\n    }\n  }\n  var replicationHandler = state.input.replicationHandler;\n  state.streamQueue.up = state.streamQueue.up.then(() => {\n    return upstreamInitialSync().then(() => {\n      return processTasks();\n    });\n  });\n\n  // used to detect which tasks etc can in it at which order.\n  var timer = 0;\n  var initialSyncStartTime = -1;\n  var openTasks = [];\n  var persistenceQueue = PROMISE_RESOLVE_FALSE;\n  var nonPersistedFromMaster = {\n    docs: {}\n  };\n  var sub = state.input.forkInstance.changeStream().subscribe(eventBulk => {\n    if (state.events.paused.getValue()) {\n      return;\n    }\n    state.stats.up.forkChangeStreamEmit = state.stats.up.forkChangeStreamEmit + 1;\n    openTasks.push({\n      task: eventBulk,\n      time: timer++\n    });\n    if (!state.events.active.up.getValue()) {\n      state.events.active.up.next(true);\n    }\n    if (state.input.waitBeforePersist) {\n      return state.input.waitBeforePersist().then(() => processTasks());\n    } else {\n      return processTasks();\n    }\n  });\n  var subResync = replicationHandler.masterChangeStream$.pipe(filter(ev => ev === 'RESYNC')).subscribe(() => {\n    openTasks.push({\n      task: 'RESYNC',\n      time: timer++\n    });\n    processTasks();\n  });\n\n  // unsubscribe when replication is canceled\n  firstValueFrom(state.events.canceled.pipe(filter(canceled => !!canceled))).then(() => {\n    sub.unsubscribe();\n    subResync.unsubscribe();\n  });\n  async function upstreamInitialSync() {\n    state.stats.up.upstreamInitialSync = state.stats.up.upstreamInitialSync + 1;\n    if (state.events.canceled.getValue()) {\n      return;\n    }\n    state.checkpointQueue = state.checkpointQueue.then(() => getLastCheckpointDoc(state, 'up'));\n    var lastCheckpoint = await state.checkpointQueue;\n    var promises = new Set();\n    var _loop = async function () {\n      initialSyncStartTime = timer++;\n\n      /**\n       * Throttle the calls to\n       * forkInstance.getChangedDocumentsSince() so that\n       * if the pushing to the remote is slower compared to the\n       * pulling out of forkInstance, we do not block the UI too much\n       * and have a big memory spike with all forkInstance documents.\n       */\n      if (promises.size > 3) {\n        await Promise.race(Array.from(promises));\n      }\n      var upResult = await getChangedDocumentsSince(state.input.forkInstance, state.input.pushBatchSize, lastCheckpoint);\n      if (upResult.documents.length === 0) {\n        return 1; // break\n      }\n      lastCheckpoint = stackCheckpoints([lastCheckpoint, upResult.checkpoint]);\n      var promise = persistToMaster(upResult.documents, ensureNotFalsy(lastCheckpoint));\n      promises.add(promise);\n      promise.catch().then(() => promises.delete(promise));\n    };\n    while (!state.events.canceled.getValue()) {\n      if (await _loop()) break;\n    }\n\n    /**\n     * If we had conflicts during the initial sync,\n     * it means that we likely have new writes to the fork\n     * and so we have to run the initial sync again to upstream these new writes.\n     */\n    var resolvedPromises = await Promise.all(promises);\n    var hadConflicts = resolvedPromises.find(r => !!r);\n    if (hadConflicts) {\n      await upstreamInitialSync();\n    } else if (!state.firstSyncDone.up.getValue() && !state.events.canceled.getValue()) {\n      state.firstSyncDone.up.next(true);\n    }\n  }\n\n  /**\n   * Takes all open tasks an processes them at once.\n   */\n  function processTasks() {\n    if (state.events.canceled.getValue() || openTasks.length === 0) {\n      state.events.active.up.next(false);\n      return;\n    }\n    state.stats.up.processTasks = state.stats.up.processTasks + 1;\n    state.events.active.up.next(true);\n    state.streamQueue.up = state.streamQueue.up.then(async () => {\n      /**\n       * Merge/filter all open tasks\n       */\n      var docs = [];\n      var checkpoint = {};\n      while (openTasks.length > 0) {\n        var taskWithTime = ensureNotFalsy(openTasks.shift());\n        /**\n         * If the task came in before the last time the initial sync fetching\n         * has run, we can ignore the task because the initial sync already processed\n         * these documents.\n         */\n        if (taskWithTime.time < initialSyncStartTime) {\n          continue;\n        }\n        if (taskWithTime.task === 'RESYNC') {\n          state.events.active.up.next(false);\n          await upstreamInitialSync();\n          return;\n        }\n\n        /**\n         * If the task came from the downstream, we can ignore these documents\n         * because we know they are replicated already.\n         * But even if they can be ignored, we later have to call persistToMaster()\n         * to have the correct checkpoint set.\n         */\n        if (taskWithTime.task.context !== (await state.downstreamBulkWriteFlag)) {\n          appendToArray(docs, taskWithTime.task.events.map(r => {\n            return r.documentData;\n          }));\n        }\n        checkpoint = stackCheckpoints([checkpoint, taskWithTime.task.checkpoint]);\n      }\n      await persistToMaster(docs, checkpoint);\n\n      // might have got more tasks while running persistToMaster()\n      if (openTasks.length === 0) {\n        state.events.active.up.next(false);\n      } else {\n        return processTasks();\n      }\n    });\n  }\n\n  /**\n   * Returns true if had conflicts,\n   * false if not.\n   */\n  function persistToMaster(docs, checkpoint) {\n    state.stats.up.persistToMaster = state.stats.up.persistToMaster + 1;\n\n    /**\n     * Add the new docs to the non-persistent list\n     */\n    docs.forEach(docData => {\n      var docId = docData[state.primaryPath];\n      nonPersistedFromMaster.docs[docId] = docData;\n    });\n    nonPersistedFromMaster.checkpoint = checkpoint;\n    persistenceQueue = persistenceQueue.then(async () => {\n      if (state.events.canceled.getValue()) {\n        return false;\n      }\n      var upDocsById = nonPersistedFromMaster.docs;\n      nonPersistedFromMaster.docs = {};\n      var useCheckpoint = nonPersistedFromMaster.checkpoint;\n      var docIds = Object.keys(upDocsById);\n      /**\n       * Even if we do not have anything to push,\n       * we still have to store the up-checkpoint.\n       * This ensures that when many documents have been pulled\n       * from the remote (that do not have to be pushed again),\n       * we continue at the correct position and do not have to load\n       * these documents from the storage again when the replication is restarted.\n       */\n      function rememberCheckpointBeforeReturn() {\n        return setCheckpoint(state, 'up', useCheckpoint);\n      }\n      ;\n      if (docIds.length === 0) {\n        rememberCheckpointBeforeReturn();\n        return false;\n      }\n      var assumedMasterState = await getAssumedMasterState(state, docIds);\n      var writeRowsToMaster = {};\n      var writeRowsToMasterIds = [];\n      var writeRowsToMeta = {};\n      var forkStateById = {};\n      await Promise.all(docIds.map(async docId => {\n        var fullDocData = upDocsById[docId];\n        forkStateById[docId] = fullDocData;\n        var docData = writeDocToDocState(fullDocData, state.hasAttachments, !!state.input.keepMeta);\n        var assumedMasterDoc = assumedMasterState[docId];\n\n        /**\n         * If the master state is equal to the\n         * fork state, we can assume that the document state is already\n         * replicated.\n         */\n        if (assumedMasterDoc &&\n        // if the isResolvedConflict is correct, we do not have to compare the documents.\n        assumedMasterDoc.metaDocument.isResolvedConflict !== fullDocData._rev && state.input.conflictHandler.isEqual(assumedMasterDoc.docData, docData, 'upstream-check-if-equal') || (\n        /**\n         * If the master works with _rev fields,\n         * we use that to check if our current doc state\n         * is different from the assumedMasterDoc.\n         */\n\n        assumedMasterDoc && assumedMasterDoc.docData._rev && getHeightOfRevision(fullDocData._rev) === fullDocData._meta[state.input.identifier])) {\n          return;\n        }\n        writeRowsToMasterIds.push(docId);\n        writeRowsToMaster[docId] = {\n          assumedMasterState: assumedMasterDoc ? assumedMasterDoc.docData : undefined,\n          newDocumentState: docData\n        };\n        writeRowsToMeta[docId] = await getMetaWriteRow(state, docData, assumedMasterDoc ? assumedMasterDoc.metaDocument : undefined);\n      }));\n      if (writeRowsToMasterIds.length === 0) {\n        rememberCheckpointBeforeReturn();\n        return false;\n      }\n      var writeRowsArray = Object.values(writeRowsToMaster);\n      var conflictIds = new Set();\n      var conflictsById = {};\n\n      /**\n       * To always respect the push.batchSize,\n       * we have to split the write rows into batches\n       * to ensure that replicationHandler.masterWrite() is never\n       * called with more documents than what the batchSize limits.\n       */\n      var writeBatches = batchArray(writeRowsArray, state.input.pushBatchSize);\n      await Promise.all(writeBatches.map(async writeBatch => {\n        // enhance docs with attachments\n        if (state.hasAttachments) {\n          await Promise.all(writeBatch.map(async row => {\n            row.newDocumentState = await fillWriteDataForAttachmentsChange(state.primaryPath, state.input.forkInstance, clone(row.newDocumentState), row.assumedMasterState);\n          }));\n        }\n        var masterWriteResult = await replicationHandler.masterWrite(writeBatch);\n        masterWriteResult.forEach(conflictDoc => {\n          var id = conflictDoc[state.primaryPath];\n          conflictIds.add(id);\n          conflictsById[id] = conflictDoc;\n        });\n      }));\n      var useWriteRowsToMeta = [];\n      writeRowsToMasterIds.forEach(docId => {\n        if (!conflictIds.has(docId)) {\n          state.events.processed.up.next(writeRowsToMaster[docId]);\n          useWriteRowsToMeta.push(writeRowsToMeta[docId]);\n        }\n      });\n      if (state.events.canceled.getValue()) {\n        return false;\n      }\n      if (useWriteRowsToMeta.length > 0) {\n        await state.input.metaInstance.bulkWrite(stripAttachmentsDataFromMetaWriteRows(state, useWriteRowsToMeta), 'replication-up-write-meta');\n        // TODO what happens when we have conflicts here?\n      }\n\n      /**\n       * Resolve conflicts by writing a new document\n       * state to the fork instance and the 'real' master state\n       * to the meta instance.\n       * Non-409 errors will be detected by resolveConflictError()\n       */\n      var hadConflictWrites = false;\n      if (conflictIds.size > 0) {\n        state.stats.up.persistToMasterHadConflicts = state.stats.up.persistToMasterHadConflicts + 1;\n        var conflictWriteFork = [];\n        var conflictWriteMeta = {};\n        await Promise.all(Object.entries(conflictsById).map(([docId, realMasterState]) => {\n          var writeToMasterRow = writeRowsToMaster[docId];\n          var input = {\n            newDocumentState: writeToMasterRow.newDocumentState,\n            assumedMasterState: writeToMasterRow.assumedMasterState,\n            realMasterState\n          };\n          return resolveConflictError(state, input, forkStateById[docId]).then(async resolved => {\n            if (resolved) {\n              state.events.resolvedConflicts.next({\n                input,\n                output: resolved\n              });\n              conflictWriteFork.push({\n                previous: forkStateById[docId],\n                document: resolved\n              });\n              var assumedMasterDoc = assumedMasterState[docId];\n              conflictWriteMeta[docId] = await getMetaWriteRow(state, ensureNotFalsy(realMasterState), assumedMasterDoc ? assumedMasterDoc.metaDocument : undefined, resolved._rev);\n            }\n          });\n        }));\n        if (conflictWriteFork.length > 0) {\n          hadConflictWrites = true;\n          state.stats.up.persistToMasterConflictWrites = state.stats.up.persistToMasterConflictWrites + 1;\n          var forkWriteResult = await state.input.forkInstance.bulkWrite(conflictWriteFork, 'replication-up-write-conflict');\n          var mustThrow;\n          forkWriteResult.error.forEach(error => {\n            /**\n             * Conflict-Errors in the forkWriteResult must not be handled\n             * because they have been caused by a write to the forkInstance\n             * in between which will anyway trigger a new upstream cycle\n             * that will then resolved the conflict again.\n             */\n            if (error.status === 409) {\n              return;\n            }\n            // other non-conflict errors must be handled\n            var throwMe = newRxError('RC_PUSH', {\n              writeError: error\n            });\n            state.events.error.next(throwMe);\n            mustThrow = throwMe;\n          });\n          if (mustThrow) {\n            throw mustThrow;\n          }\n          var useMetaWrites = [];\n          var success = getWrittenDocumentsFromBulkWriteResponse(state.primaryPath, conflictWriteFork, forkWriteResult);\n          success.forEach(docData => {\n            var docId = docData[state.primaryPath];\n            useMetaWrites.push(conflictWriteMeta[docId]);\n          });\n          if (useMetaWrites.length > 0) {\n            await state.input.metaInstance.bulkWrite(stripAttachmentsDataFromMetaWriteRows(state, useMetaWrites), 'replication-up-write-conflict-meta');\n          }\n          // TODO what to do with conflicts while writing to the metaInstance?\n        }\n      }\n\n      /**\n       * For better performance we do not await checkpoint writes,\n       * but to ensure order on parallel checkpoint writes,\n       * we have to use a queue.\n       */\n      rememberCheckpointBeforeReturn();\n      return hadConflictWrites;\n    }).catch(unhandledError => {\n      state.events.error.next(unhandledError);\n      return false;\n    });\n    return persistenceQueue;\n  }\n}\n//# sourceMappingURL=upstream.js.map","/**\n * RxChangeEvents a emitted when something in the database changes\n * they can be grabbed by the observables of database, collection and document\n */\n\nimport { overwritable } from \"./overwritable.js\";\nimport { appendToArray, getFromMapOrCreate } from \"./plugins/utils/index.js\";\nexport function getDocumentDataOfRxChangeEvent(rxChangeEvent) {\n  if (rxChangeEvent.documentData) {\n    return rxChangeEvent.documentData;\n  } else {\n    return rxChangeEvent.previousDocumentData;\n  }\n}\n\n/**\n * Might return null which means an\n * already deleted document got modified but still is deleted.\n * These kind of events are not relevant for the event-reduce algorithm\n * and must be filtered out.\n */\nexport function rxChangeEventToEventReduceChangeEvent(rxChangeEvent) {\n  switch (rxChangeEvent.operation) {\n    case 'INSERT':\n      return {\n        operation: rxChangeEvent.operation,\n        id: rxChangeEvent.documentId,\n        doc: rxChangeEvent.documentData,\n        previous: null\n      };\n    case 'UPDATE':\n      return {\n        operation: rxChangeEvent.operation,\n        id: rxChangeEvent.documentId,\n        doc: overwritable.deepFreezeWhenDevMode(rxChangeEvent.documentData),\n        previous: rxChangeEvent.previousDocumentData ? rxChangeEvent.previousDocumentData : 'UNKNOWN'\n      };\n    case 'DELETE':\n      return {\n        operation: rxChangeEvent.operation,\n        id: rxChangeEvent.documentId,\n        doc: null,\n        previous: rxChangeEvent.previousDocumentData\n      };\n  }\n}\n\n/**\n * Flattens the given events into a single array of events.\n * Used mostly in tests.\n */\nexport function flattenEvents(input) {\n  var output = [];\n  if (Array.isArray(input)) {\n    input.forEach(inputItem => {\n      var add = flattenEvents(inputItem);\n      appendToArray(output, add);\n    });\n  } else {\n    if (input.id && input.events) {\n      // is bulk\n      input.events.forEach(ev => output.push(ev));\n    } else {\n      output.push(input);\n    }\n  }\n  var usedIds = new Set();\n  var nonDuplicate = [];\n  function getEventId(ev) {\n    return [ev.documentId, ev.documentData ? ev.documentData._rev : '', ev.previousDocumentData ? ev.previousDocumentData._rev : ''].join('|');\n  }\n  output.forEach(ev => {\n    var eventId = getEventId(ev);\n    if (!usedIds.has(eventId)) {\n      usedIds.add(eventId);\n      nonDuplicate.push(ev);\n    }\n  });\n  return nonDuplicate;\n}\nvar EVENT_BULK_CACHE = new Map();\nexport function rxChangeEventBulkToRxChangeEvents(eventBulk) {\n  return getFromMapOrCreate(EVENT_BULK_CACHE, eventBulk, () => {\n    var events = new Array(eventBulk.events.length);\n    var rawEvents = eventBulk.events;\n    var collectionName = eventBulk.collectionName;\n    var isLocal = eventBulk.isLocal;\n    var deepFreezeWhenDevMode = overwritable.deepFreezeWhenDevMode;\n    for (var index = 0; index < rawEvents.length; index++) {\n      var event = rawEvents[index];\n      events[index] = {\n        documentId: event.documentId,\n        collectionName,\n        isLocal,\n        operation: event.operation,\n        documentData: deepFreezeWhenDevMode(event.documentData),\n        previousDocumentData: deepFreezeWhenDevMode(event.previousDocumentData)\n      };\n    }\n    return events;\n  });\n}\n//# sourceMappingURL=rx-change-event.js.map","import { createRevision, flatClone, getDefaultRevision, getDefaultRxDocumentMeta, now } from \"./plugins/utils/index.js\";\nimport { fillObjectWithDefaults, fillPrimaryKey } from \"./rx-schema-helper.js\";\nimport { runAsyncPluginHooks } from \"./hooks.js\";\nimport { getAllCollectionDocuments } from \"./rx-database-internal-store.js\";\nimport { flatCloneDocWithMeta } from \"./rx-storage-helper.js\";\nimport { overwritable } from \"./overwritable.js\";\nimport { newRxError } from \"./rx-error.js\";\n\n/**\n * fills in the default data.\n * This also clones the data.\n */\nexport function fillObjectDataBeforeInsert(schema, data) {\n  data = flatClone(data);\n  data = fillObjectWithDefaults(schema, data);\n  if (typeof schema.jsonSchema.primaryKey !== 'string') {\n    data = fillPrimaryKey(schema.primaryPath, schema.jsonSchema, data);\n  }\n  data._meta = getDefaultRxDocumentMeta();\n  if (!Object.prototype.hasOwnProperty.call(data, '_deleted')) {\n    data._deleted = false;\n  }\n  if (!Object.prototype.hasOwnProperty.call(data, '_attachments')) {\n    data._attachments = {};\n  }\n  if (!Object.prototype.hasOwnProperty.call(data, '_rev')) {\n    data._rev = getDefaultRevision();\n  }\n  return data;\n}\n\n/**\n * Creates the storage instances that are used internally in the collection\n */\nexport async function createRxCollectionStorageInstance(rxDatabase, storageInstanceCreationParams) {\n  storageInstanceCreationParams.multiInstance = rxDatabase.multiInstance;\n  var storageInstance = await rxDatabase.storage.createStorageInstance(storageInstanceCreationParams);\n  return storageInstance;\n}\n\n/**\n * Removes the main storage of the collection\n * and all connected storages like the ones from the replication meta etc.\n */\nexport async function removeCollectionStorages(storage, databaseInternalStorage, databaseInstanceToken, databaseName, collectionName, multiInstance, password,\n/**\n * If no hash function is provided,\n * we assume that the whole internal store is removed anyway\n * so we do not have to delete the meta documents.\n */\nhashFunction) {\n  var allCollectionMetaDocs = await getAllCollectionDocuments(databaseInternalStorage);\n  var relevantCollectionMetaDocs = allCollectionMetaDocs.filter(metaDoc => metaDoc.data.name === collectionName);\n  var removeStorages = [];\n  relevantCollectionMetaDocs.forEach(metaDoc => {\n    removeStorages.push({\n      collectionName: metaDoc.data.name,\n      schema: metaDoc.data.schema,\n      isCollection: true\n    });\n    metaDoc.data.connectedStorages.forEach(row => removeStorages.push({\n      collectionName: row.collectionName,\n      isCollection: false,\n      schema: row.schema\n    }));\n  });\n\n  // ensure uniqueness\n  var alreadyAdded = new Set();\n  removeStorages = removeStorages.filter(row => {\n    var key = row.collectionName + '||' + row.schema.version;\n    if (alreadyAdded.has(key)) {\n      return false;\n    } else {\n      alreadyAdded.add(key);\n      return true;\n    }\n  });\n\n  // remove all the storages\n  await Promise.all(removeStorages.map(async row => {\n    var storageInstance = await storage.createStorageInstance({\n      collectionName: row.collectionName,\n      databaseInstanceToken,\n      databaseName,\n      /**\n       * multiInstance must be set to true if multiInstance\n       * was true on the database\n       * so that the storageInstance can inform other\n       * instances about being removed.\n       */\n      multiInstance,\n      options: {},\n      schema: row.schema,\n      password,\n      devMode: overwritable.isDevMode()\n    });\n    await storageInstance.remove();\n    if (row.isCollection) {\n      await runAsyncPluginHooks('postRemoveRxCollection', {\n        storage,\n        databaseName: databaseName,\n        collectionName\n      });\n    }\n  }));\n\n  // remove the meta documents\n  if (hashFunction) {\n    var writeRows = relevantCollectionMetaDocs.map(doc => {\n      var writeDoc = flatCloneDocWithMeta(doc);\n      writeDoc._deleted = true;\n      writeDoc._meta.lwt = now();\n      writeDoc._rev = createRevision(databaseInstanceToken, doc);\n      return {\n        previous: doc,\n        document: writeDoc\n      };\n    });\n    await databaseInternalStorage.bulkWrite(writeRows, 'rx-database-remove-collection-all');\n  }\n}\nexport function ensureRxCollectionIsNotClosed(collection) {\n  if (collection.closed) {\n    throw newRxError('COL21', {\n      collection: collection.name,\n      version: collection.schema.version\n    });\n  }\n}\n//# sourceMappingURL=rx-collection-helper.js.map","import _createClass from \"@babel/runtime/helpers/createClass\";\nimport { filter, map, mergeMap } from 'rxjs';\nimport { ucfirst, flatClone, promiseSeries, pluginMissing, ensureNotFalsy, getFromMapOrThrow, PROMISE_RESOLVE_FALSE, PROMISE_RESOLVE_VOID, NON_PREMIUM_COLLECTION_LIMIT, hasPremiumFlag } from \"./plugins/utils/index.js\";\nimport { fillObjectDataBeforeInsert, createRxCollectionStorageInstance, removeCollectionStorages, ensureRxCollectionIsNotClosed } from \"./rx-collection-helper.js\";\nimport { createRxQuery, _getDefaultQuery } from \"./rx-query.js\";\nimport { newRxError, newRxTypeError } from \"./rx-error.js\";\nimport { DocumentCache, mapDocumentsDataToCacheDocs } from \"./doc-cache.js\";\nimport { createQueryCache, defaultCacheReplacementPolicy } from \"./query-cache.js\";\nimport { createChangeEventBuffer } from \"./change-event-buffer.js\";\nimport { runAsyncPluginHooks, runPluginHooks } from \"./hooks.js\";\nimport { createNewRxDocument, getRxDocumentConstructor } from \"./rx-document-prototype-merge.js\";\nimport { getWrappedStorageInstance, getWrittenDocumentsFromBulkWriteResponse, throwIfIsStorageWriteError } from \"./rx-storage-helper.js\";\nimport { IncrementalWriteQueue } from \"./incremental-write.js\";\nimport { beforeDocumentUpdateWrite } from \"./rx-document.js\";\nimport { overwritable } from \"./overwritable.js\";\nimport { defaultConflictHandler } from \"./replication-protocol/default-conflict-handler.js\";\nimport { rxChangeEventBulkToRxChangeEvents } from \"./rx-change-event.js\";\nvar HOOKS_WHEN = ['pre', 'post'];\nvar HOOKS_KEYS = ['insert', 'save', 'remove', 'create'];\nvar hooksApplied = false;\nexport var OPEN_COLLECTIONS = new Set();\nexport var RxCollectionBase = /*#__PURE__*/function () {\n  /**\n   * Stores all 'normal' documents\n   */\n\n  /**\n   * Before reads, all these methods are awaited. Used to \"block\" reads\n   * depending on other processes, like when the RxPipeline is running.\n   */\n\n  function RxCollectionBase(database, name, schema, internalStorageInstance, instanceCreationOptions = {}, migrationStrategies = {}, methods = {}, attachments = {}, options = {}, cacheReplacementPolicy = defaultCacheReplacementPolicy, statics = {}, conflictHandler = defaultConflictHandler) {\n    this.storageInstance = {};\n    this.timeouts = new Set();\n    this.incrementalWriteQueue = {};\n    this.awaitBeforeReads = new Set();\n    this._incrementalUpsertQueues = new Map();\n    this.synced = false;\n    this.hooks = {};\n    this._subs = [];\n    this._docCache = {};\n    this._queryCache = createQueryCache();\n    this.$ = {};\n    this.checkpoint$ = {};\n    this._changeEventBuffer = {};\n    this.eventBulks$ = {};\n    this.onClose = [];\n    this.closed = false;\n    this.onRemove = [];\n    this.database = database;\n    this.name = name;\n    this.schema = schema;\n    this.internalStorageInstance = internalStorageInstance;\n    this.instanceCreationOptions = instanceCreationOptions;\n    this.migrationStrategies = migrationStrategies;\n    this.methods = methods;\n    this.attachments = attachments;\n    this.options = options;\n    this.cacheReplacementPolicy = cacheReplacementPolicy;\n    this.statics = statics;\n    this.conflictHandler = conflictHandler;\n    _applyHookFunctions(this.asRxCollection);\n    if (database) {\n      // might be falsy on pseudoInstance\n      this.eventBulks$ = database.eventBulks$.pipe(filter(changeEventBulk => changeEventBulk.collectionName === this.name));\n    } else {}\n\n    /**\n     * Must be last because the hooks might throw on dev-mode\n     * checks and we do not want to have broken collections here.\n     * RxCollection instances created for testings do not have a database\n     * so we do not add these to the list.\n     */\n    if (this.database) {\n      OPEN_COLLECTIONS.add(this);\n    }\n  }\n  var _proto = RxCollectionBase.prototype;\n  _proto.prepare = async function prepare() {\n    if (!(await hasPremiumFlag())) {\n      /**\n       * When used in a test suite, we often open and close many databases with collections\n       * while not awaiting the database.close() call to improve the test times.\n       * So when reopening collections and the OPEN_COLLECTIONS size is full,\n       * we retry after some times to account for this.\n       */\n      var count = 0;\n      while (count < 10 && OPEN_COLLECTIONS.size > NON_PREMIUM_COLLECTION_LIMIT) {\n        count++;\n        await this.promiseWait(30);\n      }\n      if (OPEN_COLLECTIONS.size > NON_PREMIUM_COLLECTION_LIMIT) {\n        throw newRxError('COL23', {\n          database: this.database.name,\n          collection: this.name,\n          args: {\n            existing: Array.from(OPEN_COLLECTIONS.values()).map(c => ({\n              db: c.database ? c.database.name : '',\n              c: c.name\n            }))\n          }\n        });\n      }\n    }\n    this.storageInstance = getWrappedStorageInstance(this.database, this.internalStorageInstance, this.schema.jsonSchema);\n    this.incrementalWriteQueue = new IncrementalWriteQueue(this.storageInstance, this.schema.primaryPath, (newData, oldData) => beforeDocumentUpdateWrite(this, newData, oldData), result => this._runHooks('post', 'save', result));\n    this.$ = this.eventBulks$.pipe(mergeMap(changeEventBulk => rxChangeEventBulkToRxChangeEvents(changeEventBulk)));\n    this.checkpoint$ = this.eventBulks$.pipe(map(changeEventBulk => changeEventBulk.checkpoint));\n    this._changeEventBuffer = createChangeEventBuffer(this.asRxCollection);\n    var documentConstructor;\n    this._docCache = new DocumentCache(this.schema.primaryPath, this.eventBulks$.pipe(filter(bulk => !bulk.isLocal), map(bulk => bulk.events)), docData => {\n      if (!documentConstructor) {\n        documentConstructor = getRxDocumentConstructor(this.asRxCollection);\n      }\n      return createNewRxDocument(this.asRxCollection, documentConstructor, docData);\n    });\n    var listenToRemoveSub = this.database.internalStore.changeStream().pipe(filter(bulk => {\n      var key = this.name + '-' + this.schema.version;\n      var found = bulk.events.find(event => {\n        return event.documentData.context === 'collection' && event.documentData.key === key && event.operation === 'DELETE';\n      });\n      return !!found;\n    })).subscribe(async () => {\n      await this.close();\n      await Promise.all(this.onRemove.map(fn => fn()));\n    });\n    this._subs.push(listenToRemoveSub);\n    var databaseStorageToken = await this.database.storageToken;\n    var subDocs = this.storageInstance.changeStream().subscribe(eventBulk => {\n      var changeEventBulk = {\n        id: eventBulk.id,\n        isLocal: false,\n        internal: false,\n        collectionName: this.name,\n        storageToken: databaseStorageToken,\n        events: eventBulk.events,\n        databaseToken: this.database.token,\n        checkpoint: eventBulk.checkpoint,\n        context: eventBulk.context\n      };\n      this.database.$emit(changeEventBulk);\n    });\n    this._subs.push(subDocs);\n    return PROMISE_RESOLVE_VOID;\n  }\n\n  /**\n   * Manually call the cleanup function of the storage.\n   * @link https://rxdb.info/cleanup.html\n   */;\n  _proto.cleanup = function cleanup(_minimumDeletedTime) {\n    ensureRxCollectionIsNotClosed(this);\n    throw pluginMissing('cleanup');\n  }\n\n  // overwritten by migration-plugin\n  ;\n  _proto.migrationNeeded = function migrationNeeded() {\n    throw pluginMissing('migration-schema');\n  };\n  _proto.getMigrationState = function getMigrationState() {\n    throw pluginMissing('migration-schema');\n  };\n  _proto.startMigration = function startMigration(batchSize = 10) {\n    ensureRxCollectionIsNotClosed(this);\n    return this.getMigrationState().startMigration(batchSize);\n  };\n  _proto.migratePromise = function migratePromise(batchSize = 10) {\n    return this.getMigrationState().migratePromise(batchSize);\n  };\n  _proto.insert = async function insert(json) {\n    ensureRxCollectionIsNotClosed(this);\n    var writeResult = await this.bulkInsert([json]);\n    var isError = writeResult.error[0];\n    throwIfIsStorageWriteError(this, json[this.schema.primaryPath], json, isError);\n    var insertResult = ensureNotFalsy(writeResult.success[0]);\n    return insertResult;\n  };\n  _proto.insertIfNotExists = async function insertIfNotExists(json) {\n    var writeResult = await this.bulkInsert([json]);\n    if (writeResult.error.length > 0) {\n      var error = writeResult.error[0];\n      if (error.status === 409) {\n        var conflictDocData = error.documentInDb;\n        return mapDocumentsDataToCacheDocs(this._docCache, [conflictDocData])[0];\n      } else {\n        throw error;\n      }\n    }\n    return writeResult.success[0];\n  };\n  _proto.bulkInsert = async function bulkInsert(docsData) {\n    ensureRxCollectionIsNotClosed(this);\n    /**\n     * Optimization shortcut,\n     * do nothing when called with an empty array\n    */\n    if (docsData.length === 0) {\n      return {\n        success: [],\n        error: []\n      };\n    }\n    var primaryPath = this.schema.primaryPath;\n    var ids = new Set();\n\n    /**\n     * This code is a bit redundant for better performance.\n     * Instead of iterating multiple times,\n     * we directly transform the input to a write-row array.\n     */\n    var insertRows;\n    if (this.hasHooks('pre', 'insert')) {\n      insertRows = await Promise.all(docsData.map(docData => {\n        var useDocData = fillObjectDataBeforeInsert(this.schema, docData);\n        return this._runHooks('pre', 'insert', useDocData).then(() => {\n          ids.add(useDocData[primaryPath]);\n          return {\n            document: useDocData\n          };\n        });\n      }));\n    } else {\n      insertRows = new Array(docsData.length);\n      var _schema = this.schema;\n      for (var index = 0; index < docsData.length; index++) {\n        var docData = docsData[index];\n        var useDocData = fillObjectDataBeforeInsert(_schema, docData);\n        ids.add(useDocData[primaryPath]);\n        insertRows[index] = {\n          document: useDocData\n        };\n      }\n    }\n    if (ids.size !== docsData.length) {\n      throw newRxError('COL22', {\n        collection: this.name,\n        args: {\n          documents: docsData\n        }\n      });\n    }\n    var results = await this.storageInstance.bulkWrite(insertRows, 'rx-collection-bulk-insert');\n\n    /**\n     * Often the user does not need to access the RxDocuments of the bulkInsert() call.\n     * So we transform the data to RxDocuments only if needed to use less CPU performance.\n     */\n    var rxDocuments;\n    var collection = this;\n    var ret = {\n      get success() {\n        if (!rxDocuments) {\n          var success = getWrittenDocumentsFromBulkWriteResponse(collection.schema.primaryPath, insertRows, results);\n          rxDocuments = mapDocumentsDataToCacheDocs(collection._docCache, success);\n        }\n        return rxDocuments;\n      },\n      error: results.error\n    };\n    if (this.hasHooks('post', 'insert')) {\n      var docsMap = new Map();\n      insertRows.forEach(row => {\n        var doc = row.document;\n        docsMap.set(doc[primaryPath], doc);\n      });\n      await Promise.all(ret.success.map(doc => {\n        return this._runHooks('post', 'insert', docsMap.get(doc.primary), doc);\n      }));\n    }\n    return ret;\n  };\n  _proto.bulkRemove = async function bulkRemove(\n  /**\n   * You can either remove the documents by their ids\n   * or by directly providing the RxDocument instances\n   * if you have them already. This improves performance a bit.\n   */\n  idsOrDocs) {\n    ensureRxCollectionIsNotClosed(this);\n    var primaryPath = this.schema.primaryPath;\n    /**\n     * Optimization shortcut,\n     * do nothing when called with an empty array\n     */\n    if (idsOrDocs.length === 0) {\n      return {\n        success: [],\n        error: []\n      };\n    }\n    var rxDocumentMap;\n    if (typeof idsOrDocs[0] === 'string') {\n      rxDocumentMap = await this.findByIds(idsOrDocs).exec();\n    } else {\n      rxDocumentMap = new Map();\n      idsOrDocs.forEach(d => rxDocumentMap.set(d.primary, d));\n    }\n    var docsData = [];\n    var docsMap = new Map();\n    Array.from(rxDocumentMap.values()).forEach(rxDocument => {\n      var data = rxDocument.toMutableJSON(true);\n      docsData.push(data);\n      docsMap.set(rxDocument.primary, data);\n    });\n    await Promise.all(docsData.map(doc => {\n      var primary = doc[this.schema.primaryPath];\n      return this._runHooks('pre', 'remove', doc, rxDocumentMap.get(primary));\n    }));\n    var removeDocs = docsData.map(doc => {\n      var writeDoc = flatClone(doc);\n      writeDoc._deleted = true;\n      return {\n        previous: doc,\n        document: writeDoc\n      };\n    });\n    var results = await this.storageInstance.bulkWrite(removeDocs, 'rx-collection-bulk-remove');\n    var success = getWrittenDocumentsFromBulkWriteResponse(this.schema.primaryPath, removeDocs, results);\n    var deletedRxDocuments = [];\n    var successIds = success.map(d => {\n      var id = d[primaryPath];\n      var doc = this._docCache.getCachedRxDocument(d);\n      deletedRxDocuments.push(doc);\n      return id;\n    });\n\n    // run hooks\n    await Promise.all(successIds.map(id => {\n      return this._runHooks('post', 'remove', docsMap.get(id), rxDocumentMap.get(id));\n    }));\n    return {\n      success: deletedRxDocuments,\n      error: results.error\n    };\n  }\n\n  /**\n   * same as bulkInsert but overwrites existing document with same primary\n   */;\n  _proto.bulkUpsert = async function bulkUpsert(docsData) {\n    ensureRxCollectionIsNotClosed(this);\n    var insertData = [];\n    var useJsonByDocId = new Map();\n    docsData.forEach(docData => {\n      var useJson = fillObjectDataBeforeInsert(this.schema, docData);\n      var primary = useJson[this.schema.primaryPath];\n      if (!primary) {\n        throw newRxError('COL3', {\n          primaryPath: this.schema.primaryPath,\n          data: useJson,\n          schema: this.schema.jsonSchema\n        });\n      }\n      useJsonByDocId.set(primary, useJson);\n      insertData.push(useJson);\n    });\n    var insertResult = await this.bulkInsert(insertData);\n    var success = insertResult.success.slice(0);\n    var error = [];\n\n    // update the ones that existed already\n    await Promise.all(insertResult.error.map(async err => {\n      if (err.status !== 409) {\n        error.push(err);\n      } else {\n        var id = err.documentId;\n        var writeData = getFromMapOrThrow(useJsonByDocId, id);\n        var docDataInDb = ensureNotFalsy(err.documentInDb);\n        var doc = this._docCache.getCachedRxDocuments([docDataInDb])[0];\n        var newDoc = await doc.incrementalModify(() => writeData);\n        success.push(newDoc);\n      }\n    }));\n    return {\n      error,\n      success\n    };\n  }\n\n  /**\n   * same as insert but overwrites existing document with same primary\n   */;\n  _proto.upsert = async function upsert(json) {\n    ensureRxCollectionIsNotClosed(this);\n    var bulkResult = await this.bulkUpsert([json]);\n    throwIfIsStorageWriteError(this.asRxCollection, json[this.schema.primaryPath], json, bulkResult.error[0]);\n    return bulkResult.success[0];\n  }\n\n  /**\n   * upserts to a RxDocument, uses incrementalModify if document already exists\n   */;\n  _proto.incrementalUpsert = function incrementalUpsert(json) {\n    ensureRxCollectionIsNotClosed(this);\n    var useJson = fillObjectDataBeforeInsert(this.schema, json);\n    var primary = useJson[this.schema.primaryPath];\n    if (!primary) {\n      throw newRxError('COL4', {\n        data: json\n      });\n    }\n\n    // ensure that it won't try 2 parallel runs\n    var queue = this._incrementalUpsertQueues.get(primary);\n    if (!queue) {\n      queue = PROMISE_RESOLVE_VOID;\n    }\n    queue = queue.then(() => _incrementalUpsertEnsureRxDocumentExists(this, primary, useJson)).then(wasInserted => {\n      if (!wasInserted.inserted) {\n        return _incrementalUpsertUpdate(wasInserted.doc, useJson);\n      } else {\n        return wasInserted.doc;\n      }\n    });\n    this._incrementalUpsertQueues.set(primary, queue);\n    return queue;\n  };\n  _proto.find = function find(queryObj) {\n    ensureRxCollectionIsNotClosed(this);\n    runPluginHooks('prePrepareRxQuery', {\n      op: 'find',\n      queryObj,\n      collection: this\n    });\n    if (!queryObj) {\n      queryObj = _getDefaultQuery();\n    }\n    var query = createRxQuery('find', queryObj, this);\n    return query;\n  };\n  _proto.findOne = function findOne(queryObj) {\n    ensureRxCollectionIsNotClosed(this);\n    runPluginHooks('prePrepareRxQuery', {\n      op: 'findOne',\n      queryObj,\n      collection: this\n    });\n    var query;\n    if (typeof queryObj === 'string') {\n      query = createRxQuery('findOne', {\n        selector: {\n          [this.schema.primaryPath]: queryObj\n        },\n        limit: 1\n      }, this);\n    } else {\n      if (!queryObj) {\n        queryObj = _getDefaultQuery();\n      }\n\n      // cannot have limit on findOne queries because it will be overwritten\n      if (queryObj.limit) {\n        throw newRxError('QU6');\n      }\n      queryObj = flatClone(queryObj);\n      queryObj.limit = 1;\n      query = createRxQuery('findOne', queryObj, this);\n    }\n    return query;\n  };\n  _proto.count = function count(queryObj) {\n    ensureRxCollectionIsNotClosed(this);\n    if (!queryObj) {\n      queryObj = _getDefaultQuery();\n    }\n    var query = createRxQuery('count', queryObj, this);\n    return query;\n  }\n\n  /**\n   * find a list documents by their primary key\n   * has way better performance then running multiple findOne() or a find() with a complex $or-selected\n   */;\n  _proto.findByIds = function findByIds(ids) {\n    ensureRxCollectionIsNotClosed(this);\n    var mangoQuery = {\n      selector: {\n        [this.schema.primaryPath]: {\n          $in: ids.slice(0)\n        }\n      }\n    };\n    var query = createRxQuery('findByIds', mangoQuery, this);\n    return query;\n  }\n\n  /**\n   * Export collection to a JSON friendly format.\n   */;\n  _proto.exportJSON = function exportJSON() {\n    throw pluginMissing('json-dump');\n  }\n\n  /**\n   * Import the parsed JSON export into the collection.\n   * @param _exportedJSON The previously exported data from the `<collection>.exportJSON()` method.\n   */;\n  _proto.importJSON = function importJSON(_exportedJSON) {\n    throw pluginMissing('json-dump');\n  };\n  _proto.insertCRDT = function insertCRDT(_updateObj) {\n    throw pluginMissing('crdt');\n  };\n  _proto.addPipeline = function addPipeline(_options) {\n    throw pluginMissing('pipeline');\n  }\n\n  /**\n   * HOOKS\n   */;\n  _proto.addHook = function addHook(when, key, fun, parallel = false) {\n    if (typeof fun !== 'function') {\n      throw newRxTypeError('COL7', {\n        key,\n        when\n      });\n    }\n    if (!HOOKS_WHEN.includes(when)) {\n      throw newRxTypeError('COL8', {\n        key,\n        when\n      });\n    }\n    if (!HOOKS_KEYS.includes(key)) {\n      throw newRxError('COL9', {\n        key\n      });\n    }\n    if (when === 'post' && key === 'create' && parallel === true) {\n      throw newRxError('COL10', {\n        when,\n        key,\n        parallel\n      });\n    }\n\n    // bind this-scope to hook-function\n    var boundFun = fun.bind(this);\n    var runName = parallel ? 'parallel' : 'series';\n    this.hooks[key] = this.hooks[key] || {};\n    this.hooks[key][when] = this.hooks[key][when] || {\n      series: [],\n      parallel: []\n    };\n    this.hooks[key][when][runName].push(boundFun);\n  };\n  _proto.getHooks = function getHooks(when, key) {\n    if (!this.hooks[key] || !this.hooks[key][when]) {\n      return {\n        series: [],\n        parallel: []\n      };\n    }\n    return this.hooks[key][when];\n  };\n  _proto.hasHooks = function hasHooks(when, key) {\n    /**\n     * Performance shortcut\n     * so that we not have to build the empty object.\n     */\n    if (!this.hooks[key] || !this.hooks[key][when]) {\n      return false;\n    }\n    var hooks = this.getHooks(when, key);\n    if (!hooks) {\n      return false;\n    }\n    return hooks.series.length > 0 || hooks.parallel.length > 0;\n  };\n  _proto._runHooks = function _runHooks(when, key, data, instance) {\n    var hooks = this.getHooks(when, key);\n    if (!hooks) {\n      return PROMISE_RESOLVE_VOID;\n    }\n\n    // run parallel: false\n    var tasks = hooks.series.map(hook => () => hook(data, instance));\n    return promiseSeries(tasks)\n    // run parallel: true\n    .then(() => Promise.all(hooks.parallel.map(hook => hook(data, instance))));\n  }\n\n  /**\n   * does the same as ._runHooks() but with non-async-functions\n   */;\n  _proto._runHooksSync = function _runHooksSync(when, key, data, instance) {\n    if (!this.hasHooks(when, key)) {\n      return;\n    }\n    var hooks = this.getHooks(when, key);\n    if (!hooks) return;\n    hooks.series.forEach(hook => hook(data, instance));\n  }\n\n  /**\n   * Returns a promise that resolves after the given time.\n   * Ensures that is properly cleans up when the collection is closed\n   * so that no running timeouts prevent the exit of the JavaScript process.\n   */;\n  _proto.promiseWait = function promiseWait(time) {\n    var ret = new Promise(res => {\n      var timeout = setTimeout(() => {\n        this.timeouts.delete(timeout);\n        res();\n      }, time);\n      this.timeouts.add(timeout);\n    });\n    return ret;\n  };\n  _proto.close = async function close() {\n    if (this.closed) {\n      return PROMISE_RESOLVE_FALSE;\n    }\n    OPEN_COLLECTIONS.delete(this);\n    await Promise.all(this.onClose.map(fn => fn()));\n\n    /**\n     * Settings closed = true\n     * must be the first thing to do,\n     * so for example the replication can directly stop\n     * instead of sending requests to a closed storage.\n     */\n    this.closed = true;\n    Array.from(this.timeouts).forEach(timeout => clearTimeout(timeout));\n    if (this._changeEventBuffer) {\n      this._changeEventBuffer.close();\n    }\n    /**\n     * First wait until the whole database is idle.\n     * This ensures that the storage does not get closed\n     * while some operation is running.\n     * It is important that we do not intercept a running call\n     * because it might lead to undefined behavior like when a doc is written\n     * but the change is not added to the changes collection.\n     */\n    return this.database.requestIdlePromise().then(() => this.storageInstance.close()).then(() => {\n      /**\n       * Unsubscribing must be done AFTER the storageInstance.close()\n       * Because the conflict handling is part of the subscriptions and\n       * otherwise there might be open conflicts to be resolved which\n       * will then stuck and never resolve.\n       */\n      this._subs.forEach(sub => sub.unsubscribe());\n      delete this.database.collections[this.name];\n      return runAsyncPluginHooks('postCloseRxCollection', this).then(() => true);\n    });\n  }\n\n  /**\n   * remove all data of the collection\n   */;\n  _proto.remove = async function remove() {\n    await this.close();\n    await Promise.all(this.onRemove.map(fn => fn()));\n    /**\n     * TODO here we should pass the already existing\n     * storage instances instead of creating new ones.\n     */\n    await removeCollectionStorages(this.database.storage, this.database.internalStore, this.database.token, this.database.name, this.name, this.database.multiInstance, this.database.password, this.database.hashFunction);\n  };\n  return _createClass(RxCollectionBase, [{\n    key: \"insert$\",\n    get: function () {\n      return this.$.pipe(filter(cE => cE.operation === 'INSERT'));\n    }\n  }, {\n    key: \"update$\",\n    get: function () {\n      return this.$.pipe(filter(cE => cE.operation === 'UPDATE'));\n    }\n  }, {\n    key: \"remove$\",\n    get: function () {\n      return this.$.pipe(filter(cE => cE.operation === 'DELETE'));\n    }\n\n    // defaults\n\n    /**\n     * Internally only use eventBulks$\n     * Do not use .$ or .observable$ because that has to transform\n     * the events which decreases performance.\n     */\n\n    /**\n     * When the collection is closed,\n     * these functions will be called an awaited.\n     * Used to automatically clean up stuff that\n     * belongs to this collection.\n    */\n  }, {\n    key: \"asRxCollection\",\n    get: function () {\n      return this;\n    }\n  }]);\n}();\n\n/**\n * adds the hook-functions to the collections prototype\n * this runs only once\n */\nfunction _applyHookFunctions(collection) {\n  if (hooksApplied) return; // already run\n  hooksApplied = true;\n  var colProto = Object.getPrototypeOf(collection);\n  HOOKS_KEYS.forEach(key => {\n    HOOKS_WHEN.map(when => {\n      var fnName = when + ucfirst(key);\n      colProto[fnName] = function (fun, parallel) {\n        return this.addHook(when, key, fun, parallel);\n      };\n    });\n  });\n}\nfunction _incrementalUpsertUpdate(doc, json) {\n  return doc.incrementalModify(_innerDoc => {\n    return json;\n  });\n}\n\n/**\n * ensures that the given document exists\n * @return promise that resolves with new doc and flag if inserted\n */\nfunction _incrementalUpsertEnsureRxDocumentExists(rxCollection, primary, json) {\n  /**\n   * Optimisation shortcut,\n   * first try to find the document in the doc-cache\n   */\n  var docDataFromCache = rxCollection._docCache.getLatestDocumentDataIfExists(primary);\n  if (docDataFromCache) {\n    return Promise.resolve({\n      doc: rxCollection._docCache.getCachedRxDocuments([docDataFromCache])[0],\n      inserted: false\n    });\n  }\n  return rxCollection.findOne(primary).exec().then(doc => {\n    if (!doc) {\n      return rxCollection.insert(json).then(newDoc => ({\n        doc: newDoc,\n        inserted: true\n      }));\n    } else {\n      return {\n        doc,\n        inserted: false\n      };\n    }\n  });\n}\n\n/**\n * creates and prepares a new collection\n */\nexport function createRxCollection({\n  database,\n  name,\n  schema,\n  instanceCreationOptions = {},\n  migrationStrategies = {},\n  autoMigrate = true,\n  statics = {},\n  methods = {},\n  attachments = {},\n  options = {},\n  localDocuments = false,\n  cacheReplacementPolicy = defaultCacheReplacementPolicy,\n  conflictHandler = defaultConflictHandler\n}) {\n  var storageInstanceCreationParams = {\n    databaseInstanceToken: database.token,\n    databaseName: database.name,\n    collectionName: name,\n    schema: schema.jsonSchema,\n    options: instanceCreationOptions,\n    multiInstance: database.multiInstance,\n    password: database.password,\n    devMode: overwritable.isDevMode()\n  };\n  runPluginHooks('preCreateRxStorageInstance', storageInstanceCreationParams);\n  return createRxCollectionStorageInstance(database, storageInstanceCreationParams).then(storageInstance => {\n    var collection = new RxCollectionBase(database, name, schema, storageInstance, instanceCreationOptions, migrationStrategies, methods, attachments, options, cacheReplacementPolicy, statics, conflictHandler);\n    return collection.prepare().then(() => {\n      // ORM add statics\n      Object.entries(statics).forEach(([funName, fun]) => {\n        Object.defineProperty(collection, funName, {\n          get: () => fun.bind(collection)\n        });\n      });\n      var ret = PROMISE_RESOLVE_VOID;\n      if (autoMigrate && collection.schema.version !== 0) {\n        ret = collection.migratePromise();\n      }\n      return ret;\n    }).then(() => {\n      runPluginHooks('createRxCollection', {\n        collection,\n        creator: {\n          name,\n          schema,\n          storageInstance,\n          instanceCreationOptions,\n          migrationStrategies,\n          methods,\n          attachments,\n          options,\n          cacheReplacementPolicy,\n          localDocuments,\n          statics\n        }\n      });\n      return collection;\n    })\n    /**\n     * If the collection creation fails,\n     * we yet have to close the storage instances.\n     */.catch(err => {\n      OPEN_COLLECTIONS.delete(collection);\n      return storageInstance.close().then(() => Promise.reject(err));\n    });\n  });\n}\nexport function isRxCollection(obj) {\n  return obj instanceof RxCollectionBase;\n}\n//# sourceMappingURL=rx-collection.js.map","import { isBulkWriteConflictError, newRxError } from \"./rx-error.js\";\nimport { fillWithDefaultSettings, getComposedPrimaryKeyOfDocumentData } from \"./rx-schema-helper.js\";\nimport { getSingleDocument, getWrittenDocumentsFromBulkWriteResponse, writeSingle } from \"./rx-storage-helper.js\";\nimport { clone, ensureNotFalsy, getDefaultRevision, getDefaultRxDocumentMeta, randomToken } from \"./plugins/utils/index.js\";\nimport { prepareQuery } from \"./rx-query-helper.js\";\nexport var INTERNAL_CONTEXT_COLLECTION = 'collection';\nexport var INTERNAL_CONTEXT_STORAGE_TOKEN = 'storage-token';\nexport var INTERNAL_CONTEXT_MIGRATION_STATUS = 'rx-migration-status';\nexport var INTERNAL_CONTEXT_PIPELINE_CHECKPOINT = 'rx-pipeline-checkpoint';\n\n/**\n * Do not change the title,\n * we have to flag the internal schema so that\n * some RxStorage implementations are able\n * to detect if the created RxStorageInstance\n * is from the internals or not,\n * to do some optimizations in some cases.\n */\nexport var INTERNAL_STORE_SCHEMA_TITLE = 'RxInternalDocument';\nexport var INTERNAL_STORE_SCHEMA = fillWithDefaultSettings({\n  version: 0,\n  title: INTERNAL_STORE_SCHEMA_TITLE,\n  primaryKey: {\n    key: 'id',\n    fields: ['context', 'key'],\n    separator: '|'\n  },\n  type: 'object',\n  properties: {\n    id: {\n      type: 'string',\n      maxLength: 200\n    },\n    key: {\n      type: 'string'\n    },\n    context: {\n      type: 'string',\n      enum: [INTERNAL_CONTEXT_COLLECTION, INTERNAL_CONTEXT_STORAGE_TOKEN, INTERNAL_CONTEXT_MIGRATION_STATUS, INTERNAL_CONTEXT_PIPELINE_CHECKPOINT, 'OTHER']\n    },\n    data: {\n      type: 'object',\n      additionalProperties: true\n    }\n  },\n  indexes: [],\n  required: ['key', 'context', 'data'],\n  additionalProperties: false,\n  /**\n   * If the sharding plugin is used,\n   * it must not shard on the internal RxStorageInstance\n   * because that one anyway has only a small amount of documents\n   * and also its creation is in the hot path of the initial page load,\n   * so we should spend less time creating multiple RxStorageInstances.\n   */\n  sharding: {\n    shards: 1,\n    mode: 'collection'\n  }\n});\nexport function getPrimaryKeyOfInternalDocument(key, context) {\n  return getComposedPrimaryKeyOfDocumentData(INTERNAL_STORE_SCHEMA, {\n    key,\n    context\n  });\n}\n\n/**\n * Returns all internal documents\n * with context 'collection'\n */\nexport async function getAllCollectionDocuments(storageInstance) {\n  var getAllQueryPrepared = prepareQuery(storageInstance.schema, {\n    selector: {\n      context: INTERNAL_CONTEXT_COLLECTION,\n      _deleted: {\n        $eq: false\n      }\n    },\n    sort: [{\n      id: 'asc'\n    }],\n    skip: 0\n  });\n  var queryResult = await storageInstance.query(getAllQueryPrepared);\n  var allDocs = queryResult.documents;\n  return allDocs;\n}\n\n/**\n * to not confuse multiInstance-messages with other databases that have the same\n * name and adapter, but do not share state with this one (for example in-memory-instances),\n * we set a storage-token and use it in the broadcast-channel\n */\nexport var STORAGE_TOKEN_DOCUMENT_KEY = 'storageToken';\nexport var STORAGE_TOKEN_DOCUMENT_ID = getPrimaryKeyOfInternalDocument(STORAGE_TOKEN_DOCUMENT_KEY, INTERNAL_CONTEXT_STORAGE_TOKEN);\nexport async function ensureStorageTokenDocumentExists(rxDatabase) {\n  /**\n   * To have less read-write cycles,\n   * we just try to insert a new document\n   * and only fetch the existing one if a conflict happened.\n   */\n  var storageToken = randomToken(10);\n  var passwordHash = rxDatabase.password ? await rxDatabase.hashFunction(JSON.stringify(rxDatabase.password)) : undefined;\n  var docData = {\n    id: STORAGE_TOKEN_DOCUMENT_ID,\n    context: INTERNAL_CONTEXT_STORAGE_TOKEN,\n    key: STORAGE_TOKEN_DOCUMENT_KEY,\n    data: {\n      rxdbVersion: rxDatabase.rxdbVersion,\n      token: storageToken,\n      /**\n       * We add the instance token here\n       * to be able to detect if a given RxDatabase instance\n       * is the first instance that was ever created\n       * or if databases have existed earlier on that storage\n       * with the same database name.\n       */\n      instanceToken: rxDatabase.token,\n      passwordHash\n    },\n    _deleted: false,\n    _meta: getDefaultRxDocumentMeta(),\n    _rev: getDefaultRevision(),\n    _attachments: {}\n  };\n  var writeRows = [{\n    document: docData\n  }];\n  var writeResult = await rxDatabase.internalStore.bulkWrite(writeRows, 'internal-add-storage-token');\n  if (!writeResult.error[0]) {\n    return getWrittenDocumentsFromBulkWriteResponse('id', writeRows, writeResult)[0];\n  }\n\n  /**\n   * If we get a 409 error,\n   * it means another instance already inserted the storage token.\n   * So we get that token from the database and return that one.\n   */\n  var error = ensureNotFalsy(writeResult.error[0]);\n  if (error.isError && isBulkWriteConflictError(error)) {\n    var conflictError = error;\n    if (!isDatabaseStateVersionCompatibleWithDatabaseCode(conflictError.documentInDb.data.rxdbVersion, rxDatabase.rxdbVersion)) {\n      throw newRxError('DM5', {\n        args: {\n          database: rxDatabase.name,\n          databaseStateVersion: conflictError.documentInDb.data.rxdbVersion,\n          codeVersion: rxDatabase.rxdbVersion\n        }\n      });\n    }\n    if (passwordHash && passwordHash !== conflictError.documentInDb.data.passwordHash) {\n      throw newRxError('DB1', {\n        passwordHash,\n        existingPasswordHash: conflictError.documentInDb.data.passwordHash\n      });\n    }\n    var storageTokenDocInDb = conflictError.documentInDb;\n    return ensureNotFalsy(storageTokenDocInDb);\n  }\n  throw error;\n}\nexport function isDatabaseStateVersionCompatibleWithDatabaseCode(databaseStateVersion, codeVersion) {\n  if (!databaseStateVersion) {\n    return false;\n  }\n  var stateMajor = databaseStateVersion.split('.')[0];\n  var codeMajor = codeVersion.split('.')[0];\n\n  /**\n   * Version v15 data must be upwards compatible to v16\n   */\n  if (stateMajor === '15' && codeMajor === '16') {\n    return true;\n  }\n  if (stateMajor !== codeMajor) {\n    return false;\n  }\n  return true;\n}\nexport async function addConnectedStorageToCollection(collection, storageCollectionName, schema) {\n  if (collection.schema.version !== schema.version) {\n    throw newRxError('SNH', {\n      schema,\n      version: collection.schema.version,\n      name: collection.name,\n      collection,\n      args: {\n        storageCollectionName\n      }\n    });\n  }\n  var collectionNameWithVersion = _collectionNamePrimary(collection.name, collection.schema.jsonSchema);\n  var collectionDocId = getPrimaryKeyOfInternalDocument(collectionNameWithVersion, INTERNAL_CONTEXT_COLLECTION);\n  while (true) {\n    var collectionDoc = await getSingleDocument(collection.database.internalStore, collectionDocId);\n    var saveData = clone(ensureNotFalsy(collectionDoc));\n\n    // do nothing if already in array\n    var alreadyThere = saveData.data.connectedStorages.find(row => row.collectionName === storageCollectionName && row.schema.version === schema.version);\n    if (alreadyThere) {\n      return;\n    }\n\n    // otherwise add to array and save\n    saveData.data.connectedStorages.push({\n      collectionName: storageCollectionName,\n      schema\n    });\n    try {\n      await writeSingle(collection.database.internalStore, {\n        previous: ensureNotFalsy(collectionDoc),\n        document: saveData\n      }, 'add-connected-storage-to-collection');\n    } catch (err) {\n      if (!isBulkWriteConflictError(err)) {\n        throw err;\n      }\n      // retry on conflict\n    }\n  }\n}\nexport async function removeConnectedStorageFromCollection(collection, storageCollectionName, schema) {\n  if (collection.schema.version !== schema.version) {\n    throw newRxError('SNH', {\n      schema,\n      version: collection.schema.version,\n      name: collection.name,\n      collection,\n      args: {\n        storageCollectionName\n      }\n    });\n  }\n  var collectionNameWithVersion = _collectionNamePrimary(collection.name, collection.schema.jsonSchema);\n  var collectionDocId = getPrimaryKeyOfInternalDocument(collectionNameWithVersion, INTERNAL_CONTEXT_COLLECTION);\n  while (true) {\n    var collectionDoc = await getSingleDocument(collection.database.internalStore, collectionDocId);\n    var saveData = clone(ensureNotFalsy(collectionDoc));\n\n    // do nothing if not there\n    var isThere = saveData.data.connectedStorages.find(row => row.collectionName === storageCollectionName && row.schema.version === schema.version);\n    if (!isThere) {\n      return;\n    }\n\n    // otherwise remove from array and save\n    saveData.data.connectedStorages = saveData.data.connectedStorages.filter(item => item.collectionName !== storageCollectionName);\n    try {\n      await writeSingle(collection.database.internalStore, {\n        previous: ensureNotFalsy(collectionDoc),\n        document: saveData\n      }, 'remove-connected-storage-from-collection');\n    } catch (err) {\n      if (!isBulkWriteConflictError(err)) {\n        throw err;\n      }\n      // retry on conflict\n    }\n  }\n}\n\n/**\n * returns the primary for a given collection-data\n * used in the internal store of a RxDatabase\n */\nexport function _collectionNamePrimary(name, schema) {\n  return name + '-' + schema.version;\n}\n//# sourceMappingURL=rx-database-internal-store.js.map","import _createClass from \"@babel/runtime/helpers/createClass\";\nimport { IdleQueue } from 'custom-idle-queue';\nimport { ObliviousSet } from 'oblivious-set';\nimport { pluginMissing, flatClone, PROMISE_RESOLVE_FALSE, randomToken, ensureNotFalsy, getDefaultRevision, getDefaultRxDocumentMeta, defaultHashSha256, RXDB_VERSION } from \"./plugins/utils/index.js\";\nimport { newRxError } from \"./rx-error.js\";\nimport { createRxSchema } from \"./rx-schema.js\";\nimport { runPluginHooks, runAsyncPluginHooks } from \"./hooks.js\";\nimport { Subject } from 'rxjs';\nimport { mergeMap } from 'rxjs/operators';\nimport { createRxCollection } from \"./rx-collection.js\";\nimport { flatCloneDocWithMeta, getSingleDocument, getWrappedStorageInstance, INTERNAL_STORAGE_NAME } from \"./rx-storage-helper.js\";\nimport { ensureStorageTokenDocumentExists, getAllCollectionDocuments, getPrimaryKeyOfInternalDocument, INTERNAL_CONTEXT_COLLECTION, INTERNAL_STORE_SCHEMA, _collectionNamePrimary } from \"./rx-database-internal-store.js\";\nimport { removeCollectionStorages } from \"./rx-collection-helper.js\";\nimport { overwritable } from \"./overwritable.js\";\nimport { rxChangeEventBulkToRxChangeEvents } from \"./rx-change-event.js\";\n\n/**\n * stores the used database names+storage names\n * so we can throw when the same database is created more then once.\n */\nvar USED_DATABASE_NAMES = new Set();\nvar DATABASE_UNCLOSED_INSTANCE_PROMISE_MAP = new Map();\nvar DB_COUNT = 0;\nexport var RxDatabaseBase = /*#__PURE__*/function () {\n  /**\n   * Contains all known non-closed storage instances\n   * that belong to this database.\n   * Used in plugins and unit tests.\n   */\n\n  function RxDatabaseBase(name,\n  /**\n   * Uniquely identifies the instance\n   * of this RxDatabase.\n   */\n  token, storage, instanceCreationOptions, password, multiInstance, eventReduce = false, options = {},\n  /**\n   * Stores information documents about the collections of the database\n   */\n  internalStore, hashFunction, cleanupPolicy, allowSlowCount, reactivity, onClosed) {\n    this.idleQueue = new IdleQueue();\n    this.rxdbVersion = RXDB_VERSION;\n    this.storageInstances = new Set();\n    this._subs = [];\n    this.startupErrors = [];\n    this.onClose = [];\n    this.closed = false;\n    this.collections = {};\n    this.states = {};\n    this.eventBulks$ = new Subject();\n    this.closePromise = null;\n    this.observable$ = this.eventBulks$.pipe(mergeMap(changeEventBulk => rxChangeEventBulkToRxChangeEvents(changeEventBulk)));\n    this.storageToken = PROMISE_RESOLVE_FALSE;\n    this.storageTokenDocument = PROMISE_RESOLVE_FALSE;\n    this.emittedEventBulkIds = new ObliviousSet(60 * 1000);\n    this.name = name;\n    this.token = token;\n    this.storage = storage;\n    this.instanceCreationOptions = instanceCreationOptions;\n    this.password = password;\n    this.multiInstance = multiInstance;\n    this.eventReduce = eventReduce;\n    this.options = options;\n    this.internalStore = internalStore;\n    this.hashFunction = hashFunction;\n    this.cleanupPolicy = cleanupPolicy;\n    this.allowSlowCount = allowSlowCount;\n    this.reactivity = reactivity;\n    this.onClosed = onClosed;\n    DB_COUNT++;\n\n    /**\n     * In the dev-mode, we create a pseudoInstance\n     * to get all properties of RxDatabase and ensure they do not\n     * conflict with the collection names etc.\n     * So only if it is not pseudoInstance,\n     * we have all values to prepare a real RxDatabase.\n     *\n     * TODO this is ugly, we should use a different way in the dev-mode\n     * so that all non-dev-mode code can be cleaner.\n     */\n    if (this.name !== 'pseudoInstance') {\n      /**\n       * Wrap the internal store\n       * to ensure that calls to it also end up in\n       * calculation of the idle state and the hooks.\n       */\n      this.internalStore = getWrappedStorageInstance(this.asRxDatabase, internalStore, INTERNAL_STORE_SCHEMA);\n\n      /**\n       * Start writing the storage token.\n       * Do not await the creation because it would run\n       * in a critical path that increases startup time.\n       *\n       * Writing the token takes about 20 milliseconds\n       * even on a fast adapter, so this is worth it.\n       */\n      this.storageTokenDocument = ensureStorageTokenDocumentExists(this.asRxDatabase).catch(err => this.startupErrors.push(err));\n      this.storageToken = this.storageTokenDocument.then(doc => doc.data.token).catch(err => this.startupErrors.push(err));\n    }\n  }\n  var _proto = RxDatabaseBase.prototype;\n  _proto.getReactivityFactory = function getReactivityFactory() {\n    if (!this.reactivity) {\n      throw newRxError('DB14', {\n        database: this.name\n      });\n    }\n    return this.reactivity;\n  }\n\n  /**\n   * Because having unhandled exceptions would fail,\n   * we have to store the async errors of the constructor here\n   * so we can throw them later.\n   */\n\n  /**\n   * When the database is closed,\n   * these functions will be called an awaited.\n   * Used to automatically clean up stuff that\n   * belongs to this collection.\n   */\n\n  /**\n   * Internally only use eventBulks$\n   * Do not use .$ or .observable$ because that has to transform\n   * the events which decreases performance.\n   */\n\n  /**\n   * Unique token that is stored with the data.\n   * Used to detect if the dataset has been deleted\n   * and if two RxDatabase instances work on the same dataset or not.\n   *\n   * Because reading and writing the storageToken runs in the hot path\n   * of database creation, we do not await the storageWrites but instead\n   * work with the promise when we need the value.\n   */\n\n  /**\n   * Stores the whole state of the internal storage token document.\n   * We need this in some plugins.\n   */\n\n  /**\n   * Contains the ids of all event bulks that have been emitted\n   * by the database.\n   * Used to detect duplicates that come in again via BroadcastChannel\n   * or other streams.\n   * In the past we tried to remove this and to ensure\n   * all storages only emit the same event bulks only once\n   * but it turns out this is just not possible for all storages.\n   * JavaScript processes, workers and browser tabs can be closed and started at any time\n   * which can cause cases where it is not possible to know if an event bulk has been emitted already.\n   */;\n  /**\n   * This is the main handle-point for all change events\n   * ChangeEvents created by this instance go:\n   * RxDocument -> RxCollection -> RxDatabase.$emit -> MultiInstance\n   * ChangeEvents created by other instances go:\n   * MultiInstance -> RxDatabase.$emit -> RxCollection -> RxDatabase\n   */\n  _proto.$emit = function $emit(changeEventBulk) {\n    if (this.emittedEventBulkIds.has(changeEventBulk.id)) {\n      return;\n    }\n    this.emittedEventBulkIds.add(changeEventBulk.id);\n    this.eventBulks$.next(changeEventBulk);\n  }\n\n  /**\n   * removes the collection-doc from the internalStore\n   */;\n  _proto.removeCollectionDoc = async function removeCollectionDoc(name, schema) {\n    var doc = await getSingleDocument(this.internalStore, getPrimaryKeyOfInternalDocument(_collectionNamePrimary(name, schema), INTERNAL_CONTEXT_COLLECTION));\n    if (!doc) {\n      throw newRxError('SNH', {\n        name,\n        schema\n      });\n    }\n    var writeDoc = flatCloneDocWithMeta(doc);\n    writeDoc._deleted = true;\n    await this.internalStore.bulkWrite([{\n      document: writeDoc,\n      previous: doc\n    }], 'rx-database-remove-collection');\n  }\n\n  /**\n   * creates multiple RxCollections at once\n   * to be much faster by saving db txs and doing stuff in bulk-operations\n   * This function is not called often, but mostly in the critical path at the initial page load\n   * So it must be as fast as possible.\n   */;\n  _proto.addCollections = async function addCollections(collectionCreators) {\n    var jsonSchemas = {};\n    var schemas = {};\n    var bulkPutDocs = [];\n    var useArgsByCollectionName = {};\n    await Promise.all(Object.entries(collectionCreators).map(async ([name, args]) => {\n      var collectionName = name;\n      var rxJsonSchema = args.schema;\n      jsonSchemas[collectionName] = rxJsonSchema;\n      var schema = createRxSchema(rxJsonSchema, this.hashFunction);\n      schemas[collectionName] = schema;\n\n      // collection already exists\n      if (this.collections[name]) {\n        throw newRxError('DB3', {\n          name\n        });\n      }\n      var collectionNameWithVersion = _collectionNamePrimary(name, rxJsonSchema);\n      var collectionDocData = {\n        id: getPrimaryKeyOfInternalDocument(collectionNameWithVersion, INTERNAL_CONTEXT_COLLECTION),\n        key: collectionNameWithVersion,\n        context: INTERNAL_CONTEXT_COLLECTION,\n        data: {\n          name: collectionName,\n          schemaHash: await schema.hash,\n          schema: schema.jsonSchema,\n          version: schema.version,\n          connectedStorages: []\n        },\n        _deleted: false,\n        _meta: getDefaultRxDocumentMeta(),\n        _rev: getDefaultRevision(),\n        _attachments: {}\n      };\n      bulkPutDocs.push({\n        document: collectionDocData\n      });\n      var useArgs = Object.assign({}, args, {\n        name: collectionName,\n        schema,\n        database: this\n      });\n\n      // run hooks\n      var hookData = flatClone(args);\n      hookData.database = this;\n      hookData.name = name;\n      runPluginHooks('preCreateRxCollection', hookData);\n      useArgs.conflictHandler = hookData.conflictHandler;\n      useArgsByCollectionName[collectionName] = useArgs;\n    }));\n    var putDocsResult = await this.internalStore.bulkWrite(bulkPutDocs, 'rx-database-add-collection');\n    await ensureNoStartupErrors(this);\n    await Promise.all(putDocsResult.error.map(async error => {\n      if (error.status !== 409) {\n        throw newRxError('DB12', {\n          database: this.name,\n          writeError: error\n        });\n      }\n      var docInDb = ensureNotFalsy(error.documentInDb);\n      var collectionName = docInDb.data.name;\n      var schema = schemas[collectionName];\n      // collection already exists but has different schema\n      if (docInDb.data.schemaHash !== (await schema.hash)) {\n        throw newRxError('DB6', {\n          database: this.name,\n          collection: collectionName,\n          previousSchemaHash: docInDb.data.schemaHash,\n          schemaHash: await schema.hash,\n          previousSchema: docInDb.data.schema,\n          schema: ensureNotFalsy(jsonSchemas[collectionName])\n        });\n      }\n    }));\n    var ret = {};\n    await Promise.all(Object.keys(collectionCreators).map(async collectionName => {\n      var useArgs = useArgsByCollectionName[collectionName];\n      var collection = await createRxCollection(useArgs);\n      ret[collectionName] = collection;\n\n      // set as getter to the database\n      this.collections[collectionName] = collection;\n      if (!this[collectionName]) {\n        Object.defineProperty(this, collectionName, {\n          get: () => this.collections[collectionName]\n        });\n      }\n    }));\n    return ret;\n  }\n\n  /**\n   * runs the given function between idleQueue-locking\n   */;\n  _proto.lockedRun = function lockedRun(fn) {\n    return this.idleQueue.wrapCall(fn);\n  };\n  _proto.requestIdlePromise = function requestIdlePromise() {\n    return this.idleQueue.requestIdlePromise();\n  }\n\n  /**\n   * Export database to a JSON friendly format.\n   */;\n  _proto.exportJSON = function exportJSON(_collections) {\n    throw pluginMissing('json-dump');\n  };\n  _proto.addState = function addState(_name) {\n    throw pluginMissing('state');\n  }\n\n  /**\n   * Import the parsed JSON export into the collection.\n   * @param _exportedJSON The previously exported data from the `<db>.exportJSON()` method.\n   * @note When an interface is loaded in this collection all base properties of the type are typed as `any`\n   * since data could be encrypted.\n   */;\n  _proto.importJSON = function importJSON(_exportedJSON) {\n    throw pluginMissing('json-dump');\n  };\n  _proto.backup = function backup(_options) {\n    throw pluginMissing('backup');\n  };\n  _proto.leaderElector = function leaderElector() {\n    throw pluginMissing('leader-election');\n  };\n  _proto.isLeader = function isLeader() {\n    throw pluginMissing('leader-election');\n  }\n  /**\n   * returns a promise which resolves when the instance becomes leader\n   */;\n  _proto.waitForLeadership = function waitForLeadership() {\n    throw pluginMissing('leader-election');\n  };\n  _proto.migrationStates = function migrationStates() {\n    throw pluginMissing('migration-schema');\n  }\n\n  /**\n   * closes the database-instance and all collections\n   */;\n  _proto.close = function close() {\n    if (this.closePromise) {\n      return this.closePromise;\n    }\n    var {\n      promise,\n      resolve\n    } = createPromiseWithResolvers();\n    var resolveClosePromise = result => {\n      if (this.onClosed) {\n        this.onClosed();\n      }\n      this.closed = true;\n      resolve(result);\n    };\n    this.closePromise = promise;\n    (async () => {\n      await runAsyncPluginHooks('preCloseRxDatabase', this);\n      /**\n       * Complete the event stream\n       * to stop all subscribers who forgot to unsubscribe.\n       */\n      this.eventBulks$.complete();\n      DB_COUNT--;\n      this._subs.map(sub => sub.unsubscribe());\n\n      /**\n       * closing the pseudo instance will throw\n       * because stuff is missing\n       * TODO we should not need the pseudo instance on runtime.\n       * we should generate the property list on build time.\n       */\n      if (this.name === 'pseudoInstance') {\n        resolveClosePromise(false);\n        return;\n      }\n\n      /**\n       * First wait until the database is idle\n       */\n      return this.requestIdlePromise().then(() => Promise.all(this.onClose.map(fn => fn())))\n      // close all collections\n      .then(() => Promise.all(Object.keys(this.collections).map(key => this.collections[key]).map(col => col.close())))\n      // close internal storage instances\n      .then(() => this.internalStore.close()).then(() => resolveClosePromise(true));\n    })();\n    return promise;\n  }\n\n  /**\n   * deletes the database and its stored data.\n   * Returns the names of all removed collections.\n   */;\n  _proto.remove = function remove() {\n    return this.close().then(() => removeRxDatabase(this.name, this.storage, this.multiInstance, this.password));\n  };\n  return _createClass(RxDatabaseBase, [{\n    key: \"$\",\n    get: function () {\n      return this.observable$;\n    }\n  }, {\n    key: \"asRxDatabase\",\n    get: function () {\n      return this;\n    }\n  }]);\n}();\n\n/**\n * checks if an instance with same name and storage already exists\n * @throws {RxError} if used\n */\nfunction throwIfDatabaseNameUsed(name, storage) {\n  if (USED_DATABASE_NAMES.has(getDatabaseNameKey(name, storage))) {\n    throw newRxError('DB8', {\n      name,\n      storage: storage.name,\n      link: 'https://rxdb.info/rx-database.html#ignoreduplicate'\n    });\n  }\n}\n\n/**\n * ponyfill for https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Promise/withResolvers\n */\nfunction createPromiseWithResolvers() {\n  var resolve;\n  var reject;\n  var promise = new Promise((res, rej) => {\n    resolve = res;\n    reject = rej;\n  });\n  return {\n    promise,\n    resolve,\n    reject\n  };\n}\nfunction getDatabaseNameKey(name, storage) {\n  return storage.name + '|' + name;\n}\n\n/**\n * Creates the storage instances that are used internally in the database\n * to store schemas and other configuration stuff.\n */\nexport async function createRxDatabaseStorageInstance(databaseInstanceToken, storage, databaseName, options, multiInstance, password) {\n  var internalStore = await storage.createStorageInstance({\n    databaseInstanceToken,\n    databaseName,\n    collectionName: INTERNAL_STORAGE_NAME,\n    schema: INTERNAL_STORE_SCHEMA,\n    options,\n    multiInstance,\n    password,\n    devMode: overwritable.isDevMode()\n  });\n  return internalStore;\n}\nexport function createRxDatabase({\n  storage,\n  instanceCreationOptions,\n  name,\n  password,\n  multiInstance = true,\n  eventReduce = true,\n  ignoreDuplicate = false,\n  options = {},\n  cleanupPolicy,\n  closeDuplicates = false,\n  allowSlowCount = false,\n  localDocuments = false,\n  hashFunction = defaultHashSha256,\n  reactivity\n}) {\n  runPluginHooks('preCreateRxDatabase', {\n    storage,\n    instanceCreationOptions,\n    name,\n    password,\n    multiInstance,\n    eventReduce,\n    ignoreDuplicate,\n    options,\n    localDocuments\n  });\n  var databaseNameKey = getDatabaseNameKey(name, storage);\n  var databaseNameKeyUnclosedInstancesSet = DATABASE_UNCLOSED_INSTANCE_PROMISE_MAP.get(databaseNameKey) || new Set();\n  var instancePromiseWithResolvers = createPromiseWithResolvers();\n  var closeDuplicatesPromises = Array.from(databaseNameKeyUnclosedInstancesSet);\n  var onInstanceClosed = () => {\n    databaseNameKeyUnclosedInstancesSet.delete(instancePromiseWithResolvers.promise);\n    USED_DATABASE_NAMES.delete(databaseNameKey);\n  };\n  databaseNameKeyUnclosedInstancesSet.add(instancePromiseWithResolvers.promise);\n  DATABASE_UNCLOSED_INSTANCE_PROMISE_MAP.set(databaseNameKey, databaseNameKeyUnclosedInstancesSet);\n  (async () => {\n    if (closeDuplicates) {\n      await Promise.all(closeDuplicatesPromises.map(unclosedInstancePromise => unclosedInstancePromise.catch(() => null).then(instance => instance && instance.close())));\n    }\n    if (ignoreDuplicate) {\n      if (!overwritable.isDevMode()) {\n        throw newRxError('DB9', {\n          database: name\n        });\n      }\n    } else {\n      // check if combination already used\n      throwIfDatabaseNameUsed(name, storage);\n    }\n    USED_DATABASE_NAMES.add(databaseNameKey);\n    var databaseInstanceToken = randomToken(10);\n    var storageInstance = await createRxDatabaseStorageInstance(databaseInstanceToken, storage, name, instanceCreationOptions, multiInstance, password);\n    var rxDatabase = new RxDatabaseBase(name, databaseInstanceToken, storage, instanceCreationOptions, password, multiInstance, eventReduce, options, storageInstance, hashFunction, cleanupPolicy, allowSlowCount, reactivity, onInstanceClosed);\n    await runAsyncPluginHooks('createRxDatabase', {\n      database: rxDatabase,\n      creator: {\n        storage,\n        instanceCreationOptions,\n        name,\n        password,\n        multiInstance,\n        eventReduce,\n        ignoreDuplicate,\n        options,\n        localDocuments\n      }\n    });\n    return rxDatabase;\n  })().then(rxDatabase => {\n    instancePromiseWithResolvers.resolve(rxDatabase);\n  }).catch(err => {\n    instancePromiseWithResolvers.reject(err);\n    onInstanceClosed();\n  });\n  return instancePromiseWithResolvers.promise;\n}\n\n/**\n * Removes the database and all its known data\n * with all known collections and all internal meta data.\n *\n * Returns the names of the removed collections.\n */\nexport async function removeRxDatabase(databaseName, storage, multiInstance = true, password) {\n  var databaseInstanceToken = randomToken(10);\n  var dbInternalsStorageInstance = await createRxDatabaseStorageInstance(databaseInstanceToken, storage, databaseName, {}, multiInstance, password);\n  var collectionDocs = await getAllCollectionDocuments(dbInternalsStorageInstance);\n  var collectionNames = new Set();\n  collectionDocs.forEach(doc => collectionNames.add(doc.data.name));\n  var removedCollectionNames = Array.from(collectionNames);\n  await Promise.all(removedCollectionNames.map(collectionName => removeCollectionStorages(storage, dbInternalsStorageInstance, databaseInstanceToken, databaseName, collectionName, multiInstance, password)));\n  await runAsyncPluginHooks('postRemoveRxDatabase', {\n    databaseName,\n    storage\n  });\n  await dbInternalsStorageInstance.remove();\n  return removedCollectionNames;\n}\nexport function isRxDatabase(obj) {\n  return obj instanceof RxDatabaseBase;\n}\nexport function dbCount() {\n  return DB_COUNT;\n}\n\n/**\n * Returns true if the given RxDatabase was the first\n * instance that was created on the storage with this name.\n *\n * Can be used for some optimizations because on the first instantiation,\n * we can assume that no data was written before.\n */\nexport async function isRxDatabaseFirstTimeInstantiated(database) {\n  var tokenDoc = await database.storageTokenDocument;\n  return tokenDoc.data.instanceToken === database.token;\n}\n\n/**\n * For better performance some tasks run async\n * and are awaited later.\n * But we still have to ensure that there have been no errors\n * on database creation.\n */\nexport async function ensureNoStartupErrors(rxDatabase) {\n  await rxDatabase.storageToken;\n  if (rxDatabase.startupErrors[0]) {\n    throw rxDatabase.startupErrors[0];\n  }\n}\n//# sourceMappingURL=rx-database.js.map","/**\n * For the ORM capabilities,\n * we have to merge the document prototype\n * with the ORM functions and the data\n * We do this iterating over the properties and\n * adding them to a new object.\n * In the future we should do this by chaining the __proto__ objects\n */\n\nimport { createRxDocumentConstructor, basePrototype, createWithConstructor as createRxDocumentWithConstructor } from \"./rx-document.js\";\nimport { runPluginHooks } from \"./hooks.js\";\nimport { overwritable } from \"./overwritable.js\";\nimport { getFromMapOrCreate } from \"./plugins/utils/index.js\";\nvar constructorForCollection = new WeakMap();\nexport function getDocumentPrototype(rxCollection) {\n  var schemaProto = rxCollection.schema.getDocumentPrototype();\n  var ormProto = getDocumentOrmPrototype(rxCollection);\n  var baseProto = basePrototype;\n  var proto = {};\n  [schemaProto, ormProto, baseProto].forEach(obj => {\n    var props = Object.getOwnPropertyNames(obj);\n    props.forEach(key => {\n      var desc = Object.getOwnPropertyDescriptor(obj, key);\n      /**\n       * When enumerable is true, it will show on console dir(instance)\n       * To not pollute the output, only getters and methods are enumerable\n       */\n      var enumerable = true;\n      if (key.startsWith('_') || key.endsWith('_') || key.startsWith('$') || key.endsWith('$')) enumerable = false;\n      if (typeof desc.value === 'function') {\n        // when getting a function, we automatically do a .bind(this)\n        Object.defineProperty(proto, key, {\n          get() {\n            return desc.value.bind(this);\n          },\n          enumerable,\n          configurable: false\n        });\n      } else {\n        desc.enumerable = enumerable;\n        desc.configurable = false;\n        if (desc.writable) desc.writable = false;\n        Object.defineProperty(proto, key, desc);\n      }\n    });\n  });\n  return proto;\n}\nexport function getRxDocumentConstructor(rxCollection) {\n  return getFromMapOrCreate(constructorForCollection, rxCollection, () => createRxDocumentConstructor(getDocumentPrototype(rxCollection)));\n}\n\n/**\n * Create a RxDocument-instance from the jsonData\n * and the prototype merge.\n * You should never call this method directly,\n * instead you should get the document from collection._docCache.getCachedRxDocument().\n */\nexport function createNewRxDocument(rxCollection, documentConstructor, docData) {\n  var doc = createRxDocumentWithConstructor(documentConstructor, rxCollection, overwritable.deepFreezeWhenDevMode(docData));\n  rxCollection._runHooksSync('post', 'create', docData, doc);\n  runPluginHooks('postCreateRxDocument', doc);\n  return doc;\n}\n\n/**\n * returns the prototype-object\n * that contains the orm-methods,\n * used in the proto-merge\n */\nexport function getDocumentOrmPrototype(rxCollection) {\n  var proto = {};\n  Object.entries(rxCollection.methods).forEach(([k, v]) => {\n    proto[k] = v;\n  });\n  return proto;\n}\n//# sourceMappingURL=rx-document-prototype-merge.js.map","import { distinctUntilChanged, filter, map, shareReplay, startWith } from 'rxjs/operators';\nimport { clone, trimDots, pluginMissing, flatClone, PROMISE_RESOLVE_NULL, RXJS_SHARE_REPLAY_DEFAULTS, getProperty, getFromMapOrCreate, ensureNotFalsy } from \"./plugins/utils/index.js\";\nimport { newRxError } from \"./rx-error.js\";\nimport { runPluginHooks } from \"./hooks.js\";\nimport { getDocumentDataOfRxChangeEvent } from \"./rx-change-event.js\";\nimport { overwritable } from \"./overwritable.js\";\nimport { getSchemaByObjectPath } from \"./rx-schema-helper.js\";\nimport { getWrittenDocumentsFromBulkWriteResponse, throwIfIsStorageWriteError } from \"./rx-storage-helper.js\";\nimport { modifierFromPublicToInternal } from \"./incremental-write.js\";\nexport var basePrototype = {\n  get primaryPath() {\n    var _this = this;\n    if (!_this.isInstanceOfRxDocument) {\n      return undefined;\n    }\n    return _this.collection.schema.primaryPath;\n  },\n  get primary() {\n    var _this = this;\n    if (!_this.isInstanceOfRxDocument) {\n      return undefined;\n    }\n    return _this._data[_this.primaryPath];\n  },\n  get revision() {\n    var _this = this;\n    if (!_this.isInstanceOfRxDocument) {\n      return undefined;\n    }\n    return _this._data._rev;\n  },\n  get deleted$() {\n    var _this = this;\n    if (!_this.isInstanceOfRxDocument) {\n      return undefined;\n    }\n    return _this.$.pipe(map(d => d._data._deleted));\n  },\n  get deleted$$() {\n    var _this = this;\n    var reactivity = _this.collection.database.getReactivityFactory();\n    return reactivity.fromObservable(_this.deleted$, _this.getLatest().deleted, _this.collection.database);\n  },\n  get deleted() {\n    var _this = this;\n    if (!_this.isInstanceOfRxDocument) {\n      return undefined;\n    }\n    return _this._data._deleted;\n  },\n  getLatest() {\n    var latestDocData = this.collection._docCache.getLatestDocumentData(this.primary);\n    return this.collection._docCache.getCachedRxDocument(latestDocData);\n  },\n  /**\n   * returns the observable which emits the plain-data of this document\n   */\n  get $() {\n    var _this = this;\n    var id = this.primary;\n    return _this.collection.eventBulks$.pipe(filter(bulk => !bulk.isLocal), map(bulk => bulk.events.find(ev => ev.documentId === id)), filter(event => !!event), map(changeEvent => getDocumentDataOfRxChangeEvent(ensureNotFalsy(changeEvent))), startWith(_this.collection._docCache.getLatestDocumentData(id)), distinctUntilChanged((prev, curr) => prev._rev === curr._rev), map(docData => this.collection._docCache.getCachedRxDocument(docData)), shareReplay(RXJS_SHARE_REPLAY_DEFAULTS));\n  },\n  get $$() {\n    var _this = this;\n    var reactivity = _this.collection.database.getReactivityFactory();\n    return reactivity.fromObservable(_this.$, _this.getLatest()._data, _this.collection.database);\n  },\n  /**\n   * returns observable of the value of the given path\n   */\n  get$(path) {\n    if (overwritable.isDevMode()) {\n      if (path.includes('.item.')) {\n        throw newRxError('DOC1', {\n          path\n        });\n      }\n      if (path === this.primaryPath) {\n        throw newRxError('DOC2');\n      }\n\n      // final fields cannot be modified and so also not observed\n      if (this.collection.schema.finalFields.includes(path)) {\n        throw newRxError('DOC3', {\n          path\n        });\n      }\n      var schemaObj = getSchemaByObjectPath(this.collection.schema.jsonSchema, path);\n      if (!schemaObj) {\n        throw newRxError('DOC4', {\n          path\n        });\n      }\n    }\n    return this.$.pipe(map(data => getProperty(data, path)), distinctUntilChanged());\n  },\n  get$$(path) {\n    var obs = this.get$(path);\n    var reactivity = this.collection.database.getReactivityFactory();\n    return reactivity.fromObservable(obs, this.getLatest().get(path), this.collection.database);\n  },\n  /**\n   * populate the given path\n   */\n  populate(path) {\n    var schemaObj = getSchemaByObjectPath(this.collection.schema.jsonSchema, path);\n    var value = this.get(path);\n    if (!value) {\n      return PROMISE_RESOLVE_NULL;\n    }\n    if (!schemaObj) {\n      throw newRxError('DOC5', {\n        path\n      });\n    }\n    if (!schemaObj.ref) {\n      throw newRxError('DOC6', {\n        path,\n        schemaObj\n      });\n    }\n    var refCollection = this.collection.database.collections[schemaObj.ref];\n    if (!refCollection) {\n      throw newRxError('DOC7', {\n        ref: schemaObj.ref,\n        path,\n        schemaObj\n      });\n    }\n    if (schemaObj.type === 'array') {\n      return refCollection.findByIds(value).exec().then(res => {\n        var valuesIterator = res.values();\n        return Array.from(valuesIterator);\n      });\n    } else {\n      return refCollection.findOne(value).exec();\n    }\n  },\n  /**\n   * get data by objectPath\n   * @hotPath Performance here is really important,\n   * run some tests before changing anything.\n   */\n  get(objPath) {\n    return getDocumentProperty(this, objPath);\n  },\n  toJSON(withMetaFields = false) {\n    if (!withMetaFields) {\n      var data = flatClone(this._data);\n      delete data._rev;\n      delete data._attachments;\n      delete data._deleted;\n      delete data._meta;\n      return overwritable.deepFreezeWhenDevMode(data);\n    } else {\n      return overwritable.deepFreezeWhenDevMode(this._data);\n    }\n  },\n  toMutableJSON(withMetaFields = false) {\n    return clone(this.toJSON(withMetaFields));\n  },\n  /**\n   * updates document\n   * @overwritten by plugin (optional)\n   * @param updateObj mongodb-like syntax\n   */\n  update(_updateObj) {\n    throw pluginMissing('update');\n  },\n  incrementalUpdate(_updateObj) {\n    throw pluginMissing('update');\n  },\n  updateCRDT(_updateObj) {\n    throw pluginMissing('crdt');\n  },\n  putAttachment() {\n    throw pluginMissing('attachments');\n  },\n  getAttachment() {\n    throw pluginMissing('attachments');\n  },\n  allAttachments() {\n    throw pluginMissing('attachments');\n  },\n  get allAttachments$() {\n    throw pluginMissing('attachments');\n  },\n  async modify(mutationFunction,\n  // used by some plugins that wrap the method\n  _context) {\n    var oldData = this._data;\n    var newData = await modifierFromPublicToInternal(mutationFunction)(oldData);\n    return this._saveData(newData, oldData);\n  },\n  /**\n   * runs an incremental update over the document\n   * @param function that takes the document-data and returns a new data-object\n   */\n  incrementalModify(mutationFunction,\n  // used by some plugins that wrap the method\n  _context) {\n    return this.collection.incrementalWriteQueue.addWrite(this._data, modifierFromPublicToInternal(mutationFunction)).then(result => this.collection._docCache.getCachedRxDocument(result));\n  },\n  patch(patch) {\n    var oldData = this._data;\n    var newData = clone(oldData);\n    Object.entries(patch).forEach(([k, v]) => {\n      newData[k] = v;\n    });\n    return this._saveData(newData, oldData);\n  },\n  /**\n   * patches the given properties\n   */\n  incrementalPatch(patch) {\n    return this.incrementalModify(docData => {\n      Object.entries(patch).forEach(([k, v]) => {\n        docData[k] = v;\n      });\n      return docData;\n    });\n  },\n  /**\n   * saves the new document-data\n   * and handles the events\n   */\n  async _saveData(newData, oldData) {\n    newData = flatClone(newData);\n\n    // deleted documents cannot be changed\n    if (this._data._deleted) {\n      throw newRxError('DOC11', {\n        id: this.primary,\n        document: this\n      });\n    }\n    await beforeDocumentUpdateWrite(this.collection, newData, oldData);\n    var writeRows = [{\n      previous: oldData,\n      document: newData\n    }];\n    var writeResult = await this.collection.storageInstance.bulkWrite(writeRows, 'rx-document-save-data');\n    var isError = writeResult.error[0];\n    throwIfIsStorageWriteError(this.collection, this.primary, newData, isError);\n    await this.collection._runHooks('post', 'save', newData, this);\n    return this.collection._docCache.getCachedRxDocument(getWrittenDocumentsFromBulkWriteResponse(this.collection.schema.primaryPath, writeRows, writeResult)[0]);\n  },\n  /**\n   * Remove the document.\n   * Notice that there is no hard delete,\n   * instead deleted documents get flagged with _deleted=true.\n   */\n  async remove() {\n    if (this.deleted) {\n      return Promise.reject(newRxError('DOC13', {\n        document: this,\n        id: this.primary\n      }));\n    }\n    var removeResult = await this.collection.bulkRemove([this]);\n    if (removeResult.error.length > 0) {\n      var error = removeResult.error[0];\n      throwIfIsStorageWriteError(this.collection, this.primary, this._data, error);\n    }\n    return removeResult.success[0];\n  },\n  incrementalRemove() {\n    return this.incrementalModify(async docData => {\n      await this.collection._runHooks('pre', 'remove', docData, this);\n      docData._deleted = true;\n      return docData;\n    }).then(async newDoc => {\n      await this.collection._runHooks('post', 'remove', newDoc._data, newDoc);\n      return newDoc;\n    });\n  },\n  close() {\n    throw newRxError('DOC14');\n  }\n};\nexport function createRxDocumentConstructor(proto = basePrototype) {\n  var constructor = function RxDocumentConstructor(collection, docData) {\n    this.collection = collection;\n\n    // assume that this is always equal to the doc-data in the database\n    this._data = docData;\n    this._propertyCache = new Map();\n\n    /**\n     * because of the prototype-merge,\n     * we can not use the native instanceof operator\n     */\n    this.isInstanceOfRxDocument = true;\n  };\n  constructor.prototype = proto;\n  return constructor;\n}\nexport function createWithConstructor(constructor, collection, jsonData) {\n  var doc = new constructor(collection, jsonData);\n  runPluginHooks('createRxDocument', doc);\n  return doc;\n}\nexport function isRxDocument(obj) {\n  return typeof obj === 'object' && obj !== null && 'isInstanceOfRxDocument' in obj;\n}\nexport function beforeDocumentUpdateWrite(collection, newData, oldData) {\n  /**\n   * Meta values must always be merged\n   * instead of overwritten.\n   * This ensures that different plugins do not overwrite\n   * each others meta properties.\n   */\n  newData._meta = Object.assign({}, oldData._meta, newData._meta);\n\n  // ensure modifications are ok\n  if (overwritable.isDevMode()) {\n    collection.schema.validateChange(oldData, newData);\n  }\n  return collection._runHooks('pre', 'save', newData, oldData);\n}\nfunction getDocumentProperty(doc, objPath) {\n  return getFromMapOrCreate(doc._propertyCache, objPath, () => {\n    var valueObj = getProperty(doc._data, objPath);\n\n    // direct return if array or non-object\n    if (typeof valueObj !== 'object' || valueObj === null || Array.isArray(valueObj)) {\n      return overwritable.deepFreezeWhenDevMode(valueObj);\n    }\n    var proxy = new Proxy(\n    /**\n     * In dev-mode, the _data is deep-frozen\n     * so we have to flat clone here so that\n     * the proxy can work.\n     */\n    flatClone(valueObj), {\n      /**\n       * @performance is really important here\n       * because people access nested properties very often\n       * and might not be aware that this is internally using a Proxy\n       */\n      get(target, property) {\n        if (typeof property !== 'string') {\n          return target[property];\n        }\n        var lastChar = property.charAt(property.length - 1);\n        if (lastChar === '$') {\n          if (property.endsWith('$$')) {\n            var key = property.slice(0, -2);\n            return doc.get$$(trimDots(objPath + '.' + key));\n          } else {\n            var _key = property.slice(0, -1);\n            return doc.get$(trimDots(objPath + '.' + _key));\n          }\n        } else if (lastChar === '_') {\n          var _key2 = property.slice(0, -1);\n          return doc.populate(trimDots(objPath + '.' + _key2));\n        } else {\n          /**\n           * Performance shortcut\n           * In most cases access to nested properties\n           * will only access simple values which can be directly returned\n           * without creating a new Proxy or utilizing the cache.\n           */\n          var plainValue = target[property];\n          if (typeof plainValue === 'number' || typeof plainValue === 'string' || typeof plainValue === 'boolean') {\n            return plainValue;\n          }\n          return getDocumentProperty(doc, trimDots(objPath + '.' + property));\n        }\n      }\n    });\n    return proxy;\n  });\n}\n;\n//# sourceMappingURL=rx-document.js.map","import _createClass from \"@babel/runtime/helpers/createClass\";\nimport _inheritsLoose from \"@babel/runtime/helpers/inheritsLoose\";\nimport _wrapNativeSuper from \"@babel/runtime/helpers/wrapNativeSuper\";\n/**\n * here we use custom errors with the additional field 'parameters'\n */\n\nimport { overwritable } from \"./overwritable.js\";\n/**\n * transform an object of parameters to a presentable string\n */\nfunction parametersToString(parameters) {\n  var ret = '';\n  if (Object.keys(parameters).length === 0) return ret;\n  ret += '-'.repeat(20) + '\\n';\n  ret += 'Parameters:\\n';\n  ret += Object.keys(parameters).map(k => {\n    var paramStr = '[object Object]';\n    try {\n      if (k === 'errors') {\n        paramStr = parameters[k].map(err => JSON.stringify(err, Object.getOwnPropertyNames(err)));\n      } else {\n        paramStr = JSON.stringify(parameters[k], function (_k, v) {\n          return v === undefined ? null : v;\n        }, 2);\n      }\n    } catch (e) {}\n    return k + ': ' + paramStr;\n  }).join('\\n');\n  ret += '\\n';\n  return ret;\n}\nfunction messageForError(message, code, parameters) {\n  return '' + '\\n' + message + '\\n' + parametersToString(parameters);\n}\nexport var RxError = /*#__PURE__*/function (_Error) {\n  // always true, use this to detect if its an rxdb-error\n\n  function RxError(code, message, parameters = {}) {\n    var _this;\n    var mes = messageForError(message, code, parameters);\n    _this = _Error.call(this, mes) || this;\n    _this.code = code;\n    _this.message = mes;\n    _this.url = getErrorUrl(code);\n    _this.parameters = parameters;\n    _this.rxdb = true; // tag them as internal\n    return _this;\n  }\n  _inheritsLoose(RxError, _Error);\n  var _proto = RxError.prototype;\n  _proto.toString = function toString() {\n    return this.message;\n  };\n  return _createClass(RxError, [{\n    key: \"name\",\n    get: function () {\n      return 'RxError (' + this.code + ')';\n    }\n  }, {\n    key: \"typeError\",\n    get: function () {\n      return false;\n    }\n  }]);\n}(/*#__PURE__*/_wrapNativeSuper(Error));\nexport var RxTypeError = /*#__PURE__*/function (_TypeError) {\n  // always true, use this to detect if its an rxdb-error\n\n  function RxTypeError(code, message, parameters = {}) {\n    var _this2;\n    var mes = messageForError(message, code, parameters);\n    _this2 = _TypeError.call(this, mes) || this;\n    _this2.code = code;\n    _this2.message = mes;\n    _this2.url = getErrorUrl(code);\n    _this2.parameters = parameters;\n    _this2.rxdb = true; // tag them as internal\n    return _this2;\n  }\n  _inheritsLoose(RxTypeError, _TypeError);\n  var _proto2 = RxTypeError.prototype;\n  _proto2.toString = function toString() {\n    return this.message;\n  };\n  return _createClass(RxTypeError, [{\n    key: \"name\",\n    get: function () {\n      return 'RxTypeError (' + this.code + ')';\n    }\n  }, {\n    key: \"typeError\",\n    get: function () {\n      return true;\n    }\n  }]);\n}(/*#__PURE__*/_wrapNativeSuper(TypeError));\nexport function getErrorUrl(code) {\n  return 'https://rxdb.info/errors.html?console=errors#' + code;\n}\nexport function errorUrlHint(code) {\n  return '\\nFind out more about this error here: ' + getErrorUrl(code) + ' \\n';\n}\nexport function newRxError(code, parameters) {\n  return new RxError(code, overwritable.tunnelErrorMessage(code) + errorUrlHint(code), parameters);\n}\nexport function newRxTypeError(code, parameters) {\n  return new RxTypeError(code, overwritable.tunnelErrorMessage(code) + errorUrlHint(code), parameters);\n}\n\n/**\n * Returns the error if it is a 409 conflict,\n * return false if it is another error.\n */\nexport function isBulkWriteConflictError(err) {\n  if (err && err.status === 409) {\n    return err;\n  } else {\n    return false;\n  }\n}\nvar STORAGE_WRITE_ERROR_CODE_TO_MESSAGE = {\n  409: 'document write conflict',\n  422: 'schema validation error',\n  510: 'attachment data missing'\n};\nexport function rxStorageWriteErrorToRxError(err) {\n  return newRxError('COL20', {\n    name: STORAGE_WRITE_ERROR_CODE_TO_MESSAGE[err.status],\n    document: err.documentId,\n    writeError: err\n  });\n}\n//# sourceMappingURL=rx-error.js.map","import { LOGICAL_OPERATORS, getQueryPlan } from \"./query-planner.js\";\nimport { getPrimaryFieldOfPrimaryKey } from \"./rx-schema-helper.js\";\nimport { clone, firstPropertyNameOfObject, toArray, isMaybeReadonlyArray, flatClone, objectPathMonad } from \"./plugins/utils/index.js\";\nimport { compare as mingoSortComparator } from 'mingo/util';\nimport { newRxError } from \"./rx-error.js\";\nimport { getMingoQuery } from \"./rx-query-mingo.js\";\n\n/**\n * Normalize the query to ensure we have all fields set\n * and queries that represent the same query logic are detected as equal by the caching.\n */\nexport function normalizeMangoQuery(schema, mangoQuery) {\n  var primaryKey = getPrimaryFieldOfPrimaryKey(schema.primaryKey);\n  mangoQuery = flatClone(mangoQuery);\n  var normalizedMangoQuery = clone(mangoQuery);\n  if (typeof normalizedMangoQuery.skip !== 'number') {\n    normalizedMangoQuery.skip = 0;\n  }\n  if (!normalizedMangoQuery.selector) {\n    normalizedMangoQuery.selector = {};\n  } else {\n    normalizedMangoQuery.selector = normalizedMangoQuery.selector;\n    /**\n     * In mango query, it is possible to have an\n     * equals comparison by directly assigning a value\n     * to a property, without the '$eq' operator.\n     * Like:\n     * selector: {\n     *   foo: 'bar'\n     * }\n     * For normalization, we have to normalize this\n     * so our checks can perform properly.\n     *\n     *\n     * TODO this must work recursive with nested queries that\n     * contain multiple selectors via $and or $or etc.\n     */\n    Object.entries(normalizedMangoQuery.selector).forEach(([field, matcher]) => {\n      if (typeof matcher !== 'object' || matcher === null) {\n        normalizedMangoQuery.selector[field] = {\n          $eq: matcher\n        };\n      }\n    });\n  }\n\n  /**\n   * Ensure that if an index is specified,\n   * the primaryKey is inside of it.\n   */\n  if (normalizedMangoQuery.index) {\n    var indexAr = toArray(normalizedMangoQuery.index);\n    if (!indexAr.includes(primaryKey)) {\n      indexAr.push(primaryKey);\n    }\n    normalizedMangoQuery.index = indexAr;\n  }\n\n  /**\n   * To ensure a deterministic sorting,\n   * we have to ensure the primary key is always part\n   * of the sort query.\n   * Primary sorting is added as last sort parameter,\n   * similar to how we add the primary key to indexes that do not have it.\n   *\n   */\n  if (!normalizedMangoQuery.sort) {\n    /**\n     * If no sort is given at all,\n     * we can assume that the user does not care about sort order at al.\n     *\n     * we cannot just use the primary key as sort parameter\n     * because it would likely cause the query to run over the primary key index\n     * which has a bad performance in most cases.\n     */\n    if (normalizedMangoQuery.index) {\n      normalizedMangoQuery.sort = normalizedMangoQuery.index.map(field => {\n        return {\n          [field]: 'asc'\n        };\n      });\n    } else {\n      /**\n       * Find the index that best matches the fields with the logical operators\n       */\n      if (schema.indexes) {\n        var fieldsWithLogicalOperator = new Set();\n        Object.entries(normalizedMangoQuery.selector).forEach(([field, matcher]) => {\n          var hasLogical = false;\n          if (typeof matcher === 'object' && matcher !== null) {\n            hasLogical = !!Object.keys(matcher).find(operator => LOGICAL_OPERATORS.has(operator));\n          } else {\n            hasLogical = true;\n          }\n          if (hasLogical) {\n            fieldsWithLogicalOperator.add(field);\n          }\n        });\n        var currentFieldsAmount = -1;\n        var currentBestIndexForSort;\n        schema.indexes.forEach(index => {\n          var useIndex = isMaybeReadonlyArray(index) ? index : [index];\n          var firstWrongIndex = useIndex.findIndex(indexField => !fieldsWithLogicalOperator.has(indexField));\n          if (firstWrongIndex > 0 && firstWrongIndex > currentFieldsAmount) {\n            currentFieldsAmount = firstWrongIndex;\n            currentBestIndexForSort = useIndex;\n          }\n        });\n        if (currentBestIndexForSort) {\n          normalizedMangoQuery.sort = currentBestIndexForSort.map(field => {\n            return {\n              [field]: 'asc'\n            };\n          });\n        }\n      }\n\n      /**\n       * If no good index was found as default sort-order,\n       * just use the first index of the schema.\n       * If no index is in the schema, use the default-index which\n       * is created by RxDB ONLY if there is no other index defined.\n       */\n      if (!normalizedMangoQuery.sort) {\n        if (schema.indexes && schema.indexes.length > 0) {\n          var firstIndex = schema.indexes[0];\n          var useIndex = isMaybeReadonlyArray(firstIndex) ? firstIndex : [firstIndex];\n          normalizedMangoQuery.sort = useIndex.map(field => ({\n            [field]: 'asc'\n          }));\n        } else {\n          normalizedMangoQuery.sort = [{\n            [primaryKey]: 'asc'\n          }];\n        }\n      }\n    }\n  } else {\n    var isPrimaryInSort = normalizedMangoQuery.sort.find(p => firstPropertyNameOfObject(p) === primaryKey);\n    if (!isPrimaryInSort) {\n      normalizedMangoQuery.sort = normalizedMangoQuery.sort.slice(0);\n      normalizedMangoQuery.sort.push({\n        [primaryKey]: 'asc'\n      });\n    }\n  }\n  return normalizedMangoQuery;\n}\n\n/**\n * Returns the sort-comparator,\n * which is able to sort documents in the same way\n * a query over the db would do.\n */\nexport function getSortComparator(schema, query) {\n  if (!query.sort) {\n    throw newRxError('SNH', {\n      query\n    });\n  }\n  var sortParts = [];\n  query.sort.forEach(sortBlock => {\n    var key = Object.keys(sortBlock)[0];\n    var direction = Object.values(sortBlock)[0];\n    sortParts.push({\n      key,\n      direction,\n      getValueFn: objectPathMonad(key)\n    });\n  });\n  var fun = (a, b) => {\n    for (var i = 0; i < sortParts.length; ++i) {\n      var sortPart = sortParts[i];\n      var valueA = sortPart.getValueFn(a);\n      var valueB = sortPart.getValueFn(b);\n      if (valueA !== valueB) {\n        var ret = sortPart.direction === 'asc' ? mingoSortComparator(valueA, valueB) : mingoSortComparator(valueB, valueA);\n        return ret;\n      }\n    }\n  };\n  return fun;\n}\n\n/**\n * Returns a function\n * that can be used to check if a document\n * matches the query.\n */\nexport function getQueryMatcher(_schema, query) {\n  if (!query.sort) {\n    throw newRxError('SNH', {\n      query\n    });\n  }\n  var mingoQuery = getMingoQuery(query.selector);\n  var fun = doc => {\n    return mingoQuery.test(doc);\n  };\n  return fun;\n}\nexport async function runQueryUpdateFunction(rxQuery, fn) {\n  var docs = await rxQuery.exec();\n  if (!docs) {\n    // only findOne() queries can return null\n    return null;\n  }\n  if (Array.isArray(docs)) {\n    return Promise.all(docs.map(doc => fn(doc)));\n  } else if (docs instanceof Map) {\n    return Promise.all([...docs.values()].map(doc => fn(doc)));\n  } else {\n    // via findOne()\n    var result = await fn(docs);\n    return result;\n  }\n}\n\n/**\n * @returns a format of the query that can be used with the storage\n * when calling RxStorageInstance().query()\n */\nexport function prepareQuery(schema, mutateableQuery) {\n  if (!mutateableQuery.sort) {\n    throw newRxError('SNH', {\n      query: mutateableQuery\n    });\n  }\n\n  /**\n   * Store the query plan together with the\n   * prepared query to save performance.\n   */\n  var queryPlan = getQueryPlan(schema, mutateableQuery);\n  return {\n    query: mutateableQuery,\n    queryPlan\n  };\n}\n//# sourceMappingURL=rx-query-helper.js.map","import { useOperators, OperatorType } from 'mingo/core';\nimport { Query } from 'mingo/query';\nimport { $project, $sort } from 'mingo/operators/pipeline';\nimport { $and, $not, $or, $nor } from 'mingo/operators/query/logical';\nimport { $eq, $ne, $gt, $gte, $lt, $lte, $nin, $in } from 'mingo/operators/query/comparison';\nimport { $regex, $mod } from 'mingo/operators/query/evaluation';\nimport { $elemMatch, $size } from 'mingo/operators/query/array';\nimport { $exists, $type } from 'mingo/operators/query/element';\nvar mingoInitDone = false;\n\n/**\n * The MongoDB query library is huge and we do not need all the operators.\n * If you add an operator here, make sure that you properly add a test in\n * the file /test/unit/rx-storage-query-correctness.test.ts\n *\n * @link https://github.com/kofrasa/mingo#es6\n */\nexport function getMingoQuery(selector) {\n  if (!mingoInitDone) {\n    useOperators(OperatorType.PIPELINE, {\n      $sort,\n      $project\n    });\n    useOperators(OperatorType.QUERY, {\n      $and,\n      $eq,\n      $elemMatch,\n      $exists,\n      $gt,\n      $gte,\n      $in,\n      $lt,\n      $lte,\n      $ne,\n      $nin,\n      $mod,\n      $nor,\n      $not,\n      $or,\n      $regex,\n      $size,\n      $type\n    });\n    mingoInitDone = true;\n  }\n  return new Query(selector);\n}\n//# sourceMappingURL=rx-query-mingo.js.map","import _createClass from \"@babel/runtime/helpers/createClass\";\nimport { mapDocumentsDataToCacheDocs } from \"./doc-cache.js\";\nimport { now, overwriteGetterForCaching } from \"./plugins/utils/index.js\";\nimport { newRxError } from \"./rx-error.js\";\n/**\n * RxDB needs the query results in multiple formats.\n * Sometimes as a Map or an array with only the documentData.\n * For better performance we work with this class\n * that initializes stuff lazily so that\n * we can directly work with the query results after RxQuery.exec()\n */\nexport var RxQuerySingleResult = /*#__PURE__*/function () {\n  /**\n   * Time at which the current _result state was created.\n   * Used to determine if the result set has changed since X\n   * so that we do not emit the same result multiple times on subscription.\n   */\n\n  function RxQuerySingleResult(query,\n  // only used internally, do not use outside, use this.docsData instead\n  docsDataFromStorageInstance,\n  // can be overwritten for count-queries\n  count) {\n    this.time = now();\n    this.query = query;\n    this.count = count;\n    this.documents = mapDocumentsDataToCacheDocs(this.query.collection._docCache, docsDataFromStorageInstance);\n  }\n\n  /**\n   * Instead of using the newResultData in the result cache,\n   * we directly use the objects that are stored in the RxDocument\n   * to ensure we do not store the same data twice and fill up the memory.\n   * @overwrites itself with the actual value\n   */\n  var _proto = RxQuerySingleResult.prototype;\n  _proto.getValue = function getValue(throwIfMissing) {\n    var op = this.query.op;\n    if (op === 'count') {\n      return this.count;\n    } else if (op === 'findOne') {\n      // findOne()-queries emit RxDocument or null\n      var doc = this.documents.length === 0 ? null : this.documents[0];\n      if (!doc && throwIfMissing) {\n        throw newRxError('QU10', {\n          collection: this.query.collection.name,\n          query: this.query.mangoQuery,\n          op\n        });\n      } else {\n        return doc;\n      }\n    } else if (op === 'findByIds') {\n      return this.docsMap;\n    } else {\n      // find()-queries emit RxDocument[]\n      // Flat copy the array so it won't matter if the user modifies it.\n      return this.documents.slice(0);\n    }\n  };\n  return _createClass(RxQuerySingleResult, [{\n    key: \"docsData\",\n    get: function () {\n      return overwriteGetterForCaching(this, 'docsData', this.documents.map(d => d._data));\n    }\n\n    // A key->document map, used in the event reduce optimization.\n  }, {\n    key: \"docsDataMap\",\n    get: function () {\n      var map = new Map();\n      this.documents.forEach(d => {\n        map.set(d.primary, d._data);\n      });\n      return overwriteGetterForCaching(this, 'docsDataMap', map);\n    }\n  }, {\n    key: \"docsMap\",\n    get: function () {\n      var map = new Map();\n      var documents = this.documents;\n      for (var i = 0; i < documents.length; i++) {\n        var doc = documents[i];\n        map.set(doc.primary, doc);\n      }\n      return overwriteGetterForCaching(this, 'docsMap', map);\n    }\n  }]);\n}();\n//# sourceMappingURL=rx-query-single-result.js.map","import _createClass from \"@babel/runtime/helpers/createClass\";\nimport { BehaviorSubject, merge } from 'rxjs';\nimport { mergeMap, filter, map, startWith, distinctUntilChanged, shareReplay } from 'rxjs/operators';\nimport { sortObject, pluginMissing, overwriteGetterForCaching, now, PROMISE_RESOLVE_FALSE, RXJS_SHARE_REPLAY_DEFAULTS, ensureNotFalsy, areRxDocumentArraysEqual, appendToArray } from \"./plugins/utils/index.js\";\nimport { newRxError, rxStorageWriteErrorToRxError } from \"./rx-error.js\";\nimport { runPluginHooks } from \"./hooks.js\";\nimport { calculateNewResults } from \"./event-reduce.js\";\nimport { triggerCacheReplacement } from \"./query-cache.js\";\nimport { getQueryMatcher, normalizeMangoQuery, prepareQuery, runQueryUpdateFunction } from \"./rx-query-helper.js\";\nimport { RxQuerySingleResult } from \"./rx-query-single-result.js\";\nvar _queryCount = 0;\nvar newQueryID = function () {\n  return ++_queryCount;\n};\nexport var RxQueryBase = /*#__PURE__*/function () {\n  /**\n   * Some stats then are used for debugging and cache replacement policies\n   */\n\n  // used in the query-cache to determine if the RxQuery can be cleaned up.\n\n  // used to count the subscribers to the query\n\n  /**\n   * Contains the current result state\n   * or null if query has not run yet.\n   */\n\n  function RxQueryBase(op, mangoQuery, collection,\n  // used by some plugins\n  other = {}) {\n    this.id = newQueryID();\n    this._execOverDatabaseCount = 0;\n    this._creationTime = now();\n    this._lastEnsureEqual = 0;\n    this.uncached = false;\n    this.refCount$ = new BehaviorSubject(null);\n    this._result = null;\n    this._latestChangeEvent = -1;\n    this._ensureEqualQueue = PROMISE_RESOLVE_FALSE;\n    this.op = op;\n    this.mangoQuery = mangoQuery;\n    this.collection = collection;\n    this.other = other;\n    if (!mangoQuery) {\n      this.mangoQuery = _getDefaultQuery();\n    }\n    this.isFindOneByIdQuery = isFindOneByIdQuery(this.collection.schema.primaryPath, mangoQuery);\n  }\n  var _proto = RxQueryBase.prototype;\n  /**\n   * Returns an observable that emits the results\n   * This should behave like an rxjs-BehaviorSubject which means:\n   * - Emit the current result-set on subscribe\n   * - Emit the new result-set when an RxChangeEvent comes in\n   * - Do not emit anything before the first result-set was created (no null)\n   */\n  /**\n   * set the new result-data as result-docs of the query\n   * @param newResultData json-docs that were received from the storage\n   */\n  _proto._setResultData = function _setResultData(newResultData) {\n    if (typeof newResultData === 'undefined') {\n      throw newRxError('QU18', {\n        database: this.collection.database.name,\n        collection: this.collection.name\n      });\n    }\n    if (typeof newResultData === 'number') {\n      this._result = new RxQuerySingleResult(this, [], newResultData);\n      return;\n    } else if (newResultData instanceof Map) {\n      newResultData = Array.from(newResultData.values());\n    }\n    var newQueryResult = new RxQuerySingleResult(this, newResultData, newResultData.length);\n    this._result = newQueryResult;\n  }\n\n  /**\n   * executes the query on the database\n   * @return results-array with document-data\n   */;\n  _proto._execOverDatabase = async function _execOverDatabase() {\n    this._execOverDatabaseCount = this._execOverDatabaseCount + 1;\n    if (this.op === 'count') {\n      var preparedQuery = this.getPreparedQuery();\n      var result = await this.collection.storageInstance.count(preparedQuery);\n      if (result.mode === 'slow' && !this.collection.database.allowSlowCount) {\n        throw newRxError('QU14', {\n          collection: this.collection,\n          queryObj: this.mangoQuery\n        });\n      } else {\n        return result.count;\n      }\n    }\n    if (this.op === 'findByIds') {\n      var ids = ensureNotFalsy(this.mangoQuery.selector)[this.collection.schema.primaryPath].$in;\n      var ret = new Map();\n      var mustBeQueried = [];\n      // first try to fill from docCache\n      ids.forEach(id => {\n        var docData = this.collection._docCache.getLatestDocumentDataIfExists(id);\n        if (docData) {\n          if (!docData._deleted) {\n            var doc = this.collection._docCache.getCachedRxDocument(docData);\n            ret.set(id, doc);\n          }\n        } else {\n          mustBeQueried.push(id);\n        }\n      });\n      // everything which was not in docCache must be fetched from the storage\n      if (mustBeQueried.length > 0) {\n        var docs = await this.collection.storageInstance.findDocumentsById(mustBeQueried, false);\n        docs.forEach(docData => {\n          var doc = this.collection._docCache.getCachedRxDocument(docData);\n          ret.set(doc.primary, doc);\n        });\n      }\n      return ret;\n    }\n    var docsPromise = queryCollection(this);\n    return docsPromise.then(docs => {\n      return docs;\n    });\n  }\n\n  /**\n   * Execute the query\n   * To have an easier implementations,\n   * just subscribe and use the first result\n   */;\n  _proto.exec = async function exec(throwIfMissing) {\n    if (throwIfMissing && this.op !== 'findOne') {\n      throw newRxError('QU9', {\n        collection: this.collection.name,\n        query: this.mangoQuery,\n        op: this.op\n      });\n    }\n\n    /**\n     * run _ensureEqual() here,\n     * this will make sure that errors in the query which throw inside of the RxStorage,\n     * will be thrown at this execution context and not in the background.\n     */\n    await _ensureEqual(this);\n    var useResult = ensureNotFalsy(this._result);\n    return useResult.getValue(throwIfMissing);\n  }\n\n  /**\n   * cached call to get the queryMatcher\n   * @overwrites itself with the actual value\n   */;\n  /**\n   * returns a string that is used for equal-comparisons\n   * @overwrites itself with the actual value\n   */\n  _proto.toString = function toString() {\n    var stringObj = sortObject({\n      op: this.op,\n      query: normalizeMangoQuery(this.collection.schema.jsonSchema, this.mangoQuery),\n      other: this.other\n    }, true);\n    var value = JSON.stringify(stringObj);\n    this.toString = () => value;\n    return value;\n  }\n\n  /**\n   * returns the prepared query\n   * which can be send to the storage instance to query for documents.\n   * @overwrites itself with the actual value.\n   */;\n  _proto.getPreparedQuery = function getPreparedQuery() {\n    var hookInput = {\n      rxQuery: this,\n      // can be mutated by the hooks so we have to deep clone first.\n      mangoQuery: normalizeMangoQuery(this.collection.schema.jsonSchema, this.mangoQuery)\n    };\n    hookInput.mangoQuery.selector._deleted = {\n      $eq: false\n    };\n    if (hookInput.mangoQuery.index) {\n      hookInput.mangoQuery.index.unshift('_deleted');\n    }\n    runPluginHooks('prePrepareQuery', hookInput);\n    var value = prepareQuery(this.collection.schema.jsonSchema, hookInput.mangoQuery);\n    this.getPreparedQuery = () => value;\n    return value;\n  }\n\n  /**\n   * returns true if the document matches the query,\n   * does not use the 'skip' and 'limit'\n   */;\n  _proto.doesDocumentDataMatch = function doesDocumentDataMatch(docData) {\n    // if doc is deleted, it cannot match\n    if (docData._deleted) {\n      return false;\n    }\n    return this.queryMatcher(docData);\n  }\n\n  /**\n   * deletes all found documents\n   * @return promise with deleted documents\n   */;\n  _proto.remove = async function remove() {\n    var docs = await this.exec();\n    if (Array.isArray(docs)) {\n      var result = await this.collection.bulkRemove(docs);\n      if (result.error.length > 0) {\n        throw rxStorageWriteErrorToRxError(result.error[0]);\n      } else {\n        return result.success;\n      }\n    } else {\n      return docs.remove();\n    }\n  };\n  _proto.incrementalRemove = function incrementalRemove() {\n    return runQueryUpdateFunction(this.asRxQuery, doc => doc.incrementalRemove());\n  }\n\n  /**\n   * helper function to transform RxQueryBase to RxQuery type\n   */;\n  /**\n   * updates all found documents\n   * @overwritten by plugin (optional)\n   */\n  _proto.update = function update(_updateObj) {\n    throw pluginMissing('update');\n  };\n  _proto.patch = function patch(_patch) {\n    return runQueryUpdateFunction(this.asRxQuery, doc => doc.patch(_patch));\n  };\n  _proto.incrementalPatch = function incrementalPatch(patch) {\n    return runQueryUpdateFunction(this.asRxQuery, doc => doc.incrementalPatch(patch));\n  };\n  _proto.modify = function modify(mutationFunction) {\n    return runQueryUpdateFunction(this.asRxQuery, doc => doc.modify(mutationFunction));\n  };\n  _proto.incrementalModify = function incrementalModify(mutationFunction) {\n    return runQueryUpdateFunction(this.asRxQuery, doc => doc.incrementalModify(mutationFunction));\n  }\n\n  // we only set some methods of query-builder here\n  // because the others depend on these ones\n  ;\n  _proto.where = function where(_queryObj) {\n    throw pluginMissing('query-builder');\n  };\n  _proto.sort = function sort(_params) {\n    throw pluginMissing('query-builder');\n  };\n  _proto.skip = function skip(_amount) {\n    throw pluginMissing('query-builder');\n  };\n  _proto.limit = function limit(_amount) {\n    throw pluginMissing('query-builder');\n  };\n  return _createClass(RxQueryBase, [{\n    key: \"$\",\n    get: function () {\n      if (!this._$) {\n        var results$ = this.collection.eventBulks$.pipe(\n        /**\n         * Performance shortcut.\n         * Changes to local documents are not relevant for the query.\n         */\n        filter(bulk => !bulk.isLocal),\n        /**\n         * Start once to ensure the querying also starts\n         * when there where no changes.\n         */\n        startWith(null),\n        // ensure query results are up to date.\n        mergeMap(() => _ensureEqual(this)),\n        // use the current result set, written by _ensureEqual().\n        map(() => this._result),\n        // do not run stuff above for each new subscriber, only once.\n        shareReplay(RXJS_SHARE_REPLAY_DEFAULTS),\n        // do not proceed if result set has not changed.\n        distinctUntilChanged((prev, curr) => {\n          if (prev && prev.time === ensureNotFalsy(curr).time) {\n            return true;\n          } else {\n            return false;\n          }\n        }), filter(result => !!result),\n        /**\n         * Map the result set to a single RxDocument or an array,\n         * depending on query type\n         */\n        map(result => {\n          return ensureNotFalsy(result).getValue();\n        }));\n        this._$ = merge(results$,\n        /**\n         * Also add the refCount$ to the query observable\n         * to allow us to count the amount of subscribers.\n         */\n        this.refCount$.pipe(filter(() => false)));\n      }\n      return this._$;\n    }\n  }, {\n    key: \"$$\",\n    get: function () {\n      var reactivity = this.collection.database.getReactivityFactory();\n      return reactivity.fromObservable(this.$, undefined, this.collection.database);\n    }\n\n    // stores the changeEvent-number of the last handled change-event\n\n    /**\n     * ensures that the exec-runs\n     * are not run in parallel\n     */\n  }, {\n    key: \"queryMatcher\",\n    get: function () {\n      var schema = this.collection.schema.jsonSchema;\n      var normalizedQuery = normalizeMangoQuery(this.collection.schema.jsonSchema, this.mangoQuery);\n      return overwriteGetterForCaching(this, 'queryMatcher', getQueryMatcher(schema, normalizedQuery));\n    }\n  }, {\n    key: \"asRxQuery\",\n    get: function () {\n      return this;\n    }\n  }]);\n}();\nexport function _getDefaultQuery() {\n  return {\n    selector: {}\n  };\n}\n\n/**\n * run this query through the QueryCache\n */\nexport function tunnelQueryCache(rxQuery) {\n  return rxQuery.collection._queryCache.getByQuery(rxQuery);\n}\nexport function createRxQuery(op, queryObj, collection, other) {\n  runPluginHooks('preCreateRxQuery', {\n    op,\n    queryObj,\n    collection,\n    other\n  });\n  var ret = new RxQueryBase(op, queryObj, collection, other);\n\n  // ensure when created with same params, only one is created\n  ret = tunnelQueryCache(ret);\n  triggerCacheReplacement(collection);\n  return ret;\n}\n\n/**\n * Check if the current results-state is in sync with the database\n * which means that no write event happened since the last run.\n * @return false if not which means it should re-execute\n */\nfunction _isResultsInSync(rxQuery) {\n  var currentLatestEventNumber = rxQuery.asRxQuery.collection._changeEventBuffer.getCounter();\n  if (rxQuery._latestChangeEvent >= currentLatestEventNumber) {\n    return true;\n  } else {\n    return false;\n  }\n}\n\n/**\n * wraps __ensureEqual()\n * to ensure it does not run in parallel\n * @return true if has changed, false if not\n */\nasync function _ensureEqual(rxQuery) {\n  if (rxQuery.collection.awaitBeforeReads.size > 0) {\n    await Promise.all(Array.from(rxQuery.collection.awaitBeforeReads).map(fn => fn()));\n  }\n\n  // Optimisation shortcut\n  if (rxQuery.collection.database.closed || _isResultsInSync(rxQuery)) {\n    return false;\n  }\n  rxQuery._ensureEqualQueue = rxQuery._ensureEqualQueue.then(() => __ensureEqual(rxQuery));\n  return rxQuery._ensureEqualQueue;\n}\n\n/**\n * ensures that the results of this query is equal to the results which a query over the database would give\n * @return true if results have changed\n */\nfunction __ensureEqual(rxQuery) {\n  rxQuery._lastEnsureEqual = now();\n\n  /**\n   * Optimisation shortcuts\n   */\n  if (\n  // db is closed\n  rxQuery.collection.database.closed ||\n  // nothing happened since last run\n  _isResultsInSync(rxQuery)) {\n    return PROMISE_RESOLVE_FALSE;\n  }\n  var ret = false;\n  var mustReExec = false; // if this becomes true, a whole execution over the database is made\n  if (rxQuery._latestChangeEvent === -1) {\n    // have not executed yet -> must run\n    mustReExec = true;\n  }\n\n  /**\n   * try to use EventReduce to calculate the new results\n   */\n  if (!mustReExec) {\n    var missedChangeEvents = rxQuery.asRxQuery.collection._changeEventBuffer.getFrom(rxQuery._latestChangeEvent + 1);\n    if (missedChangeEvents === null) {\n      // changeEventBuffer is of bounds -> we must re-execute over the database\n      mustReExec = true;\n    } else {\n      rxQuery._latestChangeEvent = rxQuery.asRxQuery.collection._changeEventBuffer.getCounter();\n      var runChangeEvents = rxQuery.asRxQuery.collection._changeEventBuffer.reduceByLastOfDoc(missedChangeEvents);\n      if (rxQuery.op === 'count') {\n        // 'count' query\n        var previousCount = ensureNotFalsy(rxQuery._result).count;\n        var newCount = previousCount;\n        runChangeEvents.forEach(cE => {\n          var didMatchBefore = cE.previousDocumentData && rxQuery.doesDocumentDataMatch(cE.previousDocumentData);\n          var doesMatchNow = rxQuery.doesDocumentDataMatch(cE.documentData);\n          if (!didMatchBefore && doesMatchNow) {\n            newCount++;\n          }\n          if (didMatchBefore && !doesMatchNow) {\n            newCount--;\n          }\n        });\n        if (newCount !== previousCount) {\n          ret = true; // true because results changed\n          rxQuery._setResultData(newCount);\n        }\n      } else {\n        // 'find' or 'findOne' query\n        var eventReduceResult = calculateNewResults(rxQuery, runChangeEvents);\n        if (eventReduceResult.runFullQueryAgain) {\n          // could not calculate the new results, execute must be done\n          mustReExec = true;\n        } else if (eventReduceResult.changed) {\n          // we got the new results, we do not have to re-execute, mustReExec stays false\n          ret = true; // true because results changed\n          rxQuery._setResultData(eventReduceResult.newResults);\n        }\n      }\n    }\n  }\n\n  // oh no we have to re-execute the whole query over the database\n  if (mustReExec) {\n    return rxQuery._execOverDatabase().then(newResultData => {\n      /**\n       * The RxStorage is defined to always first emit events and then return\n       * on bulkWrite() calls. So here we have to use the counter AFTER the execOverDatabase()\n       * has been run, not the one from before.\n       */\n      rxQuery._latestChangeEvent = rxQuery.collection._changeEventBuffer.getCounter();\n\n      // A count query needs a different has-changed check.\n      if (typeof newResultData === 'number') {\n        if (!rxQuery._result || newResultData !== rxQuery._result.count) {\n          ret = true;\n          rxQuery._setResultData(newResultData);\n        }\n        return ret;\n      }\n      if (!rxQuery._result || !areRxDocumentArraysEqual(rxQuery.collection.schema.primaryPath, newResultData, rxQuery._result.docsData)) {\n        ret = true; // true because results changed\n        rxQuery._setResultData(newResultData);\n      }\n      return ret;\n    });\n  }\n  return Promise.resolve(ret); // true if results have changed\n}\n\n/**\n * Runs the query over the storage instance\n * of the collection.\n * Does some optimizations to ensure findById is used\n * when specific queries are used.\n */\nexport async function queryCollection(rxQuery) {\n  var docs = [];\n  var collection = rxQuery.collection;\n\n  /**\n   * Optimizations shortcut.\n   * If query is find-one-document-by-id,\n   * then we do not have to use the slow query() method\n   * but instead can use findDocumentsById()\n   */\n  if (rxQuery.isFindOneByIdQuery) {\n    if (Array.isArray(rxQuery.isFindOneByIdQuery)) {\n      var docIds = rxQuery.isFindOneByIdQuery;\n      docIds = docIds.filter(docId => {\n        // first try to fill from docCache\n        var docData = rxQuery.collection._docCache.getLatestDocumentDataIfExists(docId);\n        if (docData) {\n          if (!docData._deleted) {\n            docs.push(docData);\n          }\n          return false;\n        } else {\n          return true;\n        }\n      });\n      // otherwise get from storage\n      if (docIds.length > 0) {\n        var docsFromStorage = await collection.storageInstance.findDocumentsById(docIds, false);\n        appendToArray(docs, docsFromStorage);\n      }\n    } else {\n      var docId = rxQuery.isFindOneByIdQuery;\n\n      // first try to fill from docCache\n      var docData = rxQuery.collection._docCache.getLatestDocumentDataIfExists(docId);\n      if (!docData) {\n        // otherwise get from storage\n        var fromStorageList = await collection.storageInstance.findDocumentsById([docId], false);\n        if (fromStorageList[0]) {\n          docData = fromStorageList[0];\n        }\n      }\n      if (docData && !docData._deleted) {\n        docs.push(docData);\n      }\n    }\n  } else {\n    var preparedQuery = rxQuery.getPreparedQuery();\n    var queryResult = await collection.storageInstance.query(preparedQuery);\n    docs = queryResult.documents;\n  }\n  return docs;\n}\n\n/**\n * Returns true if the given query\n * selects exactly one document by its id.\n * Used to optimize performance because these kind of\n * queries do not have to run over an index and can use get-by-id instead.\n * Returns false if no query of that kind.\n * Returns the document id otherwise.\n */\nexport function isFindOneByIdQuery(primaryPath, query) {\n  // must have exactly one operator which must be $eq || $in\n  if (!query.skip && query.selector && Object.keys(query.selector).length === 1 && query.selector[primaryPath]) {\n    var value = query.selector[primaryPath];\n    if (typeof value === 'string') {\n      return value;\n    } else if (Object.keys(value).length === 1 && typeof value.$eq === 'string') {\n      return value.$eq;\n    }\n\n    // same with $in string arrays\n    if (Object.keys(value).length === 1 && Array.isArray(value.$eq) &&\n    // must only contain strings\n    !value.$eq.find(r => typeof r !== 'string')) {\n      return value.$eq;\n    }\n  }\n  return false;\n}\nexport function isRxQuery(obj) {\n  return obj instanceof RxQueryBase;\n}\n//# sourceMappingURL=rx-query.js.map","import { newRxError } from \"./rx-error.js\";\nimport { appendToArray, ensureNotFalsy, flatClone, getProperty, isMaybeReadonlyArray, REGEX_ALL_DOTS, RX_META_LWT_MINIMUM, sortObject, trimDots } from \"./plugins/utils/index.js\";\n/**\n * Helper function to create a valid RxJsonSchema\n * with a given version.\n */\nexport function getPseudoSchemaForVersion(version, primaryKey) {\n  var pseudoSchema = fillWithDefaultSettings({\n    version,\n    type: 'object',\n    primaryKey: primaryKey,\n    properties: {\n      [primaryKey]: {\n        type: 'string',\n        maxLength: 100\n      },\n      value: {\n        type: 'string'\n      }\n    },\n    indexes: [[primaryKey]],\n    required: [primaryKey]\n  });\n  return pseudoSchema;\n}\n\n/**\n * Returns the sub-schema for a given path\n */\nexport function getSchemaByObjectPath(rxJsonSchema, path) {\n  var usePath = path;\n  usePath = usePath.replace(REGEX_ALL_DOTS, '.properties.');\n  usePath = 'properties.' + usePath;\n  usePath = trimDots(usePath);\n  var ret = getProperty(rxJsonSchema, usePath);\n  return ret;\n}\nexport function fillPrimaryKey(primaryPath, jsonSchema, documentData) {\n  // optimization shortcut.\n  if (typeof jsonSchema.primaryKey === 'string') {\n    return documentData;\n  }\n  var newPrimary = getComposedPrimaryKeyOfDocumentData(jsonSchema, documentData);\n  var existingPrimary = documentData[primaryPath];\n  if (existingPrimary && existingPrimary !== newPrimary) {\n    throw newRxError('DOC19', {\n      args: {\n        documentData,\n        existingPrimary,\n        newPrimary\n      },\n      schema: jsonSchema\n    });\n  }\n  documentData[primaryPath] = newPrimary;\n  return documentData;\n}\nexport function getPrimaryFieldOfPrimaryKey(primaryKey) {\n  if (typeof primaryKey === 'string') {\n    return primaryKey;\n  } else {\n    return primaryKey.key;\n  }\n}\nexport function getLengthOfPrimaryKey(schema) {\n  var primaryPath = getPrimaryFieldOfPrimaryKey(schema.primaryKey);\n  var schemaPart = getSchemaByObjectPath(schema, primaryPath);\n  return ensureNotFalsy(schemaPart.maxLength);\n}\n\n/**\n * Returns the composed primaryKey of a document by its data.\n */\nexport function getComposedPrimaryKeyOfDocumentData(jsonSchema, documentData) {\n  if (typeof jsonSchema.primaryKey === 'string') {\n    return documentData[jsonSchema.primaryKey];\n  }\n  var compositePrimary = jsonSchema.primaryKey;\n  return compositePrimary.fields.map(field => {\n    var value = getProperty(documentData, field);\n    if (typeof value === 'undefined') {\n      throw newRxError('DOC18', {\n        args: {\n          field,\n          documentData\n        }\n      });\n    }\n    return value;\n  }).join(compositePrimary.separator);\n}\n\n/**\n * Normalize the RxJsonSchema.\n * We need this to ensure everything is set up properly\n * and we have the same hash on schemas that represent the same value but\n * have different json.\n *\n * - Orders the schemas attributes by alphabetical order\n * - Adds the primaryKey to all indexes that do not contain the primaryKey\n * - We need this for deterministic sort order on all queries, which is required for event-reduce to work.\n *\n * @return RxJsonSchema - ordered and filled\n */\nexport function normalizeRxJsonSchema(jsonSchema) {\n  var normalizedSchema = sortObject(jsonSchema, true);\n  return normalizedSchema;\n}\n\n/**\n * If the schema does not specify any index,\n * we add this index so we at least can run RxQuery()\n * and only select non-deleted fields.\n */\nexport function getDefaultIndex(primaryPath) {\n  return ['_deleted', primaryPath];\n}\n\n/**\n * fills the schema-json with default-settings\n * @return cloned schemaObj\n */\nexport function fillWithDefaultSettings(schemaObj) {\n  schemaObj = flatClone(schemaObj);\n  var primaryPath = getPrimaryFieldOfPrimaryKey(schemaObj.primaryKey);\n  schemaObj.properties = flatClone(schemaObj.properties);\n\n  // additionalProperties is always false\n  schemaObj.additionalProperties = false;\n\n  // fill with key-compression-state ()\n  if (!Object.prototype.hasOwnProperty.call(schemaObj, 'keyCompression')) {\n    schemaObj.keyCompression = false;\n  }\n\n  // indexes must be array\n  schemaObj.indexes = schemaObj.indexes ? schemaObj.indexes.slice(0) : [];\n\n  // required must be array\n  schemaObj.required = schemaObj.required ? schemaObj.required.slice(0) : [];\n\n  // encrypted must be array\n  schemaObj.encrypted = schemaObj.encrypted ? schemaObj.encrypted.slice(0) : [];\n\n  // add _rev\n  schemaObj.properties._rev = {\n    type: 'string',\n    minLength: 1\n  };\n\n  // add attachments\n  schemaObj.properties._attachments = {\n    type: 'object'\n  };\n\n  // add deleted flag\n  schemaObj.properties._deleted = {\n    type: 'boolean'\n  };\n\n  // add meta property\n  schemaObj.properties._meta = RX_META_SCHEMA;\n\n  /**\n   * meta fields are all required\n   */\n  schemaObj.required = schemaObj.required ? schemaObj.required.slice(0) : [];\n  schemaObj.required.push('_deleted');\n  schemaObj.required.push('_rev');\n  schemaObj.required.push('_meta');\n  schemaObj.required.push('_attachments');\n\n  // final fields are always required\n  var finalFields = getFinalFields(schemaObj);\n  appendToArray(schemaObj.required, finalFields);\n  schemaObj.required = schemaObj.required.filter(field => !field.includes('.')).filter((elem, pos, arr) => arr.indexOf(elem) === pos); // unique;\n\n  // version is 0 by default\n  schemaObj.version = schemaObj.version || 0;\n  var useIndexes = schemaObj.indexes.map(index => {\n    var arIndex = isMaybeReadonlyArray(index) ? index.slice(0) : [index];\n    /**\n     * Append primary key to indexes that do not contain the primaryKey.\n     * All indexes must have the primaryKey to ensure a deterministic sort order.\n     */\n    if (!arIndex.includes(primaryPath)) {\n      arIndex.push(primaryPath);\n    }\n\n    // add _deleted flag to all indexes so we can query only non-deleted fields\n    // in RxDB itself\n    if (arIndex[0] !== '_deleted') {\n      arIndex.unshift('_deleted');\n    }\n    return arIndex;\n  });\n  if (useIndexes.length === 0) {\n    useIndexes.push(getDefaultIndex(primaryPath));\n  }\n\n  // we need this index for the getChangedDocumentsSince() method\n  useIndexes.push(['_meta.lwt', primaryPath]);\n\n  // also add the internalIndexes\n  if (schemaObj.internalIndexes) {\n    schemaObj.internalIndexes.map(idx => {\n      useIndexes.push(idx);\n    });\n  }\n\n  // make indexes unique\n  var hasIndex = new Set();\n  useIndexes.filter(index => {\n    var indexStr = index.join(',');\n    if (hasIndex.has(indexStr)) {\n      return false;\n    } else {\n      hasIndex.add(indexStr);\n      return true;\n    }\n  });\n  schemaObj.indexes = useIndexes;\n  return schemaObj;\n}\nexport var RX_META_SCHEMA = {\n  type: 'object',\n  properties: {\n    /**\n     * The last-write time.\n     * Unix time in milliseconds.\n     */\n    lwt: {\n      type: 'number',\n      /**\n       * We use 1 as minimum so that the value is never falsy.\n       */\n      minimum: RX_META_LWT_MINIMUM,\n      maximum: 1000000000000000,\n      multipleOf: 0.01\n    }\n  },\n  /**\n   * Additional properties are allowed\n   * and can be used by plugins to set various flags.\n   */\n  additionalProperties: true,\n  required: ['lwt']\n};\n\n/**\n * returns the final-fields of the schema\n * @return field-names of the final-fields\n */\nexport function getFinalFields(jsonSchema) {\n  var ret = Object.keys(jsonSchema.properties).filter(key => jsonSchema.properties[key].final);\n\n  // primary is also final\n  var primaryPath = getPrimaryFieldOfPrimaryKey(jsonSchema.primaryKey);\n  ret.push(primaryPath);\n\n  // fields of composite primary are final\n  if (typeof jsonSchema.primaryKey !== 'string') {\n    jsonSchema.primaryKey.fields.forEach(field => ret.push(field));\n  }\n  return ret;\n}\n\n/**\n * fills all unset fields with default-values if set\n * @hotPath\n */\nexport function fillObjectWithDefaults(rxSchema, obj) {\n  var defaultKeys = Object.keys(rxSchema.defaultValues);\n  for (var i = 0; i < defaultKeys.length; ++i) {\n    var key = defaultKeys[i];\n    if (!Object.prototype.hasOwnProperty.call(obj, key) || typeof obj[key] === 'undefined') {\n      obj[key] = rxSchema.defaultValues[key];\n    }\n  }\n  return obj;\n}\nexport var DEFAULT_CHECKPOINT_SCHEMA = {\n  type: 'object',\n  properties: {\n    id: {\n      type: 'string'\n    },\n    lwt: {\n      type: 'number'\n    }\n  },\n  required: ['id', 'lwt'],\n  additionalProperties: false\n};\n//# sourceMappingURL=rx-schema-helper.js.map","import _createClass from \"@babel/runtime/helpers/createClass\";\nimport { overwriteGetterForCaching, isMaybeReadonlyArray, deepEqual } from \"./plugins/utils/index.js\";\nimport { newRxError } from \"./rx-error.js\";\nimport { runPluginHooks } from \"./hooks.js\";\nimport { fillWithDefaultSettings, getComposedPrimaryKeyOfDocumentData, getFinalFields, getPrimaryFieldOfPrimaryKey, getSchemaByObjectPath, normalizeRxJsonSchema } from \"./rx-schema-helper.js\";\nimport { overwritable } from \"./overwritable.js\";\nexport var RxSchema = /*#__PURE__*/function () {\n  function RxSchema(jsonSchema, hashFunction) {\n    this.jsonSchema = jsonSchema;\n    this.hashFunction = hashFunction;\n    this.indexes = getIndexes(this.jsonSchema);\n\n    // primary is always required\n    this.primaryPath = getPrimaryFieldOfPrimaryKey(this.jsonSchema.primaryKey);\n\n    /**\n     * Many people accidentally put in wrong schema state\n     * without the dev-mode plugin, so we need this check here\n     * even in non-dev-mode.\n     */\n    if (!jsonSchema.properties[this.primaryPath].maxLength) {\n      throw newRxError('SC39', {\n        schema: jsonSchema\n      });\n    }\n    this.finalFields = getFinalFields(this.jsonSchema);\n  }\n  var _proto = RxSchema.prototype;\n  /**\n   * checks if a given change on a document is allowed\n   * Ensures that:\n   * - final fields are not modified\n   * @throws {Error} if not valid\n   */\n  _proto.validateChange = function validateChange(dataBefore, dataAfter) {\n    this.finalFields.forEach(fieldName => {\n      if (!deepEqual(dataBefore[fieldName], dataAfter[fieldName])) {\n        throw newRxError('DOC9', {\n          dataBefore,\n          dataAfter,\n          fieldName,\n          schema: this.jsonSchema\n        });\n      }\n    });\n  }\n\n  /**\n   * creates the schema-based document-prototype,\n   * see RxCollection.getDocumentPrototype()\n   */;\n  _proto.getDocumentPrototype = function getDocumentPrototype() {\n    var proto = {};\n\n    /**\n     * On the top level, we know all keys\n     * and therefore do not have to create a new Proxy object\n     * for each document. Instead we define the getter in the prototype once.\n     */\n    var pathProperties = getSchemaByObjectPath(this.jsonSchema, '');\n    Object.keys(pathProperties).forEach(key => {\n      var fullPath = key;\n\n      // getter - value\n      proto.__defineGetter__(key, function () {\n        if (!this.get || typeof this.get !== 'function') {\n          /**\n           * When an object gets added to the state of a vuejs-component,\n           * it happens that this getter is called with another scope.\n           * To prevent errors, we have to return undefined in this case\n           */\n          return undefined;\n        }\n        var ret = this.get(fullPath);\n        return ret;\n      });\n      // getter - observable$\n      Object.defineProperty(proto, key + '$', {\n        get: function () {\n          return this.get$(fullPath);\n        },\n        enumerable: false,\n        configurable: false\n      });\n      // getter - reactivity$$\n      Object.defineProperty(proto, key + '$$', {\n        get: function () {\n          return this.get$$(fullPath);\n        },\n        enumerable: false,\n        configurable: false\n      });\n      // getter - populate_\n      Object.defineProperty(proto, key + '_', {\n        get: function () {\n          return this.populate(fullPath);\n        },\n        enumerable: false,\n        configurable: false\n      });\n    });\n    overwriteGetterForCaching(this, 'getDocumentPrototype', () => proto);\n    return proto;\n  };\n  _proto.getPrimaryOfDocumentData = function getPrimaryOfDocumentData(documentData) {\n    return getComposedPrimaryKeyOfDocumentData(this.jsonSchema, documentData);\n  };\n  return _createClass(RxSchema, [{\n    key: \"version\",\n    get: function () {\n      return this.jsonSchema.version;\n    }\n  }, {\n    key: \"defaultValues\",\n    get: function () {\n      var values = {};\n      Object.entries(this.jsonSchema.properties).filter(([, v]) => Object.prototype.hasOwnProperty.call(v, 'default')).forEach(([k, v]) => values[k] = v.default);\n      return overwriteGetterForCaching(this, 'defaultValues', values);\n    }\n\n    /**\n     * @overrides itself on the first call\n     */\n  }, {\n    key: \"hash\",\n    get: function () {\n      return overwriteGetterForCaching(this, 'hash', this.hashFunction(JSON.stringify(this.jsonSchema)));\n    }\n  }]);\n}();\nexport function getIndexes(jsonSchema) {\n  return (jsonSchema.indexes || []).map(index => isMaybeReadonlyArray(index) ? index : [index]);\n}\n\n/**\n * array with previous version-numbers\n */\nexport function getPreviousVersions(schema) {\n  var version = schema.version ? schema.version : 0;\n  var c = 0;\n  return new Array(version).fill(0).map(() => c++);\n}\nexport function createRxSchema(jsonSchema, hashFunction, runPreCreateHooks = true) {\n  if (runPreCreateHooks) {\n    runPluginHooks('preCreateRxSchema', jsonSchema);\n  }\n  var useJsonSchema = fillWithDefaultSettings(jsonSchema);\n  useJsonSchema = normalizeRxJsonSchema(useJsonSchema);\n  overwritable.deepFreezeWhenDevMode(useJsonSchema);\n  var schema = new RxSchema(useJsonSchema, hashFunction);\n  runPluginHooks('createRxSchema', schema);\n  return schema;\n}\nexport function isRxSchema(obj) {\n  return obj instanceof RxSchema;\n}\n\n/**\n * Used as helper function the generate the document type out of the schema via typescript.\n * @link https://github.com/pubkey/rxdb/discussions/3467\n */\nexport function toTypedRxJsonSchema(schema) {\n  return schema;\n}\n//# sourceMappingURL=rx-schema.js.map","/**\n * Helper functions for accessing the RxStorage instances.\n */\n\nimport { overwritable } from \"./overwritable.js\";\nimport { newRxError } from \"./rx-error.js\";\nimport { getPrimaryFieldOfPrimaryKey } from \"./rx-schema-helper.js\";\nimport { PROMISE_RESOLVE_TRUE, RXDB_VERSION, RX_META_LWT_MINIMUM, appendToArray, createRevision, ensureNotFalsy, flatClone, getFromMapOrCreate, lastOfArray, now, promiseWait, randomToken } from \"./plugins/utils/index.js\";\nimport { filter, map, startWith, switchMap } from 'rxjs';\nimport { normalizeMangoQuery, prepareQuery } from \"./rx-query-helper.js\";\nimport { runPluginHooks } from \"./hooks.js\";\nexport var INTERNAL_STORAGE_NAME = '_rxdb_internal';\nexport var RX_DATABASE_LOCAL_DOCS_STORAGE_NAME = 'rxdatabase_storage_local';\nexport async function getSingleDocument(storageInstance, documentId) {\n  var results = await storageInstance.findDocumentsById([documentId], false);\n  var doc = results[0];\n  if (doc) {\n    return doc;\n  } else {\n    return undefined;\n  }\n}\n\n/**\n * Writes a single document,\n * throws RxStorageBulkWriteError on failure\n */\nexport async function writeSingle(instance, writeRow, context) {\n  var writeResult = await instance.bulkWrite([writeRow], context);\n  if (writeResult.error.length > 0) {\n    var error = writeResult.error[0];\n    throw error;\n  } else {\n    var primaryPath = getPrimaryFieldOfPrimaryKey(instance.schema.primaryKey);\n    var success = getWrittenDocumentsFromBulkWriteResponse(primaryPath, [writeRow], writeResult);\n    var ret = success[0];\n    return ret;\n  }\n}\n\n/**\n * Observe the plain document data of a single document.\n * Do not forget to unsubscribe.\n */\nexport function observeSingle(storageInstance, documentId) {\n  var firstFindPromise = getSingleDocument(storageInstance, documentId);\n  var ret = storageInstance.changeStream().pipe(map(evBulk => evBulk.events.find(ev => ev.documentId === documentId)), filter(ev => !!ev), map(ev => Promise.resolve(ensureNotFalsy(ev).documentData)), startWith(firstFindPromise), switchMap(v => v), filter(v => !!v));\n  return ret;\n}\n\n/**\n * Checkpoints must be stackable over another.\n * This is required form some RxStorage implementations\n * like the sharding plugin, where a checkpoint only represents\n * the document state from some, but not all shards.\n */\nexport function stackCheckpoints(checkpoints) {\n  return Object.assign({}, ...checkpoints);\n}\nexport function throwIfIsStorageWriteError(collection, documentId, writeData, error) {\n  if (error) {\n    if (error.status === 409) {\n      throw newRxError('CONFLICT', {\n        collection: collection.name,\n        id: documentId,\n        writeError: error,\n        data: writeData\n      });\n    } else if (error.status === 422) {\n      throw newRxError('VD2', {\n        collection: collection.name,\n        id: documentId,\n        writeError: error,\n        data: writeData\n      });\n    } else {\n      throw error;\n    }\n  }\n}\n\n/**\n * Analyzes a list of BulkWriteRows and determines\n * which documents must be inserted, updated or deleted\n * and which events must be emitted and which documents cause a conflict\n * and must not be written.\n * Used as helper inside of some RxStorage implementations.\n * @hotPath The performance of this function is critical\n */\nexport function categorizeBulkWriteRows(storageInstance, primaryPath,\n/**\n * Current state of the documents\n * inside of the storage. Used to determine\n * which writes cause conflicts.\n * This must be a Map for better performance.\n */\ndocsInDb,\n/**\n * The write rows that are passed to\n * RxStorageInstance().bulkWrite().\n */\nbulkWriteRows, context,\n/**\n * Used by some storages for better performance.\n * For example when get-by-id and insert/update can run in parallel.\n */\nonInsert, onUpdate) {\n  var hasAttachments = !!storageInstance.schema.attachments;\n  var bulkInsertDocs = [];\n  var bulkUpdateDocs = [];\n  var errors = [];\n  var eventBulkId = randomToken(10);\n  var eventBulk = {\n    id: eventBulkId,\n    events: [],\n    checkpoint: null,\n    context\n  };\n  var eventBulkEvents = eventBulk.events;\n  var attachmentsAdd = [];\n  var attachmentsRemove = [];\n  var attachmentsUpdate = [];\n  var hasDocsInDb = docsInDb.size > 0;\n  var newestRow;\n\n  /**\n   * @performance is really important in this loop!\n   */\n  var rowAmount = bulkWriteRows.length;\n  var _loop = function () {\n    var writeRow = bulkWriteRows[rowId];\n\n    // use these variables to have less property accesses\n    var document = writeRow.document;\n    var previous = writeRow.previous;\n    var docId = document[primaryPath];\n    var documentDeleted = document._deleted;\n    var previousDeleted = previous && previous._deleted;\n    var documentInDb = undefined;\n    if (hasDocsInDb) {\n      documentInDb = docsInDb.get(docId);\n    }\n    var attachmentError;\n    if (!documentInDb) {\n      /**\n       * It is possible to insert already deleted documents,\n       * this can happen on replication.\n       */\n      var insertedIsDeleted = documentDeleted ? true : false;\n      if (hasAttachments) {\n        Object.entries(document._attachments).forEach(([attachmentId, attachmentData]) => {\n          if (!attachmentData.data) {\n            attachmentError = {\n              documentId: docId,\n              isError: true,\n              status: 510,\n              writeRow,\n              attachmentId\n            };\n            errors.push(attachmentError);\n          } else {\n            attachmentsAdd.push({\n              documentId: docId,\n              attachmentId,\n              attachmentData: attachmentData,\n              digest: attachmentData.digest\n            });\n          }\n        });\n      }\n      if (!attachmentError) {\n        if (hasAttachments) {\n          bulkInsertDocs.push(stripAttachmentsDataFromRow(writeRow));\n          if (onInsert) {\n            onInsert(document);\n          }\n        } else {\n          bulkInsertDocs.push(writeRow);\n          if (onInsert) {\n            onInsert(document);\n          }\n        }\n        newestRow = writeRow;\n      }\n      if (!insertedIsDeleted) {\n        var event = {\n          documentId: docId,\n          operation: 'INSERT',\n          documentData: hasAttachments ? stripAttachmentsDataFromDocument(document) : document,\n          previousDocumentData: hasAttachments && previous ? stripAttachmentsDataFromDocument(previous) : previous\n        };\n        eventBulkEvents.push(event);\n      }\n    } else {\n      // update existing document\n      var revInDb = documentInDb._rev;\n\n      /**\n       * Check for conflict\n       */\n      if (!previous || !!previous && revInDb !== previous._rev) {\n        // is conflict error\n        var err = {\n          isError: true,\n          status: 409,\n          documentId: docId,\n          writeRow: writeRow,\n          documentInDb\n        };\n        errors.push(err);\n        return 1; // continue\n      }\n\n      // handle attachments data\n\n      var updatedRow = hasAttachments ? stripAttachmentsDataFromRow(writeRow) : writeRow;\n      if (hasAttachments) {\n        if (documentDeleted) {\n          /**\n           * Deleted documents must have cleared all their attachments.\n           */\n          if (previous) {\n            Object.keys(previous._attachments).forEach(attachmentId => {\n              attachmentsRemove.push({\n                documentId: docId,\n                attachmentId,\n                digest: ensureNotFalsy(previous)._attachments[attachmentId].digest\n              });\n            });\n          }\n        } else {\n          // first check for errors\n          Object.entries(document._attachments).find(([attachmentId, attachmentData]) => {\n            var previousAttachmentData = previous ? previous._attachments[attachmentId] : undefined;\n            if (!previousAttachmentData && !attachmentData.data) {\n              attachmentError = {\n                documentId: docId,\n                documentInDb: documentInDb,\n                isError: true,\n                status: 510,\n                writeRow,\n                attachmentId\n              };\n            }\n            return true;\n          });\n          if (!attachmentError) {\n            Object.entries(document._attachments).forEach(([attachmentId, attachmentData]) => {\n              var previousAttachmentData = previous ? previous._attachments[attachmentId] : undefined;\n              if (!previousAttachmentData) {\n                attachmentsAdd.push({\n                  documentId: docId,\n                  attachmentId,\n                  attachmentData: attachmentData,\n                  digest: attachmentData.digest\n                });\n              } else {\n                var newDigest = updatedRow.document._attachments[attachmentId].digest;\n                if (attachmentData.data &&\n                /**\n                 * Performance shortcut,\n                 * do not update the attachment data if it did not change.\n                 */\n                previousAttachmentData.digest !== newDigest) {\n                  attachmentsUpdate.push({\n                    documentId: docId,\n                    attachmentId,\n                    attachmentData: attachmentData,\n                    digest: attachmentData.digest\n                  });\n                }\n              }\n            });\n          }\n        }\n      }\n      if (attachmentError) {\n        errors.push(attachmentError);\n      } else {\n        if (hasAttachments) {\n          bulkUpdateDocs.push(stripAttachmentsDataFromRow(updatedRow));\n          if (onUpdate) {\n            onUpdate(document);\n          }\n        } else {\n          bulkUpdateDocs.push(updatedRow);\n          if (onUpdate) {\n            onUpdate(document);\n          }\n        }\n        newestRow = updatedRow;\n      }\n      var eventDocumentData = null;\n      var previousEventDocumentData = null;\n      var operation = null;\n      if (previousDeleted && !documentDeleted) {\n        operation = 'INSERT';\n        eventDocumentData = hasAttachments ? stripAttachmentsDataFromDocument(document) : document;\n      } else if (previous && !previousDeleted && !documentDeleted) {\n        operation = 'UPDATE';\n        eventDocumentData = hasAttachments ? stripAttachmentsDataFromDocument(document) : document;\n        previousEventDocumentData = previous;\n      } else if (documentDeleted) {\n        operation = 'DELETE';\n        eventDocumentData = ensureNotFalsy(document);\n        previousEventDocumentData = previous;\n      } else {\n        throw newRxError('SNH', {\n          args: {\n            writeRow\n          }\n        });\n      }\n      var _event = {\n        documentId: docId,\n        documentData: eventDocumentData,\n        previousDocumentData: previousEventDocumentData,\n        operation: operation\n      };\n      eventBulkEvents.push(_event);\n    }\n  };\n  for (var rowId = 0; rowId < rowAmount; rowId++) {\n    if (_loop()) continue;\n  }\n  return {\n    bulkInsertDocs,\n    bulkUpdateDocs,\n    newestRow,\n    errors,\n    eventBulk,\n    attachmentsAdd,\n    attachmentsRemove,\n    attachmentsUpdate\n  };\n}\nexport function stripAttachmentsDataFromRow(writeRow) {\n  return {\n    previous: writeRow.previous,\n    document: stripAttachmentsDataFromDocument(writeRow.document)\n  };\n}\nexport function getAttachmentSize(attachmentBase64String) {\n  return atob(attachmentBase64String).length;\n}\n\n/**\n * Used in custom RxStorage implementations.\n */\nexport function attachmentWriteDataToNormalData(writeData) {\n  var data = writeData.data;\n  if (!data) {\n    return writeData;\n  }\n  var ret = {\n    length: getAttachmentSize(data),\n    digest: writeData.digest,\n    type: writeData.type\n  };\n  return ret;\n}\nexport function stripAttachmentsDataFromDocument(doc) {\n  if (!doc._attachments || Object.keys(doc._attachments).length === 0) {\n    return doc;\n  }\n  var useDoc = flatClone(doc);\n  useDoc._attachments = {};\n  Object.entries(doc._attachments).forEach(([attachmentId, attachmentData]) => {\n    useDoc._attachments[attachmentId] = attachmentWriteDataToNormalData(attachmentData);\n  });\n  return useDoc;\n}\n\n/**\n * Flat clone the document data\n * and also the _meta field.\n * Used many times when we want to change the meta\n * during replication etc.\n */\nexport function flatCloneDocWithMeta(doc) {\n  return Object.assign({}, doc, {\n    _meta: flatClone(doc._meta)\n  });\n}\n/**\n * Wraps the normal storageInstance of a RxCollection\n * to ensure that all access is properly using the hooks\n * and other data transformations and also ensure that database.lockedRun()\n * is used properly.\n */\nexport function getWrappedStorageInstance(database, storageInstance,\n/**\n * The original RxJsonSchema\n * before it was mutated by hooks.\n */\nrxJsonSchema) {\n  overwritable.deepFreezeWhenDevMode(rxJsonSchema);\n  var primaryPath = getPrimaryFieldOfPrimaryKey(storageInstance.schema.primaryKey);\n  var ret = {\n    originalStorageInstance: storageInstance,\n    schema: storageInstance.schema,\n    internals: storageInstance.internals,\n    collectionName: storageInstance.collectionName,\n    databaseName: storageInstance.databaseName,\n    options: storageInstance.options,\n    async bulkWrite(rows, context) {\n      var databaseToken = database.token;\n      var toStorageWriteRows = new Array(rows.length);\n      /**\n       * Use the same timestamp for all docs of this rows-set.\n       * This improves performance because calling Date.now() inside of the now() function\n       * is too costly.\n       */\n      var time = now();\n      for (var index = 0; index < rows.length; index++) {\n        var writeRow = rows[index];\n        var document = flatCloneDocWithMeta(writeRow.document);\n        document._meta.lwt = time;\n\n        /**\n         * Yes we really want to set the revision here.\n         * If you make a plugin that relies on having its own revision\n         * stored into the storage, use this.originalStorageInstance.bulkWrite() instead.\n         */\n        var previous = writeRow.previous;\n        document._rev = createRevision(databaseToken, previous);\n        toStorageWriteRows[index] = {\n          document,\n          previous\n        };\n      }\n      runPluginHooks('preStorageWrite', {\n        storageInstance: this.originalStorageInstance,\n        rows: toStorageWriteRows\n      });\n      var writeResult = await database.lockedRun(() => storageInstance.bulkWrite(toStorageWriteRows, context));\n\n      /**\n       * The RxStorageInstance MUST NOT allow to insert already _deleted documents,\n       * without sending the previous document version.\n       * But for better developer experience, RxDB does allow to re-insert deleted documents.\n       * We do this by automatically fixing the conflict errors for that case\n       * by running another bulkWrite() and merging the results.\n       * @link https://github.com/pubkey/rxdb/pull/3839\n      */\n      var useWriteResult = {\n        error: []\n      };\n      BULK_WRITE_ROWS_BY_RESPONSE.set(useWriteResult, toStorageWriteRows);\n      var reInsertErrors = writeResult.error.length === 0 ? [] : writeResult.error.filter(error => {\n        if (error.status === 409 && !error.writeRow.previous && !error.writeRow.document._deleted && ensureNotFalsy(error.documentInDb)._deleted) {\n          return true;\n        }\n\n        // add the \"normal\" errors to the parent error array.\n        useWriteResult.error.push(error);\n        return false;\n      });\n      if (reInsertErrors.length > 0) {\n        var reInsertIds = new Set();\n        var reInserts = reInsertErrors.map(error => {\n          reInsertIds.add(error.documentId);\n          return {\n            previous: error.documentInDb,\n            document: Object.assign({}, error.writeRow.document, {\n              _rev: createRevision(database.token, error.documentInDb)\n            })\n          };\n        });\n        var subResult = await database.lockedRun(() => storageInstance.bulkWrite(reInserts, context));\n        appendToArray(useWriteResult.error, subResult.error);\n        var successArray = getWrittenDocumentsFromBulkWriteResponse(primaryPath, toStorageWriteRows, useWriteResult, reInsertIds);\n        var subSuccess = getWrittenDocumentsFromBulkWriteResponse(primaryPath, reInserts, subResult);\n        appendToArray(successArray, subSuccess);\n        return useWriteResult;\n      }\n      return useWriteResult;\n    },\n    query(preparedQuery) {\n      return database.lockedRun(() => storageInstance.query(preparedQuery));\n    },\n    count(preparedQuery) {\n      return database.lockedRun(() => storageInstance.count(preparedQuery));\n    },\n    findDocumentsById(ids, deleted) {\n      return database.lockedRun(() => storageInstance.findDocumentsById(ids, deleted));\n    },\n    getAttachmentData(documentId, attachmentId, digest) {\n      return database.lockedRun(() => storageInstance.getAttachmentData(documentId, attachmentId, digest));\n    },\n    getChangedDocumentsSince: !storageInstance.getChangedDocumentsSince ? undefined : (limit, checkpoint) => {\n      return database.lockedRun(() => storageInstance.getChangedDocumentsSince(ensureNotFalsy(limit), checkpoint));\n    },\n    cleanup(minDeletedTime) {\n      return database.lockedRun(() => storageInstance.cleanup(minDeletedTime));\n    },\n    remove() {\n      database.storageInstances.delete(ret);\n      return database.lockedRun(() => storageInstance.remove());\n    },\n    close() {\n      database.storageInstances.delete(ret);\n      return database.lockedRun(() => storageInstance.close());\n    },\n    changeStream() {\n      return storageInstance.changeStream();\n    }\n  };\n  database.storageInstances.add(ret);\n  return ret;\n}\n\n/**\n * Each RxStorage implementation should\n * run this method at the first step of createStorageInstance()\n * to ensure that the configuration is correct.\n */\nexport function ensureRxStorageInstanceParamsAreCorrect(params) {\n  if (params.schema.keyCompression) {\n    throw newRxError('UT5', {\n      args: {\n        params\n      }\n    });\n  }\n  if (hasEncryption(params.schema)) {\n    throw newRxError('UT6', {\n      args: {\n        params\n      }\n    });\n  }\n  if (params.schema.attachments && params.schema.attachments.compression) {\n    throw newRxError('UT7', {\n      args: {\n        params\n      }\n    });\n  }\n}\nexport function hasEncryption(jsonSchema) {\n  if (!!jsonSchema.encrypted && jsonSchema.encrypted.length > 0 || jsonSchema.attachments && jsonSchema.attachments.encrypted) {\n    return true;\n  } else {\n    return false;\n  }\n}\nexport function getChangedDocumentsSinceQuery(storageInstance, limit, checkpoint) {\n  var primaryPath = getPrimaryFieldOfPrimaryKey(storageInstance.schema.primaryKey);\n  var sinceLwt = checkpoint ? checkpoint.lwt : RX_META_LWT_MINIMUM;\n  var sinceId = checkpoint ? checkpoint.id : '';\n  return normalizeMangoQuery(storageInstance.schema, {\n    selector: {\n      $or: [{\n        '_meta.lwt': {\n          $gt: sinceLwt\n        }\n      }, {\n        '_meta.lwt': {\n          $eq: sinceLwt\n        },\n        [primaryPath]: {\n          $gt: checkpoint ? sinceId : ''\n        }\n      }],\n      // add this hint for better index usage\n      '_meta.lwt': {\n        $gte: sinceLwt\n      }\n    },\n    sort: [{\n      '_meta.lwt': 'asc'\n    }, {\n      [primaryPath]: 'asc'\n    }],\n    skip: 0,\n    limit\n    /**\n     * DO NOT SET A SPECIFIC INDEX HERE!\n     * The query might be modified by some plugin\n     * before sending it to the storage.\n     * We can be sure that in the end the query planner\n     * will find the best index.\n     */\n    // index: ['_meta.lwt', primaryPath]\n  });\n}\nexport async function getChangedDocumentsSince(storageInstance, limit, checkpoint) {\n  if (storageInstance.getChangedDocumentsSince) {\n    return storageInstance.getChangedDocumentsSince(limit, checkpoint);\n  }\n  var primaryPath = getPrimaryFieldOfPrimaryKey(storageInstance.schema.primaryKey);\n  var query = prepareQuery(storageInstance.schema, getChangedDocumentsSinceQuery(storageInstance, limit, checkpoint));\n  var result = await storageInstance.query(query);\n  var documents = result.documents;\n  var lastDoc = lastOfArray(documents);\n  return {\n    documents: documents,\n    checkpoint: lastDoc ? {\n      id: lastDoc[primaryPath],\n      lwt: lastDoc._meta.lwt\n    } : checkpoint ? checkpoint : {\n      id: '',\n      lwt: 0\n    }\n  };\n}\nvar BULK_WRITE_ROWS_BY_RESPONSE = new WeakMap();\nvar BULK_WRITE_SUCCESS_MAP = new WeakMap();\n\n/**\n * For better performance, this is done only when accessed\n * because most of the time we do not need the results, only the errors.\n */\nexport function getWrittenDocumentsFromBulkWriteResponse(primaryPath, writeRows, response, reInsertIds) {\n  return getFromMapOrCreate(BULK_WRITE_SUCCESS_MAP, response, () => {\n    var ret = [];\n    var realWriteRows = BULK_WRITE_ROWS_BY_RESPONSE.get(response);\n    if (!realWriteRows) {\n      realWriteRows = writeRows;\n    }\n    if (response.error.length > 0 || reInsertIds) {\n      var errorIds = reInsertIds ? reInsertIds : new Set();\n      for (var index = 0; index < response.error.length; index++) {\n        var error = response.error[index];\n        errorIds.add(error.documentId);\n      }\n      for (var _index = 0; _index < realWriteRows.length; _index++) {\n        var doc = realWriteRows[_index].document;\n        if (!errorIds.has(doc[primaryPath])) {\n          ret.push(stripAttachmentsDataFromDocument(doc));\n        }\n      }\n    } else {\n      // pre-set array size for better performance\n      ret.length = writeRows.length - response.error.length;\n      for (var _index2 = 0; _index2 < realWriteRows.length; _index2++) {\n        var _doc = realWriteRows[_index2].document;\n        ret[_index2] = stripAttachmentsDataFromDocument(_doc);\n      }\n    }\n    return ret;\n  });\n}\n\n/**\n * Wraps the storage and simluates\n * delays. Mostly used in tests.\n */\nexport function randomDelayStorage(input) {\n  /**\n   * Ensure writes to a delay storage\n   * are still correctly run in order.\n   */\n  var randomDelayStorageWriteQueue = PROMISE_RESOLVE_TRUE;\n  var retStorage = {\n    name: 'random-delay-' + input.storage.name,\n    rxdbVersion: RXDB_VERSION,\n    async createStorageInstance(params) {\n      await promiseWait(input.delayTimeBefore());\n      var storageInstance = await input.storage.createStorageInstance(params);\n      await promiseWait(input.delayTimeAfter());\n      return {\n        databaseName: storageInstance.databaseName,\n        internals: storageInstance.internals,\n        options: storageInstance.options,\n        schema: storageInstance.schema,\n        collectionName: storageInstance.collectionName,\n        bulkWrite(a, b) {\n          randomDelayStorageWriteQueue = randomDelayStorageWriteQueue.then(async () => {\n            await promiseWait(input.delayTimeBefore());\n            var response = await storageInstance.bulkWrite(a, b);\n            await promiseWait(input.delayTimeAfter());\n            return response;\n          });\n          var ret = randomDelayStorageWriteQueue;\n          return ret;\n        },\n        async findDocumentsById(a, b) {\n          await promiseWait(input.delayTimeBefore());\n          var ret = await storageInstance.findDocumentsById(a, b);\n          await promiseWait(input.delayTimeAfter());\n          return ret;\n        },\n        async query(a) {\n          await promiseWait(input.delayTimeBefore());\n          var ret = await storageInstance.query(a);\n          return ret;\n        },\n        async count(a) {\n          await promiseWait(input.delayTimeBefore());\n          var ret = await storageInstance.count(a);\n          await promiseWait(input.delayTimeAfter());\n          return ret;\n        },\n        async getAttachmentData(a, b, c) {\n          await promiseWait(input.delayTimeBefore());\n          var ret = await storageInstance.getAttachmentData(a, b, c);\n          await promiseWait(input.delayTimeAfter());\n          return ret;\n        },\n        getChangedDocumentsSince: !storageInstance.getChangedDocumentsSince ? undefined : async (a, b) => {\n          await promiseWait(input.delayTimeBefore());\n          var ret = await ensureNotFalsy(storageInstance.getChangedDocumentsSince)(a, b);\n          await promiseWait(input.delayTimeAfter());\n          return ret;\n        },\n        changeStream() {\n          return storageInstance.changeStream();\n        },\n        async cleanup(a) {\n          await promiseWait(input.delayTimeBefore());\n          var ret = await storageInstance.cleanup(a);\n          await promiseWait(input.delayTimeAfter());\n          return ret;\n        },\n        async close() {\n          await promiseWait(input.delayTimeBefore());\n          var ret = await storageInstance.close();\n          await promiseWait(input.delayTimeAfter());\n          return ret;\n        },\n        async remove() {\n          await promiseWait(input.delayTimeBefore());\n          var ret = await storageInstance.remove();\n          await promiseWait(input.delayTimeAfter());\n          return ret;\n        }\n      };\n    }\n  };\n  return retStorage;\n}\n//# sourceMappingURL=rx-storage-helper.js.map","/**\n * When a persistent RxStorage is used in more the one JavaScript process,\n * the even stream of the changestream() function must be broadcasted to the other\n * RxStorageInstances of the same databaseName+collectionName.\n *\n * In the past this was done by RxDB but it makes more sense to do this\n * at the RxStorage level so that the broadcasting etc can all happen inside of a WebWorker\n * and not on the main thread.\n * Also it makes it less complex to stack up different RxStorages onto each other\n * like what we do with the in-memory plugin.\n *\n * This is intended to be used inside of createStorageInstance() of a storage.\n * Do not use this if the storage anyway broadcasts the events like when using MongoDB\n * or in the future W3C might introduce a way to listen to IndexedDB changes.\n */\n\nimport { Subject } from 'rxjs';\nimport { mergeWith } from 'rxjs/operators';\nimport { BroadcastChannel } from 'broadcast-channel';\n\n/**\n * The broadcast-channel is reused by the databaseInstanceToken.\n * This is required so that it is easy to simulate multi-tab usage\n * in the test where different instances of the same RxDatabase must\n * have different broadcast channels.\n * But also it ensures that for each RxDatabase we only create a single\n * broadcast channel that can even be reused in the leader election plugin.\n */\nexport var BROADCAST_CHANNEL_BY_TOKEN = new Map();\nexport function getBroadcastChannelReference(storageName, databaseInstanceToken, databaseName, refObject) {\n  var state = BROADCAST_CHANNEL_BY_TOKEN.get(databaseInstanceToken);\n  if (!state) {\n    state = {\n      /**\n       * We have to use the databaseName instead of the databaseInstanceToken\n       * in the BroadcastChannel name because different instances must end with the same\n       * channel name to be able to broadcast messages between each other.\n       */\n      bc: new BroadcastChannel(['RxDB:', storageName, databaseName].join('|')),\n      refs: new Set()\n    };\n    BROADCAST_CHANNEL_BY_TOKEN.set(databaseInstanceToken, state);\n  }\n  state.refs.add(refObject);\n  return state.bc;\n}\nexport function removeBroadcastChannelReference(databaseInstanceToken, refObject) {\n  var state = BROADCAST_CHANNEL_BY_TOKEN.get(databaseInstanceToken);\n  if (!state) {\n    return;\n  }\n  state.refs.delete(refObject);\n  if (state.refs.size === 0) {\n    BROADCAST_CHANNEL_BY_TOKEN.delete(databaseInstanceToken);\n    return state.bc.close();\n  }\n}\nexport function addRxStorageMultiInstanceSupport(storageName, instanceCreationParams, instance,\n/**\n * If provided, that channel will be used\n * instead of an own one.\n */\nprovidedBroadcastChannel) {\n  if (!instanceCreationParams.multiInstance) {\n    return;\n  }\n  var broadcastChannel = providedBroadcastChannel ? providedBroadcastChannel : getBroadcastChannelReference(storageName, instanceCreationParams.databaseInstanceToken, instance.databaseName, instance);\n  var changesFromOtherInstances$ = new Subject();\n  var eventListener = msg => {\n    if (msg.storageName === storageName && msg.databaseName === instanceCreationParams.databaseName && msg.collectionName === instanceCreationParams.collectionName && msg.version === instanceCreationParams.schema.version) {\n      changesFromOtherInstances$.next(msg.eventBulk);\n    }\n  };\n  broadcastChannel.addEventListener('message', eventListener);\n  var oldChangestream$ = instance.changeStream();\n  var closed = false;\n  var sub = oldChangestream$.subscribe(eventBulk => {\n    if (closed) {\n      return;\n    }\n    broadcastChannel.postMessage({\n      storageName: storageName,\n      databaseName: instanceCreationParams.databaseName,\n      collectionName: instanceCreationParams.collectionName,\n      version: instanceCreationParams.schema.version,\n      eventBulk\n    });\n  });\n  instance.changeStream = function () {\n    return changesFromOtherInstances$.asObservable().pipe(mergeWith(oldChangestream$));\n  };\n  var oldClose = instance.close.bind(instance);\n  instance.close = async function () {\n    closed = true;\n    sub.unsubscribe();\n    broadcastChannel.removeEventListener('message', eventListener);\n    if (!providedBroadcastChannel) {\n      await removeBroadcastChannelReference(instanceCreationParams.databaseInstanceToken, instance);\n    }\n    return oldClose();\n  };\n  var oldRemove = instance.remove.bind(instance);\n  instance.remove = async function () {\n    closed = true;\n    sub.unsubscribe();\n    broadcastChannel.removeEventListener('message', eventListener);\n    if (!providedBroadcastChannel) {\n      await removeBroadcastChannelReference(instanceCreationParams.databaseInstanceToken, instance);\n    }\n    return oldRemove();\n  };\n}\n//# sourceMappingURL=rx-storage-multiinstance.js.map","import { __extends } from \"tslib\";\nimport { Subject } from './Subject';\nvar BehaviorSubject = (function (_super) {\n    __extends(BehaviorSubject, _super);\n    function BehaviorSubject(_value) {\n        var _this = _super.call(this) || this;\n        _this._value = _value;\n        return _this;\n    }\n    Object.defineProperty(BehaviorSubject.prototype, \"value\", {\n        get: function () {\n            return this.getValue();\n        },\n        enumerable: false,\n        configurable: true\n    });\n    BehaviorSubject.prototype._subscribe = function (subscriber) {\n        var subscription = _super.prototype._subscribe.call(this, subscriber);\n        !subscription.closed && subscriber.next(this._value);\n        return subscription;\n    };\n    BehaviorSubject.prototype.getValue = function () {\n        var _a = this, hasError = _a.hasError, thrownError = _a.thrownError, _value = _a._value;\n        if (hasError) {\n            throw thrownError;\n        }\n        this._throwIfClosed();\n        return _value;\n    };\n    BehaviorSubject.prototype.next = function (value) {\n        _super.prototype.next.call(this, (this._value = value));\n    };\n    return BehaviorSubject;\n}(Subject));\nexport { BehaviorSubject };\n//# sourceMappingURL=BehaviorSubject.js.map","export var COMPLETE_NOTIFICATION = (function () { return createNotification('C', undefined, undefined); })();\nexport function errorNotification(error) {\n    return createNotification('E', undefined, error);\n}\nexport function nextNotification(value) {\n    return createNotification('N', value, undefined);\n}\nexport function createNotification(kind, value, error) {\n    return {\n        kind: kind,\n        value: value,\n        error: error,\n    };\n}\n//# sourceMappingURL=NotificationFactories.js.map","import { SafeSubscriber, Subscriber } from './Subscriber';\nimport { isSubscription } from './Subscription';\nimport { observable as Symbol_observable } from './symbol/observable';\nimport { pipeFromArray } from './util/pipe';\nimport { config } from './config';\nimport { isFunction } from './util/isFunction';\nimport { errorContext } from './util/errorContext';\nvar Observable = (function () {\n    function Observable(subscribe) {\n        if (subscribe) {\n            this._subscribe = subscribe;\n        }\n    }\n    Observable.prototype.lift = function (operator) {\n        var observable = new Observable();\n        observable.source = this;\n        observable.operator = operator;\n        return observable;\n    };\n    Observable.prototype.subscribe = function (observerOrNext, error, complete) {\n        var _this = this;\n        var subscriber = isSubscriber(observerOrNext) ? observerOrNext : new SafeSubscriber(observerOrNext, error, complete);\n        errorContext(function () {\n            var _a = _this, operator = _a.operator, source = _a.source;\n            subscriber.add(operator\n                ?\n                    operator.call(subscriber, source)\n                : source\n                    ?\n                        _this._subscribe(subscriber)\n                    :\n                        _this._trySubscribe(subscriber));\n        });\n        return subscriber;\n    };\n    Observable.prototype._trySubscribe = function (sink) {\n        try {\n            return this._subscribe(sink);\n        }\n        catch (err) {\n            sink.error(err);\n        }\n    };\n    Observable.prototype.forEach = function (next, promiseCtor) {\n        var _this = this;\n        promiseCtor = getPromiseCtor(promiseCtor);\n        return new promiseCtor(function (resolve, reject) {\n            var subscriber = new SafeSubscriber({\n                next: function (value) {\n                    try {\n                        next(value);\n                    }\n                    catch (err) {\n                        reject(err);\n                        subscriber.unsubscribe();\n                    }\n                },\n                error: reject,\n                complete: resolve,\n            });\n            _this.subscribe(subscriber);\n        });\n    };\n    Observable.prototype._subscribe = function (subscriber) {\n        var _a;\n        return (_a = this.source) === null || _a === void 0 ? void 0 : _a.subscribe(subscriber);\n    };\n    Observable.prototype[Symbol_observable] = function () {\n        return this;\n    };\n    Observable.prototype.pipe = function () {\n        var operations = [];\n        for (var _i = 0; _i < arguments.length; _i++) {\n            operations[_i] = arguments[_i];\n        }\n        return pipeFromArray(operations)(this);\n    };\n    Observable.prototype.toPromise = function (promiseCtor) {\n        var _this = this;\n        promiseCtor = getPromiseCtor(promiseCtor);\n        return new promiseCtor(function (resolve, reject) {\n            var value;\n            _this.subscribe(function (x) { return (value = x); }, function (err) { return reject(err); }, function () { return resolve(value); });\n        });\n    };\n    Observable.create = function (subscribe) {\n        return new Observable(subscribe);\n    };\n    return Observable;\n}());\nexport { Observable };\nfunction getPromiseCtor(promiseCtor) {\n    var _a;\n    return (_a = promiseCtor !== null && promiseCtor !== void 0 ? promiseCtor : config.Promise) !== null && _a !== void 0 ? _a : Promise;\n}\nfunction isObserver(value) {\n    return value && isFunction(value.next) && isFunction(value.error) && isFunction(value.complete);\n}\nfunction isSubscriber(value) {\n    return (value && value instanceof Subscriber) || (isObserver(value) && isSubscription(value));\n}\n//# sourceMappingURL=Observable.js.map","import { __extends } from \"tslib\";\nimport { Subject } from './Subject';\nimport { dateTimestampProvider } from './scheduler/dateTimestampProvider';\nvar ReplaySubject = (function (_super) {\n    __extends(ReplaySubject, _super);\n    function ReplaySubject(_bufferSize, _windowTime, _timestampProvider) {\n        if (_bufferSize === void 0) { _bufferSize = Infinity; }\n        if (_windowTime === void 0) { _windowTime = Infinity; }\n        if (_timestampProvider === void 0) { _timestampProvider = dateTimestampProvider; }\n        var _this = _super.call(this) || this;\n        _this._bufferSize = _bufferSize;\n        _this._windowTime = _windowTime;\n        _this._timestampProvider = _timestampProvider;\n        _this._buffer = [];\n        _this._infiniteTimeWindow = true;\n        _this._infiniteTimeWindow = _windowTime === Infinity;\n        _this._bufferSize = Math.max(1, _bufferSize);\n        _this._windowTime = Math.max(1, _windowTime);\n        return _this;\n    }\n    ReplaySubject.prototype.next = function (value) {\n        var _a = this, isStopped = _a.isStopped, _buffer = _a._buffer, _infiniteTimeWindow = _a._infiniteTimeWindow, _timestampProvider = _a._timestampProvider, _windowTime = _a._windowTime;\n        if (!isStopped) {\n            _buffer.push(value);\n            !_infiniteTimeWindow && _buffer.push(_timestampProvider.now() + _windowTime);\n        }\n        this._trimBuffer();\n        _super.prototype.next.call(this, value);\n    };\n    ReplaySubject.prototype._subscribe = function (subscriber) {\n        this._throwIfClosed();\n        this._trimBuffer();\n        var subscription = this._innerSubscribe(subscriber);\n        var _a = this, _infiniteTimeWindow = _a._infiniteTimeWindow, _buffer = _a._buffer;\n        var copy = _buffer.slice();\n        for (var i = 0; i < copy.length && !subscriber.closed; i += _infiniteTimeWindow ? 1 : 2) {\n            subscriber.next(copy[i]);\n        }\n        this._checkFinalizedStatuses(subscriber);\n        return subscription;\n    };\n    ReplaySubject.prototype._trimBuffer = function () {\n        var _a = this, _bufferSize = _a._bufferSize, _timestampProvider = _a._timestampProvider, _buffer = _a._buffer, _infiniteTimeWindow = _a._infiniteTimeWindow;\n        var adjustedBufferSize = (_infiniteTimeWindow ? 1 : 2) * _bufferSize;\n        _bufferSize < Infinity && adjustedBufferSize < _buffer.length && _buffer.splice(0, _buffer.length - adjustedBufferSize);\n        if (!_infiniteTimeWindow) {\n            var now = _timestampProvider.now();\n            var last = 0;\n            for (var i = 1; i < _buffer.length && _buffer[i] <= now; i += 2) {\n                last = i;\n            }\n            last && _buffer.splice(0, last + 1);\n        }\n    };\n    return ReplaySubject;\n}(Subject));\nexport { ReplaySubject };\n//# sourceMappingURL=ReplaySubject.js.map","import { __extends, __values } from \"tslib\";\nimport { Observable } from './Observable';\nimport { Subscription, EMPTY_SUBSCRIPTION } from './Subscription';\nimport { ObjectUnsubscribedError } from './util/ObjectUnsubscribedError';\nimport { arrRemove } from './util/arrRemove';\nimport { errorContext } from './util/errorContext';\nvar Subject = (function (_super) {\n    __extends(Subject, _super);\n    function Subject() {\n        var _this = _super.call(this) || this;\n        _this.closed = false;\n        _this.currentObservers = null;\n        _this.observers = [];\n        _this.isStopped = false;\n        _this.hasError = false;\n        _this.thrownError = null;\n        return _this;\n    }\n    Subject.prototype.lift = function (operator) {\n        var subject = new AnonymousSubject(this, this);\n        subject.operator = operator;\n        return subject;\n    };\n    Subject.prototype._throwIfClosed = function () {\n        if (this.closed) {\n            throw new ObjectUnsubscribedError();\n        }\n    };\n    Subject.prototype.next = function (value) {\n        var _this = this;\n        errorContext(function () {\n            var e_1, _a;\n            _this._throwIfClosed();\n            if (!_this.isStopped) {\n                if (!_this.currentObservers) {\n                    _this.currentObservers = Array.from(_this.observers);\n                }\n                try {\n                    for (var _b = __values(_this.currentObservers), _c = _b.next(); !_c.done; _c = _b.next()) {\n                        var observer = _c.value;\n                        observer.next(value);\n                    }\n                }\n                catch (e_1_1) { e_1 = { error: e_1_1 }; }\n                finally {\n                    try {\n                        if (_c && !_c.done && (_a = _b.return)) _a.call(_b);\n                    }\n                    finally { if (e_1) throw e_1.error; }\n                }\n            }\n        });\n    };\n    Subject.prototype.error = function (err) {\n        var _this = this;\n        errorContext(function () {\n            _this._throwIfClosed();\n            if (!_this.isStopped) {\n                _this.hasError = _this.isStopped = true;\n                _this.thrownError = err;\n                var observers = _this.observers;\n                while (observers.length) {\n                    observers.shift().error(err);\n                }\n            }\n        });\n    };\n    Subject.prototype.complete = function () {\n        var _this = this;\n        errorContext(function () {\n            _this._throwIfClosed();\n            if (!_this.isStopped) {\n                _this.isStopped = true;\n                var observers = _this.observers;\n                while (observers.length) {\n                    observers.shift().complete();\n                }\n            }\n        });\n    };\n    Subject.prototype.unsubscribe = function () {\n        this.isStopped = this.closed = true;\n        this.observers = this.currentObservers = null;\n    };\n    Object.defineProperty(Subject.prototype, \"observed\", {\n        get: function () {\n            var _a;\n            return ((_a = this.observers) === null || _a === void 0 ? void 0 : _a.length) > 0;\n        },\n        enumerable: false,\n        configurable: true\n    });\n    Subject.prototype._trySubscribe = function (subscriber) {\n        this._throwIfClosed();\n        return _super.prototype._trySubscribe.call(this, subscriber);\n    };\n    Subject.prototype._subscribe = function (subscriber) {\n        this._throwIfClosed();\n        this._checkFinalizedStatuses(subscriber);\n        return this._innerSubscribe(subscriber);\n    };\n    Subject.prototype._innerSubscribe = function (subscriber) {\n        var _this = this;\n        var _a = this, hasError = _a.hasError, isStopped = _a.isStopped, observers = _a.observers;\n        if (hasError || isStopped) {\n            return EMPTY_SUBSCRIPTION;\n        }\n        this.currentObservers = null;\n        observers.push(subscriber);\n        return new Subscription(function () {\n            _this.currentObservers = null;\n            arrRemove(observers, subscriber);\n        });\n    };\n    Subject.prototype._checkFinalizedStatuses = function (subscriber) {\n        var _a = this, hasError = _a.hasError, thrownError = _a.thrownError, isStopped = _a.isStopped;\n        if (hasError) {\n            subscriber.error(thrownError);\n        }\n        else if (isStopped) {\n            subscriber.complete();\n        }\n    };\n    Subject.prototype.asObservable = function () {\n        var observable = new Observable();\n        observable.source = this;\n        return observable;\n    };\n    Subject.create = function (destination, source) {\n        return new AnonymousSubject(destination, source);\n    };\n    return Subject;\n}(Observable));\nexport { Subject };\nvar AnonymousSubject = (function (_super) {\n    __extends(AnonymousSubject, _super);\n    function AnonymousSubject(destination, source) {\n        var _this = _super.call(this) || this;\n        _this.destination = destination;\n        _this.source = source;\n        return _this;\n    }\n    AnonymousSubject.prototype.next = function (value) {\n        var _a, _b;\n        (_b = (_a = this.destination) === null || _a === void 0 ? void 0 : _a.next) === null || _b === void 0 ? void 0 : _b.call(_a, value);\n    };\n    AnonymousSubject.prototype.error = function (err) {\n        var _a, _b;\n        (_b = (_a = this.destination) === null || _a === void 0 ? void 0 : _a.error) === null || _b === void 0 ? void 0 : _b.call(_a, err);\n    };\n    AnonymousSubject.prototype.complete = function () {\n        var _a, _b;\n        (_b = (_a = this.destination) === null || _a === void 0 ? void 0 : _a.complete) === null || _b === void 0 ? void 0 : _b.call(_a);\n    };\n    AnonymousSubject.prototype._subscribe = function (subscriber) {\n        var _a, _b;\n        return (_b = (_a = this.source) === null || _a === void 0 ? void 0 : _a.subscribe(subscriber)) !== null && _b !== void 0 ? _b : EMPTY_SUBSCRIPTION;\n    };\n    return AnonymousSubject;\n}(Subject));\nexport { AnonymousSubject };\n//# sourceMappingURL=Subject.js.map","import { __extends } from \"tslib\";\nimport { isFunction } from './util/isFunction';\nimport { isSubscription, Subscription } from './Subscription';\nimport { config } from './config';\nimport { reportUnhandledError } from './util/reportUnhandledError';\nimport { noop } from './util/noop';\nimport { nextNotification, errorNotification, COMPLETE_NOTIFICATION } from './NotificationFactories';\nimport { timeoutProvider } from './scheduler/timeoutProvider';\nimport { captureError } from './util/errorContext';\nvar Subscriber = (function (_super) {\n    __extends(Subscriber, _super);\n    function Subscriber(destination) {\n        var _this = _super.call(this) || this;\n        _this.isStopped = false;\n        if (destination) {\n            _this.destination = destination;\n            if (isSubscription(destination)) {\n                destination.add(_this);\n            }\n        }\n        else {\n            _this.destination = EMPTY_OBSERVER;\n        }\n        return _this;\n    }\n    Subscriber.create = function (next, error, complete) {\n        return new SafeSubscriber(next, error, complete);\n    };\n    Subscriber.prototype.next = function (value) {\n        if (this.isStopped) {\n            handleStoppedNotification(nextNotification(value), this);\n        }\n        else {\n            this._next(value);\n        }\n    };\n    Subscriber.prototype.error = function (err) {\n        if (this.isStopped) {\n            handleStoppedNotification(errorNotification(err), this);\n        }\n        else {\n            this.isStopped = true;\n            this._error(err);\n        }\n    };\n    Subscriber.prototype.complete = function () {\n        if (this.isStopped) {\n            handleStoppedNotification(COMPLETE_NOTIFICATION, this);\n        }\n        else {\n            this.isStopped = true;\n            this._complete();\n        }\n    };\n    Subscriber.prototype.unsubscribe = function () {\n        if (!this.closed) {\n            this.isStopped = true;\n            _super.prototype.unsubscribe.call(this);\n            this.destination = null;\n        }\n    };\n    Subscriber.prototype._next = function (value) {\n        this.destination.next(value);\n    };\n    Subscriber.prototype._error = function (err) {\n        try {\n            this.destination.error(err);\n        }\n        finally {\n            this.unsubscribe();\n        }\n    };\n    Subscriber.prototype._complete = function () {\n        try {\n            this.destination.complete();\n        }\n        finally {\n            this.unsubscribe();\n        }\n    };\n    return Subscriber;\n}(Subscription));\nexport { Subscriber };\nvar _bind = Function.prototype.bind;\nfunction bind(fn, thisArg) {\n    return _bind.call(fn, thisArg);\n}\nvar ConsumerObserver = (function () {\n    function ConsumerObserver(partialObserver) {\n        this.partialObserver = partialObserver;\n    }\n    ConsumerObserver.prototype.next = function (value) {\n        var partialObserver = this.partialObserver;\n        if (partialObserver.next) {\n            try {\n                partialObserver.next(value);\n            }\n            catch (error) {\n                handleUnhandledError(error);\n            }\n        }\n    };\n    ConsumerObserver.prototype.error = function (err) {\n        var partialObserver = this.partialObserver;\n        if (partialObserver.error) {\n            try {\n                partialObserver.error(err);\n            }\n            catch (error) {\n                handleUnhandledError(error);\n            }\n        }\n        else {\n            handleUnhandledError(err);\n        }\n    };\n    ConsumerObserver.prototype.complete = function () {\n        var partialObserver = this.partialObserver;\n        if (partialObserver.complete) {\n            try {\n                partialObserver.complete();\n            }\n            catch (error) {\n                handleUnhandledError(error);\n            }\n        }\n    };\n    return ConsumerObserver;\n}());\nvar SafeSubscriber = (function (_super) {\n    __extends(SafeSubscriber, _super);\n    function SafeSubscriber(observerOrNext, error, complete) {\n        var _this = _super.call(this) || this;\n        var partialObserver;\n        if (isFunction(observerOrNext) || !observerOrNext) {\n            partialObserver = {\n                next: (observerOrNext !== null && observerOrNext !== void 0 ? observerOrNext : undefined),\n                error: error !== null && error !== void 0 ? error : undefined,\n                complete: complete !== null && complete !== void 0 ? complete : undefined,\n            };\n        }\n        else {\n            var context_1;\n            if (_this && config.useDeprecatedNextContext) {\n                context_1 = Object.create(observerOrNext);\n                context_1.unsubscribe = function () { return _this.unsubscribe(); };\n                partialObserver = {\n                    next: observerOrNext.next && bind(observerOrNext.next, context_1),\n                    error: observerOrNext.error && bind(observerOrNext.error, context_1),\n                    complete: observerOrNext.complete && bind(observerOrNext.complete, context_1),\n                };\n            }\n            else {\n                partialObserver = observerOrNext;\n            }\n        }\n        _this.destination = new ConsumerObserver(partialObserver);\n        return _this;\n    }\n    return SafeSubscriber;\n}(Subscriber));\nexport { SafeSubscriber };\nfunction handleUnhandledError(error) {\n    if (config.useDeprecatedSynchronousErrorHandling) {\n        captureError(error);\n    }\n    else {\n        reportUnhandledError(error);\n    }\n}\nfunction defaultErrorHandler(err) {\n    throw err;\n}\nfunction handleStoppedNotification(notification, subscriber) {\n    var onStoppedNotification = config.onStoppedNotification;\n    onStoppedNotification && timeoutProvider.setTimeout(function () { return onStoppedNotification(notification, subscriber); });\n}\nexport var EMPTY_OBSERVER = {\n    closed: true,\n    next: noop,\n    error: defaultErrorHandler,\n    complete: noop,\n};\n//# sourceMappingURL=Subscriber.js.map","import { __read, __spreadArray, __values } from \"tslib\";\nimport { isFunction } from './util/isFunction';\nimport { UnsubscriptionError } from './util/UnsubscriptionError';\nimport { arrRemove } from './util/arrRemove';\nvar Subscription = (function () {\n    function Subscription(initialTeardown) {\n        this.initialTeardown = initialTeardown;\n        this.closed = false;\n        this._parentage = null;\n        this._finalizers = null;\n    }\n    Subscription.prototype.unsubscribe = function () {\n        var e_1, _a, e_2, _b;\n        var errors;\n        if (!this.closed) {\n            this.closed = true;\n            var _parentage = this._parentage;\n            if (_parentage) {\n                this._parentage = null;\n                if (Array.isArray(_parentage)) {\n                    try {\n                        for (var _parentage_1 = __values(_parentage), _parentage_1_1 = _parentage_1.next(); !_parentage_1_1.done; _parentage_1_1 = _parentage_1.next()) {\n                            var parent_1 = _parentage_1_1.value;\n                            parent_1.remove(this);\n                        }\n                    }\n                    catch (e_1_1) { e_1 = { error: e_1_1 }; }\n                    finally {\n                        try {\n                            if (_parentage_1_1 && !_parentage_1_1.done && (_a = _parentage_1.return)) _a.call(_parentage_1);\n                        }\n                        finally { if (e_1) throw e_1.error; }\n                    }\n                }\n                else {\n                    _parentage.remove(this);\n                }\n            }\n            var initialFinalizer = this.initialTeardown;\n            if (isFunction(initialFinalizer)) {\n                try {\n                    initialFinalizer();\n                }\n                catch (e) {\n                    errors = e instanceof UnsubscriptionError ? e.errors : [e];\n                }\n            }\n            var _finalizers = this._finalizers;\n            if (_finalizers) {\n                this._finalizers = null;\n                try {\n                    for (var _finalizers_1 = __values(_finalizers), _finalizers_1_1 = _finalizers_1.next(); !_finalizers_1_1.done; _finalizers_1_1 = _finalizers_1.next()) {\n                        var finalizer = _finalizers_1_1.value;\n                        try {\n                            execFinalizer(finalizer);\n                        }\n                        catch (err) {\n                            errors = errors !== null && errors !== void 0 ? errors : [];\n                            if (err instanceof UnsubscriptionError) {\n                                errors = __spreadArray(__spreadArray([], __read(errors)), __read(err.errors));\n                            }\n                            else {\n                                errors.push(err);\n                            }\n                        }\n                    }\n                }\n                catch (e_2_1) { e_2 = { error: e_2_1 }; }\n                finally {\n                    try {\n                        if (_finalizers_1_1 && !_finalizers_1_1.done && (_b = _finalizers_1.return)) _b.call(_finalizers_1);\n                    }\n                    finally { if (e_2) throw e_2.error; }\n                }\n            }\n            if (errors) {\n                throw new UnsubscriptionError(errors);\n            }\n        }\n    };\n    Subscription.prototype.add = function (teardown) {\n        var _a;\n        if (teardown && teardown !== this) {\n            if (this.closed) {\n                execFinalizer(teardown);\n            }\n            else {\n                if (teardown instanceof Subscription) {\n                    if (teardown.closed || teardown._hasParent(this)) {\n                        return;\n                    }\n                    teardown._addParent(this);\n                }\n                (this._finalizers = (_a = this._finalizers) !== null && _a !== void 0 ? _a : []).push(teardown);\n            }\n        }\n    };\n    Subscription.prototype._hasParent = function (parent) {\n        var _parentage = this._parentage;\n        return _parentage === parent || (Array.isArray(_parentage) && _parentage.includes(parent));\n    };\n    Subscription.prototype._addParent = function (parent) {\n        var _parentage = this._parentage;\n        this._parentage = Array.isArray(_parentage) ? (_parentage.push(parent), _parentage) : _parentage ? [_parentage, parent] : parent;\n    };\n    Subscription.prototype._removeParent = function (parent) {\n        var _parentage = this._parentage;\n        if (_parentage === parent) {\n            this._parentage = null;\n        }\n        else if (Array.isArray(_parentage)) {\n            arrRemove(_parentage, parent);\n        }\n    };\n    Subscription.prototype.remove = function (teardown) {\n        var _finalizers = this._finalizers;\n        _finalizers && arrRemove(_finalizers, teardown);\n        if (teardown instanceof Subscription) {\n            teardown._removeParent(this);\n        }\n    };\n    Subscription.EMPTY = (function () {\n        var empty = new Subscription();\n        empty.closed = true;\n        return empty;\n    })();\n    return Subscription;\n}());\nexport { Subscription };\nexport var EMPTY_SUBSCRIPTION = Subscription.EMPTY;\nexport function isSubscription(value) {\n    return (value instanceof Subscription ||\n        (value && 'closed' in value && isFunction(value.remove) && isFunction(value.add) && isFunction(value.unsubscribe)));\n}\nfunction execFinalizer(finalizer) {\n    if (isFunction(finalizer)) {\n        finalizer();\n    }\n    else {\n        finalizer.unsubscribe();\n    }\n}\n//# sourceMappingURL=Subscription.js.map","export var config = {\n    onUnhandledError: null,\n    onStoppedNotification: null,\n    Promise: undefined,\n    useDeprecatedSynchronousErrorHandling: false,\n    useDeprecatedNextContext: false,\n};\n//# sourceMappingURL=config.js.map","import { EmptyError } from './util/EmptyError';\nimport { SafeSubscriber } from './Subscriber';\nexport function firstValueFrom(source, config) {\n    var hasConfig = typeof config === 'object';\n    return new Promise(function (resolve, reject) {\n        var subscriber = new SafeSubscriber({\n            next: function (value) {\n                resolve(value);\n                subscriber.unsubscribe();\n            },\n            error: reject,\n            complete: function () {\n                if (hasConfig) {\n                    resolve(config.defaultValue);\n                }\n                else {\n                    reject(new EmptyError());\n                }\n            },\n        });\n        source.subscribe(subscriber);\n    });\n}\n//# sourceMappingURL=firstValueFrom.js.map","import { Observable } from '../Observable';\nimport { argsArgArrayOrObject } from '../util/argsArgArrayOrObject';\nimport { from } from './from';\nimport { identity } from '../util/identity';\nimport { mapOneOrManyArgs } from '../util/mapOneOrManyArgs';\nimport { popResultSelector, popScheduler } from '../util/args';\nimport { createObject } from '../util/createObject';\nimport { createOperatorSubscriber } from '../operators/OperatorSubscriber';\nimport { executeSchedule } from '../util/executeSchedule';\nexport function combineLatest() {\n    var args = [];\n    for (var _i = 0; _i < arguments.length; _i++) {\n        args[_i] = arguments[_i];\n    }\n    var scheduler = popScheduler(args);\n    var resultSelector = popResultSelector(args);\n    var _a = argsArgArrayOrObject(args), observables = _a.args, keys = _a.keys;\n    if (observables.length === 0) {\n        return from([], scheduler);\n    }\n    var result = new Observable(combineLatestInit(observables, scheduler, keys\n        ?\n            function (values) { return createObject(keys, values); }\n        :\n            identity));\n    return resultSelector ? result.pipe(mapOneOrManyArgs(resultSelector)) : result;\n}\nexport function combineLatestInit(observables, scheduler, valueTransform) {\n    if (valueTransform === void 0) { valueTransform = identity; }\n    return function (subscriber) {\n        maybeSchedule(scheduler, function () {\n            var length = observables.length;\n            var values = new Array(length);\n            var active = length;\n            var remainingFirstValues = length;\n            var _loop_1 = function (i) {\n                maybeSchedule(scheduler, function () {\n                    var source = from(observables[i], scheduler);\n                    var hasFirstValue = false;\n                    source.subscribe(createOperatorSubscriber(subscriber, function (value) {\n                        values[i] = value;\n                        if (!hasFirstValue) {\n                            hasFirstValue = true;\n                            remainingFirstValues--;\n                        }\n                        if (!remainingFirstValues) {\n                            subscriber.next(valueTransform(values.slice()));\n                        }\n                    }, function () {\n                        if (!--active) {\n                            subscriber.complete();\n                        }\n                    }));\n                }, subscriber);\n            };\n            for (var i = 0; i < length; i++) {\n                _loop_1(i);\n            }\n        }, subscriber);\n    };\n}\nfunction maybeSchedule(scheduler, execute, subscription) {\n    if (scheduler) {\n        executeSchedule(subscription, scheduler, execute);\n    }\n    else {\n        execute();\n    }\n}\n//# sourceMappingURL=combineLatest.js.map","import { concatAll } from '../operators/concatAll';\nimport { popScheduler } from '../util/args';\nimport { from } from './from';\nexport function concat() {\n    var args = [];\n    for (var _i = 0; _i < arguments.length; _i++) {\n        args[_i] = arguments[_i];\n    }\n    return concatAll()(from(args, popScheduler(args)));\n}\n//# sourceMappingURL=concat.js.map","import { Observable } from '../Observable';\nexport var EMPTY = new Observable(function (subscriber) { return subscriber.complete(); });\nexport function empty(scheduler) {\n    return scheduler ? emptyScheduled(scheduler) : EMPTY;\n}\nfunction emptyScheduled(scheduler) {\n    return new Observable(function (subscriber) { return scheduler.schedule(function () { return subscriber.complete(); }); });\n}\n//# sourceMappingURL=empty.js.map","import { scheduled } from '../scheduled/scheduled';\nimport { innerFrom } from './innerFrom';\nexport function from(input, scheduler) {\n    return scheduler ? scheduled(input, scheduler) : innerFrom(input);\n}\n//# sourceMappingURL=from.js.map","import { __asyncValues, __awaiter, __generator, __values } from \"tslib\";\nimport { isArrayLike } from '../util/isArrayLike';\nimport { isPromise } from '../util/isPromise';\nimport { Observable } from '../Observable';\nimport { isInteropObservable } from '../util/isInteropObservable';\nimport { isAsyncIterable } from '../util/isAsyncIterable';\nimport { createInvalidObservableTypeError } from '../util/throwUnobservableError';\nimport { isIterable } from '../util/isIterable';\nimport { isReadableStreamLike, readableStreamLikeToAsyncGenerator } from '../util/isReadableStreamLike';\nimport { isFunction } from '../util/isFunction';\nimport { reportUnhandledError } from '../util/reportUnhandledError';\nimport { observable as Symbol_observable } from '../symbol/observable';\nexport function innerFrom(input) {\n    if (input instanceof Observable) {\n        return input;\n    }\n    if (input != null) {\n        if (isInteropObservable(input)) {\n            return fromInteropObservable(input);\n        }\n        if (isArrayLike(input)) {\n            return fromArrayLike(input);\n        }\n        if (isPromise(input)) {\n            return fromPromise(input);\n        }\n        if (isAsyncIterable(input)) {\n            return fromAsyncIterable(input);\n        }\n        if (isIterable(input)) {\n            return fromIterable(input);\n        }\n        if (isReadableStreamLike(input)) {\n            return fromReadableStreamLike(input);\n        }\n    }\n    throw createInvalidObservableTypeError(input);\n}\nexport function fromInteropObservable(obj) {\n    return new Observable(function (subscriber) {\n        var obs = obj[Symbol_observable]();\n        if (isFunction(obs.subscribe)) {\n            return obs.subscribe(subscriber);\n        }\n        throw new TypeError('Provided object does not correctly implement Symbol.observable');\n    });\n}\nexport function fromArrayLike(array) {\n    return new Observable(function (subscriber) {\n        for (var i = 0; i < array.length && !subscriber.closed; i++) {\n            subscriber.next(array[i]);\n        }\n        subscriber.complete();\n    });\n}\nexport function fromPromise(promise) {\n    return new Observable(function (subscriber) {\n        promise\n            .then(function (value) {\n            if (!subscriber.closed) {\n                subscriber.next(value);\n                subscriber.complete();\n            }\n        }, function (err) { return subscriber.error(err); })\n            .then(null, reportUnhandledError);\n    });\n}\nexport function fromIterable(iterable) {\n    return new Observable(function (subscriber) {\n        var e_1, _a;\n        try {\n            for (var iterable_1 = __values(iterable), iterable_1_1 = iterable_1.next(); !iterable_1_1.done; iterable_1_1 = iterable_1.next()) {\n                var value = iterable_1_1.value;\n                subscriber.next(value);\n                if (subscriber.closed) {\n                    return;\n                }\n            }\n        }\n        catch (e_1_1) { e_1 = { error: e_1_1 }; }\n        finally {\n            try {\n                if (iterable_1_1 && !iterable_1_1.done && (_a = iterable_1.return)) _a.call(iterable_1);\n            }\n            finally { if (e_1) throw e_1.error; }\n        }\n        subscriber.complete();\n    });\n}\nexport function fromAsyncIterable(asyncIterable) {\n    return new Observable(function (subscriber) {\n        process(asyncIterable, subscriber).catch(function (err) { return subscriber.error(err); });\n    });\n}\nexport function fromReadableStreamLike(readableStream) {\n    return fromAsyncIterable(readableStreamLikeToAsyncGenerator(readableStream));\n}\nfunction process(asyncIterable, subscriber) {\n    var asyncIterable_1, asyncIterable_1_1;\n    var e_2, _a;\n    return __awaiter(this, void 0, void 0, function () {\n        var value, e_2_1;\n        return __generator(this, function (_b) {\n            switch (_b.label) {\n                case 0:\n                    _b.trys.push([0, 5, 6, 11]);\n                    asyncIterable_1 = __asyncValues(asyncIterable);\n                    _b.label = 1;\n                case 1: return [4, asyncIterable_1.next()];\n                case 2:\n                    if (!(asyncIterable_1_1 = _b.sent(), !asyncIterable_1_1.done)) return [3, 4];\n                    value = asyncIterable_1_1.value;\n                    subscriber.next(value);\n                    if (subscriber.closed) {\n                        return [2];\n                    }\n                    _b.label = 3;\n                case 3: return [3, 1];\n                case 4: return [3, 11];\n                case 5:\n                    e_2_1 = _b.sent();\n                    e_2 = { error: e_2_1 };\n                    return [3, 11];\n                case 6:\n                    _b.trys.push([6, , 9, 10]);\n                    if (!(asyncIterable_1_1 && !asyncIterable_1_1.done && (_a = asyncIterable_1.return))) return [3, 8];\n                    return [4, _a.call(asyncIterable_1)];\n                case 7:\n                    _b.sent();\n                    _b.label = 8;\n                case 8: return [3, 10];\n                case 9:\n                    if (e_2) throw e_2.error;\n                    return [7];\n                case 10: return [7];\n                case 11:\n                    subscriber.complete();\n                    return [2];\n            }\n        });\n    });\n}\n//# sourceMappingURL=innerFrom.js.map","import { mergeAll } from '../operators/mergeAll';\nimport { innerFrom } from './innerFrom';\nimport { EMPTY } from './empty';\nimport { popNumber, popScheduler } from '../util/args';\nimport { from } from './from';\nexport function merge() {\n    var args = [];\n    for (var _i = 0; _i < arguments.length; _i++) {\n        args[_i] = arguments[_i];\n    }\n    var scheduler = popScheduler(args);\n    var concurrent = popNumber(args, Infinity);\n    var sources = args;\n    return !sources.length\n        ?\n            EMPTY\n        : sources.length === 1\n            ?\n                innerFrom(sources[0])\n            :\n                mergeAll(concurrent)(from(sources, scheduler));\n}\n//# sourceMappingURL=merge.js.map","import { __extends } from \"tslib\";\nimport { Subscriber } from '../Subscriber';\nexport function createOperatorSubscriber(destination, onNext, onComplete, onError, onFinalize) {\n    return new OperatorSubscriber(destination, onNext, onComplete, onError, onFinalize);\n}\nvar OperatorSubscriber = (function (_super) {\n    __extends(OperatorSubscriber, _super);\n    function OperatorSubscriber(destination, onNext, onComplete, onError, onFinalize, shouldUnsubscribe) {\n        var _this = _super.call(this, destination) || this;\n        _this.onFinalize = onFinalize;\n        _this.shouldUnsubscribe = shouldUnsubscribe;\n        _this._next = onNext\n            ? function (value) {\n                try {\n                    onNext(value);\n                }\n                catch (err) {\n                    destination.error(err);\n                }\n            }\n            : _super.prototype._next;\n        _this._error = onError\n            ? function (err) {\n                try {\n                    onError(err);\n                }\n                catch (err) {\n                    destination.error(err);\n                }\n                finally {\n                    this.unsubscribe();\n                }\n            }\n            : _super.prototype._error;\n        _this._complete = onComplete\n            ? function () {\n                try {\n                    onComplete();\n                }\n                catch (err) {\n                    destination.error(err);\n                }\n                finally {\n                    this.unsubscribe();\n                }\n            }\n            : _super.prototype._complete;\n        return _this;\n    }\n    OperatorSubscriber.prototype.unsubscribe = function () {\n        var _a;\n        if (!this.shouldUnsubscribe || this.shouldUnsubscribe()) {\n            var closed_1 = this.closed;\n            _super.prototype.unsubscribe.call(this);\n            !closed_1 && ((_a = this.onFinalize) === null || _a === void 0 ? void 0 : _a.call(this));\n        }\n    };\n    return OperatorSubscriber;\n}(Subscriber));\nexport { OperatorSubscriber };\n//# sourceMappingURL=OperatorSubscriber.js.map","import { mergeAll } from './mergeAll';\nexport function concatAll() {\n    return mergeAll(1);\n}\n//# sourceMappingURL=concatAll.js.map","import { identity } from '../util/identity';\nimport { operate } from '../util/lift';\nimport { createOperatorSubscriber } from './OperatorSubscriber';\nexport function distinctUntilChanged(comparator, keySelector) {\n    if (keySelector === void 0) { keySelector = identity; }\n    comparator = comparator !== null && comparator !== void 0 ? comparator : defaultCompare;\n    return operate(function (source, subscriber) {\n        var previousKey;\n        var first = true;\n        source.subscribe(createOperatorSubscriber(subscriber, function (value) {\n            var currentKey = keySelector(value);\n            if (first || !comparator(previousKey, currentKey)) {\n                first = false;\n                previousKey = currentKey;\n                subscriber.next(value);\n            }\n        }));\n    });\n}\nfunction defaultCompare(a, b) {\n    return a === b;\n}\n//# sourceMappingURL=distinctUntilChanged.js.map","import { operate } from '../util/lift';\nimport { createOperatorSubscriber } from './OperatorSubscriber';\nexport function filter(predicate, thisArg) {\n    return operate(function (source, subscriber) {\n        var index = 0;\n        source.subscribe(createOperatorSubscriber(subscriber, function (value) { return predicate.call(thisArg, value, index++) && subscriber.next(value); }));\n    });\n}\n//# sourceMappingURL=filter.js.map","import { operate } from '../util/lift';\nimport { createOperatorSubscriber } from './OperatorSubscriber';\nexport function map(project, thisArg) {\n    return operate(function (source, subscriber) {\n        var index = 0;\n        source.subscribe(createOperatorSubscriber(subscriber, function (value) {\n            subscriber.next(project.call(thisArg, value, index++));\n        }));\n    });\n}\n//# sourceMappingURL=map.js.map","import { __read, __spreadArray } from \"tslib\";\nimport { operate } from '../util/lift';\nimport { mergeAll } from './mergeAll';\nimport { popNumber, popScheduler } from '../util/args';\nimport { from } from '../observable/from';\nexport function merge() {\n    var args = [];\n    for (var _i = 0; _i < arguments.length; _i++) {\n        args[_i] = arguments[_i];\n    }\n    var scheduler = popScheduler(args);\n    var concurrent = popNumber(args, Infinity);\n    return operate(function (source, subscriber) {\n        mergeAll(concurrent)(from(__spreadArray([source], __read(args)), scheduler)).subscribe(subscriber);\n    });\n}\n//# sourceMappingURL=merge.js.map","import { mergeMap } from './mergeMap';\nimport { identity } from '../util/identity';\nexport function mergeAll(concurrent) {\n    if (concurrent === void 0) { concurrent = Infinity; }\n    return mergeMap(identity, concurrent);\n}\n//# sourceMappingURL=mergeAll.js.map","import { innerFrom } from '../observable/innerFrom';\nimport { executeSchedule } from '../util/executeSchedule';\nimport { createOperatorSubscriber } from './OperatorSubscriber';\nexport function mergeInternals(source, subscriber, project, concurrent, onBeforeNext, expand, innerSubScheduler, additionalFinalizer) {\n    var buffer = [];\n    var active = 0;\n    var index = 0;\n    var isComplete = false;\n    var checkComplete = function () {\n        if (isComplete && !buffer.length && !active) {\n            subscriber.complete();\n        }\n    };\n    var outerNext = function (value) { return (active < concurrent ? doInnerSub(value) : buffer.push(value)); };\n    var doInnerSub = function (value) {\n        expand && subscriber.next(value);\n        active++;\n        var innerComplete = false;\n        innerFrom(project(value, index++)).subscribe(createOperatorSubscriber(subscriber, function (innerValue) {\n            onBeforeNext === null || onBeforeNext === void 0 ? void 0 : onBeforeNext(innerValue);\n            if (expand) {\n                outerNext(innerValue);\n            }\n            else {\n                subscriber.next(innerValue);\n            }\n        }, function () {\n            innerComplete = true;\n        }, undefined, function () {\n            if (innerComplete) {\n                try {\n                    active--;\n                    var _loop_1 = function () {\n                        var bufferedValue = buffer.shift();\n                        if (innerSubScheduler) {\n                            executeSchedule(subscriber, innerSubScheduler, function () { return doInnerSub(bufferedValue); });\n                        }\n                        else {\n                            doInnerSub(bufferedValue);\n                        }\n                    };\n                    while (buffer.length && active < concurrent) {\n                        _loop_1();\n                    }\n                    checkComplete();\n                }\n                catch (err) {\n                    subscriber.error(err);\n                }\n            }\n        }));\n    };\n    source.subscribe(createOperatorSubscriber(subscriber, outerNext, function () {\n        isComplete = true;\n        checkComplete();\n    }));\n    return function () {\n        additionalFinalizer === null || additionalFinalizer === void 0 ? void 0 : additionalFinalizer();\n    };\n}\n//# sourceMappingURL=mergeInternals.js.map","import { map } from './map';\nimport { innerFrom } from '../observable/innerFrom';\nimport { operate } from '../util/lift';\nimport { mergeInternals } from './mergeInternals';\nimport { isFunction } from '../util/isFunction';\nexport function mergeMap(project, resultSelector, concurrent) {\n    if (concurrent === void 0) { concurrent = Infinity; }\n    if (isFunction(resultSelector)) {\n        return mergeMap(function (a, i) { return map(function (b, ii) { return resultSelector(a, b, i, ii); })(innerFrom(project(a, i))); }, concurrent);\n    }\n    else if (typeof resultSelector === 'number') {\n        concurrent = resultSelector;\n    }\n    return operate(function (source, subscriber) { return mergeInternals(source, subscriber, project, concurrent); });\n}\n//# sourceMappingURL=mergeMap.js.map","import { __read, __spreadArray } from \"tslib\";\nimport { merge } from './merge';\nexport function mergeWith() {\n    var otherSources = [];\n    for (var _i = 0; _i < arguments.length; _i++) {\n        otherSources[_i] = arguments[_i];\n    }\n    return merge.apply(void 0, __spreadArray([], __read(otherSources)));\n}\n//# sourceMappingURL=mergeWith.js.map","import { executeSchedule } from '../util/executeSchedule';\nimport { operate } from '../util/lift';\nimport { createOperatorSubscriber } from './OperatorSubscriber';\nexport function observeOn(scheduler, delay) {\n    if (delay === void 0) { delay = 0; }\n    return operate(function (source, subscriber) {\n        source.subscribe(createOperatorSubscriber(subscriber, function (value) { return executeSchedule(subscriber, scheduler, function () { return subscriber.next(value); }, delay); }, function () { return executeSchedule(subscriber, scheduler, function () { return subscriber.complete(); }, delay); }, function (err) { return executeSchedule(subscriber, scheduler, function () { return subscriber.error(err); }, delay); }));\n    });\n}\n//# sourceMappingURL=observeOn.js.map","import { __read, __spreadArray } from \"tslib\";\nimport { innerFrom } from '../observable/innerFrom';\nimport { Subject } from '../Subject';\nimport { SafeSubscriber } from '../Subscriber';\nimport { operate } from '../util/lift';\nexport function share(options) {\n    if (options === void 0) { options = {}; }\n    var _a = options.connector, connector = _a === void 0 ? function () { return new Subject(); } : _a, _b = options.resetOnError, resetOnError = _b === void 0 ? true : _b, _c = options.resetOnComplete, resetOnComplete = _c === void 0 ? true : _c, _d = options.resetOnRefCountZero, resetOnRefCountZero = _d === void 0 ? true : _d;\n    return function (wrapperSource) {\n        var connection;\n        var resetConnection;\n        var subject;\n        var refCount = 0;\n        var hasCompleted = false;\n        var hasErrored = false;\n        var cancelReset = function () {\n            resetConnection === null || resetConnection === void 0 ? void 0 : resetConnection.unsubscribe();\n            resetConnection = undefined;\n        };\n        var reset = function () {\n            cancelReset();\n            connection = subject = undefined;\n            hasCompleted = hasErrored = false;\n        };\n        var resetAndUnsubscribe = function () {\n            var conn = connection;\n            reset();\n            conn === null || conn === void 0 ? void 0 : conn.unsubscribe();\n        };\n        return operate(function (source, subscriber) {\n            refCount++;\n            if (!hasErrored && !hasCompleted) {\n                cancelReset();\n            }\n            var dest = (subject = subject !== null && subject !== void 0 ? subject : connector());\n            subscriber.add(function () {\n                refCount--;\n                if (refCount === 0 && !hasErrored && !hasCompleted) {\n                    resetConnection = handleReset(resetAndUnsubscribe, resetOnRefCountZero);\n                }\n            });\n            dest.subscribe(subscriber);\n            if (!connection &&\n                refCount > 0) {\n                connection = new SafeSubscriber({\n                    next: function (value) { return dest.next(value); },\n                    error: function (err) {\n                        hasErrored = true;\n                        cancelReset();\n                        resetConnection = handleReset(reset, resetOnError, err);\n                        dest.error(err);\n                    },\n                    complete: function () {\n                        hasCompleted = true;\n                        cancelReset();\n                        resetConnection = handleReset(reset, resetOnComplete);\n                        dest.complete();\n                    },\n                });\n                innerFrom(source).subscribe(connection);\n            }\n        })(wrapperSource);\n    };\n}\nfunction handleReset(reset, on) {\n    var args = [];\n    for (var _i = 2; _i < arguments.length; _i++) {\n        args[_i - 2] = arguments[_i];\n    }\n    if (on === true) {\n        reset();\n        return;\n    }\n    if (on === false) {\n        return;\n    }\n    var onSubscriber = new SafeSubscriber({\n        next: function () {\n            onSubscriber.unsubscribe();\n            reset();\n        },\n    });\n    return innerFrom(on.apply(void 0, __spreadArray([], __read(args)))).subscribe(onSubscriber);\n}\n//# sourceMappingURL=share.js.map","import { ReplaySubject } from '../ReplaySubject';\nimport { share } from './share';\nexport function shareReplay(configOrBufferSize, windowTime, scheduler) {\n    var _a, _b, _c;\n    var bufferSize;\n    var refCount = false;\n    if (configOrBufferSize && typeof configOrBufferSize === 'object') {\n        (_a = configOrBufferSize.bufferSize, bufferSize = _a === void 0 ? Infinity : _a, _b = configOrBufferSize.windowTime, windowTime = _b === void 0 ? Infinity : _b, _c = configOrBufferSize.refCount, refCount = _c === void 0 ? false : _c, scheduler = configOrBufferSize.scheduler);\n    }\n    else {\n        bufferSize = (configOrBufferSize !== null && configOrBufferSize !== void 0 ? configOrBufferSize : Infinity);\n    }\n    return share({\n        connector: function () { return new ReplaySubject(bufferSize, windowTime, scheduler); },\n        resetOnError: true,\n        resetOnComplete: false,\n        resetOnRefCountZero: refCount,\n    });\n}\n//# sourceMappingURL=shareReplay.js.map","import { concat } from '../observable/concat';\nimport { popScheduler } from '../util/args';\nimport { operate } from '../util/lift';\nexport function startWith() {\n    var values = [];\n    for (var _i = 0; _i < arguments.length; _i++) {\n        values[_i] = arguments[_i];\n    }\n    var scheduler = popScheduler(values);\n    return operate(function (source, subscriber) {\n        (scheduler ? concat(values, source, scheduler) : concat(values, source)).subscribe(subscriber);\n    });\n}\n//# sourceMappingURL=startWith.js.map","import { operate } from '../util/lift';\nexport function subscribeOn(scheduler, delay) {\n    if (delay === void 0) { delay = 0; }\n    return operate(function (source, subscriber) {\n        subscriber.add(scheduler.schedule(function () { return source.subscribe(subscriber); }, delay));\n    });\n}\n//# sourceMappingURL=subscribeOn.js.map","import { innerFrom } from '../observable/innerFrom';\nimport { operate } from '../util/lift';\nimport { createOperatorSubscriber } from './OperatorSubscriber';\nexport function switchMap(project, resultSelector) {\n    return operate(function (source, subscriber) {\n        var innerSubscriber = null;\n        var index = 0;\n        var isComplete = false;\n        var checkComplete = function () { return isComplete && !innerSubscriber && subscriber.complete(); };\n        source.subscribe(createOperatorSubscriber(subscriber, function (value) {\n            innerSubscriber === null || innerSubscriber === void 0 ? void 0 : innerSubscriber.unsubscribe();\n            var innerIndex = 0;\n            var outerIndex = index++;\n            innerFrom(project(value, outerIndex)).subscribe((innerSubscriber = createOperatorSubscriber(subscriber, function (innerValue) { return subscriber.next(resultSelector ? resultSelector(value, innerValue, outerIndex, innerIndex++) : innerValue); }, function () {\n                innerSubscriber = null;\n                checkComplete();\n            })));\n        }, function () {\n            isComplete = true;\n            checkComplete();\n        }));\n    });\n}\n//# sourceMappingURL=switchMap.js.map","import { Observable } from '../Observable';\nexport function scheduleArray(input, scheduler) {\n    return new Observable(function (subscriber) {\n        var i = 0;\n        return scheduler.schedule(function () {\n            if (i === input.length) {\n                subscriber.complete();\n            }\n            else {\n                subscriber.next(input[i++]);\n                if (!subscriber.closed) {\n                    this.schedule();\n                }\n            }\n        });\n    });\n}\n//# sourceMappingURL=scheduleArray.js.map","import { Observable } from '../Observable';\nimport { executeSchedule } from '../util/executeSchedule';\nexport function scheduleAsyncIterable(input, scheduler) {\n    if (!input) {\n        throw new Error('Iterable cannot be null');\n    }\n    return new Observable(function (subscriber) {\n        executeSchedule(subscriber, scheduler, function () {\n            var iterator = input[Symbol.asyncIterator]();\n            executeSchedule(subscriber, scheduler, function () {\n                iterator.next().then(function (result) {\n                    if (result.done) {\n                        subscriber.complete();\n                    }\n                    else {\n                        subscriber.next(result.value);\n                    }\n                });\n            }, 0, true);\n        });\n    });\n}\n//# sourceMappingURL=scheduleAsyncIterable.js.map","import { Observable } from '../Observable';\nimport { iterator as Symbol_iterator } from '../symbol/iterator';\nimport { isFunction } from '../util/isFunction';\nimport { executeSchedule } from '../util/executeSchedule';\nexport function scheduleIterable(input, scheduler) {\n    return new Observable(function (subscriber) {\n        var iterator;\n        executeSchedule(subscriber, scheduler, function () {\n            iterator = input[Symbol_iterator]();\n            executeSchedule(subscriber, scheduler, function () {\n                var _a;\n                var value;\n                var done;\n                try {\n                    (_a = iterator.next(), value = _a.value, done = _a.done);\n                }\n                catch (err) {\n                    subscriber.error(err);\n                    return;\n                }\n                if (done) {\n                    subscriber.complete();\n                }\n                else {\n                    subscriber.next(value);\n                }\n            }, 0, true);\n        });\n        return function () { return isFunction(iterator === null || iterator === void 0 ? void 0 : iterator.return) && iterator.return(); };\n    });\n}\n//# sourceMappingURL=scheduleIterable.js.map","import { innerFrom } from '../observable/innerFrom';\nimport { observeOn } from '../operators/observeOn';\nimport { subscribeOn } from '../operators/subscribeOn';\nexport function scheduleObservable(input, scheduler) {\n    return innerFrom(input).pipe(subscribeOn(scheduler), observeOn(scheduler));\n}\n//# sourceMappingURL=scheduleObservable.js.map","import { innerFrom } from '../observable/innerFrom';\nimport { observeOn } from '../operators/observeOn';\nimport { subscribeOn } from '../operators/subscribeOn';\nexport function schedulePromise(input, scheduler) {\n    return innerFrom(input).pipe(subscribeOn(scheduler), observeOn(scheduler));\n}\n//# sourceMappingURL=schedulePromise.js.map","import { scheduleAsyncIterable } from './scheduleAsyncIterable';\nimport { readableStreamLikeToAsyncGenerator } from '../util/isReadableStreamLike';\nexport function scheduleReadableStreamLike(input, scheduler) {\n    return scheduleAsyncIterable(readableStreamLikeToAsyncGenerator(input), scheduler);\n}\n//# sourceMappingURL=scheduleReadableStreamLike.js.map","import { scheduleObservable } from './scheduleObservable';\nimport { schedulePromise } from './schedulePromise';\nimport { scheduleArray } from './scheduleArray';\nimport { scheduleIterable } from './scheduleIterable';\nimport { scheduleAsyncIterable } from './scheduleAsyncIterable';\nimport { isInteropObservable } from '../util/isInteropObservable';\nimport { isPromise } from '../util/isPromise';\nimport { isArrayLike } from '../util/isArrayLike';\nimport { isIterable } from '../util/isIterable';\nimport { isAsyncIterable } from '../util/isAsyncIterable';\nimport { createInvalidObservableTypeError } from '../util/throwUnobservableError';\nimport { isReadableStreamLike } from '../util/isReadableStreamLike';\nimport { scheduleReadableStreamLike } from './scheduleReadableStreamLike';\nexport function scheduled(input, scheduler) {\n    if (input != null) {\n        if (isInteropObservable(input)) {\n            return scheduleObservable(input, scheduler);\n        }\n        if (isArrayLike(input)) {\n            return scheduleArray(input, scheduler);\n        }\n        if (isPromise(input)) {\n            return schedulePromise(input, scheduler);\n        }\n        if (isAsyncIterable(input)) {\n            return scheduleAsyncIterable(input, scheduler);\n        }\n        if (isIterable(input)) {\n            return scheduleIterable(input, scheduler);\n        }\n        if (isReadableStreamLike(input)) {\n            return scheduleReadableStreamLike(input, scheduler);\n        }\n    }\n    throw createInvalidObservableTypeError(input);\n}\n//# sourceMappingURL=scheduled.js.map","export var dateTimestampProvider = {\n    now: function () {\n        return (dateTimestampProvider.delegate || Date).now();\n    },\n    delegate: undefined,\n};\n//# sourceMappingURL=dateTimestampProvider.js.map","import { __read, __spreadArray } from \"tslib\";\nexport var timeoutProvider = {\n    setTimeout: function (handler, timeout) {\n        var args = [];\n        for (var _i = 2; _i < arguments.length; _i++) {\n            args[_i - 2] = arguments[_i];\n        }\n        var delegate = timeoutProvider.delegate;\n        if (delegate === null || delegate === void 0 ? void 0 : delegate.setTimeout) {\n            return delegate.setTimeout.apply(delegate, __spreadArray([handler, timeout], __read(args)));\n        }\n        return setTimeout.apply(void 0, __spreadArray([handler, timeout], __read(args)));\n    },\n    clearTimeout: function (handle) {\n        var delegate = timeoutProvider.delegate;\n        return ((delegate === null || delegate === void 0 ? void 0 : delegate.clearTimeout) || clearTimeout)(handle);\n    },\n    delegate: undefined,\n};\n//# sourceMappingURL=timeoutProvider.js.map","export function getSymbolIterator() {\n    if (typeof Symbol !== 'function' || !Symbol.iterator) {\n        return '@@iterator';\n    }\n    return Symbol.iterator;\n}\nexport var iterator = getSymbolIterator();\n//# sourceMappingURL=iterator.js.map","export var observable = (function () { return (typeof Symbol === 'function' && Symbol.observable) || '@@observable'; })();\n//# sourceMappingURL=observable.js.map","import { createErrorClass } from './createErrorClass';\nexport var EmptyError = createErrorClass(function (_super) {\n    return function EmptyErrorImpl() {\n        _super(this);\n        this.name = 'EmptyError';\n        this.message = 'no elements in sequence';\n    };\n});\n//# sourceMappingURL=EmptyError.js.map","import { createErrorClass } from './createErrorClass';\nexport var ObjectUnsubscribedError = createErrorClass(function (_super) {\n    return function ObjectUnsubscribedErrorImpl() {\n        _super(this);\n        this.name = 'ObjectUnsubscribedError';\n        this.message = 'object unsubscribed';\n    };\n});\n//# sourceMappingURL=ObjectUnsubscribedError.js.map","import { createErrorClass } from './createErrorClass';\nexport var UnsubscriptionError = createErrorClass(function (_super) {\n    return function UnsubscriptionErrorImpl(errors) {\n        _super(this);\n        this.message = errors\n            ? errors.length + \" errors occurred during unsubscription:\\n\" + errors.map(function (err, i) { return i + 1 + \") \" + err.toString(); }).join('\\n  ')\n            : '';\n        this.name = 'UnsubscriptionError';\n        this.errors = errors;\n    };\n});\n//# sourceMappingURL=UnsubscriptionError.js.map","import { isFunction } from './isFunction';\nimport { isScheduler } from './isScheduler';\nfunction last(arr) {\n    return arr[arr.length - 1];\n}\nexport function popResultSelector(args) {\n    return isFunction(last(args)) ? args.pop() : undefined;\n}\nexport function popScheduler(args) {\n    return isScheduler(last(args)) ? args.pop() : undefined;\n}\nexport function popNumber(args, defaultValue) {\n    return typeof last(args) === 'number' ? args.pop() : defaultValue;\n}\n//# sourceMappingURL=args.js.map","var isArray = Array.isArray;\nvar getPrototypeOf = Object.getPrototypeOf, objectProto = Object.prototype, getKeys = Object.keys;\nexport function argsArgArrayOrObject(args) {\n    if (args.length === 1) {\n        var first_1 = args[0];\n        if (isArray(first_1)) {\n            return { args: first_1, keys: null };\n        }\n        if (isPOJO(first_1)) {\n            var keys = getKeys(first_1);\n            return {\n                args: keys.map(function (key) { return first_1[key]; }),\n                keys: keys,\n            };\n        }\n    }\n    return { args: args, keys: null };\n}\nfunction isPOJO(obj) {\n    return obj && typeof obj === 'object' && getPrototypeOf(obj) === objectProto;\n}\n//# sourceMappingURL=argsArgArrayOrObject.js.map","export function arrRemove(arr, item) {\n    if (arr) {\n        var index = arr.indexOf(item);\n        0 <= index && arr.splice(index, 1);\n    }\n}\n//# sourceMappingURL=arrRemove.js.map","export function createErrorClass(createImpl) {\n    var _super = function (instance) {\n        Error.call(instance);\n        instance.stack = new Error().stack;\n    };\n    var ctorFunc = createImpl(_super);\n    ctorFunc.prototype = Object.create(Error.prototype);\n    ctorFunc.prototype.constructor = ctorFunc;\n    return ctorFunc;\n}\n//# sourceMappingURL=createErrorClass.js.map","export function createObject(keys, values) {\n    return keys.reduce(function (result, key, i) { return ((result[key] = values[i]), result); }, {});\n}\n//# sourceMappingURL=createObject.js.map","import { config } from '../config';\nvar context = null;\nexport function errorContext(cb) {\n    if (config.useDeprecatedSynchronousErrorHandling) {\n        var isRoot = !context;\n        if (isRoot) {\n            context = { errorThrown: false, error: null };\n        }\n        cb();\n        if (isRoot) {\n            var _a = context, errorThrown = _a.errorThrown, error = _a.error;\n            context = null;\n            if (errorThrown) {\n                throw error;\n            }\n        }\n    }\n    else {\n        cb();\n    }\n}\nexport function captureError(err) {\n    if (config.useDeprecatedSynchronousErrorHandling && context) {\n        context.errorThrown = true;\n        context.error = err;\n    }\n}\n//# sourceMappingURL=errorContext.js.map","export function executeSchedule(parentSubscription, scheduler, work, delay, repeat) {\n    if (delay === void 0) { delay = 0; }\n    if (repeat === void 0) { repeat = false; }\n    var scheduleSubscription = scheduler.schedule(function () {\n        work();\n        if (repeat) {\n            parentSubscription.add(this.schedule(null, delay));\n        }\n        else {\n            this.unsubscribe();\n        }\n    }, delay);\n    parentSubscription.add(scheduleSubscription);\n    if (!repeat) {\n        return scheduleSubscription;\n    }\n}\n//# sourceMappingURL=executeSchedule.js.map","export function identity(x) {\n    return x;\n}\n//# sourceMappingURL=identity.js.map","export var isArrayLike = (function (x) { return x && typeof x.length === 'number' && typeof x !== 'function'; });\n//# sourceMappingURL=isArrayLike.js.map","import { isFunction } from './isFunction';\nexport function isAsyncIterable(obj) {\n    return Symbol.asyncIterator && isFunction(obj === null || obj === void 0 ? void 0 : obj[Symbol.asyncIterator]);\n}\n//# sourceMappingURL=isAsyncIterable.js.map","export function isFunction(value) {\n    return typeof value === 'function';\n}\n//# sourceMappingURL=isFunction.js.map","import { observable as Symbol_observable } from '../symbol/observable';\nimport { isFunction } from './isFunction';\nexport function isInteropObservable(input) {\n    return isFunction(input[Symbol_observable]);\n}\n//# sourceMappingURL=isInteropObservable.js.map","import { iterator as Symbol_iterator } from '../symbol/iterator';\nimport { isFunction } from './isFunction';\nexport function isIterable(input) {\n    return isFunction(input === null || input === void 0 ? void 0 : input[Symbol_iterator]);\n}\n//# sourceMappingURL=isIterable.js.map","import { isFunction } from \"./isFunction\";\nexport function isPromise(value) {\n    return isFunction(value === null || value === void 0 ? void 0 : value.then);\n}\n//# sourceMappingURL=isPromise.js.map","import { __asyncGenerator, __await, __generator } from \"tslib\";\nimport { isFunction } from './isFunction';\nexport function readableStreamLikeToAsyncGenerator(readableStream) {\n    return __asyncGenerator(this, arguments, function readableStreamLikeToAsyncGenerator_1() {\n        var reader, _a, value, done;\n        return __generator(this, function (_b) {\n            switch (_b.label) {\n                case 0:\n                    reader = readableStream.getReader();\n                    _b.label = 1;\n                case 1:\n                    _b.trys.push([1, , 9, 10]);\n                    _b.label = 2;\n                case 2:\n                    if (!true) return [3, 8];\n                    return [4, __await(reader.read())];\n                case 3:\n                    _a = _b.sent(), value = _a.value, done = _a.done;\n                    if (!done) return [3, 5];\n                    return [4, __await(void 0)];\n                case 4: return [2, _b.sent()];\n                case 5: return [4, __await(value)];\n                case 6: return [4, _b.sent()];\n                case 7:\n                    _b.sent();\n                    return [3, 2];\n                case 8: return [3, 10];\n                case 9:\n                    reader.releaseLock();\n                    return [7];\n                case 10: return [2];\n            }\n        });\n    });\n}\nexport function isReadableStreamLike(obj) {\n    return isFunction(obj === null || obj === void 0 ? void 0 : obj.getReader);\n}\n//# sourceMappingURL=isReadableStreamLike.js.map","import { isFunction } from './isFunction';\nexport function isScheduler(value) {\n    return value && isFunction(value.schedule);\n}\n//# sourceMappingURL=isScheduler.js.map","import { isFunction } from './isFunction';\nexport function hasLift(source) {\n    return isFunction(source === null || source === void 0 ? void 0 : source.lift);\n}\nexport function operate(init) {\n    return function (source) {\n        if (hasLift(source)) {\n            return source.lift(function (liftedSource) {\n                try {\n                    return init(liftedSource, this);\n                }\n                catch (err) {\n                    this.error(err);\n                }\n            });\n        }\n        throw new TypeError('Unable to lift unknown Observable type');\n    };\n}\n//# sourceMappingURL=lift.js.map","import { __read, __spreadArray } from \"tslib\";\nimport { map } from \"../operators/map\";\nvar isArray = Array.isArray;\nfunction callOrApply(fn, args) {\n    return isArray(args) ? fn.apply(void 0, __spreadArray([], __read(args))) : fn(args);\n}\nexport function mapOneOrManyArgs(fn) {\n    return map(function (args) { return callOrApply(fn, args); });\n}\n//# sourceMappingURL=mapOneOrManyArgs.js.map","export function noop() { }\n//# sourceMappingURL=noop.js.map","import { identity } from './identity';\nexport function pipe() {\n    var fns = [];\n    for (var _i = 0; _i < arguments.length; _i++) {\n        fns[_i] = arguments[_i];\n    }\n    return pipeFromArray(fns);\n}\nexport function pipeFromArray(fns) {\n    if (fns.length === 0) {\n        return identity;\n    }\n    if (fns.length === 1) {\n        return fns[0];\n    }\n    return function piped(input) {\n        return fns.reduce(function (prev, fn) { return fn(prev); }, input);\n    };\n}\n//# sourceMappingURL=pipe.js.map","import { config } from '../config';\nimport { timeoutProvider } from '../scheduler/timeoutProvider';\nexport function reportUnhandledError(err) {\n    timeoutProvider.setTimeout(function () {\n        var onUnhandledError = config.onUnhandledError;\n        if (onUnhandledError) {\n            onUnhandledError(err);\n        }\n        else {\n            throw err;\n        }\n    });\n}\n//# sourceMappingURL=reportUnhandledError.js.map","export function createInvalidObservableTypeError(input) {\n    return new TypeError(\"You provided \" + (input !== null && typeof input === 'object' ? 'an invalid object' : \"'\" + input + \"'\") + \" where a stream was expected. You can provide an Observable, Promise, ReadableStream, Array, AsyncIterable, or Iterable.\");\n}\n//# sourceMappingURL=throwUnobservableError.js.map","/******************************************************************************\nCopyright (c) Microsoft Corporation.\n\nPermission to use, copy, modify, and/or distribute this software for any\npurpose with or without fee is hereby granted.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH\nREGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY\nAND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT,\nINDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM\nLOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR\nOTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR\nPERFORMANCE OF THIS SOFTWARE.\n***************************************************************************** */\n/* global Reflect, Promise, SuppressedError, Symbol, Iterator */\n\nvar extendStatics = function(d, b) {\n  extendStatics = Object.setPrototypeOf ||\n      ({ __proto__: [] } instanceof Array && function (d, b) { d.__proto__ = b; }) ||\n      function (d, b) { for (var p in b) if (Object.prototype.hasOwnProperty.call(b, p)) d[p] = b[p]; };\n  return extendStatics(d, b);\n};\n\nexport function __extends(d, b) {\n  if (typeof b !== \"function\" && b !== null)\n      throw new TypeError(\"Class extends value \" + String(b) + \" is not a constructor or null\");\n  extendStatics(d, b);\n  function __() { this.constructor = d; }\n  d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n}\n\nexport var __assign = function() {\n  __assign = Object.assign || function __assign(t) {\n      for (var s, i = 1, n = arguments.length; i < n; i++) {\n          s = arguments[i];\n          for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p)) t[p] = s[p];\n      }\n      return t;\n  }\n  return __assign.apply(this, arguments);\n}\n\nexport function __rest(s, e) {\n  var t = {};\n  for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p) && e.indexOf(p) < 0)\n      t[p] = s[p];\n  if (s != null && typeof Object.getOwnPropertySymbols === \"function\")\n      for (var i = 0, p = Object.getOwnPropertySymbols(s); i < p.length; i++) {\n          if (e.indexOf(p[i]) < 0 && Object.prototype.propertyIsEnumerable.call(s, p[i]))\n              t[p[i]] = s[p[i]];\n      }\n  return t;\n}\n\nexport function __decorate(decorators, target, key, desc) {\n  var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;\n  if (typeof Reflect === \"object\" && typeof Reflect.decorate === \"function\") r = Reflect.decorate(decorators, target, key, desc);\n  else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;\n  return c > 3 && r && Object.defineProperty(target, key, r), r;\n}\n\nexport function __param(paramIndex, decorator) {\n  return function (target, key) { decorator(target, key, paramIndex); }\n}\n\nexport function __esDecorate(ctor, descriptorIn, decorators, contextIn, initializers, extraInitializers) {\n  function accept(f) { if (f !== void 0 && typeof f !== \"function\") throw new TypeError(\"Function expected\"); return f; }\n  var kind = contextIn.kind, key = kind === \"getter\" ? \"get\" : kind === \"setter\" ? \"set\" : \"value\";\n  var target = !descriptorIn && ctor ? contextIn[\"static\"] ? ctor : ctor.prototype : null;\n  var descriptor = descriptorIn || (target ? Object.getOwnPropertyDescriptor(target, contextIn.name) : {});\n  var _, done = false;\n  for (var i = decorators.length - 1; i >= 0; i--) {\n      var context = {};\n      for (var p in contextIn) context[p] = p === \"access\" ? {} : contextIn[p];\n      for (var p in contextIn.access) context.access[p] = contextIn.access[p];\n      context.addInitializer = function (f) { if (done) throw new TypeError(\"Cannot add initializers after decoration has completed\"); extraInitializers.push(accept(f || null)); };\n      var result = (0, decorators[i])(kind === \"accessor\" ? { get: descriptor.get, set: descriptor.set } : descriptor[key], context);\n      if (kind === \"accessor\") {\n          if (result === void 0) continue;\n          if (result === null || typeof result !== \"object\") throw new TypeError(\"Object expected\");\n          if (_ = accept(result.get)) descriptor.get = _;\n          if (_ = accept(result.set)) descriptor.set = _;\n          if (_ = accept(result.init)) initializers.unshift(_);\n      }\n      else if (_ = accept(result)) {\n          if (kind === \"field\") initializers.unshift(_);\n          else descriptor[key] = _;\n      }\n  }\n  if (target) Object.defineProperty(target, contextIn.name, descriptor);\n  done = true;\n};\n\nexport function __runInitializers(thisArg, initializers, value) {\n  var useValue = arguments.length > 2;\n  for (var i = 0; i < initializers.length; i++) {\n      value = useValue ? initializers[i].call(thisArg, value) : initializers[i].call(thisArg);\n  }\n  return useValue ? value : void 0;\n};\n\nexport function __propKey(x) {\n  return typeof x === \"symbol\" ? x : \"\".concat(x);\n};\n\nexport function __setFunctionName(f, name, prefix) {\n  if (typeof name === \"symbol\") name = name.description ? \"[\".concat(name.description, \"]\") : \"\";\n  return Object.defineProperty(f, \"name\", { configurable: true, value: prefix ? \"\".concat(prefix, \" \", name) : name });\n};\n\nexport function __metadata(metadataKey, metadataValue) {\n  if (typeof Reflect === \"object\" && typeof Reflect.metadata === \"function\") return Reflect.metadata(metadataKey, metadataValue);\n}\n\nexport function __awaiter(thisArg, _arguments, P, generator) {\n  function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n  return new (P || (P = Promise))(function (resolve, reject) {\n      function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n      function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n      function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n      step((generator = generator.apply(thisArg, _arguments || [])).next());\n  });\n}\n\nexport function __generator(thisArg, body) {\n  var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g = Object.create((typeof Iterator === \"function\" ? Iterator : Object).prototype);\n  return g.next = verb(0), g[\"throw\"] = verb(1), g[\"return\"] = verb(2), typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\n  function verb(n) { return function (v) { return step([n, v]); }; }\n  function step(op) {\n      if (f) throw new TypeError(\"Generator is already executing.\");\n      while (g && (g = 0, op[0] && (_ = 0)), _) try {\n          if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n          if (y = 0, t) op = [op[0] & 2, t.value];\n          switch (op[0]) {\n              case 0: case 1: t = op; break;\n              case 4: _.label++; return { value: op[1], done: false };\n              case 5: _.label++; y = op[1]; op = [0]; continue;\n              case 7: op = _.ops.pop(); _.trys.pop(); continue;\n              default:\n                  if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\n                  if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\n                  if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\n                  if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\n                  if (t[2]) _.ops.pop();\n                  _.trys.pop(); continue;\n          }\n          op = body.call(thisArg, _);\n      } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\n      if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\n  }\n}\n\nexport var __createBinding = Object.create ? (function(o, m, k, k2) {\n  if (k2 === undefined) k2 = k;\n  var desc = Object.getOwnPropertyDescriptor(m, k);\n  if (!desc || (\"get\" in desc ? !m.__esModule : desc.writable || desc.configurable)) {\n      desc = { enumerable: true, get: function() { return m[k]; } };\n  }\n  Object.defineProperty(o, k2, desc);\n}) : (function(o, m, k, k2) {\n  if (k2 === undefined) k2 = k;\n  o[k2] = m[k];\n});\n\nexport function __exportStar(m, o) {\n  for (var p in m) if (p !== \"default\" && !Object.prototype.hasOwnProperty.call(o, p)) __createBinding(o, m, p);\n}\n\nexport function __values(o) {\n  var s = typeof Symbol === \"function\" && Symbol.iterator, m = s && o[s], i = 0;\n  if (m) return m.call(o);\n  if (o && typeof o.length === \"number\") return {\n      next: function () {\n          if (o && i >= o.length) o = void 0;\n          return { value: o && o[i++], done: !o };\n      }\n  };\n  throw new TypeError(s ? \"Object is not iterable.\" : \"Symbol.iterator is not defined.\");\n}\n\nexport function __read(o, n) {\n  var m = typeof Symbol === \"function\" && o[Symbol.iterator];\n  if (!m) return o;\n  var i = m.call(o), r, ar = [], e;\n  try {\n      while ((n === void 0 || n-- > 0) && !(r = i.next()).done) ar.push(r.value);\n  }\n  catch (error) { e = { error: error }; }\n  finally {\n      try {\n          if (r && !r.done && (m = i[\"return\"])) m.call(i);\n      }\n      finally { if (e) throw e.error; }\n  }\n  return ar;\n}\n\n/** @deprecated */\nexport function __spread() {\n  for (var ar = [], i = 0; i < arguments.length; i++)\n      ar = ar.concat(__read(arguments[i]));\n  return ar;\n}\n\n/** @deprecated */\nexport function __spreadArrays() {\n  for (var s = 0, i = 0, il = arguments.length; i < il; i++) s += arguments[i].length;\n  for (var r = Array(s), k = 0, i = 0; i < il; i++)\n      for (var a = arguments[i], j = 0, jl = a.length; j < jl; j++, k++)\n          r[k] = a[j];\n  return r;\n}\n\nexport function __spreadArray(to, from, pack) {\n  if (pack || arguments.length === 2) for (var i = 0, l = from.length, ar; i < l; i++) {\n      if (ar || !(i in from)) {\n          if (!ar) ar = Array.prototype.slice.call(from, 0, i);\n          ar[i] = from[i];\n      }\n  }\n  return to.concat(ar || Array.prototype.slice.call(from));\n}\n\nexport function __await(v) {\n  return this instanceof __await ? (this.v = v, this) : new __await(v);\n}\n\nexport function __asyncGenerator(thisArg, _arguments, generator) {\n  if (!Symbol.asyncIterator) throw new TypeError(\"Symbol.asyncIterator is not defined.\");\n  var g = generator.apply(thisArg, _arguments || []), i, q = [];\n  return i = Object.create((typeof AsyncIterator === \"function\" ? AsyncIterator : Object).prototype), verb(\"next\"), verb(\"throw\"), verb(\"return\", awaitReturn), i[Symbol.asyncIterator] = function () { return this; }, i;\n  function awaitReturn(f) { return function (v) { return Promise.resolve(v).then(f, reject); }; }\n  function verb(n, f) { if (g[n]) { i[n] = function (v) { return new Promise(function (a, b) { q.push([n, v, a, b]) > 1 || resume(n, v); }); }; if (f) i[n] = f(i[n]); } }\n  function resume(n, v) { try { step(g[n](v)); } catch (e) { settle(q[0][3], e); } }\n  function step(r) { r.value instanceof __await ? Promise.resolve(r.value.v).then(fulfill, reject) : settle(q[0][2], r); }\n  function fulfill(value) { resume(\"next\", value); }\n  function reject(value) { resume(\"throw\", value); }\n  function settle(f, v) { if (f(v), q.shift(), q.length) resume(q[0][0], q[0][1]); }\n}\n\nexport function __asyncDelegator(o) {\n  var i, p;\n  return i = {}, verb(\"next\"), verb(\"throw\", function (e) { throw e; }), verb(\"return\"), i[Symbol.iterator] = function () { return this; }, i;\n  function verb(n, f) { i[n] = o[n] ? function (v) { return (p = !p) ? { value: __await(o[n](v)), done: false } : f ? f(v) : v; } : f; }\n}\n\nexport function __asyncValues(o) {\n  if (!Symbol.asyncIterator) throw new TypeError(\"Symbol.asyncIterator is not defined.\");\n  var m = o[Symbol.asyncIterator], i;\n  return m ? m.call(o) : (o = typeof __values === \"function\" ? __values(o) : o[Symbol.iterator](), i = {}, verb(\"next\"), verb(\"throw\"), verb(\"return\"), i[Symbol.asyncIterator] = function () { return this; }, i);\n  function verb(n) { i[n] = o[n] && function (v) { return new Promise(function (resolve, reject) { v = o[n](v), settle(resolve, reject, v.done, v.value); }); }; }\n  function settle(resolve, reject, d, v) { Promise.resolve(v).then(function(v) { resolve({ value: v, done: d }); }, reject); }\n}\n\nexport function __makeTemplateObject(cooked, raw) {\n  if (Object.defineProperty) { Object.defineProperty(cooked, \"raw\", { value: raw }); } else { cooked.raw = raw; }\n  return cooked;\n};\n\nvar __setModuleDefault = Object.create ? (function(o, v) {\n  Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n  o[\"default\"] = v;\n};\n\nvar ownKeys = function(o) {\n  ownKeys = Object.getOwnPropertyNames || function (o) {\n    var ar = [];\n    for (var k in o) if (Object.prototype.hasOwnProperty.call(o, k)) ar[ar.length] = k;\n    return ar;\n  };\n  return ownKeys(o);\n};\n\nexport function __importStar(mod) {\n  if (mod && mod.__esModule) return mod;\n  var result = {};\n  if (mod != null) for (var k = ownKeys(mod), i = 0; i < k.length; i++) if (k[i] !== \"default\") __createBinding(result, mod, k[i]);\n  __setModuleDefault(result, mod);\n  return result;\n}\n\nexport function __importDefault(mod) {\n  return (mod && mod.__esModule) ? mod : { default: mod };\n}\n\nexport function __classPrivateFieldGet(receiver, state, kind, f) {\n  if (kind === \"a\" && !f) throw new TypeError(\"Private accessor was defined without a getter\");\n  if (typeof state === \"function\" ? receiver !== state || !f : !state.has(receiver)) throw new TypeError(\"Cannot read private member from an object whose class did not declare it\");\n  return kind === \"m\" ? f : kind === \"a\" ? f.call(receiver) : f ? f.value : state.get(receiver);\n}\n\nexport function __classPrivateFieldSet(receiver, state, value, kind, f) {\n  if (kind === \"m\") throw new TypeError(\"Private method is not writable\");\n  if (kind === \"a\" && !f) throw new TypeError(\"Private accessor was defined without a setter\");\n  if (typeof state === \"function\" ? receiver !== state || !f : !state.has(receiver)) throw new TypeError(\"Cannot write private member to an object whose class did not declare it\");\n  return (kind === \"a\" ? f.call(receiver, value) : f ? f.value = value : state.set(receiver, value)), value;\n}\n\nexport function __classPrivateFieldIn(state, receiver) {\n  if (receiver === null || (typeof receiver !== \"object\" && typeof receiver !== \"function\")) throw new TypeError(\"Cannot use 'in' operator on non-object\");\n  return typeof state === \"function\" ? receiver === state : state.has(receiver);\n}\n\nexport function __addDisposableResource(env, value, async) {\n  if (value !== null && value !== void 0) {\n    if (typeof value !== \"object\" && typeof value !== \"function\") throw new TypeError(\"Object expected.\");\n    var dispose, inner;\n    if (async) {\n      if (!Symbol.asyncDispose) throw new TypeError(\"Symbol.asyncDispose is not defined.\");\n      dispose = value[Symbol.asyncDispose];\n    }\n    if (dispose === void 0) {\n      if (!Symbol.dispose) throw new TypeError(\"Symbol.dispose is not defined.\");\n      dispose = value[Symbol.dispose];\n      if (async) inner = dispose;\n    }\n    if (typeof dispose !== \"function\") throw new TypeError(\"Object not disposable.\");\n    if (inner) dispose = function() { try { inner.call(this); } catch (e) { return Promise.reject(e); } };\n    env.stack.push({ value: value, dispose: dispose, async: async });\n  }\n  else if (async) {\n    env.stack.push({ async: true });\n  }\n  return value;\n}\n\nvar _SuppressedError = typeof SuppressedError === \"function\" ? SuppressedError : function (error, suppressed, message) {\n  var e = new Error(message);\n  return e.name = \"SuppressedError\", e.error = error, e.suppressed = suppressed, e;\n};\n\nexport function __disposeResources(env) {\n  function fail(e) {\n    env.error = env.hasError ? new _SuppressedError(e, env.error, \"An error was suppressed during disposal.\") : e;\n    env.hasError = true;\n  }\n  var r, s = 0;\n  function next() {\n    while (r = env.stack.pop()) {\n      try {\n        if (!r.async && s === 1) return s = 0, env.stack.push(r), Promise.resolve().then(next);\n        if (r.dispose) {\n          var result = r.dispose.call(r.value);\n          if (r.async) return s |= 2, Promise.resolve(result).then(next, function(e) { fail(e); return next(); });\n        }\n        else s |= 1;\n      }\n      catch (e) {\n        fail(e);\n      }\n    }\n    if (s === 1) return env.hasError ? Promise.reject(env.error) : Promise.resolve();\n    if (env.hasError) throw env.error;\n  }\n  return next();\n}\n\nexport function __rewriteRelativeImportExtension(path, preserveJsx) {\n  if (typeof path === \"string\" && /^\\.\\.?\\//.test(path)) {\n      return path.replace(/\\.(tsx)$|((?:\\.d)?)((?:\\.[^./]+?)?)\\.([cm]?)ts$/i, function (m, tsx, d, ext, cm) {\n          return tsx ? preserveJsx ? \".jsx\" : \".js\" : d && (!ext || !cm) ? m : (d + ext + \".\" + cm.toLowerCase() + \"js\");\n      });\n  }\n  return path;\n}\n\nexport default {\n  __extends,\n  __assign,\n  __rest,\n  __decorate,\n  __param,\n  __esDecorate,\n  __runInitializers,\n  __propKey,\n  __setFunctionName,\n  __metadata,\n  __awaiter,\n  __generator,\n  __createBinding,\n  __exportStar,\n  __values,\n  __read,\n  __spread,\n  __spreadArrays,\n  __spreadArray,\n  __await,\n  __asyncGenerator,\n  __asyncDelegator,\n  __asyncValues,\n  __makeTemplateObject,\n  __importStar,\n  __importDefault,\n  __classPrivateFieldGet,\n  __classPrivateFieldSet,\n  __classPrivateFieldIn,\n  __addDisposableResource,\n  __disposeResources,\n  __rewriteRelativeImportExtension,\n};\n","/* global WorkerGlobalScope */\n\nexport function addBrowser(fn) {\n  if (typeof WorkerGlobalScope === 'function' && self instanceof WorkerGlobalScope) {\n    /**\n     * Because killing a worker does directly stop the excution\n     * of the code, our only chance is to overwrite the close function\n     * which could work some times.\n     * @link https://stackoverflow.com/q/72903255/3443137\n     */\n    var oldClose = self.close.bind(self);\n    self.close = function () {\n      fn();\n      return oldClose();\n    };\n  } else {\n    /**\n     * if we are on react-native, there is no window.addEventListener\n     * @link https://github.com/pubkey/unload/issues/6\n     */\n    if (typeof window.addEventListener !== 'function') {\n      return;\n    }\n\n    /**\n     * for normal browser-windows, we use the beforeunload-event\n     */\n    window.addEventListener('beforeunload', function () {\n      fn();\n    }, true);\n\n    /**\n     * for iframes, we have to use the unload-event\n     * @link https://stackoverflow.com/q/47533670/3443137\n     */\n    window.addEventListener('unload', function () {\n      fn();\n    }, true);\n  }\n\n  /**\n   * TODO add fallback for safari-mobile\n   * @link https://stackoverflow.com/a/26193516/3443137\n   */\n}","import { addBrowser } from './browser.js';\nimport { addNode } from './node.js';\n\n/**\n * Use the code directly to prevent import problems\n * with the detect-node package.\n * @link https://github.com/iliakan/detect-node/blob/master/index.js\n */\nvar isNode = Object.prototype.toString.call(typeof process !== 'undefined' ? process : 0) === '[object process]';\nvar USE_METHOD = isNode ? addNode : addBrowser;\nvar LISTENERS = new Set();\nvar startedListening = false;\nfunction startListening() {\n  if (startedListening) {\n    return;\n  }\n  startedListening = true;\n  USE_METHOD(runAll);\n}\nexport function add(fn) {\n  startListening();\n  if (typeof fn !== 'function') {\n    throw new Error('Listener is no function');\n  }\n  LISTENERS.add(fn);\n  var addReturn = {\n    remove: function remove() {\n      return LISTENERS[\"delete\"](fn);\n    },\n    run: function run() {\n      LISTENERS[\"delete\"](fn);\n      return fn();\n    }\n  };\n  return addReturn;\n}\nexport function runAll() {\n  var promises = [];\n  LISTENERS.forEach(function (fn) {\n    promises.push(fn());\n    LISTENERS[\"delete\"](fn);\n  });\n  return Promise.all(promises);\n}\nexport function removeAll() {\n  LISTENERS.clear();\n}\nexport function getSize() {\n  return LISTENERS.size;\n}","export function addNode(fn) {\n  process.on('exit', function () {\n    return fn();\n  });\n\n  /**\n   * on the following events,\n   * the process will not end if there are\n   * event-handlers attached,\n   * therefore we have to call process.exit()\n   */\n  process.on('beforeExit', function () {\n    return fn().then(function () {\n      return process.exit();\n    });\n  });\n  // catches ctrl+c event\n  process.on('SIGINT', function () {\n    return fn().then(function () {\n      return process.exit();\n    });\n  });\n  // catches uncaught exceptions\n  process.on('uncaughtException', function (err) {\n    return fn().then(function () {\n      console.trace(err);\n      process.exit(101);\n    });\n  });\n}","(function (global, factory) {\n  if (typeof define === \"function\" && define.amd) {\n    define(\"webextension-polyfill\", [\"module\"], factory);\n  } else if (typeof exports !== \"undefined\") {\n    factory(module);\n  } else {\n    var mod = {\n      exports: {}\n    };\n    factory(mod);\n    global.browser = mod.exports;\n  }\n})(typeof globalThis !== \"undefined\" ? globalThis : typeof self !== \"undefined\" ? self : this, function (module) {\n  /* webextension-polyfill - v0.12.0 - Tue May 14 2024 18:01:29 */\n  /* -*- Mode: indent-tabs-mode: nil; js-indent-level: 2 -*- */\n  /* vim: set sts=2 sw=2 et tw=80: */\n  /* This Source Code Form is subject to the terms of the Mozilla Public\n   * License, v. 2.0. If a copy of the MPL was not distributed with this\n   * file, You can obtain one at http://mozilla.org/MPL/2.0/. */\n  \"use strict\";\n\n  if (!(globalThis.chrome && globalThis.chrome.runtime && globalThis.chrome.runtime.id)) {\n    throw new Error(\"This script should only be loaded in a browser extension.\");\n  }\n  if (!(globalThis.browser && globalThis.browser.runtime && globalThis.browser.runtime.id)) {\n    const CHROME_SEND_MESSAGE_CALLBACK_NO_RESPONSE_MESSAGE = \"The message port closed before a response was received.\";\n\n    // Wrapping the bulk of this polyfill in a one-time-use function is a minor\n    // optimization for Firefox. Since Spidermonkey does not fully parse the\n    // contents of a function until the first time it's called, and since it will\n    // never actually need to be called, this allows the polyfill to be included\n    // in Firefox nearly for free.\n    const wrapAPIs = extensionAPIs => {\n      // NOTE: apiMetadata is associated to the content of the api-metadata.json file\n      // at build time by replacing the following \"include\" with the content of the\n      // JSON file.\n      const apiMetadata = {\n        \"alarms\": {\n          \"clear\": {\n            \"minArgs\": 0,\n            \"maxArgs\": 1\n          },\n          \"clearAll\": {\n            \"minArgs\": 0,\n            \"maxArgs\": 0\n          },\n          \"get\": {\n            \"minArgs\": 0,\n            \"maxArgs\": 1\n          },\n          \"getAll\": {\n            \"minArgs\": 0,\n            \"maxArgs\": 0\n          }\n        },\n        \"bookmarks\": {\n          \"create\": {\n            \"minArgs\": 1,\n            \"maxArgs\": 1\n          },\n          \"get\": {\n            \"minArgs\": 1,\n            \"maxArgs\": 1\n          },\n          \"getChildren\": {\n            \"minArgs\": 1,\n            \"maxArgs\": 1\n          },\n          \"getRecent\": {\n            \"minArgs\": 1,\n            \"maxArgs\": 1\n          },\n          \"getSubTree\": {\n            \"minArgs\": 1,\n            \"maxArgs\": 1\n          },\n          \"getTree\": {\n            \"minArgs\": 0,\n            \"maxArgs\": 0\n          },\n          \"move\": {\n            \"minArgs\": 2,\n            \"maxArgs\": 2\n          },\n          \"remove\": {\n            \"minArgs\": 1,\n            \"maxArgs\": 1\n          },\n          \"removeTree\": {\n            \"minArgs\": 1,\n            \"maxArgs\": 1\n          },\n          \"search\": {\n            \"minArgs\": 1,\n            \"maxArgs\": 1\n          },\n          \"update\": {\n            \"minArgs\": 2,\n            \"maxArgs\": 2\n          }\n        },\n        \"browserAction\": {\n          \"disable\": {\n            \"minArgs\": 0,\n            \"maxArgs\": 1,\n            \"fallbackToNoCallback\": true\n          },\n          \"enable\": {\n            \"minArgs\": 0,\n            \"maxArgs\": 1,\n            \"fallbackToNoCallback\": true\n          },\n          \"getBadgeBackgroundColor\": {\n            \"minArgs\": 1,\n            \"maxArgs\": 1\n          },\n          \"getBadgeText\": {\n            \"minArgs\": 1,\n            \"maxArgs\": 1\n          },\n          \"getPopup\": {\n            \"minArgs\": 1,\n            \"maxArgs\": 1\n          },\n          \"getTitle\": {\n            \"minArgs\": 1,\n            \"maxArgs\": 1\n          },\n          \"openPopup\": {\n            \"minArgs\": 0,\n            \"maxArgs\": 0\n          },\n          \"setBadgeBackgroundColor\": {\n            \"minArgs\": 1,\n            \"maxArgs\": 1,\n            \"fallbackToNoCallback\": true\n          },\n          \"setBadgeText\": {\n            \"minArgs\": 1,\n            \"maxArgs\": 1,\n            \"fallbackToNoCallback\": true\n          },\n          \"setIcon\": {\n            \"minArgs\": 1,\n            \"maxArgs\": 1\n          },\n          \"setPopup\": {\n            \"minArgs\": 1,\n            \"maxArgs\": 1,\n            \"fallbackToNoCallback\": true\n          },\n          \"setTitle\": {\n            \"minArgs\": 1,\n            \"maxArgs\": 1,\n            \"fallbackToNoCallback\": true\n          }\n        },\n        \"browsingData\": {\n          \"remove\": {\n            \"minArgs\": 2,\n            \"maxArgs\": 2\n          },\n          \"removeCache\": {\n            \"minArgs\": 1,\n            \"maxArgs\": 1\n          },\n          \"removeCookies\": {\n            \"minArgs\": 1,\n            \"maxArgs\": 1\n          },\n          \"removeDownloads\": {\n            \"minArgs\": 1,\n            \"maxArgs\": 1\n          },\n          \"removeFormData\": {\n            \"minArgs\": 1,\n            \"maxArgs\": 1\n          },\n          \"removeHistory\": {\n            \"minArgs\": 1,\n            \"maxArgs\": 1\n          },\n          \"removeLocalStorage\": {\n            \"minArgs\": 1,\n            \"maxArgs\": 1\n          },\n          \"removePasswords\": {\n            \"minArgs\": 1,\n            \"maxArgs\": 1\n          },\n          \"removePluginData\": {\n            \"minArgs\": 1,\n            \"maxArgs\": 1\n          },\n          \"settings\": {\n            \"minArgs\": 0,\n            \"maxArgs\": 0\n          }\n        },\n        \"commands\": {\n          \"getAll\": {\n            \"minArgs\": 0,\n            \"maxArgs\": 0\n          }\n        },\n        \"contextMenus\": {\n          \"remove\": {\n            \"minArgs\": 1,\n            \"maxArgs\": 1\n          },\n          \"removeAll\": {\n            \"minArgs\": 0,\n            \"maxArgs\": 0\n          },\n          \"update\": {\n            \"minArgs\": 2,\n            \"maxArgs\": 2\n          }\n        },\n        \"cookies\": {\n          \"get\": {\n            \"minArgs\": 1,\n            \"maxArgs\": 1\n          },\n          \"getAll\": {\n            \"minArgs\": 1,\n            \"maxArgs\": 1\n          },\n          \"getAllCookieStores\": {\n            \"minArgs\": 0,\n            \"maxArgs\": 0\n          },\n          \"remove\": {\n            \"minArgs\": 1,\n            \"maxArgs\": 1\n          },\n          \"set\": {\n            \"minArgs\": 1,\n            \"maxArgs\": 1\n          }\n        },\n        \"devtools\": {\n          \"inspectedWindow\": {\n            \"eval\": {\n              \"minArgs\": 1,\n              \"maxArgs\": 2,\n              \"singleCallbackArg\": false\n            }\n          },\n          \"panels\": {\n            \"create\": {\n              \"minArgs\": 3,\n              \"maxArgs\": 3,\n              \"singleCallbackArg\": true\n            },\n            \"elements\": {\n              \"createSidebarPane\": {\n                \"minArgs\": 1,\n                \"maxArgs\": 1\n              }\n            }\n          }\n        },\n        \"downloads\": {\n          \"cancel\": {\n            \"minArgs\": 1,\n            \"maxArgs\": 1\n          },\n          \"download\": {\n            \"minArgs\": 1,\n            \"maxArgs\": 1\n          },\n          \"erase\": {\n            \"minArgs\": 1,\n            \"maxArgs\": 1\n          },\n          \"getFileIcon\": {\n            \"minArgs\": 1,\n            \"maxArgs\": 2\n          },\n          \"open\": {\n            \"minArgs\": 1,\n            \"maxArgs\": 1,\n            \"fallbackToNoCallback\": true\n          },\n          \"pause\": {\n            \"minArgs\": 1,\n            \"maxArgs\": 1\n          },\n          \"removeFile\": {\n            \"minArgs\": 1,\n            \"maxArgs\": 1\n          },\n          \"resume\": {\n            \"minArgs\": 1,\n            \"maxArgs\": 1\n          },\n          \"search\": {\n            \"minArgs\": 1,\n            \"maxArgs\": 1\n          },\n          \"show\": {\n            \"minArgs\": 1,\n            \"maxArgs\": 1,\n            \"fallbackToNoCallback\": true\n          }\n        },\n        \"extension\": {\n          \"isAllowedFileSchemeAccess\": {\n            \"minArgs\": 0,\n            \"maxArgs\": 0\n          },\n          \"isAllowedIncognitoAccess\": {\n            \"minArgs\": 0,\n            \"maxArgs\": 0\n          }\n        },\n        \"history\": {\n          \"addUrl\": {\n            \"minArgs\": 1,\n            \"maxArgs\": 1\n          },\n          \"deleteAll\": {\n            \"minArgs\": 0,\n            \"maxArgs\": 0\n          },\n          \"deleteRange\": {\n            \"minArgs\": 1,\n            \"maxArgs\": 1\n          },\n          \"deleteUrl\": {\n            \"minArgs\": 1,\n            \"maxArgs\": 1\n          },\n          \"getVisits\": {\n            \"minArgs\": 1,\n            \"maxArgs\": 1\n          },\n          \"search\": {\n            \"minArgs\": 1,\n            \"maxArgs\": 1\n          }\n        },\n        \"i18n\": {\n          \"detectLanguage\": {\n            \"minArgs\": 1,\n            \"maxArgs\": 1\n          },\n          \"getAcceptLanguages\": {\n            \"minArgs\": 0,\n            \"maxArgs\": 0\n          }\n        },\n        \"identity\": {\n          \"launchWebAuthFlow\": {\n            \"minArgs\": 1,\n            \"maxArgs\": 1\n          }\n        },\n        \"idle\": {\n          \"queryState\": {\n            \"minArgs\": 1,\n            \"maxArgs\": 1\n          }\n        },\n        \"management\": {\n          \"get\": {\n            \"minArgs\": 1,\n            \"maxArgs\": 1\n          },\n          \"getAll\": {\n            \"minArgs\": 0,\n            \"maxArgs\": 0\n          },\n          \"getSelf\": {\n            \"minArgs\": 0,\n            \"maxArgs\": 0\n          },\n          \"setEnabled\": {\n            \"minArgs\": 2,\n            \"maxArgs\": 2\n          },\n          \"uninstallSelf\": {\n            \"minArgs\": 0,\n            \"maxArgs\": 1\n          }\n        },\n        \"notifications\": {\n          \"clear\": {\n            \"minArgs\": 1,\n            \"maxArgs\": 1\n          },\n          \"create\": {\n            \"minArgs\": 1,\n            \"maxArgs\": 2\n          },\n          \"getAll\": {\n            \"minArgs\": 0,\n            \"maxArgs\": 0\n          },\n          \"getPermissionLevel\": {\n            \"minArgs\": 0,\n            \"maxArgs\": 0\n          },\n          \"update\": {\n            \"minArgs\": 2,\n            \"maxArgs\": 2\n          }\n        },\n        \"pageAction\": {\n          \"getPopup\": {\n            \"minArgs\": 1,\n            \"maxArgs\": 1\n          },\n          \"getTitle\": {\n            \"minArgs\": 1,\n            \"maxArgs\": 1\n          },\n          \"hide\": {\n            \"minArgs\": 1,\n            \"maxArgs\": 1,\n            \"fallbackToNoCallback\": true\n          },\n          \"setIcon\": {\n            \"minArgs\": 1,\n            \"maxArgs\": 1\n          },\n          \"setPopup\": {\n            \"minArgs\": 1,\n            \"maxArgs\": 1,\n            \"fallbackToNoCallback\": true\n          },\n          \"setTitle\": {\n            \"minArgs\": 1,\n            \"maxArgs\": 1,\n            \"fallbackToNoCallback\": true\n          },\n          \"show\": {\n            \"minArgs\": 1,\n            \"maxArgs\": 1,\n            \"fallbackToNoCallback\": true\n          }\n        },\n        \"permissions\": {\n          \"contains\": {\n            \"minArgs\": 1,\n            \"maxArgs\": 1\n          },\n          \"getAll\": {\n            \"minArgs\": 0,\n            \"maxArgs\": 0\n          },\n          \"remove\": {\n            \"minArgs\": 1,\n            \"maxArgs\": 1\n          },\n          \"request\": {\n            \"minArgs\": 1,\n            \"maxArgs\": 1\n          }\n        },\n        \"runtime\": {\n          \"getBackgroundPage\": {\n            \"minArgs\": 0,\n            \"maxArgs\": 0\n          },\n          \"getPlatformInfo\": {\n            \"minArgs\": 0,\n            \"maxArgs\": 0\n          },\n          \"openOptionsPage\": {\n            \"minArgs\": 0,\n            \"maxArgs\": 0\n          },\n          \"requestUpdateCheck\": {\n            \"minArgs\": 0,\n            \"maxArgs\": 0\n          },\n          \"sendMessage\": {\n            \"minArgs\": 1,\n            \"maxArgs\": 3\n          },\n          \"sendNativeMessage\": {\n            \"minArgs\": 2,\n            \"maxArgs\": 2\n          },\n          \"setUninstallURL\": {\n            \"minArgs\": 1,\n            \"maxArgs\": 1\n          }\n        },\n        \"sessions\": {\n          \"getDevices\": {\n            \"minArgs\": 0,\n            \"maxArgs\": 1\n          },\n          \"getRecentlyClosed\": {\n            \"minArgs\": 0,\n            \"maxArgs\": 1\n          },\n          \"restore\": {\n            \"minArgs\": 0,\n            \"maxArgs\": 1\n          }\n        },\n        \"storage\": {\n          \"local\": {\n            \"clear\": {\n              \"minArgs\": 0,\n              \"maxArgs\": 0\n            },\n            \"get\": {\n              \"minArgs\": 0,\n              \"maxArgs\": 1\n            },\n            \"getBytesInUse\": {\n              \"minArgs\": 0,\n              \"maxArgs\": 1\n            },\n            \"remove\": {\n              \"minArgs\": 1,\n              \"maxArgs\": 1\n            },\n            \"set\": {\n              \"minArgs\": 1,\n              \"maxArgs\": 1\n            }\n          },\n          \"managed\": {\n            \"get\": {\n              \"minArgs\": 0,\n              \"maxArgs\": 1\n            },\n            \"getBytesInUse\": {\n              \"minArgs\": 0,\n              \"maxArgs\": 1\n            }\n          },\n          \"sync\": {\n            \"clear\": {\n              \"minArgs\": 0,\n              \"maxArgs\": 0\n            },\n            \"get\": {\n              \"minArgs\": 0,\n              \"maxArgs\": 1\n            },\n            \"getBytesInUse\": {\n              \"minArgs\": 0,\n              \"maxArgs\": 1\n            },\n            \"remove\": {\n              \"minArgs\": 1,\n              \"maxArgs\": 1\n            },\n            \"set\": {\n              \"minArgs\": 1,\n              \"maxArgs\": 1\n            }\n          }\n        },\n        \"tabs\": {\n          \"captureVisibleTab\": {\n            \"minArgs\": 0,\n            \"maxArgs\": 2\n          },\n          \"create\": {\n            \"minArgs\": 1,\n            \"maxArgs\": 1\n          },\n          \"detectLanguage\": {\n            \"minArgs\": 0,\n            \"maxArgs\": 1\n          },\n          \"discard\": {\n            \"minArgs\": 0,\n            \"maxArgs\": 1\n          },\n          \"duplicate\": {\n            \"minArgs\": 1,\n            \"maxArgs\": 1\n          },\n          \"executeScript\": {\n            \"minArgs\": 1,\n            \"maxArgs\": 2\n          },\n          \"get\": {\n            \"minArgs\": 1,\n            \"maxArgs\": 1\n          },\n          \"getCurrent\": {\n            \"minArgs\": 0,\n            \"maxArgs\": 0\n          },\n          \"getZoom\": {\n            \"minArgs\": 0,\n            \"maxArgs\": 1\n          },\n          \"getZoomSettings\": {\n            \"minArgs\": 0,\n            \"maxArgs\": 1\n          },\n          \"goBack\": {\n            \"minArgs\": 0,\n            \"maxArgs\": 1\n          },\n          \"goForward\": {\n            \"minArgs\": 0,\n            \"maxArgs\": 1\n          },\n          \"highlight\": {\n            \"minArgs\": 1,\n            \"maxArgs\": 1\n          },\n          \"insertCSS\": {\n            \"minArgs\": 1,\n            \"maxArgs\": 2\n          },\n          \"move\": {\n            \"minArgs\": 2,\n            \"maxArgs\": 2\n          },\n          \"query\": {\n            \"minArgs\": 1,\n            \"maxArgs\": 1\n          },\n          \"reload\": {\n            \"minArgs\": 0,\n            \"maxArgs\": 2\n          },\n          \"remove\": {\n            \"minArgs\": 1,\n            \"maxArgs\": 1\n          },\n          \"removeCSS\": {\n            \"minArgs\": 1,\n            \"maxArgs\": 2\n          },\n          \"sendMessage\": {\n            \"minArgs\": 2,\n            \"maxArgs\": 3\n          },\n          \"setZoom\": {\n            \"minArgs\": 1,\n            \"maxArgs\": 2\n          },\n          \"setZoomSettings\": {\n            \"minArgs\": 1,\n            \"maxArgs\": 2\n          },\n          \"update\": {\n            \"minArgs\": 1,\n            \"maxArgs\": 2\n          }\n        },\n        \"topSites\": {\n          \"get\": {\n            \"minArgs\": 0,\n            \"maxArgs\": 0\n          }\n        },\n        \"webNavigation\": {\n          \"getAllFrames\": {\n            \"minArgs\": 1,\n            \"maxArgs\": 1\n          },\n          \"getFrame\": {\n            \"minArgs\": 1,\n            \"maxArgs\": 1\n          }\n        },\n        \"webRequest\": {\n          \"handlerBehaviorChanged\": {\n            \"minArgs\": 0,\n            \"maxArgs\": 0\n          }\n        },\n        \"windows\": {\n          \"create\": {\n            \"minArgs\": 0,\n            \"maxArgs\": 1\n          },\n          \"get\": {\n            \"minArgs\": 1,\n            \"maxArgs\": 2\n          },\n          \"getAll\": {\n            \"minArgs\": 0,\n            \"maxArgs\": 1\n          },\n          \"getCurrent\": {\n            \"minArgs\": 0,\n            \"maxArgs\": 1\n          },\n          \"getLastFocused\": {\n            \"minArgs\": 0,\n            \"maxArgs\": 1\n          },\n          \"remove\": {\n            \"minArgs\": 1,\n            \"maxArgs\": 1\n          },\n          \"update\": {\n            \"minArgs\": 2,\n            \"maxArgs\": 2\n          }\n        }\n      };\n      if (Object.keys(apiMetadata).length === 0) {\n        throw new Error(\"api-metadata.json has not been included in browser-polyfill\");\n      }\n\n      /**\n       * A WeakMap subclass which creates and stores a value for any key which does\n       * not exist when accessed, but behaves exactly as an ordinary WeakMap\n       * otherwise.\n       *\n       * @param {function} createItem\n       *        A function which will be called in order to create the value for any\n       *        key which does not exist, the first time it is accessed. The\n       *        function receives, as its only argument, the key being created.\n       */\n      class DefaultWeakMap extends WeakMap {\n        constructor(createItem, items = undefined) {\n          super(items);\n          this.createItem = createItem;\n        }\n        get(key) {\n          if (!this.has(key)) {\n            this.set(key, this.createItem(key));\n          }\n          return super.get(key);\n        }\n      }\n\n      /**\n       * Returns true if the given object is an object with a `then` method, and can\n       * therefore be assumed to behave as a Promise.\n       *\n       * @param {*} value The value to test.\n       * @returns {boolean} True if the value is thenable.\n       */\n      const isThenable = value => {\n        return value && typeof value === \"object\" && typeof value.then === \"function\";\n      };\n\n      /**\n       * Creates and returns a function which, when called, will resolve or reject\n       * the given promise based on how it is called:\n       *\n       * - If, when called, `chrome.runtime.lastError` contains a non-null object,\n       *   the promise is rejected with that value.\n       * - If the function is called with exactly one argument, the promise is\n       *   resolved to that value.\n       * - Otherwise, the promise is resolved to an array containing all of the\n       *   function's arguments.\n       *\n       * @param {object} promise\n       *        An object containing the resolution and rejection functions of a\n       *        promise.\n       * @param {function} promise.resolve\n       *        The promise's resolution function.\n       * @param {function} promise.reject\n       *        The promise's rejection function.\n       * @param {object} metadata\n       *        Metadata about the wrapped method which has created the callback.\n       * @param {boolean} metadata.singleCallbackArg\n       *        Whether or not the promise is resolved with only the first\n       *        argument of the callback, alternatively an array of all the\n       *        callback arguments is resolved. By default, if the callback\n       *        function is invoked with only a single argument, that will be\n       *        resolved to the promise, while all arguments will be resolved as\n       *        an array if multiple are given.\n       *\n       * @returns {function}\n       *        The generated callback function.\n       */\n      const makeCallback = (promise, metadata) => {\n        return (...callbackArgs) => {\n          if (extensionAPIs.runtime.lastError) {\n            promise.reject(new Error(extensionAPIs.runtime.lastError.message));\n          } else if (metadata.singleCallbackArg || callbackArgs.length <= 1 && metadata.singleCallbackArg !== false) {\n            promise.resolve(callbackArgs[0]);\n          } else {\n            promise.resolve(callbackArgs);\n          }\n        };\n      };\n      const pluralizeArguments = numArgs => numArgs == 1 ? \"argument\" : \"arguments\";\n\n      /**\n       * Creates a wrapper function for a method with the given name and metadata.\n       *\n       * @param {string} name\n       *        The name of the method which is being wrapped.\n       * @param {object} metadata\n       *        Metadata about the method being wrapped.\n       * @param {integer} metadata.minArgs\n       *        The minimum number of arguments which must be passed to the\n       *        function. If called with fewer than this number of arguments, the\n       *        wrapper will raise an exception.\n       * @param {integer} metadata.maxArgs\n       *        The maximum number of arguments which may be passed to the\n       *        function. If called with more than this number of arguments, the\n       *        wrapper will raise an exception.\n       * @param {boolean} metadata.singleCallbackArg\n       *        Whether or not the promise is resolved with only the first\n       *        argument of the callback, alternatively an array of all the\n       *        callback arguments is resolved. By default, if the callback\n       *        function is invoked with only a single argument, that will be\n       *        resolved to the promise, while all arguments will be resolved as\n       *        an array if multiple are given.\n       *\n       * @returns {function(object, ...*)}\n       *       The generated wrapper function.\n       */\n      const wrapAsyncFunction = (name, metadata) => {\n        return function asyncFunctionWrapper(target, ...args) {\n          if (args.length < metadata.minArgs) {\n            throw new Error(`Expected at least ${metadata.minArgs} ${pluralizeArguments(metadata.minArgs)} for ${name}(), got ${args.length}`);\n          }\n          if (args.length > metadata.maxArgs) {\n            throw new Error(`Expected at most ${metadata.maxArgs} ${pluralizeArguments(metadata.maxArgs)} for ${name}(), got ${args.length}`);\n          }\n          return new Promise((resolve, reject) => {\n            if (metadata.fallbackToNoCallback) {\n              // This API method has currently no callback on Chrome, but it return a promise on Firefox,\n              // and so the polyfill will try to call it with a callback first, and it will fallback\n              // to not passing the callback if the first call fails.\n              try {\n                target[name](...args, makeCallback({\n                  resolve,\n                  reject\n                }, metadata));\n              } catch (cbError) {\n                console.warn(`${name} API method doesn't seem to support the callback parameter, ` + \"falling back to call it without a callback: \", cbError);\n                target[name](...args);\n\n                // Update the API method metadata, so that the next API calls will not try to\n                // use the unsupported callback anymore.\n                metadata.fallbackToNoCallback = false;\n                metadata.noCallback = true;\n                resolve();\n              }\n            } else if (metadata.noCallback) {\n              target[name](...args);\n              resolve();\n            } else {\n              target[name](...args, makeCallback({\n                resolve,\n                reject\n              }, metadata));\n            }\n          });\n        };\n      };\n\n      /**\n       * Wraps an existing method of the target object, so that calls to it are\n       * intercepted by the given wrapper function. The wrapper function receives,\n       * as its first argument, the original `target` object, followed by each of\n       * the arguments passed to the original method.\n       *\n       * @param {object} target\n       *        The original target object that the wrapped method belongs to.\n       * @param {function} method\n       *        The method being wrapped. This is used as the target of the Proxy\n       *        object which is created to wrap the method.\n       * @param {function} wrapper\n       *        The wrapper function which is called in place of a direct invocation\n       *        of the wrapped method.\n       *\n       * @returns {Proxy<function>}\n       *        A Proxy object for the given method, which invokes the given wrapper\n       *        method in its place.\n       */\n      const wrapMethod = (target, method, wrapper) => {\n        return new Proxy(method, {\n          apply(targetMethod, thisObj, args) {\n            return wrapper.call(thisObj, target, ...args);\n          }\n        });\n      };\n      let hasOwnProperty = Function.call.bind(Object.prototype.hasOwnProperty);\n\n      /**\n       * Wraps an object in a Proxy which intercepts and wraps certain methods\n       * based on the given `wrappers` and `metadata` objects.\n       *\n       * @param {object} target\n       *        The target object to wrap.\n       *\n       * @param {object} [wrappers = {}]\n       *        An object tree containing wrapper functions for special cases. Any\n       *        function present in this object tree is called in place of the\n       *        method in the same location in the `target` object tree. These\n       *        wrapper methods are invoked as described in {@see wrapMethod}.\n       *\n       * @param {object} [metadata = {}]\n       *        An object tree containing metadata used to automatically generate\n       *        Promise-based wrapper functions for asynchronous. Any function in\n       *        the `target` object tree which has a corresponding metadata object\n       *        in the same location in the `metadata` tree is replaced with an\n       *        automatically-generated wrapper function, as described in\n       *        {@see wrapAsyncFunction}\n       *\n       * @returns {Proxy<object>}\n       */\n      const wrapObject = (target, wrappers = {}, metadata = {}) => {\n        let cache = Object.create(null);\n        let handlers = {\n          has(proxyTarget, prop) {\n            return prop in target || prop in cache;\n          },\n          get(proxyTarget, prop, receiver) {\n            if (prop in cache) {\n              return cache[prop];\n            }\n            if (!(prop in target)) {\n              return undefined;\n            }\n            let value = target[prop];\n            if (typeof value === \"function\") {\n              // This is a method on the underlying object. Check if we need to do\n              // any wrapping.\n\n              if (typeof wrappers[prop] === \"function\") {\n                // We have a special-case wrapper for this method.\n                value = wrapMethod(target, target[prop], wrappers[prop]);\n              } else if (hasOwnProperty(metadata, prop)) {\n                // This is an async method that we have metadata for. Create a\n                // Promise wrapper for it.\n                let wrapper = wrapAsyncFunction(prop, metadata[prop]);\n                value = wrapMethod(target, target[prop], wrapper);\n              } else {\n                // This is a method that we don't know or care about. Return the\n                // original method, bound to the underlying object.\n                value = value.bind(target);\n              }\n            } else if (typeof value === \"object\" && value !== null && (hasOwnProperty(wrappers, prop) || hasOwnProperty(metadata, prop))) {\n              // This is an object that we need to do some wrapping for the children\n              // of. Create a sub-object wrapper for it with the appropriate child\n              // metadata.\n              value = wrapObject(value, wrappers[prop], metadata[prop]);\n            } else if (hasOwnProperty(metadata, \"*\")) {\n              // Wrap all properties in * namespace.\n              value = wrapObject(value, wrappers[prop], metadata[\"*\"]);\n            } else {\n              // We don't need to do any wrapping for this property,\n              // so just forward all access to the underlying object.\n              Object.defineProperty(cache, prop, {\n                configurable: true,\n                enumerable: true,\n                get() {\n                  return target[prop];\n                },\n                set(value) {\n                  target[prop] = value;\n                }\n              });\n              return value;\n            }\n            cache[prop] = value;\n            return value;\n          },\n          set(proxyTarget, prop, value, receiver) {\n            if (prop in cache) {\n              cache[prop] = value;\n            } else {\n              target[prop] = value;\n            }\n            return true;\n          },\n          defineProperty(proxyTarget, prop, desc) {\n            return Reflect.defineProperty(cache, prop, desc);\n          },\n          deleteProperty(proxyTarget, prop) {\n            return Reflect.deleteProperty(cache, prop);\n          }\n        };\n\n        // Per contract of the Proxy API, the \"get\" proxy handler must return the\n        // original value of the target if that value is declared read-only and\n        // non-configurable. For this reason, we create an object with the\n        // prototype set to `target` instead of using `target` directly.\n        // Otherwise we cannot return a custom object for APIs that\n        // are declared read-only and non-configurable, such as `chrome.devtools`.\n        //\n        // The proxy handlers themselves will still use the original `target`\n        // instead of the `proxyTarget`, so that the methods and properties are\n        // dereferenced via the original targets.\n        let proxyTarget = Object.create(target);\n        return new Proxy(proxyTarget, handlers);\n      };\n\n      /**\n       * Creates a set of wrapper functions for an event object, which handles\n       * wrapping of listener functions that those messages are passed.\n       *\n       * A single wrapper is created for each listener function, and stored in a\n       * map. Subsequent calls to `addListener`, `hasListener`, or `removeListener`\n       * retrieve the original wrapper, so that  attempts to remove a\n       * previously-added listener work as expected.\n       *\n       * @param {DefaultWeakMap<function, function>} wrapperMap\n       *        A DefaultWeakMap object which will create the appropriate wrapper\n       *        for a given listener function when one does not exist, and retrieve\n       *        an existing one when it does.\n       *\n       * @returns {object}\n       */\n      const wrapEvent = wrapperMap => ({\n        addListener(target, listener, ...args) {\n          target.addListener(wrapperMap.get(listener), ...args);\n        },\n        hasListener(target, listener) {\n          return target.hasListener(wrapperMap.get(listener));\n        },\n        removeListener(target, listener) {\n          target.removeListener(wrapperMap.get(listener));\n        }\n      });\n      const onRequestFinishedWrappers = new DefaultWeakMap(listener => {\n        if (typeof listener !== \"function\") {\n          return listener;\n        }\n\n        /**\n         * Wraps an onRequestFinished listener function so that it will return a\n         * `getContent()` property which returns a `Promise` rather than using a\n         * callback API.\n         *\n         * @param {object} req\n         *        The HAR entry object representing the network request.\n         */\n        return function onRequestFinished(req) {\n          const wrappedReq = wrapObject(req, {} /* wrappers */, {\n            getContent: {\n              minArgs: 0,\n              maxArgs: 0\n            }\n          });\n          listener(wrappedReq);\n        };\n      });\n      const onMessageWrappers = new DefaultWeakMap(listener => {\n        if (typeof listener !== \"function\") {\n          return listener;\n        }\n\n        /**\n         * Wraps a message listener function so that it may send responses based on\n         * its return value, rather than by returning a sentinel value and calling a\n         * callback. If the listener function returns a Promise, the response is\n         * sent when the promise either resolves or rejects.\n         *\n         * @param {*} message\n         *        The message sent by the other end of the channel.\n         * @param {object} sender\n         *        Details about the sender of the message.\n         * @param {function(*)} sendResponse\n         *        A callback which, when called with an arbitrary argument, sends\n         *        that value as a response.\n         * @returns {boolean}\n         *        True if the wrapped listener returned a Promise, which will later\n         *        yield a response. False otherwise.\n         */\n        return function onMessage(message, sender, sendResponse) {\n          let didCallSendResponse = false;\n          let wrappedSendResponse;\n          let sendResponsePromise = new Promise(resolve => {\n            wrappedSendResponse = function (response) {\n              didCallSendResponse = true;\n              resolve(response);\n            };\n          });\n          let result;\n          try {\n            result = listener(message, sender, wrappedSendResponse);\n          } catch (err) {\n            result = Promise.reject(err);\n          }\n          const isResultThenable = result !== true && isThenable(result);\n\n          // If the listener didn't returned true or a Promise, or called\n          // wrappedSendResponse synchronously, we can exit earlier\n          // because there will be no response sent from this listener.\n          if (result !== true && !isResultThenable && !didCallSendResponse) {\n            return false;\n          }\n\n          // A small helper to send the message if the promise resolves\n          // and an error if the promise rejects (a wrapped sendMessage has\n          // to translate the message into a resolved promise or a rejected\n          // promise).\n          const sendPromisedResult = promise => {\n            promise.then(msg => {\n              // send the message value.\n              sendResponse(msg);\n            }, error => {\n              // Send a JSON representation of the error if the rejected value\n              // is an instance of error, or the object itself otherwise.\n              let message;\n              if (error && (error instanceof Error || typeof error.message === \"string\")) {\n                message = error.message;\n              } else {\n                message = \"An unexpected error occurred\";\n              }\n              sendResponse({\n                __mozWebExtensionPolyfillReject__: true,\n                message\n              });\n            }).catch(err => {\n              // Print an error on the console if unable to send the response.\n              console.error(\"Failed to send onMessage rejected reply\", err);\n            });\n          };\n\n          // If the listener returned a Promise, send the resolved value as a\n          // result, otherwise wait the promise related to the wrappedSendResponse\n          // callback to resolve and send it as a response.\n          if (isResultThenable) {\n            sendPromisedResult(result);\n          } else {\n            sendPromisedResult(sendResponsePromise);\n          }\n\n          // Let Chrome know that the listener is replying.\n          return true;\n        };\n      });\n      const wrappedSendMessageCallback = ({\n        reject,\n        resolve\n      }, reply) => {\n        if (extensionAPIs.runtime.lastError) {\n          // Detect when none of the listeners replied to the sendMessage call and resolve\n          // the promise to undefined as in Firefox.\n          // See https://github.com/mozilla/webextension-polyfill/issues/130\n          if (extensionAPIs.runtime.lastError.message === CHROME_SEND_MESSAGE_CALLBACK_NO_RESPONSE_MESSAGE) {\n            resolve();\n          } else {\n            reject(new Error(extensionAPIs.runtime.lastError.message));\n          }\n        } else if (reply && reply.__mozWebExtensionPolyfillReject__) {\n          // Convert back the JSON representation of the error into\n          // an Error instance.\n          reject(new Error(reply.message));\n        } else {\n          resolve(reply);\n        }\n      };\n      const wrappedSendMessage = (name, metadata, apiNamespaceObj, ...args) => {\n        if (args.length < metadata.minArgs) {\n          throw new Error(`Expected at least ${metadata.minArgs} ${pluralizeArguments(metadata.minArgs)} for ${name}(), got ${args.length}`);\n        }\n        if (args.length > metadata.maxArgs) {\n          throw new Error(`Expected at most ${metadata.maxArgs} ${pluralizeArguments(metadata.maxArgs)} for ${name}(), got ${args.length}`);\n        }\n        return new Promise((resolve, reject) => {\n          const wrappedCb = wrappedSendMessageCallback.bind(null, {\n            resolve,\n            reject\n          });\n          args.push(wrappedCb);\n          apiNamespaceObj.sendMessage(...args);\n        });\n      };\n      const staticWrappers = {\n        devtools: {\n          network: {\n            onRequestFinished: wrapEvent(onRequestFinishedWrappers)\n          }\n        },\n        runtime: {\n          onMessage: wrapEvent(onMessageWrappers),\n          onMessageExternal: wrapEvent(onMessageWrappers),\n          sendMessage: wrappedSendMessage.bind(null, \"sendMessage\", {\n            minArgs: 1,\n            maxArgs: 3\n          })\n        },\n        tabs: {\n          sendMessage: wrappedSendMessage.bind(null, \"sendMessage\", {\n            minArgs: 2,\n            maxArgs: 3\n          })\n        }\n      };\n      const settingMetadata = {\n        clear: {\n          minArgs: 1,\n          maxArgs: 1\n        },\n        get: {\n          minArgs: 1,\n          maxArgs: 1\n        },\n        set: {\n          minArgs: 1,\n          maxArgs: 1\n        }\n      };\n      apiMetadata.privacy = {\n        network: {\n          \"*\": settingMetadata\n        },\n        services: {\n          \"*\": settingMetadata\n        },\n        websites: {\n          \"*\": settingMetadata\n        }\n      };\n      return wrapObject(extensionAPIs, staticWrappers, apiMetadata);\n    };\n\n    // The build process adds a UMD wrapper around this file, which makes the\n    // `module` variable available.\n    module.exports = wrapAPIs(chrome);\n  } else {\n    module.exports = globalThis.browser;\n  }\n});\n//# sourceMappingURL=browser-polyfill.js.map\n","import browser from 'webextension-polyfill';\nimport { DBEventNames, InternalEventBusMessageTypes, Contexts } from './events/eventNames.js';\nimport { DbGetReadyStateRequest, DbInitializeRequest } from './events/dbEvents.js';\n\nexport function isBackgroundContext() {\n  return (typeof window === 'undefined') && (typeof self !== 'undefined') && !!self.registration;\n}\n\nfunction getContextName() {\n  if (isBackgroundContext()) return Contexts.BACKGROUND;\n  if (typeof window !== 'undefined' && window.EXTENSION_CONTEXT) return window.EXTENSION_CONTEXT;\n  return Contexts.UNKNOWN; // Fallback\n}\n\nlet dbInitPromise = null;\n\nconst broadcastableEventTypes = [\n  DBEventNames.DB_MESSAGES_UPDATED_NOTIFICATION,\n  DBEventNames.DB_STATUS_UPDATED_NOTIFICATION,\n  DBEventNames.DB_SESSION_UPDATED_NOTIFICATION,\n  DBEventNames.DB_INITIALIZATION_COMPLETE_NOTIFICATION\n];\n\nclass EventBus {\n  constructor() {\n    this.listeners = new Map();\n    this.isDbInitInProgress = false;\n  }\n\n  subscribe(eventName, callback) {\n    if (!this.listeners.has(eventName)) {\n      this.listeners.set(eventName, []);\n    }\n    this.listeners.get(eventName).push(callback);\n  }\n\n  unsubscribe(eventName, callback) {\n    if (this.listeners.has(eventName)) {\n      const eventListeners = this.listeners.get(eventName);\n      const index = eventListeners.indexOf(callback);\n      if (index > -1) {\n        eventListeners.splice(index, 1);\n      }\n      if (eventListeners.length === 0) {\n        this.listeners.delete(eventName);\n      }\n    }\n  }\n\n  dispatchToLocalListeners(eventName, data, context) {\n\n\n\n    console.log(`[EventBus][${getContextName()}] : dispatchToLocalListeners -> Dispatching locally: ${eventName}`, data);\n    const localListeners = this.listeners.get(eventName);\n    const promises = [];\n    if (localListeners && localListeners.length > 0) {\n      try {\n        const eventData = structuredClone(data);\n        console.log(`[EventBus][${getContextName()}] : dispatchToLocalListeners -> Found ${localListeners.length} listeners for ${eventName}.`);\n        localListeners.forEach(callback => {\n          try {\n            const result = callback(eventData);\n            if (result && typeof result.then === 'function') {\n              promises.push(result);\n            }\n          } catch (error) {\n            console.error(`[EventBus][${getContextName()}] Error in local listener for ${eventName}:`, error);\n            promises.push(Promise.reject(error));\n          }\n        });\n      } catch (cloneError) {\n        console.error(`[EventBus][${getContextName()}] Failed to structuredClone data for local dispatch of ${eventName}:`, cloneError, data);\n        return Promise.reject(cloneError);\n      }\n    } else {\n      console.log(`[EventBus][${getContextName()}] : dispatchToLocalListeners -> No local listeners for ${eventName}.`);\n    }\n    return Promise.all(promises);\n  }\n\n  async autoEnsureDbInitialized() {\n    const context = getContextName();\n    if (this.isDbInitInProgress) {\n      return dbInitPromise;\n    }\n    if (!dbInitPromise) {\n      this.isDbInitInProgress = true;\n      console.info(`[EventBus][${context}] : autoEnsureDbInitialized -> Starting DB initialization...`);\n      dbInitPromise = (async () => {\n        try {\n          const [response] = await this.publish(DbGetReadyStateRequest.type, new DbGetReadyStateRequest());\n          if (response?.data?.ready) {\n            console.info(`[EventBus][${context}] : autoEnsureDbInitialized -> DB is already ready.`);\n            return true;\n          }\n          await this.publish(DbInitializeRequest.type, new DbInitializeRequest());\n          for (let i = 0; i < 5; i++) {\n            const [check] = await this.publish(DbGetReadyStateRequest.type, new DbGetReadyStateRequest());\n            if (check?.data?.ready) {\n              console.info(`[EventBus][${context}] : autoEnsureDbInitialized -> DB became ready after ${i+1} checks.`);\n              return true;\n            }\n            await new Promise(res => setTimeout(res, 300));\n          }\n          console.error(`[EventBus][${context}] : autoEnsureDbInitialized -> Database failed to initialize after retries.`);\n          throw new Error('Database failed to initialize');\n        } catch (err) {\n          console.error(`[EventBus][${context}] : autoEnsureDbInitialized -> Initialization failed:`, err);\n          throw err;\n        } finally {\n          this.isDbInitInProgress = false;\n        }\n      })();\n    }\n    return dbInitPromise;\n  }\n\n  async publish(eventName, data, contextName = getContextName()) {\n    const context = contextName;\n    console.log(`[EventBus][${context}] : publish -> Event: ${eventName}`, data);\n  \n\n    if (!isBackgroundContext()) { // UI Context\n      \n      // background event broadcast, no need to forward\n      if (eventName === InternalEventBusMessageTypes.BACKGROUND_EVENT_BROADCAST) {\n        return Promise.resolve([]); \n      }\n      \n      // db event, forward to background\n      if (Object.values(DBEventNames).includes(eventName)) {            \n        console.log(`[EventBus][${context}] : publish -> Forwarding event to background: ${eventName}`);\n        const resultFromBg = await browser.runtime.sendMessage({ type: eventName, payload: data , originalContext: context, crossContext: false});\n        console.log(`[EventBus][${context}] : publish -> Received response from background for ${eventName}:`, resultFromBg);\n        return resultFromBg;\n\n      }\n\n      // same context, dispatch locally\n      if (getContextName() === context) {    \n        return this.dispatchToLocalListeners(eventName, data, context);\n      }\n\n      // different context, forward to background\n\n      if (getContextName() != context) {    \n        console.log(`[EventBus][${context}] : publish -> Forwarding event to background: ${eventName}`);\n        const resultFromBg = await browser.runtime.sendMessage({ type: eventName, payload: data , originalContext: context, crossContext: true});\n        console.log(`[EventBus][${context}] : publish -> Received response from background for ${eventName}:`, resultFromBg);\n        return resultFromBg;\n      }\n\n\n\n    } else { // Background Context\n      if (broadcastableEventTypes.includes(eventName)) {\n        console.log(`[EventBus][${context}] :: publish -> Event ${eventName} is broadcastable. Sending wrapper.`);\n        const broadcastPayload = {\n          type: InternalEventBusMessageTypes.BACKGROUND_EVENT_BROADCAST,\n          payload: {\n            eventName: eventName,\n            data: structuredClone(data),\n            originalContext: context,\n            crossContext: false\n          }\n        };\n        browser.runtime.sendMessage(broadcastPayload)\n          .catch(error => {\n            if (error.message.includes(\"Could not establish connection\") ||\n              error.message.includes(\"Receiving end does not exist\") ||\n              error.message.includes(\"The message port closed before a response was received\")) {\n              console.warn(`[EventBus][${context}] :publish Failed to broadcast ${eventName} to UI: No active receiver.`);\n            } else {\n              console.error(`[EventBus][${context}] : publish Error broadcasting event ${eventName}:`, error);\n            }\n          });\n        console.log(`[EventBus][${context}] : publish -> Dispatching broadcastable event ${eventName} locally in background as well.`);\n        return this.dispatchToLocalListeners(eventName, data, context);\n      } else {\n        console.log(`[EventBus][${context}] : : publish -> Event ${eventName} is not broadcastable. Dispatching locally in background.`);\n        return this.dispatchToLocalListeners(eventName, data, context);\n      }\n    }\n  }\n}\n\nexport const eventBus = new EventBus();\n\nbrowser.runtime.onMessage.addListener((message, sender, sendResponse) => {\n  if (!message || !message.type) {\n    return false;\n  }\n  const context = getContextName();\n\n  if (message.type === InternalEventBusMessageTypes.BACKGROUND_EVENT_BROADCAST) {\n    console.log(`[EventBus][${context}] : onMessage -> Received BACKGROUND_EVENT_BROADCAST. Original event: ${message.payload?.eventName}`);\n    if (message.payload && broadcastableEventTypes.includes(message.payload.eventName)) {\n      eventBus.dispatchToLocalListeners(message.payload.eventName, message.payload.data);\n    } \n    return false; \n  }\n\n  if (message.crossContext === true && !isBackgroundContext()) {\n    eventBus.dispatchToLocalListeners(message.type, message.payload, message.originalContext);\n    return false;\n  }\n\n  if (isBackgroundContext()) {\n    if (message.crossContext === true && message.originalContext) {\n      browser.runtime.sendMessage({\n        type: message.type,\n        payload: message.payload,\n        originalContext: message.originalContext,\n        crossContext: true\n      });\n      return false;\n    }\n    if (Object.values(DBEventNames).includes(message.type)) { \n      console.log(`[EventBus][${context}] : onMessage -> Received direct DBEvent (request): ${message.type}. Publishing to local BG eventBus.`);\n      eventBus.publish(message.type, message.payload) \n        .then(result => {\n            try {\n                console.log(`[EventBus][${context}] : onMessage -> DBEvent ${message.type} processed. Sending response.`);\n                sendResponse(structuredClone(result));\n            } catch(e) {\n                console.error(`[EventBus][${context}] :onMessage Failed to clone response for DBEvent ${message.type}:`, e);\n                sendResponse({success: false, error: \"Failed to clone response in background\"});\n            }\n        })\n        .catch(error => {\n            console.error(`[EventBus][${context}] : onMessage Error processing DBEvent ${message.type}:`, error);\n            sendResponse({ success: false, error: error.message });\n        });\n      return true; \n    }\n  }\n\n  console.log(`[EventBus][${context}] : onMessage -> Message type ${message.type} not handled by eventBus onMessage logic.`);\n  return false; \n});","import { DBEventNames } from './eventNames.js';\n\nfunction generateUUID() {\n  return 'xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx'.replace(/[xy]/g, function(c) {\n    var r = Math.random() * 16 | 0, v = c == 'x' ? r : (r & 0x3 | 0x8);\n    return v.toString(16);\n  });\n}\n\n\nexport class DbEventBase {\n  constructor(requestId = null) {\n    this.requestId = requestId || generateUUID();\n    this.timestamp = Date.now();\n  }\n}\n\nexport class DbResponseBase extends DbEventBase {\n  constructor(originalRequestId, success, data = null, error = null) {\n    super(originalRequestId);\n    this.success = success;\n    this.data = data;\n    this.error = error ? (error.message || String(error)) : null;\n  }\n}\n\nclass DbNotificationBase {\n    constructor(sessionId) {\n        this.sessionId = sessionId;\n        this.timestamp = Date.now();\n    }\n}\n\n\n\nexport class DbGetSessionResponse extends DbResponseBase {\n  static type = DBEventNames.DB_GET_SESSION_RESPONSE;\n  constructor(originalRequestId, success, sessionData, error = null) {\n    super(originalRequestId, success, sessionData, error);\n    this.type = DbGetSessionResponse.type;\n  }\n}\n\nexport class DbAddMessageResponse extends DbResponseBase {\n  static type = DBEventNames.DB_ADD_MESSAGE_RESPONSE;\n  constructor(originalRequestId, success, newMessageId, error = null) {\n    super(originalRequestId, success, { newMessageId }, error);\n    this.type = DbAddMessageResponse.type;\n  }\n}\n\nexport class DbUpdateMessageResponse extends DbResponseBase {\n    static type = DBEventNames.DB_UPDATE_MESSAGE_RESPONSE;\n    constructor(originalRequestId, success, error = null) {\n        super(originalRequestId, success, null, error);\n        this.type = DbUpdateMessageResponse.type;\n    }\n}\n\nexport class DbUpdateStatusResponse extends DbResponseBase {\n  static type = DBEventNames.DB_UPDATE_STATUS_RESPONSE;\n  constructor(originalRequestId, success, error = null) {\n    super(originalRequestId, success, null, error);\n    this.type = DbUpdateStatusResponse.type;\n  }\n}\n\nexport class DbDeleteMessageResponse extends DbResponseBase {\n    static type = DBEventNames.DB_DELETE_MESSAGE_RESPONSE;\n    constructor(originalRequestId, success, error = null) {\n        super(originalRequestId, success, null, error);\n        this.type = DbDeleteMessageResponse.type;\n    }\n}\n\nexport class DbToggleStarResponse extends DbResponseBase {\n    static type = DBEventNames.DB_TOGGLE_STAR_RESPONSE;\n    constructor(originalRequestId, success, updatedSessionData, error = null) {\n        super(originalRequestId, success, updatedSessionData, error);\n        this.type = DbToggleStarResponse.type;\n    }\n}\n\nexport class DbCreateSessionResponse extends DbResponseBase {\n    static type = DBEventNames.DB_CREATE_SESSION_RESPONSE;\n    constructor(originalRequestId, success, newSessionId, error = null) {\n        super(originalRequestId, success, { newSessionId }, error);\n        this.type = DbCreateSessionResponse.type;\n        console.log(`[dbEvents] DbCreateSessionResponse constructor: type set to ${this.type}`);\n    }\n\n    get newSessionId() {\n        return this.data?.newSessionId;\n    }\n}\n\nexport class DbDeleteSessionResponse extends DbResponseBase {\n    static type = DBEventNames.DB_DELETE_SESSION_RESPONSE;\n    constructor(originalRequestId, success, error = null) {\n        super(originalRequestId, success, null, error);\n        this.type = DbDeleteSessionResponse.type;\n    }\n}\n\nexport class DbRenameSessionResponse extends DbResponseBase {\n    static type = DBEventNames.DB_RENAME_SESSION_RESPONSE;\n    constructor(originalRequestId, success, error = null) {\n        super(originalRequestId, success, null, error);\n        this.type = DbRenameSessionResponse.type;\n    }\n}\n\nexport class DbGetAllSessionsResponse extends DbResponseBase {\n    static type = DBEventNames.DB_GET_ALL_SESSIONS_RESPONSE;\n    constructor(requestId, success, sessions = null, error = null) {\n        super(requestId, success, sessions, error);\n        this.type = DbGetAllSessionsResponse.type;\n        this.payload = { sessions };\n    }\n}\n\nexport class DbGetStarredSessionsResponse extends DbResponseBase {\n    static type = DBEventNames.DB_GET_STARRED_SESSIONS_RESPONSE;\n    constructor(requestId, success, starredSessions = null, error = null) {\n        super(requestId, success, starredSessions, error); \n        this.type = DbGetStarredSessionsResponse.type;\n    }\n}\n\nexport class DbGetReadyStateResponse extends DbResponseBase {\n    static type = DBEventNames.DB_GET_READY_STATE_RESPONSE;\n    constructor(originalRequestId, success, ready, error = null) {\n        super(originalRequestId, success, { ready }, error);\n        this.type = DbGetReadyStateResponse.type;\n        this.payload = { ready };\n    }\n}\n\n// --- Request Events (Define After Response Events) ---\n\nexport class DbGetSessionRequest extends DbEventBase {\n  static type = DBEventNames.DB_GET_SESSION_REQUEST;\n  static responseEventName = DBEventNames.DB_GET_SESSION_RESPONSE;\n  constructor(sessionId) {\n    super();\n    this.type = DbGetSessionRequest.type;\n    this.payload = { sessionId };\n  }\n}\n\nexport class DbAddMessageRequest extends DbEventBase {\n  static type = DBEventNames.DB_ADD_MESSAGE_REQUEST;\n  static responseEventName = DBEventNames.DB_ADD_MESSAGE_RESPONSE;\n  constructor(sessionId, messageObject) {\n    super();\n    this.type = DbAddMessageRequest.type;\n    this.payload = { sessionId, messageObject };\n  }\n}\n\nexport class DbUpdateMessageRequest extends DbEventBase {\n    static type = DBEventNames.DB_UPDATE_MESSAGE_REQUEST;\n    static responseEventName = DBEventNames.DB_UPDATE_MESSAGE_RESPONSE;\n    constructor(sessionId, messageId, updates) {\n        super();\n        this.type = DbUpdateMessageRequest.type;\n        this.payload = { sessionId, messageId, updates };\n    }\n}\n\nexport class DbUpdateStatusRequest extends DbEventBase {\n  static type = DBEventNames.DB_UPDATE_STATUS_REQUEST;\n  static responseEventName = DBEventNames.DB_UPDATE_STATUS_RESPONSE;\n  constructor(sessionId, status) {\n    super();\n    this.type = DbUpdateStatusRequest.type;\n    this.payload = { sessionId, status };\n  }\n}\n\nexport class DbDeleteMessageRequest extends DbEventBase {\n    static type = DBEventNames.DB_DELETE_MESSAGE_REQUEST;\n    static responseEventName = DBEventNames.DB_DELETE_MESSAGE_RESPONSE;\n    constructor(sessionId, messageId) {\n        super();\n        this.type = DbDeleteMessageRequest.type;\n        this.payload = { sessionId, messageId };\n    }\n}\n\nexport class DbToggleStarRequest extends DbEventBase {\n    static type = DBEventNames.DB_TOGGLE_STAR_REQUEST;\n    static responseEventName = DBEventNames.DB_TOGGLE_STAR_RESPONSE;\n    constructor(sessionId) {\n        super();\n        this.type = DbToggleStarRequest.type;\n        this.payload = { sessionId };\n    }\n}\n\nexport class DbCreateSessionRequest extends DbEventBase {\n    static type = DBEventNames.DB_CREATE_SESSION_REQUEST;\n    static responseEventName = DBEventNames.DB_CREATE_SESSION_RESPONSE;\n    constructor(initialMessage) {\n        super();\n        this.type = DbCreateSessionRequest.type;\n        this.payload = { initialMessage };\n        console.log(`[dbEvents] DbCreateSessionRequest constructor: type set to ${this.type}`);\n    }\n}\n\nexport class DbInitializeRequest extends DbEventBase {\n    static type = DBEventNames.DB_INITIALIZE_REQUEST;\n    constructor() {\n        super();\n        this.type = DbInitializeRequest.type;\n        this.payload = {}; \n    }\n}\n\nexport class DbDeleteSessionRequest extends DbEventBase {\n    static type = DBEventNames.DB_DELETE_SESSION_REQUEST;\n    static responseEventName = DBEventNames.DB_DELETE_SESSION_RESPONSE;\n    constructor(sessionId) {\n        super();\n        this.type = DbDeleteSessionRequest.type;\n        this.payload = { sessionId };\n    }\n}\n\nexport class DbRenameSessionRequest extends DbEventBase {\n    static type = DBEventNames.DB_RENAME_SESSION_REQUEST;\n    static responseEventName = DBEventNames.DB_RENAME_SESSION_RESPONSE;\n    constructor(sessionId, newName) {\n        super();\n        this.type = DbRenameSessionRequest.type;\n        this.payload = { sessionId, newName };\n    }\n}\n\nexport class DbGetAllSessionsRequest extends DbEventBase {\n    static type = DBEventNames.DB_GET_ALL_SESSIONS_REQUEST;\n    static responseEventName = DBEventNames.DB_GET_ALL_SESSIONS_RESPONSE;\n    constructor() {\n        super();\n        this.type = DbGetAllSessionsRequest.type;\n        console.log('[DEBUG][Create] DbGetAllSessionsRequest:', this, this.type);\n    }\n}\n\nexport class DbGetStarredSessionsRequest extends DbEventBase {\n    static type = DBEventNames.DB_GET_STARRED_SESSIONS_REQUEST;\n    static responseEventName = DBEventNames.DB_GET_STARRED_SESSIONS_RESPONSE;\n    constructor() {\n        super();\n        this.type = DbGetStarredSessionsRequest.type;\n    }\n}\n\nexport class DbGetReadyStateRequest extends DbEventBase {\n    static type = DBEventNames.DB_GET_READY_STATE_REQUEST;\n    static responseEventName = DBEventNames.DB_GET_READY_STATE_RESPONSE;\n    constructor() {\n        super();\n        this.type = DbGetReadyStateRequest.type;\n    }\n}\n\n// --- Notification Events ---\n\nexport class DbMessagesUpdatedNotification extends DbNotificationBase {\n    static type = DBEventNames.DB_MESSAGES_UPDATED_NOTIFICATION;\n    constructor(sessionId, messages) {\n        super(sessionId);\n        this.type = DbMessagesUpdatedNotification.type;\n        this.payload = { messages }; \n    }\n}\n\nexport class DbStatusUpdatedNotification extends DbNotificationBase {\n    static type = DBEventNames.DB_STATUS_UPDATED_NOTIFICATION;\n    constructor(sessionId, status) {\n        super(sessionId);\n        this.type = DbStatusUpdatedNotification.type;\n        this.payload = { status };\n    }\n}\n\nexport class DbSessionUpdatedNotification extends DbNotificationBase {\n    static type = DBEventNames.DB_SESSION_UPDATED_NOTIFICATION;\n    constructor(sessionId, updatedSessionData) {\n        super(sessionId);\n        this.type = DbSessionUpdatedNotification.type;\n        this.payload = { session: updatedSessionData }; \n    }\n}\n\nexport class DbInitializationCompleteNotification {\n    static type = DBEventNames.DB_INITIALIZATION_COMPLETE_NOTIFICATION;\n    constructor({ success, error = null }) {\n        this.type = DbInitializationCompleteNotification.type;\n        this.timestamp = Date.now();\n        this.payload = { success, error: error ? (error.message || String(error)) : null };\n    }\n}\n\n// --- Log Response Events ---\n\nexport class DbGetLogsResponse extends DbResponseBase {\n  static type = DBEventNames.DB_GET_LOGS_RESPONSE;\n  constructor(originalRequestId, success, logs, error = null) {\n    super(originalRequestId, success, logs, error); // data = logs array\n    this.type = DbGetLogsResponse.type;\n  }\n}\n\nexport class DbGetUniqueLogValuesResponse extends DbResponseBase {\n  static type = DBEventNames.DB_GET_UNIQUE_LOG_VALUES_RESPONSE;\n  constructor(originalRequestId, success, values, error = null) {\n    super(originalRequestId, success, values, error); // data = values array\n    this.type = DbGetUniqueLogValuesResponse.type;\n  }\n}\n\nexport class DbClearLogsResponse extends DbResponseBase {\n  static type = DBEventNames.DB_CLEAR_LOGS_RESPONSE;\n  constructor(originalRequestId, success, error = null) {\n    super(originalRequestId, success, null, error);\n    this.type = DbClearLogsResponse.type;\n  }\n}\n\nexport class DbGetCurrentAndLastLogSessionIdsResponse extends DbResponseBase {\n    static type = DBEventNames.DB_GET_CURRENT_AND_LAST_LOG_SESSION_IDS_RESPONSE;\n    constructor(originalRequestId, success, ids, error = null) {\n      // data = { currentLogSessionId: '...', previousLogSessionId: '...' | null }\n      super(originalRequestId, success, ids, error);\n      this.type = DbGetCurrentAndLastLogSessionIdsResponse.type;\n    }\n  }\n\nexport class DbAddLogRequest extends DbEventBase {\n  static type = DBEventNames.DB_ADD_LOG_REQUEST;\n  // No responseEventName needed for fire-and-forget\n  constructor(logEntryData) {\n    super(); \n    this.type = DbAddLogRequest.type;\n    this.payload = { logEntryData };\n  }\n}\n\nexport class DbGetLogsRequest extends DbEventBase {\n  static type = DBEventNames.DB_GET_LOGS_REQUEST;\n  static responseEventName = DBEventNames.DB_GET_LOGS_RESPONSE;\n  constructor(filters) {\n    // filters = { extensionSessionId: 'id' | 'current' | 'last' | 'all',\n    //             component: 'name' | 'all',\n    //             level: 'level' | 'all' }\n    super();\n    this.type = DbGetLogsRequest.type;\n    this.payload = { filters };\n  }\n}\n\nexport class DbGetUniqueLogValuesRequest extends DbEventBase {\n  static type = DBEventNames.DB_GET_UNIQUE_LOG_VALUES_REQUEST;\n  static responseEventName = DBEventNames.DB_GET_UNIQUE_LOG_VALUES_RESPONSE;\n  constructor(fieldName) {\n    // fieldName = 'extensionSessionId', 'component', 'level'\n    super();\n    this.type = DbGetUniqueLogValuesRequest.type;\n    this.payload = { fieldName };\n  }\n}\n\nexport class DbClearLogsRequest extends DbEventBase {\n    static type = DBEventNames.DB_CLEAR_LOGS_REQUEST;\n    static responseEventName = DBEventNames.DB_CLEAR_LOGS_RESPONSE;\n    constructor(filter = 'all') { // 'all' or potentially 'last_session' or specific session ID later\n        super();\n        this.type = DbClearLogsRequest.type;\n        this.payload = { filter };\n    }\n}\n\nexport class DbGetCurrentAndLastLogSessionIdsRequest extends DbEventBase {\n    static type = DBEventNames.DB_GET_CURRENT_AND_LAST_LOG_SESSION_IDS_REQUEST;\n    static responseEventName = DBEventNames.DB_GET_CURRENT_AND_LAST_LOG_SESSION_IDS_RESPONSE;\n    constructor() {\n        super();\n        this.type = DbGetCurrentAndLastLogSessionIdsRequest.type;\n    }\n}\n\nexport class DbResetDatabaseRequest extends DbEventBase {\n  static type = DBEventNames.DB_RESET_DATABASE_REQUEST;\n  constructor() {\n    super();\n    this.type = DbResetDatabaseRequest.type;\n  }\n}\n\nexport class DbResetDatabaseResponse extends DbResponseBase {\n  static type = DBEventNames.DB_RESET_DATABASE_RESPONSE;\n  constructor(originalRequestId, success, error = null) {\n    super(originalRequestId, success, null, error);\n    this.type = DbResetDatabaseResponse.type;\n  }\n} ","export const DBEventNames = Object.freeze({\n  DB_GET_SESSION_REQUEST: 'DbGetSessionRequest',\n  DB_GET_SESSION_RESPONSE: 'DbGetSessionResponse',\n  DB_ADD_MESSAGE_REQUEST: 'DbAddMessageRequest',\n  DB_ADD_MESSAGE_RESPONSE: 'DbAddMessageResponse',\n  DB_UPDATE_MESSAGE_REQUEST: 'DbUpdateMessageRequest',\n  DB_UPDATE_MESSAGE_RESPONSE: 'DbUpdateMessageResponse',\n  DB_UPDATE_STATUS_REQUEST: 'DbUpdateStatusRequest',\n  DB_UPDATE_STATUS_RESPONSE: 'DbUpdateStatusResponse',\n  DB_DELETE_MESSAGE_REQUEST: 'DbDeleteMessageRequest',\n  DB_DELETE_MESSAGE_RESPONSE: 'DbDeleteMessageResponse',\n  DB_TOGGLE_STAR_REQUEST: 'DbToggleStarRequest',\n  DB_TOGGLE_STAR_RESPONSE: 'DbToggleStarResponse',\n  DB_CREATE_SESSION_REQUEST: 'DbCreateSessionRequest',\n  DB_CREATE_SESSION_RESPONSE: 'DbCreateSessionResponse',\n  DB_DELETE_SESSION_REQUEST: 'DbDeleteSessionRequest',\n  DB_DELETE_SESSION_RESPONSE: 'DbDeleteSessionResponse',\n  DB_RENAME_SESSION_REQUEST: 'DbRenameSessionRequest',\n  DB_RENAME_SESSION_RESPONSE: 'DbRenameSessionResponse',\n  DB_GET_ALL_SESSIONS_REQUEST: 'DbGetAllSessionsRequest',\n  DB_GET_ALL_SESSIONS_RESPONSE: 'DbGetAllSessionsResponse',\n  DB_GET_STARRED_SESSIONS_REQUEST: 'DbGetStarredSessionsRequest',\n  DB_GET_STARRED_SESSIONS_RESPONSE: 'DbGetStarredSessionsResponse',\n  DB_MESSAGES_UPDATED_NOTIFICATION: 'DbMessagesUpdatedNotification',\n  DB_STATUS_UPDATED_NOTIFICATION: 'DbStatusUpdatedNotification',\n  DB_SESSION_UPDATED_NOTIFICATION: 'DbSessionUpdatedNotification',\n  DB_INITIALIZE_REQUEST: 'DbInitializeRequest',\n  DB_INITIALIZATION_COMPLETE_NOTIFICATION: 'DbInitializationCompleteNotification',\n  DB_GET_LOGS_REQUEST: 'DbGetLogsRequest',\n  DB_GET_LOGS_RESPONSE: 'DbGetLogsResponse',\n  DB_GET_UNIQUE_LOG_VALUES_REQUEST: 'DbGetUniqueLogValuesRequest',\n  DB_GET_UNIQUE_LOG_VALUES_RESPONSE: 'DbGetUniqueLogValuesResponse',\n  DB_CLEAR_LOGS_REQUEST: 'DbClearLogsRequest',\n  DB_CLEAR_LOGS_RESPONSE: 'DbClearLogsResponse',\n  DB_GET_CURRENT_AND_LAST_LOG_SESSION_IDS_REQUEST: 'DbGetCurrentAndLastLogSessionIdsRequest',\n  DB_GET_CURRENT_AND_LAST_LOG_SESSION_IDS_RESPONSE: 'DbGetCurrentAndLastLogSessionIdsResponse',\n  DB_ADD_LOG_REQUEST: 'DbAddLogRequest',\n  DB_ADD_LOG_RESPONSE: 'DbAddLogResponse',\n  DB_GET_READY_STATE_REQUEST: 'DbGetReadyStateRequest',\n  DB_GET_READY_STATE_RESPONSE: 'DbGetReadyStateResponse',\n  DB_RESET_DATABASE_REQUEST: 'DbResetDatabaseRequest',\n  DB_RESET_DATABASE_RESPONSE: 'DbResetDatabaseResponse',\n});\n\nexport const UIEventNames = Object.freeze({\n  QUERY_SUBMITTED: 'ui:querySubmitted',\n  BACKGROUND_RESPONSE_RECEIVED: 'background:responseReceived',\n  BACKGROUND_ERROR_RECEIVED: 'background:errorReceived',\n  BACKGROUND_SCRAPE_STAGE_RESULT: 'background:scrapeStageResult',\n  BACKGROUND_SCRAPE_RESULT_RECEIVED: 'background:scrapeResultReceived',\n  BACKGROUND_LOADING_STATUS_UPDATE: 'ui:loadingStatusUpdate',\n  REQUEST_MODEL_LOAD: 'ui:requestModelLoad',\n  WORKER_READY: 'worker:ready',\n  WORKER_ERROR: 'worker:error',\n  NAVIGATION_PAGE_CHANGED: 'navigation:pageChanged',\n  SCRAPE_ACTIVE_TAB: 'SCRAPE_ACTIVE_TAB',\n  DYNAMIC_SCRIPT_MESSAGE_TYPE: 'offscreenIframeResult',\n  // Add more as needed\n});\n\nexport const WorkerEventNames = Object.freeze({\n  WORKER_SCRIPT_READY: 'workerScriptReady',\n  WORKER_READY: 'workerReady',\n  LOADING_STATUS: 'loadingStatus',\n  GENERATION_STATUS: 'generationStatus',\n  GENERATION_UPDATE: 'generationUpdate',\n  GENERATION_COMPLETE: 'generationComplete',\n  GENERATION_ERROR: 'generationError',\n  RESET_COMPLETE: 'resetComplete',\n  ERROR: 'error',\n});\n\nexport const ModelWorkerStates = Object.freeze({\n  UNINITIALIZED: 'uninitialized',\n  CREATING_WORKER: 'creating_worker',\n  WORKER_SCRIPT_READY: 'worker_script_ready',\n  LOADING_MODEL: 'loading_model',\n  MODEL_READY: 'model_ready',\n  GENERATING: 'generating',\n  ERROR: 'error',\n  IDLE: 'idle',\n});\n\nexport const RuntimeMessageTypes = Object.freeze({\n  LOAD_MODEL: 'loadModel',\n  SEND_CHAT_MESSAGE: 'sendChatMessage',\n  INTERRUPT_GENERATION: 'interruptGeneration',\n  RESET_WORKER: 'resetWorker',\n  GET_MODEL_WORKER_STATE: 'getModelWorkerState',\n  SCRAPE_REQUEST: 'scrapeRequest',\n  GET_DRIVE_FILE_LIST: 'getDriveFileList',\n  GET_LOG_SESSIONS: 'getLogSessions',\n  GET_LOG_ENTRIES: 'getLogEntries',\n  DETACH_SIDE_PANEL: 'detachSidePanel',\n  GET_DETACHED_STATE: 'getDetachedState',\n  GET_DB_READY_STATE: 'getDbReadyState',\n});\n\nexport const SiteMapperMessageTypes = Object.freeze({\n  OPEN_TAB: 'openTab',\n  MAPPED: 'mapped',\n});\n\nexport const ModelLoaderMessageTypes = Object.freeze({\n  INIT: 'init',\n  GENERATE: 'generate',\n  INTERRUPT: 'interrupt',\n  RESET: 'reset',\n});\n\nexport const InternalEventBusMessageTypes = Object.freeze({\n  BACKGROUND_EVENT_BROADCAST: 'InternalEventBus:BackgroundEventBroadcast'\n});\n\nexport const RawDirectMessageTypes = Object.freeze({\n  WORKER_GENERIC_RESPONSE: 'response',\n  WORKER_GENERIC_ERROR: 'error',\n  WORKER_SCRAPE_STAGE_RESULT: 'STAGE_SCRAPE_RESULT',\n  WORKER_DIRECT_SCRAPE_RESULT: 'DIRECT_SCRAPE_RESULT',\n  WORKER_UI_LOADING_STATUS_UPDATE: 'uiLoadingStatusUpdate' // This one is used as a direct message type\n});\n\nexport const Contexts = Object.freeze({\n  BACKGROUND: 'Background',\n  MAIN_UI: 'MainUI',\n  POPUP: 'Popup',\n  OTHERS: 'Others',\n  UNKNOWN: 'Unknown',\n}); ","import { eventBus } from './eventBus.js';\nimport { DbAddLogRequest, DbInitializationCompleteNotification } from './events/dbEvents.js';\n\n\nconst hasChromeRuntime = typeof chrome !== 'undefined' && chrome.runtime;\nlet componentName = 'unknown';\nlet mirrorToConsoleDefault = true;\nlet sendToDbDefault = true;\nlet isDbReadyForLogs = false;\nconst logBuffer = [];\n\nasync function flushLogBuffer() {\n    if (!eventBus) return;\n    while (logBuffer.length > 0) {\n        const logEvent = logBuffer.shift();\n        if (logEvent) {\n            try {\n                await eventBus.publish(logEvent.type, logEvent);\n            } catch (error) {\n                console.error(`LogClient (${componentName}): Error publishing buffered log. Error: ${error}. Event:`, logEvent);\n            }\n        }\n    }\n}\n\nfunction init(compName, options = {}) {\n    if (!compName) {\n        console.error(\"LogClient: init() requires a component name.\");\n        return;\n    }\n    componentName = compName;\n    mirrorToConsoleDefault = options.mirrorToConsole !== undefined ? options.mirrorToConsole : true;\n    sendToDbDefault = options.sendToDb !== undefined ? options.sendToDb : true;\n\n    if (eventBus) {\n        eventBus.subscribe(DbInitializationCompleteNotification.type, (notification) => {\n            if (notification.payload.success) {\n                console.log(`[LogClient (${componentName})] Received DB Initialization Complete. Flushing buffer.`);\n                isDbReadyForLogs = true;\n                 flushLogBuffer(); \n            } else {\n                console.error(`[LogClient (${componentName})] Received DB Initialization FAILED notification. Logs will not be sent to DB. Error:`, notification.payload.error);\n            }\n        });\n    } else {\n        console.error(`LogClient (${componentName}): CRITICAL - eventBus not available during init. DB logging disabled.`);\n        sendToDbDefault = false;\n    }\n\n    let logMode = 'unknown';\n    if (typeof eventBus !== 'undefined') {\n        logMode = 'sendMessage logging (Standard)';\n    } else {\n        logMode = 'console fallback';\n        console.error(`LogClient (${componentName}): CRITICAL - No logging mechanism available. Falling back to console.`);\n    }\n\n    const initialLogMessage = `Log client initialized for component: ${componentName}. (${logMode}, Console Mirror: ${mirrorToConsoleDefault}, SendToDB: ${sendToDbDefault})`;\n    _internalLogHelper('info', initialLogMessage, { mirrorToConsole: mirrorToConsoleDefault, sendToDb: sendToDbDefault, skipInitCheck: true });\n}\n\nasync function _internalLogHelper(level, ...args) {\n    const rawOptions = args.length > 0 && typeof args[args.length - 1] === 'object' && !Array.isArray(args[args.length - 1]) ? args.pop() : {};\n    const options = rawOptions || {};\n\n    const mirrorThisCall = options.mirrorToConsole !== undefined ? options.mirrorToConsole : mirrorToConsoleDefault;\n    let sendThisCall = options.sendToDb !== undefined ? options.sendToDb : sendToDbDefault;\n    const skipInitCheck = options.skipInitCheck || false;\n\n    if (sendThisCall && typeof eventBus === 'undefined') {\n        console.warn(`LogClient (${componentName}): Attempted DB log but eventBus is unavailable. Disabling DB log for this call.`);\n        sendThisCall = false;\n    }\n\n    if (!componentName && !skipInitCheck) {\n        console.error(\"LogClient: Attempted to log before init() was called. Message:\", level, ...args);\n        return;\n    }\n\n    if (mirrorThisCall || level.toLowerCase() === 'error') {\n        const consolePrefix = componentName ? `[${componentName}]` : `[LogClient]`;\n        const consoleArgs = [consolePrefix, ...args];\n        switch (level.toLowerCase()) {\n            case 'error': console.error(...consoleArgs); break;\n            case 'warn': if (mirrorThisCall) console.warn(...consoleArgs); break;\n            case 'debug': if (mirrorThisCall) console.debug(...consoleArgs); break;\n            case 'info': default: if (mirrorThisCall) console.log(...consoleArgs); break;\n        }\n    }\n\n    if (!sendThisCall) return;\n\n    const formattedMessage = args.map(arg => {\n        try {\n            if (arg instanceof Error) {\n                return `Error: ${arg.message}${arg.stack ? '\\n' + arg.stack : ''}`;\n            }\n            if (typeof arg === 'object' && arg !== null) {\n                return '[Object]';\n            }\n            return String(arg);\n        } catch (e) {\n            return `[Unstringifiable Object: ${e.message}]`;\n        }\n    }).join(' ');\n\n    const logPayload = {\n        id: crypto.randomUUID(),\n        timestamp: Date.now(),\n        component: componentName,\n        level: level.toLowerCase(),\n        message: formattedMessage,\n    };\n\n    if (hasChromeRuntime && chrome.storage?.local) {\n        try {\n            const { currentLogSessionId } = await chrome.storage.local.get('currentLogSessionId');\n            if (currentLogSessionId) {\n                logPayload.extensionSessionId = currentLogSessionId;\n            } else {\n                console.warn(`LogClient (${componentName}): Could not retrieve currentLogSessionId from storage.`);\n                logPayload.extensionSessionId = 'unknown-session';\n            }\n        } catch (storageError) {\n            console.error(`LogClient (${componentName}): Error retrieving session ID from storage:`, storageError);\n            logPayload.extensionSessionId = 'storage-error-session';\n        }\n    } else {\n        logPayload.extensionSessionId = 'no-storage-session';\n    }\n\n    const logEvent = new DbAddLogRequest(logPayload);\n\n    if (isDbReadyForLogs) {\n        try {\n            await eventBus.publish(logEvent.type, logEvent);\n        } catch (error) {\n            console.error(`LogClient (${componentName}): Error during eventBus log submission. Error: ${error}. Original message:`, level, ...args);\n        }\n    } else {\n        logBuffer.push(logEvent);\n    }\n}\n\nfunction log(level, ...args) {\n    _internalLogHelper(level, ...args);\n}\n\nfunction logDebug(...args) {\n    _internalLogHelper('debug', ...args);\n}\n\nfunction logInfo(...args) {\n    _internalLogHelper('info', ...args);\n}\n\nfunction logWarn(...args) {\n    _internalLogHelper('warn', ...args);\n}\n\nfunction logError(...args) {\n    _internalLogHelper('error', ...args);\n}\n\nexport { init, log, logDebug, logInfo, logWarn, logError };","console.log('[DB] minimaldb.js context check:', {\n  typeofWindow: typeof window,\n  typeofSelf: typeof self,\n  hasRegistration: typeof self !== 'undefined' && !!self.registration,\n  locationHref: typeof location !== 'undefined' ? location.href : 'N/A'\n});\nif (typeof window !== 'undefined') {\n  console.trace('[DB] minimaldb.js loaded in window context! (trace below)');\n}\n// Throw if loaded in sidepanel or any non-background context\nif (typeof window !== 'undefined' && typeof location !== 'undefined' && location.href.includes('sidepanel.html')) {\n  throw new Error('[DB] FATAL: minimaldb.js loaded in sidepanel context!');\n}\nimport { isBackgroundContext } from './eventBus.js';\nif (!isBackgroundContext()) {\n  throw new Error('[DB] FATAL: minimaldb.js loaded outside background context!');\n}\nclass AppError extends Error {\n    constructor(code, message, details = {}) {\n        super(message);\n        this.code = code;\n        this.details = details;\n    }\n}\n\nasync function withTimeout(promise, ms, errorMessage = `Operation timed out after ${ms}ms`) {\n    const timeout = new Promise((_, reject) => setTimeout(() => reject(new AppError('TIMEOUT', errorMessage)), ms));\n    return Promise.race([promise, timeout]);\n}\n\n\nimport { createRxDatabase, addRxPlugin } from 'rxdb';\nimport { getRxStorageDexie } from 'rxdb/plugins/storage-dexie';\nimport { RxDBQueryBuilderPlugin } from 'rxdb/plugins/query-builder';\nimport { RxDBMigrationSchemaPlugin } from 'rxdb/plugins/migration-schema';\nimport { RxDBUpdatePlugin } from 'rxdb/plugins/update';\nimport browser from 'webextension-polyfill';\nimport { eventBus } from './eventBus.js';\nimport {\n    DbCreateSessionRequest, DbCreateSessionResponse,\n    DbGetSessionRequest, DbGetSessionResponse,\n    DbAddMessageRequest, DbAddMessageResponse,\n    DbUpdateMessageRequest, DbUpdateMessageResponse,\n    DbDeleteMessageRequest, DbDeleteMessageResponse,\n    DbUpdateStatusRequest, DbUpdateStatusResponse,\n    DbToggleStarRequest, DbToggleStarResponse,\n    DbGetAllSessionsRequest, DbGetAllSessionsResponse,\n    DbMessagesUpdatedNotification,\n    DbStatusUpdatedNotification,\n    DbSessionUpdatedNotification,\n    DbInitializeRequest, \n    DbDeleteSessionRequest, DbDeleteSessionResponse,\n    DbRenameSessionRequest, DbRenameSessionResponse,\n    DbGetStarredSessionsRequest, DbGetStarredSessionsResponse,\n    DbGetReadyStateRequest, DbGetReadyStateResponse,\n    DbResetDatabaseRequest, DbResetDatabaseResponse,\n} from './events/dbEvents.js';\nimport {\n    DbAddLogRequest,\n    DbGetLogsRequest, DbGetLogsResponse,\n    DbGetUniqueLogValuesRequest, DbGetUniqueLogValuesResponse,\n    DbClearLogsRequest, DbClearLogsResponse,\n    DbGetCurrentAndLastLogSessionIdsRequest, DbGetCurrentAndLastLogSessionIdsResponse\n} from './events/dbEvents.js'; \n\n\n\nlet db = null;\nlet chatHistoryCollection = null;\nlet logDbInstance = null;\nlet logsCollection = null;\nlet isDbInitialized = false;\nlet isLogDbInitialized = false;\nlet dbReadyResolve;\nconst dbReadyPromise = new Promise(resolve => { dbReadyResolve = resolve; });\nlet currentExtensionSessionId = null;\nlet previousExtensionSessionId = null;\nlet isDbReadyFlag = false;\n\n\n\nconst chatHistorySchema = {\n    title: 'chat history schema',\n    version: 0,\n    description: 'Stores chat sessions',\n    primaryKey: 'id',\n    type: 'object',\n    properties: {\n        id: { type: 'string', maxLength: 100 },\n        tabId: { type: 'number' },\n        timestamp: { type: 'number' },\n        title: { type: 'string', maxLength: 100 },\n        messages: {\n            type: 'array',\n            items: {\n                type: 'object',\n                properties: {\n                    messageId: { type: 'string', maxLength: 100 },\n                    sender: { type: 'string' },\n                    text: { type: 'string' },\n                    timestamp: { type: 'number' },\n                    isLoading: { type: 'boolean', default: false }\n                },\n                required: ['messageId', 'sender', 'text', 'timestamp']\n            }\n        },\n        isStarred: { type: 'boolean', default: false },\n        status: { type: 'string', default: 'idle' }\n    },\n    required: ['id', 'timestamp', 'messages'],\n    indexes: [['timestamp']]\n};\n\n\nconst logSchema = {\n  title: 'log schema',\n  version: 0,\n  description: 'Stores application log entries',\n  primaryKey: 'id',\n  type: 'object',\n  properties: {\n    id: { \n      type: 'string',\n      maxLength: 100,\n      final: true \n    },\n    timestamp: { \n      type: 'number',\n      index: true \n    },\n    level: { \n      type: 'string',\n      enum: ['error', 'warn', 'info', 'debug'],\n      index: true \n    },\n    message: { \n      type: 'string'\n    },\n    component: { \n      type: 'string',\n      index: true\n    },\n    extensionSessionId: { \n      type: 'string',\n      index: true\n    },\n    chatSessionId: {\n      type: ['string', 'null'],\n      index: true,\n      default: null \n    }\n  },\n  required: ['id', 'timestamp', 'level', 'component', 'extensionSessionId', 'message']\n};\n\neventBus.subscribe(DbInitializeRequest.type, handleInitializeRequest);\neventBus.subscribe(DbGetReadyStateRequest.type, handleDbGetReadyStateRequest);\neventBus.subscribe(DbCreateSessionRequest.type, handleDbCreateSessionRequest);\neventBus.subscribe(DbGetSessionRequest.type, handleDbGetSessionRequest);\neventBus.subscribe(DbAddMessageRequest.type, handleDbAddMessageRequest);\neventBus.subscribe(DbUpdateMessageRequest.type, handleDbUpdateMessageRequest);\neventBus.subscribe(DbDeleteMessageRequest.type, handleDbDeleteMessageRequest);\neventBus.subscribe(DbUpdateStatusRequest.type, handleDbUpdateStatusRequest);\neventBus.subscribe(DbToggleStarRequest.type, handleDbToggleStarRequest);\neventBus.subscribe(DbGetAllSessionsRequest.type, handleDbGetAllSessionsRequest);\neventBus.subscribe(DbGetStarredSessionsRequest.type, handleDbGetStarredSessionsRequest);\neventBus.subscribe(DbDeleteSessionRequest.type, handleDbDeleteSessionRequest);\neventBus.subscribe(DbRenameSessionRequest.type, handleDbRenameSessionRequest);\neventBus.subscribe(DbAddLogRequest.type, handleDbAddLogRequest);\neventBus.subscribe(DbGetLogsRequest.type, handleDbGetLogsRequest);\neventBus.subscribe(DbGetUniqueLogValuesRequest.type, handleDbGetUniqueLogValuesRequest);\neventBus.subscribe(DbClearLogsRequest.type, handleDbClearLogsRequest);\neventBus.subscribe(DbGetCurrentAndLastLogSessionIdsRequest.type, handleDbGetCurrentAndLastLogSessionIdsRequest);\neventBus.subscribe(DbResetDatabaseRequest.type, handleDbResetDatabaseRequest);\nasync function handleDbGetReadyStateRequest(event) {\n    const requestId = event?.requestId || crypto.randomUUID();\n    console.log('[DB] handleDbGetReadyStateRequest: ready=' + isDbReadyFlag);\n    return { success: true, data: { ready: isDbReadyFlag } };\n}\n\nasync function ensureDbReady(type = 'chat') {\n    const timeoutMs = 5000;\n    const pollInterval = 100;\n    const start = Date.now();\n    let collection = null;\n    let lastLogTime = 0;\n    while (Date.now() - start < timeoutMs) {\n        if (type === 'chat') {\n            if (chatHistoryCollection) {\n                console.log(`[DB][ensureDbReady] chatHistoryCollection is ready after ${Date.now() - start}ms`);\n                collection = chatHistoryCollection;\n                break;\n            }\n        } else if (type === 'log') {\n            if (logsCollection) {\n                console.log(`[DB][ensureDbReady] logsCollection is ready after ${Date.now() - start}ms`);\n                collection = logsCollection;\n                break;\n            }\n        } else {\n            throw new AppError('INVALID_INPUT', `Unknown DB type requested: ${type}`);\n        }\n        // Log every 500ms to avoid spamming\n        if (Date.now() - lastLogTime > 500) {\n            console.log(`[DB][ensureDbReady] Waiting for collection '${type}'... elapsed: ${Date.now() - start}ms`);\n            lastLogTime = Date.now();\n        }\n        await new Promise(res => setTimeout(res, pollInterval));\n    }\n    if (!collection) {\n        console.error(`[DB][ensureDbReady] Collection for type '${type}' not initialized after ${timeoutMs}ms`);\n        throw new AppError('COLLECTION_NOT_READY', `Collection for type '${type}' not initialized after ${timeoutMs}ms`);\n    }\n    return collection;\n}\n\n\nasync function handleDbResetDatabaseRequest() {\n    console.log('[DB] Resetting databases due to initialization failure');\n    try {\n        if (db) {\n            await db.destroy();\n            console.log('[DB] Main database instance destroyed');\n        }\n        if (logDbInstance) {\n            await logDbInstance.destroy();\n            console.log('[DB] Log database instance destroyed');\n        }\n        db = null;\n        chatHistoryCollection = null;\n        isDbInitialized = false;\n        logDbInstance = null;\n        logsCollection = null;\n        isLogDbInitialized = false;\n\n\n        try {\n\n            const mainStorage = getRxStorageDexie('tabagentdb');\n            if (mainStorage && typeof mainStorage.remove === 'function') {\n                 await mainStorage.remove();\n                 console.log('[DB] Removed tabagentdb storage');\n            } else {\n                 console.warn('[DB] Could not get main storage or remove method.');\n            }\n        } catch (e) { console.warn('[DB] Could not remove tabagentdb storage (might not exist)', { error: e?.message }); }\n         try {\n\n             const logStorage = getRxStorageDexie('tabagent_logs_db');\n             if (logStorage && typeof logStorage.remove === 'function') {\n                 await logStorage.remove();\n                 console.log('[DB] Removed tabagent_logs_db storage');\n             } else {\n                  console.warn('[DB] Could not get log storage or remove method.');\n             }\n        } catch (e) { console.warn('[DB] Could not remove tabagent_logs_db storage (might not exist)', { error: e?.message }); }\n\n        dbReadyResolve(false);\n    } catch (error) {\n        console.error('[DB] [Database:Reset] CAUGHT RAW ERROR during reset:', error);\n        console.error('[DB] Failed to reset databases', { error });\n        throw new AppError('RESET_FAILED', 'Could not reset databases', { originalError: error });\n    }\n}\n\n\nasync function handleInitializeRequest(event) {\n    console.log('[DB] handleInitializeRequest ENTRY', {\n        dbReadyPromiseExists: !!dbReadyPromise,\n        dbReadyPromiseType: typeof dbReadyPromise,\n        isDbReadyFlag,\n        isDbInitialized,\n        isLogDbInitialized,\n        eventType: event?.type,\n        eventRequestId: event?.requestId\n    });\n\n    // 1. Try to get session IDs\n    let ids;\n    try {\n        ids = await browser.storage.local.get(['currentLogSessionId', 'previousLogSessionId']);\n        currentExtensionSessionId = ids.currentLogSessionId || null;\n        previousExtensionSessionId = ids.previousLogSessionId || null;\n        console.log('[DB] Retrieved log session IDs', { current: currentExtensionSessionId, previous: previousExtensionSessionId });\n        if (!currentExtensionSessionId) {\n            const msg = 'CRITICAL: currentLogSessionId not found in storage during DB init!';\n            console.error('[DB] Database:Initialize]', msg);\n            console.log('[DB] About to resolve dbReadyPromise with value: false (missing session ID)');\n            dbReadyResolve(false);\n            console.log('[DB] dbReadyPromise resolved (missing session ID)');\n            console.log('[DB] handleInitializeRequest EXIT (missing session ID)');\n            return { success: false, error: msg };\n        }\n    } catch (storageError) {\n        console.error('[DB] Failed to retrieve log session IDs from storage', { error: storageError });\n        console.log('[DB] About to resolve dbReadyPromise with value: false (storage error)');\n        dbReadyResolve(false);\n        console.log('[DB] dbReadyPromise resolved (storage error)');\n        console.log('[DB] handleInitializeRequest EXIT (storage error)');\n        return { success: false, error: storageError.message || String(storageError) };\n    }\n\n    // 2. Already initialized?\n    if (isDbInitialized && isLogDbInitialized) {\n        console.log('[DB] Both databases already initialized, skipping');\n        isDbReadyFlag = true;\n        console.log('[DB] About to resolve dbReadyPromise with value: true (already initialized)');\n        dbReadyResolve(true);\n        console.log('[DB] dbReadyPromise resolved (already initialized)');\n        console.log('[DB] handleInitializeRequest EXIT (already initialized)');\n        return { success: true };\n    }\n\n    // 3. In progress?\n    if (dbReadyPromise && !isDbReadyFlag) {\n        console.log('[DB] Initialization already in progress, waiting for completion');\n       // await dbReadyPromise;\n       // console.log('[DB] dbReadyPromise finished waiting (in progress check)');\n       // console.log('[DB] handleInitializeRequest EXIT (in progress check)');\n       // return { success: isDbReadyFlag };\n    }\n\n    // 4. Main initialization\n    try {\n        console.log('[DB][Init Step 1] About to add plugins');\n        addRxPlugin(RxDBQueryBuilderPlugin);\n        addRxPlugin(RxDBMigrationSchemaPlugin);\n        addRxPlugin(RxDBUpdatePlugin);\n        console.log('[DB][Init Step 1] Plugins added');\n      \n\n        if (!isDbInitialized) {\n            console.log('[DB][Init Step 2] About to create main database');\n            db = await withTimeout(createRxDatabase({\n                name: 'tabagentdb',\n                storage: getRxStorageDexie()\n            }), 10000);\n            console.log('[DB][Init Step 2] Main database instance created', { name: db.name });\n\n            console.log('[DB][Init Step 3] About to add chat collections');\n            try {\n                const chatCollections = await db.addCollections({\n                    chatHistory: {\n                        schema: chatHistorySchema\n                    }\n                });\n                chatHistoryCollection = chatCollections.chatHistory;\n                console.log('[DB][Init Step 3] Chat history collection initialized');\n                isDbInitialized = true;\n             \n            } catch (e) {\n                console.error('[DB][Init Step 3] Error adding chat collections:', e);\n                throw e;\n            }\n        } else {\n            console.log('[DB][Init Step 2/3] Main database and chat collections already initialized');\n        }\n\n        // Step 4: Log DB\n        console.log('[DB][Init Step 4] Checking if log DB needs to be initialized:', isLogDbInitialized);\n        if (!isLogDbInitialized) {\n            console.log('[DB][Init Step 4] About to create log database');\n            try {\n                logDbInstance = await withTimeout(createRxDatabase({\n                    name: 'tabagent_logs_db',\n                    storage: getRxStorageDexie()\n                }), 10000);\n                console.log('[DB][Init Step 4] Log database instance created', { name: logDbInstance.name });\n            } catch (e) {\n                console.error('[DB][Init Step 4] Error creating log database:', e);\n                throw e;\n            }\n\n            console.log('[DB][Init Step 5] About to add log collections');\n            const logCollections = await logDbInstance.addCollections({\n                logs: {\n                    schema: logSchema\n                }\n            });\n            logsCollection = logCollections.logs;\n            console.log('[DB][Init Step 5] Logs collection initialized');\n            isLogDbInitialized = true;\n            console.log('[DB] After Step 5, before subscriptions');\n          \n        } else {\n            console.log('[DB][Init Step 4/5] Log database and log collections already initialized');\n        }\n          \n\n        console.log('[DB] Before pruning');\n\n       \n        setTimeout(async () => {\n            console.log('[DB] Running startup log pruning (delayed)...');\n            console.log('[DB] Current/Previous IDs for pruning', { current: currentExtensionSessionId, previous: previousExtensionSessionId });\n            try {\n                const currentId = currentExtensionSessionId;\n                const previousId = previousExtensionSessionId; \n\n                if (!currentId) {\n                    console.log('[DB] Cannot prune logs, currentExtensionSessionId is not set!');\n                } else {\n                    console.log('[DB] Attempting to get all unique log session IDs...');\n                    const allLogSessionIds = await getAllUniqueLogSessionIdsInternal();\n                    console.log('[DB] Found unique log session IDs in DB', { ids: allLogSessionIds });\n                    const sessionsToKeep = new Set();\n                    sessionsToKeep.add(currentId);\n                    if (previousId) sessionsToKeep.add(previousId);\n                    console.log('[DB] Session IDs to keep', { ids: Array.from(sessionsToKeep) });\n                    const sessionIdsToDelete = Array.from(allLogSessionIds).filter(id => !sessionsToKeep.has(id));\n                    console.log('[DB] Session IDs to delete', { ids: sessionIdsToDelete });\n                    if (sessionIdsToDelete.length > 0) {\n                        console.log('[DB] Attempting to clear logs for', sessionIdsToDelete.length, 'old session(s).');\n                        const { deletedCount } = await clearLogsInternal(sessionIdsToDelete);\n                        console.log('[DB] Startup pruning removed', deletedCount, 'logs from old session(s).');\n                    } else {\n                        console.log('[DB] No old log sessions found to prune during startup.');\n                    }\n                }\n            } catch (pruneError) {\n                console.error('[DB] Error during startup log pruning:', pruneError);\n            }\n           \n        }, 100);\n\n        console.log('[DB] Before setting isDbReadyFlag and resolving dbReadyPromise');\n       \n        isDbReadyFlag = true;\n        console.log('[DB] About to resolve dbReadyPromise with value: true (init complete)');\n        dbReadyResolve(true);\n        console.log('[DB] dbReadyPromise resolved (init complete)');\n        return { success: true };\n    } catch (error) {\n        console.error(\"[DB] Entered CATCH block for init error.\");\n        console.error(\"[DB] Raw Error Name:\", error?.name);\n        console.error(\"[DB] Raw Error Message:\", error?.message);\n        console.error(\"[DB] CAUGHT RAW ERROR OBJECT during init:\", error); \n\n        const appError = error instanceof AppError ? error : new AppError('INIT_FAILED', 'Database initialization failed', { originalError: error });\n        console.error('[DB] Initialization failed', { error: appError, details: error }); \n        isDbInitialized = false;\n        isLogDbInitialized = false;\n        isDbReadyFlag = false;\n        console.log('[DB] About to resolve dbReadyPromise with value: false (init error)');\n        dbReadyResolve(false); \n        return { success: false, error: appError.message || String(appError) };\n    }\n}\n\n// Generate unique message ID\nfunction generateMessageId(chatId) {\n    if (!chatId || typeof chatId !== 'string') {\n        throw new AppError('INVALID_INPUT', 'Chat ID must be a non-empty string');\n    }\n    return `${chatId}-msg-${Date.now()}-${Math.random().toString(36).substring(2, 7)}`;\n}\n\nfunction sanitizeInput(input) {\n    if (typeof input !== 'string') return input;\n    return input.replace(/[<>]/g, '');\n}\n\n\nasync function publishSessionUpdate(sessionId, updateType = 'update', sessionDataOverride = null) {\n    try {\n        let sessionData = sessionDataOverride;\n        if (!sessionData) {\n            const result = await getChatSessionByIdInternal(sessionId);\n            if (result.success && result.data) {\n                sessionData = result.data.toJSON ? result.data.toJSON() : result.data;\n            } else if (updateType === 'delete') {\n                sessionData = { id: sessionId };\n            } else {\n                console.error('[DB] Session not found for notification', { sessionId, updateType });\n                return;\n            }\n        }\n        let plainSession = sessionData;\n        try {\n            const testString = JSON.stringify(sessionData);\n            plainSession = JSON.parse(testString);\n        } catch (e) {\n            console.error('[DB] Session data is NOT serializable:', e, sessionData);\n            return;\n        }\n        const notification = {\n            type: DbSessionUpdatedNotification.type,\n            payload: { session: plainSession, updateType }\n        };\n        JSON.stringify(notification); \n        await eventBus.publish(notification.type, notification);\n        console.log('[DB] Session update notification published', { sessionId, updateType });\n    } catch (e) {\n        console.error('[DB] Failed to publish session update notification', e, { sessionId, updateType });\n    }\n}\n\n\nasync function publishMessagesUpdate(sessionId, messages) {\n    try {\n\n        let plainMessages = messages;\n        try {\n            const testString = JSON.stringify(messages);\n            plainMessages = JSON.parse(testString);\n        } catch (e) {\n            console.error('[DB] Messages are NOT serializable:', e, messages);\n            return;\n        }\n        const notification = new DbMessagesUpdatedNotification(sessionId, plainMessages);\n        JSON.stringify(notification); \n        await eventBus.publish(notification.type, notification);\n        console.log('[DB] Messages update notification published', { sessionId, count: plainMessages.length });\n    } catch (e) {\n        console.error('[DB] Failed to publish messages update notification', e, { sessionId });\n    }\n}\n\nasync function publishStatusUpdate(sessionId, status) {\n    try {\n        let safeStatus = status;\n        try {\n            JSON.stringify(status);\n        } catch (e) {\n            console.error('[DB] Status is NOT serializable:', e, status);\n            return;\n        }\n        const notification = new DbStatusUpdatedNotification(sessionId, safeStatus);\n        JSON.stringify(notification); \n        await eventBus.publish(notification.type, notification);\n        console.log('[DB] Status update notification published', { sessionId, status });\n    } catch (e) {\n        console.error('[DB] Failed to publish status update notification', e, { sessionId });\n    }\n}\n\nasync function createChatSessionInternal(initialMessage) {\n    console.log('[DB] Creating new chat session', { initialMessage });\n    try {\n        const collection = await ensureDbReady();\n        if (!initialMessage || !initialMessage.text) {\n            return { success: false, error: 'Initial message with text is required' };\n        }\n        const timestamp = Date.now();\n        const sessionId = crypto.randomUUID();\n        const message = {\n            ...initialMessage,\n            text: sanitizeInput(initialMessage.text),\n            messageId: generateMessageId(sessionId),\n            timestamp: initialMessage.timestamp || timestamp,\n            sender: initialMessage.sender || 'user'\n        };\n        const sessionData = {\n            id: sessionId,\n            tabId: null,\n            timestamp,\n            title: sanitizeInput(message.text.substring(0, 30)) + '...',\n            messages: [message],\n            isStarred: false,\n            status: 'idle'\n        };\n        console.log('[DB] Inserting session', { sessionId });\n        const newSessionDoc = await withTimeout(collection.insert(sessionData), 3000);\n        await publishSessionUpdate(sessionId, 'create');\n        await publishMessagesUpdate(sessionId, newSessionDoc.messages.map(m => m.toJSON ? m.toJSON() : m));\n        await publishStatusUpdate(newSessionDoc.id, newSessionDoc.status);\n        return { success: true, data: newSessionDoc };\n    } catch (error) {\n        console.error('[DB] Failed to create chat session', { error });\n        return { success: false, error: error.message || String(error) };\n    }\n}\n\nasync function getChatSessionByIdInternal(sessionId) {\n    console.log('[DB] Getting session', { sessionId });\n    try {\n        if (!sessionId) {\n            return { success: false, error: 'Session ID is required' };\n        }\n        const collection = await ensureDbReady();\n        const doc = await withTimeout(collection.findOne(sessionId).exec(), 3000);\n        if (!doc) {\n            console.log('[DB] Session not found', { sessionId });\n            return { success: false, error: `Session ${sessionId} not found` };\n        }\n        console.log('[DB] Session retrieved', { sessionId });\n        return { success: true, data: doc };\n    } catch (error) {\n        console.error('[DB] Failed to get session', { sessionId, error });\n        return { success: false, error: error.message || String(error) };\n    }\n}\n\nasync function addMessageToChatInternal(chatId, messageObject) {\n    console.log('[DB] Adding message', { chatId });\n    try {\n        if (!chatId || !messageObject || !messageObject.text) {\n            return { success: false, error: 'Chat ID and message with text are required' };\n        }\n        const collection = await ensureDbReady();\n        const chatDoc = await withTimeout(collection.findOne(chatId).exec(), 3000);\n        if (!chatDoc) {\n            return { success: false, error: `Chat session ${chatId} not found` };\n        }\n        const newMessage = {\n            ...messageObject,\n            text: sanitizeInput(messageObject.text),\n            messageId: messageObject.messageId || generateMessageId(chatId),\n            timestamp: messageObject.timestamp || Date.now(),\n            isLoading: messageObject.isLoading ?? false\n        };\n        const updatedDoc = await withTimeout(\n            chatDoc.incrementalPatch({ messages: [...chatDoc.messages, newMessage] }),\n            3000\n        );\n        console.log('[DB] Message added', { chatId, messageId: newMessage.messageId });\n        await publishSessionUpdate(chatId, 'update');\n        await publishMessagesUpdate(chatId, updatedDoc.messages.map(m => m.toJSON ? m.toJSON() : m));\n        return { success: true, data: { updatedDoc, newMessageId: newMessage.messageId } };\n    } catch (error) {\n        console.error('[DB] Failed to add message', { chatId, error });\n        return { success: false, error: error.message || String(error) };\n    }\n}\n\nasync function updateMessageInChatInternal(chatId, messageId, updates) {\n    console.log('[DB] Updating message', { chatId, messageId });\n    try {\n        if (!chatId || !messageId || !updates || !updates.text) {\n            return { success: false, error: 'Chat ID, message ID, and updates with text are required' };\n        }\n        const collection = await ensureDbReady();\n        const chatDoc = await withTimeout(collection.findOne(chatId).exec(), 3000);\n        if (!chatDoc) {\n            return { success: false, error: `Chat session ${chatId} not found` };\n        }\n        let messageFound = false;\n        const updatedDoc = await withTimeout(\n            chatDoc.incrementalModify((docData) => {\n                const messageIndex = docData.messages.findIndex(m => m.messageId === messageId);\n                if (messageIndex === -1) return docData;\n                messageFound = true;\n                const currentMessage = docData.messages[messageIndex];\n                docData.messages[messageIndex] = {\n                    ...currentMessage,\n                    ...updates,\n                    text: sanitizeInput(updates.text),\n                    messageId: currentMessage.messageId\n                };\n                return docData;\n            }),\n            3000\n        );\n        if (!messageFound) {\n            return { success: false, error: `Message ${messageId} not found in chat ${chatId}` };\n        }\n        console.log('[DB] Message updated', { chatId, messageId });\n        await publishSessionUpdate(chatId, 'update');\n        await publishMessagesUpdate(chatId, updatedDoc.messages.map(m => m.toJSON ? m.toJSON() : m));\n        return { success: true, data: updatedDoc };\n    } catch (error) {\n        console.error('[DB] Failed to update message', { chatId, messageId, error });\n        return { success: false, error: error.message || String(error) };\n    }\n}\n\nasync function deleteMessageFromChatInternal(sessionId, messageId) {\n    console.log('[DB] Deleting message', { sessionId, messageId });\n    try {\n        if (!sessionId || !messageId) {\n            return { success: false, error: 'Session ID and message ID are required' };\n        }\n        const collection = await ensureDbReady();\n        const sessionDoc = await withTimeout(collection.findOne(sessionId).exec(), 3000);\n        if (!sessionDoc) {\n            return { success: false, error: `Session ${sessionId} not found` };\n        }\n        const initialLength = sessionDoc.messages.length;\n        const updatedMessages = sessionDoc.messages.filter(msg => msg.messageId !== messageId);\n        if (updatedMessages.length === initialLength) {\n            console.log('[DB] Message not found', { sessionId, messageId });\n            return { success: false, error: `Message ${messageId} not found in session ${sessionId}` };\n        }\n        const updatedDoc = await withTimeout(\n            sessionDoc.incrementalPatch({ messages: updatedMessages }),\n            3000\n        );\n        console.log('[DB] Message deleted', { sessionId, messageId });\n        await publishSessionUpdate(sessionId, 'update');\n        await publishMessagesUpdate(sessionId, updatedDoc.messages.map(m => m.toJSON ? m.toJSON() : m));\n        return { success: true, data: { updatedDoc, deleted: true } };\n    } catch (error) {\n        console.error('[DB] Failed to delete message', { sessionId, messageId, error });\n        return { success: false, error: error.message || String(error) };\n    }\n}\n\nasync function updateSessionStatusInternal(sessionId, newStatus) {\n    console.log('[DB] Updating status', { sessionId, newStatus });\n    try {\n        const validStatuses = ['idle', 'processing', 'complete', 'error'];\n        if (!sessionId || !validStatuses.includes(newStatus)) {\n            return { success: false, error: `Invalid session ID or status: ${newStatus}` };\n        }\n        const collection = await ensureDbReady();\n        const chatDoc = await withTimeout(collection.findOne(sessionId).exec(), 3000);\n        if (!chatDoc) {\n            return { success: false, error: `Session ${sessionId} not found` };\n        }\n        const updatedDoc = await withTimeout(\n            chatDoc.incrementalPatch({ status: newStatus }),\n            3000\n        );\n        console.log('[DB] Status updated', { sessionId, newStatus });\n        await publishSessionUpdate(sessionId, 'update');\n        await publishStatusUpdate(sessionId, newStatus);\n        return { success: true, data: updatedDoc };\n    } catch (error) {\n        console.error('[DB] Failed to update status', { sessionId, newStatus, error });\n        return { success: false, error: error.message || String(error) };\n    }\n}\n\nasync function toggleItemStarredInternal(itemId) {\n    console.log('[DB] Toggling starred status', { itemId });\n    try {\n        if (!itemId) {\n            return { success: false, error: 'Item ID is required' };\n        }\n        const collection = await ensureDbReady();\n        const entryDoc = await withTimeout(collection.findOne(itemId).exec(), 3000);\n        if (!entryDoc) {\n            return { success: false, error: `Item ${itemId} not found` };\n        }\n        const currentStarredStatus = entryDoc.get('isStarred') || false;\n        const updatedDoc = await withTimeout(\n            entryDoc.incrementalPatch({ isStarred: !currentStarredStatus }),\n            3000\n        );\n        console.log('[DB] Starred status toggled', { itemId, isStarred: !currentStarredStatus });\n        await publishSessionUpdate(itemId, 'update');\n        return { success: true, data: updatedDoc };\n    } catch (error) {\n        console.error('[DB] Failed to toggle starred status', { itemId, error });\n        return { success: false, error: error.message || String(error) };\n    }\n}\n\nasync function deleteHistoryItemInternal(itemId) {\n    console.log('[DB] Deleting history item', { itemId });\n    try {\n        if (!itemId) {\n            return { success: false, error: 'Item ID is required' };\n        }\n        const collection = await ensureDbReady();\n        const entryDoc = await withTimeout(collection.findOne(itemId).exec(), 3000);\n        if (!entryDoc) {\n            console.log('[DB] Item not found', { itemId });\n            return { success: false, error: `Item ${itemId} not found` };\n        }\n        await withTimeout(entryDoc.remove(), 3000);\n        console.log('[DB] Item deleted', { itemId });\n        await publishSessionUpdate(itemId, 'delete');\n        return { success: true, data: true };\n    } catch (error) {\n        console.error('[DB] Failed to delete history item', { itemId, error });\n        return { success: false, error: error.message || String(error) };\n    }\n}\n\nasync function renameHistoryItemInternal(itemId, newTitle) {\n    console.log('[DB] Renaming history item', { itemId, newTitle });\n    try {\n        if (!itemId || !newTitle) {\n            return { success: false, error: 'Item ID and new title are required' };\n        }\n        const collection = await ensureDbReady();\n        const entryDoc = await withTimeout(collection.findOne(itemId).exec(), 3000);\n        if (!entryDoc) {\n            return { success: false, error: `Item ${itemId} not found` };\n        }\n        const updatedDoc = await withTimeout(\n            entryDoc.incrementalPatch({ title: sanitizeInput(newTitle) }),\n            3000\n        );\n        console.log('[DB] Item renamed', { itemId, newTitle });\n        await publishSessionUpdate(itemId, 'rename');\n        return { success: true, data: updatedDoc };\n    } catch (error) {\n        console.error('[DB] Failed to rename history item', { itemId, newTitle, error });\n        return { success: false, error: error.message || String(error) };\n    }\n}\n\nasync function getAllSessionsInternal() {\n    console.log('[DB] Getting all sessions');\n    try {\n        const collection = await ensureDbReady();\n        \n        const sessionsDocs = await withTimeout(\n            collection.find().sort({ timestamp: 'desc' }).exec(),\n            5000\n        );\n        const plainSessions = sessionsDocs.map(doc => doc.toJSON());\n        console.log('[DB] Retrieved sessions', { count: plainSessions.length });\n        return { success: true, data: plainSessions };\n    } catch (error) {\n        console.error('[DB] Failed to get all sessions', { error });\n        return { success: false, error: error.message || String(error) };\n    }\n}\n\nasync function getStarredSessionsInternal() {\n    console.log('[DB] Getting starred sessions');\n    try {\n        const collection = await ensureDbReady();\n        const sessions = await withTimeout(\n            collection.find({ selector: { isStarred: true } }).sort({ timestamp: 'desc' }).exec(),\n            5000\n        );\n        console.log('[DB] Retrieved starred sessions', { count: sessions.length });\n        return { success: true, data: sessions };\n    } catch (error) {\n        console.error('[DB] Failed to get starred sessions', { error });\n        return { success: false, error: error.message || String(error) };\n    }\n}\n\nasync function handleDbCreateSessionRequest(event) {\n    const requestId = event?.requestId || crypto.randomUUID();\n    console.log('[DB] Handling session creation', { requestId });\n    let response;\n    try {\n        if (!event?.requestId || !event?.payload?.initialMessage || !event.payload.initialMessage.text) {\n            throw new AppError('INVALID_INPUT', 'Missing requestId, initialMessage, or message text');\n        }\n\n        const result = await withTimeout(createChatSessionInternal(event.payload.initialMessage), 5000);\n        if (!result.success || !result.data?.id) {\n            throw new AppError('INVALID_DOCUMENT', 'Invalid session document returned');\n        }\n        const newSessionDoc = result.data;\n        const plainMessages = newSessionDoc.messages.map(m => m.toJSON ? m.toJSON() : m);\n        console.log('[DB] About to publish DbMessagesUpdatedNotification (create session)', { sessionId: newSessionDoc.id, messages: plainMessages });\n        await publishMessagesUpdate(newSessionDoc.id, plainMessages);\n        await publishStatusUpdate(newSessionDoc.id, newSessionDoc.status);\n\n        response = new DbCreateSessionResponse(requestId, true, newSessionDoc.id);\n        await withTimeout(eventBus.publish(response.type, response), 3000);\n        console.log('[DB] Session created successfully', { requestId, sessionId: newSessionDoc.id });\n    } catch (error) {\n        const appError = error instanceof AppError ? error : new AppError('UNKNOWN', 'Failed to create session', { originalError: error });\n        response = new DbCreateSessionResponse(requestId, false, null, appError);\n        try {\n             await withTimeout(eventBus.publish(response.type, response), 3000);\n        } catch (publishError) {\n             console.error('[DB] FATAL: Failed even to publish error response!', { requestId, publishError });\n        }\n        console.error('[DB] Session creation failed', { requestId, error: appError });\n    }\n    return response;\n}\n\nasync function handleDbGetSessionRequest(event) {\n    const requestId = event?.requestId || crypto.randomUUID();\n    console.log('[DB] Handling get session', { requestId });\n    let response;\n    try {\n        if (!event?.payload?.sessionId) {\n            throw new AppError('INVALID_INPUT', 'Session ID is required');\n        }\n        const result = await withTimeout(getChatSessionByIdInternal(event.payload.sessionId), 5000);\n        if (!result.success) {\n            throw new AppError('GET_SESSION_FAILED', result.error || 'Unknown error');\n        }\n        response = new DbGetSessionResponse(requestId, true, result.data ? result.data.toJSON() : null);\n        await withTimeout(eventBus.publish(response.type, response), 3000);\n        console.log('[DB] Session retrieved', { requestId, sessionId: event.payload.sessionId });\n    } catch (error) {\n        const appError = error instanceof AppError ? error : new AppError('UNKNOWN', 'Failed to get session', { originalError: error });\n        response = new DbGetSessionResponse(requestId, false, null, appError);\n        await withTimeout(eventBus.publish(response.type, response), 3000);\n        console.error('[DB] Get session failed', { requestId, error: appError });\n    }\n    return response;\n}\n\nasync function handleDbAddMessageRequest(event) {\n    const requestId = event?.requestId || crypto.randomUUID();\n    console.log('[DB] Handling add message', { requestId });\n    let response;\n    try {\n        if (!event?.payload?.sessionId || !event?.payload?.messageObject || !event.payload.messageObject.text) {\n            throw new AppError('INVALID_INPUT', 'Session ID and message with text are required');\n        }\n        const result = await withTimeout(\n            addMessageToChatInternal(event.payload.sessionId, event.payload.messageObject),\n            5000\n        );\n        if (!result.success) {\n            console.error('[DB][handleDbAddMessageRequest] addMessageToChatInternal failed', { result });\n            throw new AppError('ADD_MESSAGE_FAILED', result.error || 'Unknown error');\n        }\n        const updatedDoc = result.data.updatedDoc || result.data;\n        const newMessageId = result.data.newMessageId;\n        const plainMessages = updatedDoc.messages.map(m => m.toJSON ? m.toJSON() : m); // Ensure plain messages\n        console.log('[DB] About to publish DbMessagesUpdatedNotification (add message)', { sessionId: updatedDoc.id, messages: plainMessages });\n        await publishMessagesUpdate(updatedDoc.id, plainMessages);\n        response = new DbAddMessageResponse(requestId, true, newMessageId);\n        await withTimeout(eventBus.publish(response.type, response), 3000);\n        console.log('[DB] Message added', { requestId, sessionId: event.payload.sessionId, messageId: newMessageId });\n    } catch (error) {\n        const appError = error instanceof AppError ? error : new AppError('UNKNOWN', 'Failed to add message', { originalError: error });\n        response = new DbAddMessageResponse(requestId, false, null, appError);\n        await withTimeout(eventBus.publish(response.type, response), 3000);\n        console.error('[DB] Add message failed', { requestId, error: appError });\n    }\n    return response;\n}\n\nasync function handleDbUpdateMessageRequest(event) {\n    const requestId = event?.requestId || crypto.randomUUID();\n    console.log('[DB] Handling update message', { requestId });\n    let response;\n    try {\n        if (!event?.payload?.sessionId || !event?.payload?.messageId || !event?.payload?.updates || !event.payload.updates.text) {\n            throw new AppError('INVALID_INPUT', 'Session ID, message ID, and updates with text are required');\n        }\n        const result = await withTimeout(\n            updateMessageInChatInternal(event.payload.sessionId, event.payload.messageId, event.payload.updates),\n            5000\n        );\n        if (!result.success) {\n            throw new AppError('UPDATE_MESSAGE_FAILED', result.error || 'Unknown error');\n        }\n        const updatedDoc = result.data;\n        const plainMessages = updatedDoc.messages.map(m => m.toJSON ? m.toJSON() : m);\n        console.log('[DB] About to publish DbMessagesUpdatedNotification (update message)', { sessionId: updatedDoc.id, messages: plainMessages });\n        await publishMessagesUpdate(updatedDoc.id, plainMessages);\n        response = new DbUpdateMessageResponse(requestId, true);\n        await withTimeout(eventBus.publish(response.type, response), 3000);\n        console.log('[DB] Message updated', { requestId, sessionId: event.payload.sessionId, messageId: event.payload.messageId });\n    } catch (error) {\n        const appError = error instanceof AppError ? error : new AppError('UNKNOWN', 'Failed to update message', { originalError: error });\n        response = new DbUpdateMessageResponse(requestId, false, appError);\n        await withTimeout(eventBus.publish(response.type, response), 3000);\n        console.error('[DB] Update message failed', { requestId, error: appError });\n    }\n    return response;\n}\n\nasync function handleDbDeleteMessageRequest(event) {\n    const requestId = event?.requestId || crypto.randomUUID();\n    console.log('[DB] Handling delete message', { requestId });\n    let response;\n    try {\n        if (!event?.payload?.sessionId || !event?.payload?.messageId) {\n            throw new AppError('INVALID_INPUT', 'Session ID and message ID are required');\n        }\n        const result = await withTimeout(\n            deleteMessageFromChatInternal(event.payload.sessionId, event.payload.messageId),\n            5000\n        );\n        if (!result.success) {\n            throw new AppError('DELETE_MESSAGE_FAILED', result.error || 'Unknown error');\n        }\n        const { updatedDoc, deleted } = result.data;\n        if (deleted) {\n            const plainMessages = updatedDoc.messages.map(m => m.toJSON ? m.toJSON() : m);\n            console.log('[DB] About to publish DbMessagesUpdatedNotification (delete message)', { sessionId: updatedDoc.id, messages: plainMessages });\n            await publishMessagesUpdate(updatedDoc.id, plainMessages);\n        }\n        response = new DbDeleteMessageResponse(requestId, true);\n        await withTimeout(eventBus.publish(response.type, response), 3000);\n        console.log('[DB] Message deleted', { requestId, sessionId: event.payload.sessionId, messageId: event.payload.messageId });\n    } catch (error) {\n        const appError = error instanceof AppError ? error : new AppError('UNKNOWN', 'Failed to delete message', { originalError: error });\n        response = new DbDeleteMessageResponse(requestId, false, appError);\n        await withTimeout(eventBus.publish(response.type, response), 3000);\n        console.error('[DB] Delete message failed', { requestId, error: appError });\n    }\n    return response;\n}\n\nasync function handleDbUpdateStatusRequest(event) {\n    const requestId = event?.requestId || crypto.randomUUID();\n    console.log('[DB] Handling update status', { requestId });\n    let response;\n    try {\n        if (!event?.payload?.sessionId || !event?.payload?.status) {\n            throw new AppError('INVALID_INPUT', 'Session ID and status are required');\n        }\n        const result = await withTimeout(\n            updateSessionStatusInternal(event.payload.sessionId, event.payload.status),\n            5000\n        );\n        if (!result.success) {\n            throw new AppError('UPDATE_STATUS_FAILED', result.error || 'Unknown error');\n        }\n        const updatedDoc = result.data;\n        await publishStatusUpdate(updatedDoc.id, updatedDoc.status);\n        response = new DbUpdateStatusResponse(requestId, true);\n        await withTimeout(eventBus.publish(response.type, response), 3000);\n        console.log('[DB] Status updated', { requestId, sessionId: event.payload.sessionId, status: event.payload.status });\n    } catch (error) {\n        const appError = error instanceof AppError ? error : new AppError('UNKNOWN', 'Failed to update status', { originalError: error });\n        response = new DbUpdateStatusResponse(requestId, false, appError);\n        await withTimeout(eventBus.publish(response.type, response), 3000);\n        console.error('[DB] Update status failed', { requestId, error: appError });\n        try {\n            await publishStatusUpdate(event.payload.sessionId, 'error');\n        } catch (notificationError) {\n            console.error('Failed to publish error status notification', { requestId, error: notificationError });\n        }\n    }\n    return response;\n}\n\nasync function handleDbToggleStarRequest(event) {\n    const requestId = event?.requestId || crypto.randomUUID();\n    console.log('[DB] Handling toggle star', { requestId });\n    let response;\n    try {\n        if (!event?.payload?.sessionId) {\n            throw new AppError('INVALID_INPUT', 'Session ID is required');\n        }\n        const result = await withTimeout(toggleItemStarredInternal(event.payload.sessionId), 5000);\n        if (!result.success) {\n            throw new AppError('TOGGLE_STAR_FAILED', result.error || 'Unknown error');\n        }\n        const updatedDoc = result.data;\n        response = new DbToggleStarResponse(requestId, true, updatedDoc.toJSON());\n        await withTimeout(eventBus.publish(response.type, response), 3000);\n        console.log('[DB] Star toggled', { requestId, sessionId: event.payload.sessionId });\n    } catch (error) {\n        const appError = error instanceof AppError ? error : new AppError('UNKNOWN', 'Failed to toggle star', { originalError: error });\n        response = new DbToggleStarResponse(requestId, false, null, appError);\n        await withTimeout(eventBus.publish(response.type, response), 3000);\n        console.error('[DB] Toggle star failed', { requestId, error: appError });\n    }\n    return response;\n}\n\nasync function handleDbGetAllSessionsRequest(event) {\n    const requestId = event?.requestId || crypto.randomUUID();\n    console.log('[DB] Handling get all sessions', { requestId });\n    let response;\n    try {\n        const result = await withTimeout(getAllSessionsInternal(), 5000);\n        if (!result.success) {\n            throw new AppError('GET_ALL_SESSIONS_FAILED', result.error || 'Unknown error');\n        }\n        const sortedSessions = (result.data || []).sort((a, b) => b.timestamp - a.timestamp);\n        console.log('Using plain sessions directly', { count: sortedSessions.length });\n        response = new DbGetAllSessionsResponse(requestId, true, sortedSessions);\n        await withTimeout(eventBus.publish(response.type, response), 3000);\n        console.log('[DB] Sessions retrieved', { requestId, count: sortedSessions.length });\n    } catch (error) {\n        const appError = error instanceof AppError ? error : new AppError('UNKNOWN', 'Failed to get all sessions', { originalError: error });\n        response = new DbGetAllSessionsResponse(requestId, false, null, appError);\n        await withTimeout(eventBus.publish(response.type, response), 3000);\n        console.error('[DB] Get all sessions failed', { requestId, error: appError });\n    }\n    return response;\n}\n\nasync function handleDbGetStarredSessionsRequest(event) {\n    const requestId = event?.requestId || crypto.randomUUID();\n    console.log('[DB] Handling get starred sessions', { requestId });\n    let response;\n    try {\n        const result = await withTimeout(getStarredSessionsInternal(), 5000);\n        if (!result.success) {\n            throw new AppError('GET_STARRED_SESSIONS_FAILED', result.error || 'Unknown error');\n        }\n        const starredSessions = (result.data || []).map(s => ({\n            sessionId: s.id,\n            name: s.title,\n            lastUpdated: s.timestamp,\n            isStarred: s.isStarred\n        })).sort((a, b) => b.lastUpdated - a.lastUpdated);\n        console.log('Retrieved starred sessions', { count: starredSessions.length });\n        response = new DbGetStarredSessionsResponse(requestId, true, starredSessions);\n        await withTimeout(eventBus.publish(response.type, response), 3000);\n        console.log('[DB] Starred sessions retrieved', { requestId, count: starredSessions.length });\n    } catch (error) {\n        const appError = error instanceof AppError ? error : new AppError('UNKNOWN', 'Failed to get starred sessions', { originalError: error });\n        response = new DbGetStarredSessionsResponse(requestId, false, null, appError);\n        await withTimeout(eventBus.publish(response.type, response), 3000);\n        console.error('[DB] Get starred sessions failed', { requestId, error: appError });\n    }\n    return response;\n}\n\nasync function handleDbDeleteSessionRequest(event) {\n    const requestId = event?.requestId || crypto.randomUUID();\n    console.log('[DB] Handling delete session', { requestId });\n    let response;\n    try {\n        if (!event?.payload?.sessionId) {\n            throw new AppError('INVALID_INPUT', 'Session ID is required');\n        }\n        const result = await withTimeout(deleteHistoryItemInternal(event.payload.sessionId), 5000);\n        if (!result.success) {\n            throw new AppError('DELETE_SESSION_FAILED', result.error || 'Unknown error');\n        }\n        // Publish a session update notification for delete\n        try {\n            const notification = {\n                type: DbSessionUpdatedNotification.type,\n                payload: {\n                    session: { id: event.payload.sessionId },\n                    updateType: 'delete'\n                }\n            };\n            JSON.stringify(notification); // Ensure serializable\n            await eventBus.publish(notification.type, notification);\n        } catch (e) {\n            console.error('[DB] Failed to publish session delete notification', e);\n        }\n        response = new DbDeleteSessionResponse(requestId, true);\n        await withTimeout(eventBus.publish(response.type, response), 3000);\n        console.log('[DB] Session deleted', { requestId, sessionId: event.payload.sessionId });\n    } catch (error) {\n        const appError = error instanceof AppError ? error : new AppError('UNKNOWN', 'Failed to delete session', { originalError: error });\n        response = new DbDeleteSessionResponse(requestId, false, appError);\n        await withTimeout(eventBus.publish(response.type, response), 3000);\n        console.error('[DB] Delete session failed', { requestId, error: appError });\n    }\n    return response;\n}\n\nasync function handleDbRenameSessionRequest(event) {\n    const requestId = event?.requestId || crypto.randomUUID();\n    console.log('[DB] Handling rename session', { requestId });\n    let response;\n    try {\n        if (!event?.payload?.sessionId || !event?.payload?.newName) {\n            throw new AppError('INVALID_INPUT', 'Session ID and new name are required');\n        }\n        const result = await withTimeout(\n            renameHistoryItemInternal(event.payload.sessionId, event.payload.newName),\n            5000\n        );\n        if (!result.success) {\n            throw new AppError('RENAME_SESSION_FAILED', result.error || 'Unknown error');\n        }\n        response = new DbRenameSessionResponse(requestId, true);\n        await withTimeout(eventBus.publish(response.type, response), 3000);\n        console.log('[DB] Session renamed', { requestId, sessionId: event.payload.sessionId });\n    } catch (error) {\n        const appError = error instanceof AppError ? error : new AppError('UNKNOWN', 'Failed to rename session', { originalError: error });\n        response = new DbRenameSessionResponse(requestId, false, appError);\n        await withTimeout(eventBus.publish(response.type, response), 3000);\n        console.error('[DB] Rename session failed', { requestId, error: appError });\n    }\n    return response;\n}\n\n\nasync function handleDbAddLogRequest(event) {\n    const requestId = event?.requestId || crypto.randomUUID();\n    let response;\n    try {\n        if (!event?.payload?.logEntryData) {\n            throw new AppError('INVALID_INPUT', 'Missing logEntryData in payload');\n        }\n        \n        const collection = await ensureDbReady('log');\n        await withTimeout(collection.insert(event.payload.logEntryData), 3000); \n        console.log('Log entry added successfully', { logId: event.payload.logEntryData.id });\n        response = { success: true };\n    } catch (error) {\n        response = { success: false, error: error.message || String(error) };\n        console.error('Failed to handle add log request', { requestId, error });\n    }\n    return response;\n}\n\nasync function handleDbGetLogsRequest(event) {\n    const requestId = event?.requestId || crypto.randomUUID();\n    let response;\n    try {\n        if (!event?.payload?.filters) {\n            throw new AppError('INVALID_INPUT', 'Missing filters in payload');\n        }\n        const logs = await getLogsInternal(event.payload.filters);\n        response = new DbGetLogsResponse(requestId, true, logs);\n        try {\n            JSON.stringify(response);\n            await eventBus.publish(response.type, response);\n        } catch (e) {\n            console.error('[DB] DbGetLogsResponse is NOT serializable:', e, response);\n        }\n        console.log('Log retrieval successful', { requestId, count: logs.length });\n    } catch (error) {\n        const appError = error instanceof AppError ? error : new AppError('UNKNOWN', 'Failed to get logs', { originalError: error });\n        response = new DbGetLogsResponse(requestId, false, null, appError);\n        try {\n            JSON.stringify(response);\n            await eventBus.publish(response.type, response); // Publish error response\n        } catch (e) {\n            console.error('[DB] DbGetLogsResponse (error) is NOT serializable:', e, response);\n        }\n        console.error('Get logs failed', { requestId, error: appError });\n    }\n    return response;\n}\n\nasync function handleDbGetUniqueLogValuesRequest(event) {\n    const requestId = event?.requestId || crypto.randomUUID();\n    let response;\n    try {\n        if (!event?.payload?.fieldName) {\n            throw new AppError('INVALID_INPUT', 'Missing fieldName in payload');\n        }\n        const values = await getUniqueLogValuesInternal(event.payload.fieldName);\n        response = new DbGetUniqueLogValuesResponse(requestId, true, values);\n        try {\n            JSON.stringify(response);\n            await eventBus.publish(response.type, response);\n        } catch (e) {\n            console.error('[DB] DbGetUniqueLogValuesResponse is NOT serializable:', e, response);\n        }\n        console.log('Unique value retrieval successful', { requestId, field: event.payload.fieldName, count: values.length });\n    } catch (error) {\n        const appError = error instanceof AppError ? error : new AppError('UNKNOWN', 'Failed to get unique log values', { originalError: error });\n        response = new DbGetUniqueLogValuesResponse(requestId, false, null, appError);\n        try {\n            JSON.stringify(response);\n            await eventBus.publish(response.type, response); // Publish error response\n        } catch (e) {\n            console.error('[DB] DbGetUniqueLogValuesResponse (error) is NOT serializable:', e, response);\n        }\n        console.error('Get unique log values failed', { requestId, error: appError });\n    }\n    return response;\n}\n\nasync function handleDbClearLogsRequest(event) {\n    const requestId = event?.requestId || crypto.randomUUID();\n    let response;\n    try {\n        console.log('ClearLogs request received. Performing pruning of non-current/last sessions.');\n        \n        const allLogSessionIds = await getAllUniqueLogSessionIdsInternal();\n        const sessionsToKeep = new Set();\n        if (currentExtensionSessionId) sessionsToKeep.add(currentExtensionSessionId);\n        if (previousExtensionSessionId) sessionsToKeep.add(previousExtensionSessionId);\n        const sessionIdsToDelete = Array.from(allLogSessionIds).filter(id => !sessionsToKeep.has(id));\n\n        if (sessionIdsToDelete.length > 0) {\n            const { deletedCount } = await clearLogsInternal(sessionIdsToDelete);\n            console.log('[DB] ClearLogs request resulted in pruning ' + deletedCount + ' logs from old sessions.');\n        } else {\n             console.log('ClearLogs request found no old sessions to prune.');\n        }\n        \n        response = new DbClearLogsResponse(requestId, true);\n        try {\n            JSON.stringify(response);\n            await eventBus.publish(response.type, response);\n        } catch (e) {\n            console.error('[DB] DbClearLogsResponse is NOT serializable:', e, response);\n        }\n        \n    } catch (error) {\n        const appError = error instanceof AppError ? error : new AppError('UNKNOWN', 'Failed to clear logs', { originalError: error });\n        response = new DbClearLogsResponse(requestId, false, appError);\n        try {\n            JSON.stringify(response);\n            await eventBus.publish(response.type, response); // Publish error response\n        } catch (e) {\n            console.error('[DB] DbClearLogsResponse (error) is NOT serializable:', e, response);\n        }\n        console.error('Clear logs failed', { requestId, error: appError });\n    }\n    return response;\n}\n\nasync function handleDbGetCurrentAndLastLogSessionIdsRequest(event) {\n    const requestId = event?.requestId || crypto.randomUUID();\n    let response;\n    try {\n        const ids = {\n             currentLogSessionId: currentExtensionSessionId,\n             previousLogSessionId: previousExtensionSessionId // This might be null if it's the first run\n        };\n        response = new DbGetCurrentAndLastLogSessionIdsResponse(requestId, true, ids);\n        try {\n            JSON.stringify(response);\n            await eventBus.publish(response.type, response);\n        } catch (e) {\n            console.error('[DB] DbGetCurrentAndLastLogSessionIdsResponse is NOT serializable:', e, response);\n        }\n        console.log('Current/Last session ID retrieval successful', { requestId });\n    } catch (error) { \n        const appError = new AppError('UNKNOWN', 'Failed to get current/last log session IDs', { originalError: error });\n        response = new DbGetCurrentAndLastLogSessionIdsResponse(requestId, false, null, appError);\n        try {\n            JSON.stringify(response);\n            await eventBus.publish(response.type, response);\n        } catch (e) {\n            console.error('[DB] DbGetCurrentAndLastLogSessionIdsResponse (error) is NOT serializable:', e, response);\n        }\n        console.error('Get current/last log session IDs failed', { requestId, error: appError });\n    }\n    return response;\n}\n\n\nasync function getAllUniqueLogSessionIdsInternal() {\n    console.log('Starting retrieval of unique session IDs...');\n    try {\n        const collection = await ensureDbReady('log');\n        console.log('Log collection ensured ready.');\n        const results = await collection.find().exec();\n        console.log('Found ' + results.length + ' log documents.');\n        \n        const uniqueIds = new Set(results.map(doc => doc.get('extensionSessionId')));\n        console.log('Unique session IDs calculated', { count: uniqueIds.size });\n        return { success: true, data: uniqueIds };\n    } catch (error) {\n        console.error('Error during find().select().exec() for unique session IDs', { error });\n        return { success: false, error: error.message || String(error) };\n    }\n}\n\n\nasync function clearLogsInternal(sessionIdsToDelete) {\n    console.log('ClearLogs request received. Performing pruning of non-current/last sessions.');\n    \n    const collection = await ensureDbReady('log');\n    console.log('Log collection ensured ready.');\n\n    const results = await collection.find().exec();\n    console.log('Found ' + results.length + ' log documents.');\n    \n    const filteredResults = results.filter(doc => {\n        const sessionId = doc.get('extensionSessionId');\n        return sessionId && !sessionIdsToDelete.includes(sessionId);\n    });\n\n    console.log('Filtered results count: ' + filteredResults.length);\n    const deletedCount = filteredResults.length;\n    await withTimeout(collection.bulkRemove(filteredResults), 3000);\n    console.log('ClearLogs request resulted in pruning ' + deletedCount + ' logs from old sessions.');\n\n    return { success: true, data: { deletedCount } };\n}\n\n\n\n\n\n\n","// The module cache\nvar __webpack_module_cache__ = {};\n\n// The require function\nfunction __webpack_require__(moduleId) {\n\t// Check if module is in cache\n\tvar cachedModule = __webpack_module_cache__[moduleId];\n\tif (cachedModule !== undefined) {\n\t\treturn cachedModule.exports;\n\t}\n\t// Create a new module (and put it into the cache)\n\tvar module = __webpack_module_cache__[moduleId] = {\n\t\t// no module.id needed\n\t\t// no module.loaded needed\n\t\texports: {}\n\t};\n\n\t// Execute the module function\n\t__webpack_modules__[moduleId].call(module.exports, module, module.exports, __webpack_require__);\n\n\t// Return the exports of the module\n\treturn module.exports;\n}\n\n","// getDefaultExport function for compatibility with non-harmony modules\n__webpack_require__.n = (module) => {\n\tvar getter = module && module.__esModule ?\n\t\t() => (module['default']) :\n\t\t() => (module);\n\t__webpack_require__.d(getter, { a: getter });\n\treturn getter;\n};","// define getter functions for harmony exports\n__webpack_require__.d = (exports, definition) => {\n\tfor(var key in definition) {\n\t\tif(__webpack_require__.o(definition, key) && !__webpack_require__.o(exports, key)) {\n\t\t\tObject.defineProperty(exports, key, { enumerable: true, get: definition[key] });\n\t\t}\n\t}\n};","__webpack_require__.g = (function() {\n\tif (typeof globalThis === 'object') return globalThis;\n\ttry {\n\t\treturn this || new Function('return this')();\n\t} catch (e) {\n\t\tif (typeof window === 'object') return window;\n\t}\n})();","__webpack_require__.o = (obj, prop) => (Object.prototype.hasOwnProperty.call(obj, prop))","// define __esModule on exports\n__webpack_require__.r = (exports) => {\n\tif(typeof Symbol !== 'undefined' && Symbol.toStringTag) {\n\t\tObject.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });\n\t}\n\tObject.defineProperty(exports, '__esModule', { value: true });\n};","import browser from 'webextension-polyfill';\nimport './minimaldb.js'; // Static import for service worker compatibility\nconst MODEL_WORKER_OFFSCREEN_PATH = 'modelLoaderWorkerOffscreen.html';\n\nimport * as logClient from './log-client.js';\nimport { eventBus } from './eventBus.js';\nimport { UIEventNames, WorkerEventNames, ModelWorkerStates, RuntimeMessageTypes, DBEventNames } from './events/eventNames.js';\n\nlogClient.init('Background');\n\n\nlet detachedPopups = {};\nlet popupIdToTabId = {};\n\nconst DNR_RULE_ID_1 = 1;\nconst DNR_RULE_PRIORITY_1 = 1;\n\nlet modelWorkerState = ModelWorkerStates.UNINITIALIZED;\nlet workerScriptReadyPromise = null;\nlet workerScriptReadyResolver = null;\nlet workerScriptReadyRejecter = null;\nlet modelLoadPromise = null;\nlet modelLoadResolver = null;\nlet modelLoadRejecter = null;\n\nlet activeGenerations = {};\n\nlet currentLogSessionId = null;\nlet previousLogSessionId = null;\n\nlet lastLoggedProgress = -10;\n\n\n// Log Session Management\nasync function initializeSessionIds() {\n    let { currentLogSessionId: storedCurrentId, previousLogSessionId: storedPreviousId } = await browser.storage.local.get(['currentLogSessionId', 'previousLogSessionId']);\n    if (storedCurrentId) {\n        // Already initialized for this session\n        currentLogSessionId = storedCurrentId;\n        previousLogSessionId = storedPreviousId || null;\n        logClient.logInfo('Current log session ID (already set):', currentLogSessionId);\n        logClient.logInfo('Previous log session ID (already set):', previousLogSessionId);\n        return;\n    }\n    // Not set yet, so generate new\n    currentLogSessionId = Date.now() + '-' + Math.random().toString(36).substring(2, 9);\n    logClient.logInfo('Current log session ID (new):', currentLogSessionId);\n    await browser.storage.local.set({ currentLogSessionId: currentLogSessionId });\n    previousLogSessionId = storedPreviousId || null;\n    logClient.logInfo('Previous log session ID found in storage:', previousLogSessionId);\n    await browser.storage.local.set({ previousLogSessionId: currentLogSessionId });\n    logClient.logInfo('Stored new previousLogSessionId for next run.');\n}\n\n// Model Worker Offscreen Communication\nasync function hasModelWorkerOffscreenDocument() {\n    const targetUrl = browser.runtime.getURL(MODEL_WORKER_OFFSCREEN_PATH);\n    const existingContexts = await browser.runtime.getContexts({\n        contextTypes: ['OFFSCREEN_DOCUMENT'],\n        documentUrls: [targetUrl]\n    });\n    return existingContexts.length > 0;\n}\n\nasync function setupModelWorkerOffscreenDocument() {\n    if (await hasModelWorkerOffscreenDocument()) {\n        logClient.logInfo(\"Model worker offscreen document already exists.\");\n        return;\n    }\n    logClient.logInfo(\"Creating model worker offscreen document...\");\n    await browser.offscreen.createDocument({\n        url: MODEL_WORKER_OFFSCREEN_PATH,\n        reasons: [browser.offscreen.Reason.WORKERS],\n        justification: 'Run model inference in a separate worker via offscreen document',\n    });\n    logClient.logInfo(\"Model worker offscreen document created.\");\n}\n\nasync function sendToModelWorkerOffscreen(message) {\n    if (message.type !== 'init' && message.type !== 'generate' && message.type !== 'interrupt' && message.type !== 'reset') {\n        if (modelWorkerState === ModelWorkerStates.UNINITIALIZED || !(await hasModelWorkerOffscreenDocument())) {\n            logClient.logInfo(`Background: Ensuring model worker offscreen doc potentially exists before sending ${message?.type}`);\n            await setupModelWorkerOffscreenDocument();\n        }\n    } else {\n        logClient.logDebug(`Background: Ensuring worker script is ready before sending ${message.type}...`);\n        try {\n            await ensureWorkerScriptIsReady();\n            logClient.logDebug(`Background: Worker script confirmed ready. Proceeding to send ${message.type}.`);\n        } catch (error) {\n            logClient.logError(`Background: Worker script failed to become ready. Cannot send ${message.type}. Error:`, error);\n            modelWorkerState = ModelWorkerStates.ERROR;\n            throw new Error(`Worker script failed to initialize, cannot send ${message.type}.`);\n        }\n    }\n\n    logClient.logDebug(`Background: Sending message type '${message?.type}' to model worker offscreen doc`);\n    try {\n        const contexts = await browser.runtime.getContexts({\n            contextTypes: ['OFFSCREEN_DOCUMENT'],\n            documentUrls: [browser.runtime.getURL(MODEL_WORKER_OFFSCREEN_PATH)]\n        });\n        if (contexts.length > 0) {\n            browser.runtime.sendMessage(message);\n            logClient.logDebug(`Background: Message type '${message?.type}' sent to offscreen.`);\n            return { success: true };\n        } else {\n            logClient.logError(`Background: Could not find target offscreen document context to send ${message?.type}.`);\n            throw new Error(`Target offscreen document not found.`);\n        }\n    } catch (error) {\n        logClient.logError(`Background: Error sending message type '${message?.type}' to offscreen:`, error);\n        modelWorkerState = ModelWorkerStates.ERROR;\n        if (message.type === 'init') {\n            if (modelLoadRejecter) modelLoadRejecter(new Error(`Failed to send init message: ${error.message}`));\n            modelLoadPromise = null;\n        } else if (workerScriptReadyRejecter && (modelWorkerState === ModelWorkerStates.UNINITIALIZED || modelWorkerState === ModelWorkerStates.CREATING_WORKER)) {\n            workerScriptReadyRejecter(new Error(`Failed to send message early: ${error.message}`));\n            workerScriptReadyPromise = null;\n        }\n        throw new Error(`Failed to send message to model worker offscreen: ${error.message}`);\n    }\n}\n\nfunction ensureWorkerScriptIsReady() {\n    logClient.logDebug(`[ensureWorkerScriptIsReady] Current state: ${modelWorkerState}`);\n    if (modelWorkerState !== ModelWorkerStates.UNINITIALIZED && modelWorkerState !== ModelWorkerStates.CREATING_WORKER) {\n        if (modelWorkerState === ModelWorkerStates.ERROR && !workerScriptReadyPromise) {\n            return Promise.reject(new Error(\"Worker script initialization previously failed.\"));\n        }\n        return Promise.resolve();\n    }\n    if (workerScriptReadyPromise) {\n        return workerScriptReadyPromise;\n    }\n\n    logClient.logDebug(\"[ensureWorkerScriptIsReady] Worker script not ready. Initializing and creating promise.\");\n    modelWorkerState = ModelWorkerStates.CREATING_WORKER;\n    workerScriptReadyPromise = new Promise((resolve, reject) => {\n        workerScriptReadyResolver = resolve;\n        workerScriptReadyRejecter = reject;\n\n        setupModelWorkerOffscreenDocument().catch(err => {\n            logClient.logError(\"[ensureWorkerScriptIsReady] Error setting up offscreen doc:\", err);\n            modelWorkerState = ModelWorkerStates.ERROR;\n            if (workerScriptReadyRejecter) workerScriptReadyRejecter(err);\n            workerScriptReadyPromise = null;\n        });\n    });\n\n    const scriptLoadTimeout = 30000;\n    setTimeout(() => {\n        if (modelWorkerState === ModelWorkerStates.CREATING_WORKER && workerScriptReadyRejecter) {\n            logClient.logError(`[ensureWorkerScriptIsReady] Timeout (${scriptLoadTimeout}ms) waiting for workerScriptReady.`);\n            workerScriptReadyRejecter(new Error('Timeout waiting for model worker script to load.'));\n            modelWorkerState = ModelWorkerStates.ERROR;\n            workerScriptReadyPromise = null;\n        }\n    }, scriptLoadTimeout);\n\n    return workerScriptReadyPromise;\n}\n\nasync function loadModel(modelId) {\n    logClient.logInfo(`Request to load model: ${modelId}. Current state: ${modelWorkerState}`);\n    try {\n        await ensureWorkerScriptIsReady();\n        logClient.logDebug(`Worker script confirmed ready (state: ${modelWorkerState}). Proceeding with model load.`);\n    } catch (err) {\n        logClient.logError(\"Failed to ensure worker script readiness:\", err);\n        throw new Error(`Failed to ensure worker script readiness: ${err.message}`);\n    }\n\n    if (modelWorkerState !== ModelWorkerStates.WORKER_SCRIPT_READY && modelWorkerState !== ModelWorkerStates.IDLE && modelWorkerState !== ModelWorkerStates.ERROR) {\n        const errorMsg = `Cannot load model '${modelId}'. Worker state is '${modelWorkerState}', expected 'worker_script_ready', 'idle', or 'error'.`;\n        logClient.logError(\"State check failed loading model:\", errorMsg);\n        throw new Error(errorMsg);\n    }\n\n    if (!modelId) {\n        return Promise.reject(new Error(\"Cannot load model: Model ID not provided.\"));\n    }\n\n    if (modelWorkerState === ModelWorkerStates.MODEL_READY) {\n        logClient.logInfo(`Model appears ready. Assuming it's ${modelId}.`);\n        return Promise.resolve();\n    }\n    if (modelWorkerState === ModelWorkerStates.LOADING_MODEL && modelLoadPromise) {\n        logClient.logInfo(`Model is already loading. Assuming it's ${modelId}.`);\n        return modelLoadPromise;\n    }\n    if (modelWorkerState !== ModelWorkerStates.WORKER_SCRIPT_READY) {\n        logClient.logError(\"Cannot load model. Worker script is not ready. State:\", modelWorkerState);\n        return Promise.reject(new Error(`Cannot load model, worker script not ready (state: ${modelWorkerState})`));\n    }\n\n    logClient.logInfo(`Worker script ready. Initiating load for model: ${modelId}.`);\n    modelWorkerState = ModelWorkerStates.LOADING_MODEL;\n    // TODO: Store the modelId being loaded\n    modelLoadPromise = new Promise((resolve, reject) => {\n        modelLoadResolver = resolve;\n        modelLoadRejecter = reject;\n\n        logClient.logDebug(`Attempting to send 'init' message for model: ${modelId}`);\n        sendToModelWorkerOffscreen({ type: 'init', payload: { modelId: modelId } })\n            .catch(err => {\n                logClient.logError(`Failed to send 'init' message for ${modelId}:`, err);\n                modelWorkerState = ModelWorkerStates.ERROR;\n                if (modelLoadRejecter) modelLoadRejecter(err);\n                modelLoadPromise = null;\n            });\n    });\n\n    const modelLoadTimeout = 300000;\n    setTimeout(() => {\n        if (modelWorkerState === ModelWorkerStates.LOADING_MODEL && modelLoadRejecter) {\n            logClient.logError(`Timeout (${modelLoadTimeout}ms) waiting for model ${modelId} load completion.`);\n            modelLoadRejecter(new Error(`Timeout waiting for model ${modelId} to load.`));\n            modelWorkerState = ModelWorkerStates.ERROR;\n            modelLoadPromise = null;\n        }\n    }, modelLoadTimeout);\n\n    return modelLoadPromise;\n}\n\n// Declarative Net Request Management\nasync function updateDeclarativeNetRequestRules() {\n    const currentRules = await browser.declarativeNetRequest.getDynamicRules();\n    const currentRuleIds = currentRules.map(rule => rule.id);\n\n    const rulesToAdd = [\n        {\n            id: DNR_RULE_ID_1,\n            priority: DNR_RULE_PRIORITY_1,\n            action: {\n                type: 'modifyHeaders',\n                responseHeaders: [\n                    { header: 'x-frame-options', operation: 'remove' },\n                    { header: 'X-Frame-Options', operation: 'remove' },\n                    { header: 'content-security-policy', operation: 'remove' },\n                    { header: 'Content-Security-Policy', operation: 'remove' }\n                ]\n            },\n            condition: {\n                resourceTypes: ['main_frame'],\n                urlFilter: '|http*://*/*|'\n            }\n        }\n    ];\n\n    const rulesToRemove = currentRuleIds.filter(id => id === DNR_RULE_ID_1);\n\n    try {\n        await browser.declarativeNetRequest.updateDynamicRules({\n            removeRuleIds: rulesToRemove,\n            addRules: rulesToAdd\n        });\n        logClient.logInfo(\"Declarative Net Request rules updated successfully.\");\n    } catch (error) {\n        logClient.logError(\"Error updating Declarative Net Request rules:\", error);\n    }\n}\nupdateDeclarativeNetRequestRules();\n\n// Offscreen Document Management\nasync function hasOffscreenDocument(path) {\n    if (browser.runtime.getContexts) {\n        const contexts = await browser.runtime.getContexts({\n            contextTypes: ['OFFSCREEN_DOCUMENT'],\n            documentUrls: [browser.runtime.getURL(path)] \n        });\n        return contexts.length > 0;\n    }\n    return false;\n}\n\nasync function setupOffscreenDocument(path, reasons, justification) {\n    if (await hasOffscreenDocument(path)) {\n        logClient.logInfo(`Background: Offscreen document at ${path} already exists.`);\n        return;\n    }\n    const filename = path.split('/').pop();\n    logClient.logInfo(`Background: Creating offscreen document using filename: ${filename}...`);\n    await browser.offscreen.createDocument({\n        url: filename,\n        reasons: reasons,\n        justification: justification,\n    });\n    logClient.logInfo(`Background: <<< Offscreen document ${path} CREATED successfully. Script should now load. >>>`);\n    logClient.logInfo(`Background: Offscreen document created successfully using ${filename}.`);\n}\n\n// Scraping Logic\n\n\nasync function scrapeUrlWithTempTabExecuteScript(url) {\n    logClient.logInfo(`[Stage 1 (ExecuteScript)] Attempting Temp Tab + executeScript: ${url}`);\n    let tempTabId = null;\n    const TEMP_TAB_LOAD_TIMEOUT = 30000;\n\n    return new Promise(async (resolve, reject) => {\n        const cleanupAndReject = (errorMsg, errorObj = null) => {\n            const finalError = errorObj ? errorObj : new Error(errorMsg);\n            logClient.logWarn(`[Stage 1 (ExecuteScript)] Cleanup & Reject: ${errorMsg}`, errorObj);\n            if (tempTabId) {\n                browser.tabs.remove(tempTabId).catch(err => logClient.logWarn(`[Stage 1 (ExecuteScript)] Error removing tab ${tempTabId}: ${err.message}`));\n                tempTabId = null;\n            }\n            reject(finalError);\n        };\n\n        try {\n            const tab = await browser.tabs.create({ url: url, active: false });\n            tempTabId = tab.id;\n            if (!tempTabId) {\n                cleanupAndReject('[Stage 1 (ExecuteScript)] Failed to get temporary tab ID.');\n                return;\n            }\n            logClient.logInfo(`[Stage 1 (ExecuteScript)] Created temp tab ${tempTabId}.`);\n\n            // Wait for the tab to load\n            let loadTimeoutId = null;\n            const loadPromise = new Promise((resolveLoad, rejectLoad) => {\n                const listener = (tabIdUpdated, changeInfo, updatedTab) => {\n                    if (tabIdUpdated === tempTabId && changeInfo.status === 'complete') {\n                        logClient.logInfo(`[Stage 1 (ExecuteScript)] Tab ${tempTabId} loaded.`);\n                        if (loadTimeoutId) clearTimeout(loadTimeoutId);\n                        browser.tabs.onUpdated.removeListener(listener);\n                        resolveLoad();\n                    }\n                };\n                browser.tabs.onUpdated.addListener(listener);\n                loadTimeoutId = setTimeout(() => {\n                    browser.tabs.onUpdated.removeListener(listener);\n                    rejectLoad(new Error(`Timeout (${TEMP_TAB_LOAD_TIMEOUT / 1000}s) waiting for page load in tab ${tempTabId}.`));\n                }, TEMP_TAB_LOAD_TIMEOUT);\n            });\n\n            await loadPromise;\n            logClient.logInfo(`[Stage 1 (ExecuteScript)] Page loaded. Injecting pageExtractor.js module into tab ${tempTabId}...`);\n\n            // 1. Inject the PageExtractor.js script\n            await browser.scripting.executeScript({\n                target: { tabId: tempTabId },\n                files: ['pageExtractor.js'] \n            });\n            logClient.logInfo(`[Stage 1 (ExecuteScript)] pageExtractor.js module INJECTED successfully into tab ${tempTabId}.`);\n\n            // 2. Execute a function that calls the globally exposed extract method\n            logClient.logInfo(`[Stage 1 (ExecuteScript)] Executing function to call window.TabAgentPageExtractor.extract in tab ${tempTabId}...`);\n            const injectionResults = await browser.scripting.executeScript({\n                target: { tabId: tempTabId },\n                func: () => { // Arrow function for lexical this, though not strictly needed here\n                    if (window.TabAgentPageExtractor && typeof window.TabAgentPageExtractor.extract === 'function') {\n                        try {\n                            return window.TabAgentPageExtractor.extract(document);\n                        } catch (e) {\n                            console.error('[In-Tab] Error during execution of PageExtractor.extract:', e);\n                            return { error: `Error in PageExtractor.extract: ${e.message} (Stack: ${e.stack})` };\n                        }\n                    } else {\n                        console.error('[In-Tab] TabAgentPageExtractor or its extract function not found on window.');\n                        return { error: 'TabAgentPageExtractor.extract function not found on window.' };\n                    }\n                }\n            });\n\n            logClient.logInfo('[Stage 1 (ExecuteScript)] Raw results from executeScript func:', injectionResults);\n\n            if (!injectionResults || injectionResults.length === 0 || !injectionResults[0].result) {\n                cleanupAndReject('[Stage 1 (ExecuteScript)] No result returned from executeScript func.', injectionResults && injectionResults[0] ? injectionResults[0].error : null);\n                return;\n            }\n\n            const scriptResult = injectionResults[0].result;\n\n            if (scriptResult && scriptResult.error) {\n                cleanupAndReject(`[Stage 1 (ExecuteScript)] Script execution reported an error: ${scriptResult.error}`, scriptResult);\n                return;\n            }\n            \n            if (scriptResult && typeof scriptResult === 'object') {\n                logClient.logInfo('[Stage 1 (ExecuteScript)] pageExtractor.js module execution succeeded (returned object).');\n                resolve(scriptResult);\n            } else {\n                cleanupAndReject('[Stage 1 (ExecuteScript)] pageExtractor.js module returned unexpected non-object/error type.', scriptResult);\n            }\n\n        } catch (error) {\n            cleanupAndReject(`[Stage 1 (ExecuteScript)] Error: ${error.message}`, error);\n        } finally {\n            if (tempTabId) { // Ensure tab is closed if something went wrong before explicit resolve/reject\n                browser.tabs.remove(tempTabId).catch(err => logClient.logWarn(`[Stage 1 (ExecuteScript)] Error removing tab ${tempTabId} in final catch: ${err.message}`));\n            }\n        }\n    });\n}\n\n\nasync function scrapeUrlMultiStage(url, chatId, messageId) {\n    logClient.logInfo(`Scraping Orchestrator: Starting for ${url}. ChatID: ${chatId}, MessageID: ${messageId}`);\n    const sendStageResult = (stageResult) => {\n        logClient.logInfo(`[Orchestrator] Sending STAGE_SCRAPE_RESULT for Stage ${stageResult.stage}, ChatID: ${chatId}, Success: ${stageResult.success}`);\n        browser.runtime.sendMessage({\n            type: 'STAGE_SCRAPE_RESULT',\n            payload: stageResult\n        }).catch(e => logClient.logWarn(`[Orchestrator] Failed to send result for Stage ${stageResult.stage}:`, e));\n    };\n\n\n    try {\n        try {\n            const executeScriptResult = await scrapeUrlWithTempTabExecuteScript(url);\n            logClient.logInfo(`[Orchestrator Log] Stage 1 (Temp Tab + executeScript) Succeeded for ${url}.`);\n            const stage1SuccessPayload = {\n                stage: 1, success: true, chatId: chatId, messageId: messageId,\n                method: 'tempTabExecuteScript', url: url,\n                length: executeScriptResult?.text?.length || 0,\n                ...executeScriptResult\n            };\n            sendStageResult(stage1SuccessPayload);\n            return; \n        } catch (stage1Error) {\n            logClient.logWarn(`[Orchestrator Log] Stage 1 (Temp Tab + executeScript) Failed for ${url}: ${stage1Error.message}`);\n            sendStageResult({ stage: 1, success: false, chatId: chatId, messageId: messageId, method: 'tempTabExecuteScript', error: stage1Error.message });\n            return; \n        }\n\n\n    } finally {\n        logClient.logInfo(`[Scraping Orchestrator] Finished processing for ${url}.`);\n    }\n}\n\n// Google Drive Integration\nasync function getDriveToken() {\n    return new Promise((resolve, reject) => {\n        browser.identity.getAuthToken({ interactive: true }, (token) => {\n            if (browser.runtime.lastError) {\n                reject(new Error(browser.runtime.lastError.message));\n            } else {\n                resolve(token);\n            }\n        });\n    });\n}\n\nasync function fetchDriveFileList(token, folderId = 'root') {\n    const fields = \"files(id, name, mimeType, iconLink, webViewLink, size, createdTime, modifiedTime)\";\n    const query = `'${folderId}' in parents and trashed=false`;\n    const pageSize = 100;\n    const orderBy = 'folder,modifiedTime desc';\n    const url = `https://www.googleapis.com/drive/v3/files?${new URLSearchParams({\n        pageSize: pageSize.toString(),\n        q: query,\n        fields: fields,\n        orderBy: orderBy\n    })}`;\n    logClient.logInfo(`Background: Fetching Drive list for folder '${folderId}': ${url}`);\n    const response = await fetch(url, {\n        headers: {\n            'Authorization': `Bearer ${token}`,\n            'Accept': 'application/json'\n        }\n    });\n    if (!response.ok) {\n        const errorData = await response.text();\n        logClient.logError(`Background: Drive API files.list error (Folder: ${folderId}):`, response.status, errorData);\n        if (response.status === 404) {\n            throw new Error(`Folder with ID '${folderId}' not found or access denied.`);\n        }\n        throw new Error(`Drive API Error ${response.status} (Folder: ${folderId}): ${errorData || response.statusText}`);\n    }\n    const data = await response.json();\n    logClient.logInfo(`Background: Drive API files.list success (Folder: ${folderId}). Found ${data.files?.length || 0} items.`);\n    return data.files || [];\n}\n\n\n\nasync function forwardMessageToSidePanelOrPopup(message, originalSender) {\n    logClient.logInfo(`Attempting to forward message type '${message?.type}' from worker.`);\n    for (const tabId in detachedPopups) {\n        const popupId = detachedPopups[tabId];\n        logClient.logInfo(`Forwarding message to detached popup ID: ${popupId} (original tab: ${tabId})`);\n        try {\n            await browser.windows.get(popupId);\n            browser.runtime.sendMessage(message);\n        } catch (error) {\n            logClient.logWarn(`Error sending to detached popup ID ${popupId}:`, error.message);\n            if (error.message.includes(\"No window with id\")) {\n                delete detachedPopups[tabId];\n                delete popupIdToTabId[popupId];\n            }\n        }\n    }\n\n    const tabs = await browser.tabs.query({ status: 'complete' });\n    for (const tab of tabs) {\n        if (detachedPopups[tab.id]) continue;\n        try {\n            await browser.tabs.sendMessage(tab.id, message);\n        } catch (error) {\n            if (!error.message.includes('Could not establish connection') && !error.message.includes('Receiving end does not exist')) {\n                logClient.logWarn(`Error forwarding message to tab ${tab.id}:`, error.message);\n            }\n        }\n    }\n}\n\nbrowser.runtime.onInstalled.addListener(async (details) => {\n    logClient.logInfo('onInstalled event fired. Reason:', details.reason);\n    await initializeSessionIds();\n    await eventBus.autoEnsureDbInitialized();\n    browser.sidePanel\n        .setPanelBehavior({ openPanelOnActionClick: true })\n        .catch((error) => logClient.logError('Error setting side panel behavior:', error));\n    logClient.logInfo('Side panel behavior set.');\n    browser.storage.local.get().then((items) => {\n        const keysToRemove = Object.keys(items).filter(key => key.startsWith('detachedState_'));\n        if (keysToRemove.length > 0) {\n            browser.storage.local.remove(keysToRemove).then(() => {\n                logClient.logInfo('Cleaned up old storage keys on install/update.');\n            }).catch(err => {\n                logClient.logError('Error removing old storage keys:', err);\n            });\n        }\n    }).catch(err => {\n         logClient.logError('Error getting storage items for cleanup:', err);\n    });\n    ensureWorkerScriptIsReady().catch(err => {\n        logClient.logError(\"Initial worker script readiness check failed after install:\", err);\n    });\n});\n\nbrowser.runtime.onStartup.addListener(async () => {\n    logClient.logInfo('onStartup event fired.');\n    await initializeSessionIds();\n    await eventBus.autoEnsureDbInitialized();\n    if (modelWorkerState === ModelWorkerStates.UNINITIALIZED) {\n        ensureWorkerScriptIsReady().catch(err => {\n            logClient.logError(\"Worker script readiness check failed on startup:\", err);\n        });\n    }\n});\n\nbrowser.action.onClicked.addListener(async (tab) => {\n    if (!tab.id) {\n        logClient.logError(\"Action Clicked: Missing tab ID.\");\n        return;\n    }\n    const tabId = tab.id;\n    logClient.logInfo(`Action clicked for tab ${tabId}`);\n    const existingPopupId = detachedPopups[tabId];\n    if (existingPopupId) {\n        logClient.logInfo(`Popup ${existingPopupId} exists for tab ${tabId}. Attempting to close popup.`);\n        try {\n            await browser.windows.remove(existingPopupId);\n            logClient.logInfo(`Closed popup window ${existingPopupId} via action click.`);\n        } catch (error) {\n            logClient.logWarn(`Failed to close popup ${existingPopupId} via action click, maybe already closed?`, error);\n            if (popupIdToTabId[existingPopupId]) {\n                logClient.logInfo(`Force cleaning maps and storage for tab ${tabId} after failed close.`);\n                delete detachedPopups[tabId];\n                delete popupIdToTabId[existingPopupId];\n                try {\n                    await browser.storage.local.remove(`detachedState_${tabId}`);\n                    await browser.sidePanel.setOptions({ tabId: tabId, enabled: true });\n                } catch (cleanupError) {\n                    logClient.logError(\"Error during defensive cleanup:\", cleanupError);\n                }\n            }\n        }\n    } else {\n        logClient.logInfo(`No popup exists for tab ${tabId}. Default side panel opening behavior should trigger.`);\n    }\n});\n\nbrowser.windows.onRemoved.addListener(async (windowId) => {\n    logClient.logInfo(`Window removed: ${windowId}`);\n    const tabId = popupIdToTabId[windowId];\n    if (tabId) {\n        logClient.logInfo(`Popup window ${windowId} for tab ${tabId} was closed.`);\n        delete detachedPopups[tabId];\n        delete popupIdToTabId[windowId];\n        try {\n            await browser.storage.local.remove(`detachedState_${tabId}`);\n            logClient.logInfo(`Removed detached state from storage for tab ${tabId}`);\n            await browser.sidePanel.setOptions({ tabId: tabId, enabled: true });\n            logClient.logInfo(`Re-enabled side panel for tab ${tabId} after popup closed.`);\n        } catch (error) {\n            logClient.logError(`Error cleaning up storage or re-enabling side panel for tab ${tabId} on popup close:`, error);\n        }\n    } else {\n        logClient.logInfo(`Window ${windowId} closed, but it wasn't a tracked popup.`);\n    }\n});\n\n// Message Handling\nbrowser.runtime.onMessage.addListener((message, sender, sendResponse) => {\n    console.log('[Background] Received message:', message, 'type:', message?.type);\n    const { type, payload } = message;\n    let isResponseAsync = false;\n\n    logClient.logInfo(`Received message type '${type}' from`, sender.tab ? `tab ${sender.tab.id}` : sender.url || sender.id);\n\n    if (Object.values(WorkerEventNames).includes(type)) {\n        logClient.logInfo(`Handling message from worker: ${type}`);\n        let uiUpdatePayload = null;\n        switch (type) {\n            case WorkerEventNames.WORKER_SCRIPT_READY:\n                logClient.logInfo(\"[Background] Worker SCRIPT is ready!\");\n                modelWorkerState = ModelWorkerStates.WORKER_SCRIPT_READY;\n                if (workerScriptReadyResolver) {\n                    workerScriptReadyResolver();\n                    workerScriptReadyPromise = null;\n                }\n                uiUpdatePayload = { modelStatus: 'script_ready' };\n                break;\n            case WorkerEventNames.WORKER_READY:\n                logClient.logInfo(\"[Background] Worker MODEL is ready! Model:\", payload?.model);\n                modelWorkerState = ModelWorkerStates.MODEL_READY;\n                if (modelLoadResolver) {\n                    modelLoadResolver();\n                    modelLoadPromise = null;\n                }\n                uiUpdatePayload = { modelStatus: 'model_ready', model: payload?.model };\n                if (workerScriptReadyResolver) {\n                    workerScriptReadyResolver();\n                    workerScriptReadyPromise = null;\n                }\n                break;\n            case WorkerEventNames.LOADING_STATUS:\n                if (payload?.status === 'progress' && payload?.progress) {\n                    const currentProgress = Math.floor(payload.progress);\n                    if (currentProgress >= lastLoggedProgress + 10) {\n                        logClient.logInfo(\"[Background] Worker loading status (progress):\", payload);\n                        lastLoggedProgress = currentProgress;\n                    }\n                } else {\n                    logClient.logInfo(\"[Background] Worker loading status (other):\", payload);\n                    lastLoggedProgress = -10;\n                }\n                if (modelWorkerState !== ModelWorkerStates.LOADING_MODEL) {\n                    logClient.logWarn(`[Background] Received loadingStatus in unexpected state: ${modelWorkerState}`);\n                    modelWorkerState = ModelWorkerStates.LOADING_MODEL;\n                }\n                browser.runtime.sendMessage({ type: UIEventNames.BACKGROUND_LOADING_STATUS_UPDATE, payload: payload }).catch(err => {\n                    if (err.message !== \"Could not establish connection. Receiving end does not exist.\") {\n                        logClient.logWarn(\"[Background] Error sending loading status to UI:\", err.message);\n                    }\n                });\n                break;\n            case WorkerEventNames.GENERATION_STATUS:\n                logClient.logInfo(`[Background] Generation status: ${payload?.status}`);\n                if (payload?.status === 'generating') modelWorkerState = ModelWorkerStates.GENERATING;\n                else if (payload?.status === 'interrupted') modelWorkerState = ModelWorkerStates.MODEL_READY;\n                break;\n            case WorkerEventNames.GENERATION_UPDATE:\n                if (modelWorkerState !== ModelWorkerStates.GENERATING) {\n                    logClient.logWarn(`[Background] Received generationUpdate in unexpected state: ${modelWorkerState}`);\n                }\n                modelWorkerState = ModelWorkerStates.GENERATING;\n                break;\n            case WorkerEventNames.GENERATION_COMPLETE:\n                logClient.logInfo(\"[Background] Generation complete.\");\n                modelWorkerState = ModelWorkerStates.MODEL_READY;\n                break;\n            case WorkerEventNames.GENERATION_ERROR:\n                logClient.logError(\"[Background] Generation error from worker:\", payload);\n                modelWorkerState = ModelWorkerStates.ERROR;\n                break;\n            case WorkerEventNames.RESET_COMPLETE:\n                logClient.logInfo(\"[Background] Worker reset complete.\");\n                modelWorkerState = ModelWorkerStates.MODEL_READY;\n                break;\n            case WorkerEventNames.ERROR:\n                logClient.logError(\"[Background] Received generic error from worker/offscreen:\", payload);\n                const previousState = modelWorkerState;\n                modelWorkerState = ModelWorkerStates.ERROR;\n                if (previousState === ModelWorkerStates.CREATING_WORKER && workerScriptReadyRejecter) {\n                    workerScriptReadyRejecter(new Error(payload || 'Generic error during script init'));\n                    workerScriptReadyPromise = null;\n                } else if (previousState === ModelWorkerStates.LOADING_MODEL && modelLoadRejecter) {\n                    modelLoadRejecter(new Error(payload || 'Generic error during model load'));\n                    modelLoadPromise = null;\n                }\n                uiUpdatePayload = { modelStatus: 'error', error: payload };\n                break;\n        }\n        \n        if (uiUpdatePayload) {\n            logClient.logInfo(`[Background] Sending uiUpdate to tabs:`, uiUpdatePayload);\n            browser.tabs.query({}).then(tabs => {\n                tabs.forEach(tab => {\n                    if (tab.id) {\n                        browser.tabs.sendMessage(tab.id, { type: UIEventNames.BACKGROUND_RESPONSE_RECEIVED, payload: uiUpdatePayload })\n                            .catch(err => { \n                                if (!err.message.includes('Could not establish connection') && !err.message.includes('Receiving end does not exist')) {\n                                     logClient.logWarn(`[Background] Error sending uiUpdate to tab ${tab.id}:`, err.message);\n                                }\n                            });\n                    }\n                });\n            }).catch(err => {\n                logClient.logError('[Background] Error querying tabs to send uiUpdate:', err);\n            });\n        }\n        \n        forwardMessageToSidePanelOrPopup(message, sender);\n        return false;\n    }\n\n    if (type === RuntimeMessageTypes.LOAD_MODEL) {\n        logClient.logInfo(`Received 'loadModel' request from sender:`, sender);\n        const modelId = payload?.modelId;\n        logClient.logInfo(`Received 'loadModel' request from UI for model: ${modelId}.`);\n        if (!modelId) {\n            logClient.logError(\"[Background] 'loadModel' request missing modelId.\");\n            sendResponse({ success: false, error: \"Model ID not provided in request.\" });\n            return false;\n        }\n\n        isResponseAsync = true;\n        loadModel(modelId)\n            .then(() => {\n                logClient.logInfo(`loadModel(${modelId}) promise resolved successfully.`);\n                sendResponse({ success: true, message: `Model loading initiated or already complete for ${modelId}.` });\n            })\n            .catch(error => {\n                logClient.logError(`loadModel(${modelId}) failed:`, error);\n                sendResponse({ success: false, error: error.message });\n            });\n        return isResponseAsync;\n    }\n\n    if (type === RuntimeMessageTypes.SEND_CHAT_MESSAGE) {\n        isResponseAsync = true;\n        const { chatId, messages, options, messageId } = payload;\n        const correlationId = messageId || chatId;\n\n        if (modelWorkerState !== ModelWorkerStates.MODEL_READY) {\n            logClient.logError(`Cannot send chat message. Model state is ${modelWorkerState}, not 'model_ready'.`);\n            sendResponse({ success: false, error: `Model not ready (state: ${modelWorkerState}). Please load a model first.` });\n            return false;\n        }\n\n        logClient.logInfo(`Model ready, sending generate request for ${correlationId}`);\n        sendToModelWorkerOffscreen({\n            type: 'generate',\n            payload: {\n                messages: messages,\n                max_new_tokens: options?.max_new_tokens,\n                temperature: options?.temperature,\n                top_k: options?.top_k,\n                correlationId: correlationId\n            }\n        })\n        .then(sendResult => {\n            if (!sendResult.success) throw new Error(\"Failed to send generate message initially.\");\n            logClient.logInfo(`Generate request sent for ${correlationId}. Waiting for worker responses.`);\n            sendResponse({ success: true, message: \"Generation request forwarded to worker.\"});\n        })\n        .catch(error => {\n            logClient.logError(`Error processing sendChatMessage for ${correlationId}:`, error);\n            if (modelWorkerState === ModelWorkerStates.GENERATING) modelWorkerState = ModelWorkerStates.MODEL_READY;\n            sendResponse({ success: false, error: error.message });\n        });\n\n        return isResponseAsync;\n    }\n\n    if (type === RuntimeMessageTypes.INTERRUPT_GENERATION) {\n        logClient.logInfo(\"[Background] Received interrupt request from UI.\");\n        ensureWorkerScriptIsReady()\n            .then(() => sendToModelWorkerOffscreen({ type: 'interrupt' }))\n            .then(() => sendResponse({ success: true }))\n            .catch(err => sendResponse({ success: false, error: err.message }));\n        isResponseAsync = true;\n        return isResponseAsync;\n    }\n\n    if (type === RuntimeMessageTypes.RESET_WORKER) {\n        logClient.logInfo(\"[Background] Received reset request from UI.\");\n        ensureWorkerScriptIsReady()\n            .then(() => sendToModelWorkerOffscreen({ type: 'reset' }))\n            .then(() => sendResponse({ success: true }))\n            .catch(err => sendResponse({ success: false, error: err.message }));\n        isResponseAsync = true;\n        return isResponseAsync;\n    }\n\n    if (type === RuntimeMessageTypes.GET_MODEL_WORKER_STATE) {\n        logClient.logInfo(`Handling 'getModelWorkerState' request. Current state: ${modelWorkerState}`);\n        sendResponse({ success: true, state: modelWorkerState });\n        return false;\n    }\n\n    if (type === RuntimeMessageTypes.SCRAPE_REQUEST) {\n        logClient.logInfo(`Handling 'scrapeRequest' request. Scraping URL: ${payload?.url}`);\n        isResponseAsync = true;\n        scrapeUrlMultiStage(payload?.url, payload?.chatId, payload?.messageId)\n            .then(() => {\n                logClient.logInfo(`scrapeRequest(${payload?.url}) promise resolved successfully.`);\n                sendResponse({ success: true, message: `Scraping orchestrator started for ${payload?.url}.` });\n            })\n            .catch(error => {\n                logClient.logError(`scrapeRequest(${payload?.url}) failed:`, error);\n                sendResponse({ success: false, error: error.message });\n            });\n        return isResponseAsync;\n    }\n\n    if (type === RuntimeMessageTypes.GET_DRIVE_FILE_LIST) {\n        const receivedFolderId = message.folderId;\n        logClient.logInfo(`Handling 'getDriveFileList' for folder: ${receivedFolderId}`);\n        isResponseAsync = true;\n        (async () => {\n            try {\n                const token = await getDriveToken();\n                const files = await fetchDriveFileList(token, receivedFolderId);\n                logClient.logInfo(`Successfully fetched ${files?.length || 0} files/folders.`);\n                sendResponse({\n                    success: true,\n                    files: files,\n                    folderId: receivedFolderId\n                });\n            } catch (error) {\n                logClient.logError(\"Error handling getDriveFileList:\", error);\n                sendResponse({\n                    success: false,\n                    error: error.message,\n                    folderId: receivedFolderId\n                });\n            }\n        })();\n        return isResponseAsync;\n    }\n\n    if (type === RuntimeMessageTypes.GET_LOG_SESSIONS) {\n        isResponseAsync = true;\n        (async () => {\n            try {\n                const { logSessions: sessions } = await browser.storage.local.get('logSessions');\n                sendResponse({ success: true, sessions: sessions || [] });\n            } catch (err) {\n                logClient.logError(\"Error fetching log sessions:\", err);\n                sendResponse({ success: false, error: err.message });\n            }\n        })();\n        return isResponseAsync;\n    }\n\n    if (type === RuntimeMessageTypes.GET_LOG_ENTRIES) {\n        isResponseAsync = true;\n        (async () => {\n            const sessionId = payload?.sessionId;\n            if (!sessionId) {\n                sendResponse({ success: false, error: 'Session ID required' });\n                return true;\n            }\n            try {\n                const key = `logs_${sessionId}`;\n                const result = await browser.storage.local.get(key);\n                sendResponse({ success: true, entries: result[key] || [] });\n            } catch (err) {\n                logClient.logError(`Error fetching log entries for ${sessionId}:`, err);\n                sendResponse({ success: false, error: err.message });\n            }\n        })();\n        return isResponseAsync;\n    }\n\n    if (type === RuntimeMessageTypes.DETACH_SIDE_PANEL) {\n        isResponseAsync = true;\n        handleDetach(sender.tab?.id).then(result => {\n            sendResponse(result);\n        }).catch(error => {\n            sendResponse({ success: false, error: error.message });\n        });\n        return isResponseAsync;\n    }\n\n    if (type === RuntimeMessageTypes.GET_DETACHED_STATE) {\n        isResponseAsync = true;\n        (async () => {\n            try {\n                const { [`detachedState_${sender.tab?.id}`]: state } = await browser.storage.local.get(`detachedState_${sender.tab?.id}`);\n                sendResponse({ success: true, state: state });\n            } catch (error) {\n                sendResponse({ success: false, error: error.message });\n            }\n        })();\n        return isResponseAsync;\n    }\n\n    if (type === RuntimeMessageTypes.GET_DB_READY_STATE) {\n        sendResponse({ ready: isDbReady() });\n        return false;\n    }\n\n    if (Object.values(DBEventNames).includes(type)) {\n       \n        return false;\n    }\n\n    logClient.logWarn(`Unhandled message type: ${type}`);\n    return false;\n});\n\nlogClient.logInfo(\"[Background-Simple] Script loaded and listening.\");"],"names":[],"sourceRoot":""}